{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CAVASOL/aiffel_quest/blob/main/Reference/30vnfoods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a801eec0",
      "metadata": {
        "id": "a801eec0"
      },
      "source": [
        "## 3-1. 프로젝트: 베트남 음식 분류하기\n",
        "\n",
        "**Index**\n",
        "\n",
        "Set up  \n",
        "Remove broken files  \n",
        "Check data for training  \n",
        "Dataloader  \n",
        "Create a model  \n",
        "Custom Trainer  \n",
        "Training  \n",
        "Test model  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cde78c00",
      "metadata": {
        "id": "cde78c00"
      },
      "source": [
        "### Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a0ac037",
      "metadata": {
        "id": "8a0ac037"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b30c91a2",
      "metadata": {
        "id": "b30c91a2"
      },
      "source": [
        "### Remove broken files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11816e93",
      "metadata": {
        "id": "11816e93"
      },
      "outputs": [],
      "source": [
        "# training set과 test set의 모든 이미지 파일에 대해서,\n",
        "# jpg image header가 포함되지 않은 (jpg의 파일 구조에 어긋나는) 파일들을 삭제해줍니다.\n",
        "\n",
        "data_path = '/aiffel/aiffel/model-fit/data/30vnfoods/'\n",
        "train_path = data_path + 'Train/'\n",
        "test_path = data_path + 'Test/'\n",
        "\n",
        "for path in [train_path, test_path]:\n",
        "    classes = os.listdir(path)\n",
        "\n",
        "    for food in classes:\n",
        "        food_path = os.path.join(path, food)\n",
        "        images = os.listdir(food_path)\n",
        "\n",
        "        for image in images:\n",
        "            with open(os.path.join(food_path, image), 'rb') as f:\n",
        "                bytes = f.read()\n",
        "            if bytes[:3] != b'\\xff\\xd8\\xff':\n",
        "                print(os.path.join(food_path, image))\n",
        "                os.remove(os.path.join(food_path, image))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d978aa8",
      "metadata": {
        "id": "1d978aa8"
      },
      "source": [
        "### Check data for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9108c3c1",
      "metadata": {
        "id": "9108c3c1",
        "outputId": "73044096-6456-424f-95b5-bc87e641255d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training data의 개수: 9775\n"
          ]
        }
      ],
      "source": [
        "classes = os.listdir(train_path)\n",
        "train_length = 0\n",
        "\n",
        "for food in classes:\n",
        "    food_path = os.path.join(train_path, food)\n",
        "    images = os.listdir(food_path)\n",
        "\n",
        "    train_length += len(images)\n",
        "\n",
        "print('training data의 개수: '+str(train_length))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c8449f9",
      "metadata": {
        "id": "2c8449f9"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b67f79a",
      "metadata": {
        "id": "1b67f79a"
      },
      "outputs": [],
      "source": [
        "# 문제 1: dataloader 구현하기\n",
        "\n",
        "def process_path(file_path, class_names, img_shape=(224, 224)):\n",
        "    '''\n",
        "    file_path로 부터 class label을 만들고, 이미지를 읽는 함수\n",
        "    이미지 크기를 (224, 224)로 맞춰주세요.\n",
        "    '''\n",
        "    label = tf.strings.split(file_path, os.path.sep)\n",
        "    label = label[-2] == class_names\n",
        "\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, img_shape)\n",
        "\n",
        "    return img, label\n",
        "\n",
        "def prepare_for_training(ds, batch_size=32, cache=True, shuffle_buffer_size=10000):\n",
        "    '''\n",
        "    TensorFlow Data API를 이용해 data batch를 만드는 함수\n",
        "    '''\n",
        "    if cache:\n",
        "        if isinstance(cache, str):\n",
        "            ds = ds.cache(cache)\n",
        "        else:\n",
        "            ds = ds.cache()\n",
        "\n",
        "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "    ds = ds.repeat()\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return ds\n",
        "\n",
        "def load_data(data_path, batch_size=32):\n",
        "    '''\n",
        "    데이터를 만들기 위해 필요한 함수들을 호출하고 데이터를 리턴해주는 함수\n",
        "    TensorFlow Dataset 객체를 생성하고 process_path 함수로 이미지와 라벨을 묶은 다음,\n",
        "    prepare_for_training 함수로 batch가 적용된 Dataset 객체를 만들어주세요.\n",
        "    '''\n",
        "    class_names = [cls for cls in os.listdir(data_path) if cls != '.DS_Store']\n",
        "    print(class_names)\n",
        "    data_path = pathlib.Path(data_path)\n",
        "\n",
        "    list_ds = tf.data.Dataset.list_files(str(data_path/'*/*'))\n",
        "    labeled_ds = list_ds.map(lambda x: process_path(x, class_names, img_shape=(224, 224)))\n",
        "    ds = prepare_for_training(labeled_ds, batch_size=batch_size)\n",
        "\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10e3298f",
      "metadata": {
        "id": "10e3298f"
      },
      "source": [
        "### Create a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca47f1e9",
      "metadata": {
        "id": "ca47f1e9",
        "outputId": "9f006e7a-81cc-48fc-ae7b-bf80aac6c4da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "efficientnetb0 (Functional)  (None, None, None, 1280)  4049571   \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 1280)              5120      \n",
            "_________________________________________________________________\n",
            "pred (Dense)                 multiple                  6405      \n",
            "=================================================================\n",
            "Total params: 4,061,096\n",
            "Trainable params: 8,965\n",
            "Non-trainable params: 4,052,131\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# 문제 2: 모델 구현하기\n",
        "\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "class Model(tf.keras.Model):\n",
        "    '''\n",
        "    EfficientNetB0을 백본으로 사용하는 모델을 구성합니다.\n",
        "    Classification 문제로 접근할 것이기 때문에 맨 마지막 Dense 레이어에\n",
        "    우리가 원하는 클래스 개수만큼을 지정해주어야 합니다.\n",
        "    '''\n",
        "    def __init__(self, num_classes=10, freeze=False):\n",
        "        super(Model, self).__init__()\n",
        "        self.base_model = EfficientNetB0(include_top=False, weights='imagenet')\n",
        "        if freeze:\n",
        "            self.base_model.trainable = False\n",
        "        self.top = tf.keras.Sequential([tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\"),\n",
        "                                       tf.keras.layers.BatchNormalization(),\n",
        "                                       tf.keras.layers.Dropout(0.5, name=\"top_dropout\")])\n",
        "        self.classifier = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")\n",
        "    def call(self, inputs, training=True):\n",
        "        x = self.base_model(inputs)\n",
        "        x = self.top(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = Model(num_classes=5, freeze=True)\n",
        "    model.build(input_shape=(None, 224, 224, 3))\n",
        "    print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ade157a2",
      "metadata": {
        "id": "ade157a2"
      },
      "source": [
        "### Custom Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf434e25",
      "metadata": {
        "id": "cf434e25"
      },
      "outputs": [],
      "source": [
        "# 문제 3: custom trainer 구현하기\n",
        "class Trainer:\n",
        "    def __init__(self, model, epochs, batch, ds_length, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.epochs = epochs\n",
        "        self.batch = batch\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def train(self, train_dataset, train_metric, callbacks=None):\n",
        "        for epoch in range(self.epochs):\n",
        "            print(\"\\nStart of epoch %d\" % (epoch+1,))\n",
        "            for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "                with tf.GradientTape() as tape:\n",
        "                    logits = self.model(x_batch_train, training=True)\n",
        "                    loss_value = self.loss_fn(y_batch_train, logits)\n",
        "                grads = tape.gradient(loss_value, self.model.trainable_weights)\n",
        "                self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
        "                # train metric 업데이트\n",
        "                train_metric.update_state(y_batch_train, logits)\n",
        "                # 5 배치마다 로깅\n",
        "                if step % 5 == 0:\n",
        "                    print(\n",
        "                        \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                        % (step, float(loss_value))\n",
        "                    )\n",
        "                    print(\"Seen so far: %d samples\" % ((step + 1) * self.batch))\n",
        "                    print(train_metric.result().numpy())\n",
        "            # 마지막 epoch 학습이 끝나면 train 결과를 보여줌\n",
        "            train_acc = train_metric.result()\n",
        "            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "\n",
        "            # Execute callbacks if provided\n",
        "            if callbacks:\n",
        "                for callback in callbacks:\n",
        "                    callback.on_epoch_end(epoch=epoch, logs={'loss': float(loss_value)})\n",
        "\n",
        "            train_metric.reset_states()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "271e4273",
      "metadata": {
        "id": "271e4273"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b907275",
      "metadata": {
        "id": "1b907275",
        "outputId": "1b05346d-1787-4489-9c30-b80b5153846a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Bun rieu', 'Banh mi', 'Banh xeo', 'Chao long', 'Pho', 'Banh khot', 'Bun bo Hue', 'Banh cuon', 'Com tam', 'Bun dau mam tom']\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 3.6740\n",
            "Seen so far: 32 samples\n",
            "0.15625\n",
            "Training loss (for one batch) at step 5: 2.1887\n",
            "Seen so far: 192 samples\n",
            "0.21875\n",
            "Training loss (for one batch) at step 10: 2.1733\n",
            "Seen so far: 352 samples\n",
            "0.2840909\n",
            "Training loss (for one batch) at step 15: 1.4603\n",
            "Seen so far: 512 samples\n",
            "0.34570312\n",
            "Training loss (for one batch) at step 20: 1.7064\n",
            "Seen so far: 672 samples\n",
            "0.38392857\n",
            "Training loss (for one batch) at step 25: 2.0584\n",
            "Seen so far: 832 samples\n",
            "0.41346154\n",
            "Training loss (for one batch) at step 30: 1.3685\n",
            "Seen so far: 992 samples\n",
            "0.45262095\n",
            "Training loss (for one batch) at step 35: 0.9986\n",
            "Seen so far: 1152 samples\n",
            "0.48177084\n",
            "Training loss (for one batch) at step 40: 1.3662\n",
            "Seen so far: 1312 samples\n",
            "0.50990856\n",
            "Training loss (for one batch) at step 45: 0.9204\n",
            "Seen so far: 1472 samples\n",
            "0.52921194\n",
            "Training loss (for one batch) at step 50: 1.1510\n",
            "Seen so far: 1632 samples\n",
            "0.5459559\n",
            "Training loss (for one batch) at step 55: 0.7955\n",
            "Seen so far: 1792 samples\n",
            "0.561942\n",
            "Training loss (for one batch) at step 60: 0.9958\n",
            "Seen so far: 1952 samples\n",
            "0.5732582\n",
            "Training loss (for one batch) at step 65: 0.6832\n",
            "Seen so far: 2112 samples\n",
            "0.58664775\n",
            "Training loss (for one batch) at step 70: 0.9198\n",
            "Seen so far: 2272 samples\n",
            "0.59727114\n",
            "Training loss (for one batch) at step 75: 0.8487\n",
            "Seen so far: 2432 samples\n",
            "0.60361844\n",
            "Training loss (for one batch) at step 80: 1.0416\n",
            "Seen so far: 2592 samples\n",
            "0.6103395\n",
            "Training loss (for one batch) at step 85: 0.8198\n",
            "Seen so far: 2752 samples\n",
            "0.6166424\n",
            "Training loss (for one batch) at step 90: 0.8154\n",
            "Seen so far: 2912 samples\n",
            "0.62259614\n",
            "Training loss (for one batch) at step 95: 1.0347\n",
            "Seen so far: 3072 samples\n",
            "0.62890625\n",
            "Training loss (for one batch) at step 100: 1.2157\n",
            "Seen so far: 3232 samples\n",
            "0.6302599\n",
            "Training loss (for one batch) at step 105: 0.7401\n",
            "Seen so far: 3392 samples\n",
            "0.6379717\n",
            "Training loss (for one batch) at step 110: 0.2178\n",
            "Seen so far: 3552 samples\n",
            "0.6449887\n",
            "Training loss (for one batch) at step 115: 0.4185\n",
            "Seen so far: 3712 samples\n",
            "0.64897627\n",
            "Training loss (for one batch) at step 120: 0.7573\n",
            "Seen so far: 3872 samples\n",
            "0.6547004\n",
            "Training loss (for one batch) at step 125: 0.8485\n",
            "Seen so far: 4032 samples\n",
            "0.6609623\n",
            "Training loss (for one batch) at step 130: 0.4719\n",
            "Seen so far: 4192 samples\n",
            "0.66626906\n",
            "Training loss (for one batch) at step 135: 0.8823\n",
            "Seen so far: 4352 samples\n",
            "0.66980696\n",
            "Training loss (for one batch) at step 140: 0.6204\n",
            "Seen so far: 4512 samples\n",
            "0.67353725\n",
            "Training loss (for one batch) at step 145: 0.6449\n",
            "Seen so far: 4672 samples\n",
            "0.6755137\n",
            "Training loss (for one batch) at step 150: 0.7826\n",
            "Seen so far: 4832 samples\n",
            "0.6777732\n",
            "Training loss (for one batch) at step 155: 0.7048\n",
            "Seen so far: 4992 samples\n",
            "0.68108976\n",
            "Training loss (for one batch) at step 160: 0.8441\n",
            "Seen so far: 5152 samples\n",
            "0.68342394\n",
            "Training loss (for one batch) at step 165: 0.6037\n",
            "Seen so far: 5312 samples\n",
            "0.6865587\n",
            "Training loss (for one batch) at step 170: 0.2903\n",
            "Seen so far: 5472 samples\n",
            "0.6909722\n",
            "Training loss (for one batch) at step 175: 0.5280\n",
            "Seen so far: 5632 samples\n",
            "0.6937145\n",
            "Training loss (for one batch) at step 180: 0.4511\n",
            "Seen so far: 5792 samples\n",
            "0.69665056\n",
            "Training loss (for one batch) at step 185: 0.3941\n",
            "Seen so far: 5952 samples\n",
            "0.6999328\n",
            "Training loss (for one batch) at step 190: 0.6489\n",
            "Seen so far: 6112 samples\n",
            "0.7030432\n",
            "Training loss (for one batch) at step 195: 0.6432\n",
            "Seen so far: 6272 samples\n",
            "0.705676\n",
            "Training loss (for one batch) at step 200: 0.5862\n",
            "Seen so far: 6432 samples\n",
            "0.7083333\n",
            "Training loss (for one batch) at step 205: 0.5125\n",
            "Seen so far: 6592 samples\n",
            "0.71010315\n",
            "Training loss (for one batch) at step 210: 0.1812\n",
            "Seen so far: 6752 samples\n",
            "0.713122\n",
            "Training loss (for one batch) at step 215: 0.6557\n",
            "Seen so far: 6912 samples\n",
            "0.7149884\n",
            "Training loss (for one batch) at step 220: 0.2176\n",
            "Seen so far: 7072 samples\n",
            "0.7179016\n",
            "Training loss (for one batch) at step 225: 0.3387\n",
            "Seen so far: 7232 samples\n",
            "0.72013277\n",
            "Training loss (for one batch) at step 230: 0.7784\n",
            "Seen so far: 7392 samples\n",
            "0.7228084\n",
            "Training loss (for one batch) at step 235: 0.3172\n",
            "Seen so far: 7552 samples\n",
            "0.7247087\n",
            "Training loss (for one batch) at step 240: 0.7224\n",
            "Seen so far: 7712 samples\n",
            "0.7261411\n",
            "Training loss (for one batch) at step 245: 0.5750\n",
            "Seen so far: 7872 samples\n",
            "0.7270071\n",
            "Training loss (for one batch) at step 250: 0.5832\n",
            "Seen so far: 8032 samples\n",
            "0.7292082\n",
            "Training loss (for one batch) at step 255: 0.6516\n",
            "Seen so far: 8192 samples\n",
            "0.7312012\n",
            "Training loss (for one batch) at step 260: 0.9783\n",
            "Seen so far: 8352 samples\n",
            "0.733477\n",
            "Training loss (for one batch) at step 265: 0.7973\n",
            "Seen so far: 8512 samples\n",
            "0.7350799\n",
            "Training loss (for one batch) at step 270: 0.4110\n",
            "Seen so far: 8672 samples\n",
            "0.73696953\n",
            "Training loss (for one batch) at step 275: 0.3245\n",
            "Seen so far: 8832 samples\n",
            "0.7383379\n",
            "Training loss (for one batch) at step 280: 0.6011\n",
            "Seen so far: 8992 samples\n",
            "0.74043596\n",
            "Training loss (for one batch) at step 285: 0.4841\n",
            "Seen so far: 9152 samples\n",
            "0.74246067\n",
            "Training loss (for one batch) at step 290: 0.2717\n",
            "Seen so far: 9312 samples\n",
            "0.7443084\n",
            "Training loss (for one batch) at step 295: 0.6301\n",
            "Seen so far: 9472 samples\n",
            "0.74651605\n",
            "Training loss (for one batch) at step 300: 0.8649\n",
            "Seen so far: 9632 samples\n",
            "0.7481312\n",
            "Training loss (for one batch) at step 305: 0.5444\n",
            "Seen so far: 9792 samples\n",
            "0.75020427\n",
            "Training loss (for one batch) at step 310: 0.1728\n",
            "Seen so far: 9952 samples\n",
            "0.75301445\n",
            "Training loss (for one batch) at step 315: 0.4817\n",
            "Seen so far: 10112 samples\n",
            "0.754549\n",
            "Training loss (for one batch) at step 320: 0.2314\n",
            "Seen so far: 10272 samples\n",
            "0.75623053\n",
            "Training loss (for one batch) at step 325: 0.5320\n",
            "Seen so far: 10432 samples\n",
            "0.757477\n",
            "Training loss (for one batch) at step 330: 0.5112\n",
            "Seen so far: 10592 samples\n",
            "0.7594411\n",
            "Training loss (for one batch) at step 335: 0.3938\n",
            "Seen so far: 10752 samples\n",
            "0.7612537\n",
            "Training loss (for one batch) at step 340: 0.3311\n",
            "Seen so far: 10912 samples\n",
            "0.7623717\n",
            "Training loss (for one batch) at step 345: 0.4040\n",
            "Seen so far: 11072 samples\n",
            "0.76427025\n",
            "Training loss (for one batch) at step 350: 0.2332\n",
            "Seen so far: 11232 samples\n",
            "0.76584756\n",
            "Training loss (for one batch) at step 355: 0.1601\n",
            "Seen so far: 11392 samples\n",
            "0.7673806\n",
            "Training loss (for one batch) at step 360: 0.4097\n",
            "Seen so far: 11552 samples\n",
            "0.76921743\n",
            "Training loss (for one batch) at step 365: 0.2345\n",
            "Seen so far: 11712 samples\n",
            "0.7709187\n",
            "Training loss (for one batch) at step 370: 0.2894\n",
            "Seen so far: 11872 samples\n",
            "0.7716476\n",
            "Training loss (for one batch) at step 375: 0.2891\n",
            "Seen so far: 12032 samples\n",
            "0.773105\n",
            "Training loss (for one batch) at step 380: 0.2935\n",
            "Seen so far: 12192 samples\n",
            "0.77395016\n",
            "Training loss (for one batch) at step 385: 0.3043\n",
            "Seen so far: 12352 samples\n",
            "0.77517813\n",
            "Training loss (for one batch) at step 390: 0.8037\n",
            "Seen so far: 12512 samples\n",
            "0.7765345\n",
            "Training loss (for one batch) at step 395: 0.2951\n",
            "Seen so far: 12672 samples\n",
            "0.77833015\n",
            "Training loss (for one batch) at step 400: 0.2024\n",
            "Seen so far: 12832 samples\n",
            "0.77937967\n",
            "Training loss (for one batch) at step 405: 0.1561\n",
            "Seen so far: 12992 samples\n",
            "0.78086513\n",
            "Training loss (for one batch) at step 410: 0.1850\n",
            "Seen so far: 13152 samples\n",
            "0.7821624\n",
            "Training loss (for one batch) at step 415: 0.0769\n",
            "Seen so far: 13312 samples\n",
            "0.7827524\n",
            "Training loss (for one batch) at step 420: 0.3362\n",
            "Seen so far: 13472 samples\n",
            "0.783848\n",
            "Training loss (for one batch) at step 425: 0.3860\n",
            "Seen so far: 13632 samples\n",
            "0.7846978\n",
            "Training loss (for one batch) at step 430: 0.3485\n",
            "Seen so far: 13792 samples\n",
            "0.7855278\n",
            "Training loss (for one batch) at step 435: 0.4664\n",
            "Seen so far: 13952 samples\n",
            "0.7865539\n",
            "Training loss (for one batch) at step 440: 0.7588\n",
            "Seen so far: 14112 samples\n",
            "0.78720236\n",
            "Training loss (for one batch) at step 445: 0.1965\n",
            "Seen so far: 14272 samples\n",
            "0.78860706\n",
            "Training loss (for one batch) at step 450: 0.3156\n",
            "Seen so far: 14432 samples\n",
            "0.7891491\n",
            "Training loss (for one batch) at step 455: 0.3181\n",
            "Seen so far: 14592 samples\n",
            "0.7899534\n",
            "Training loss (for one batch) at step 460: 0.7607\n",
            "Seen so far: 14752 samples\n",
            "0.79107916\n",
            "Training loss (for one batch) at step 465: 0.0671\n",
            "Seen so far: 14912 samples\n",
            "0.7923149\n",
            "Training loss (for one batch) at step 470: 0.3392\n",
            "Seen so far: 15072 samples\n",
            "0.793259\n",
            "Training loss (for one batch) at step 475: 0.4908\n",
            "Seen so far: 15232 samples\n",
            "0.79438025\n",
            "Training loss (for one batch) at step 480: 0.3879\n",
            "Seen so far: 15392 samples\n",
            "0.7953482\n",
            "Training loss (for one batch) at step 485: 0.2441\n",
            "Seen so far: 15552 samples\n",
            "0.7963606\n",
            "Training loss (for one batch) at step 490: 0.2597\n",
            "Seen so far: 15712 samples\n",
            "0.7971614\n",
            "Training loss (for one batch) at step 495: 0.8419\n",
            "Seen so far: 15872 samples\n",
            "0.79782003\n",
            "Training loss (for one batch) at step 500: 0.6337\n",
            "Seen so far: 16032 samples\n",
            "0.79827845\n",
            "Training loss (for one batch) at step 505: 0.7206\n",
            "Seen so far: 16192 samples\n",
            "0.798666\n",
            "Training loss (for one batch) at step 510: 0.3673\n",
            "Seen so far: 16352 samples\n",
            "0.7991683\n",
            "Training loss (for one batch) at step 515: 0.4922\n",
            "Seen so far: 16512 samples\n",
            "0.80008477\n",
            "Training loss (for one batch) at step 520: 0.3549\n",
            "Seen so far: 16672 samples\n",
            "0.8011636\n",
            "Training loss (for one batch) at step 525: 0.7523\n",
            "Seen so far: 16832 samples\n",
            "0.80168724\n",
            "Training loss (for one batch) at step 530: 0.2473\n",
            "Seen so far: 16992 samples\n",
            "0.8020833\n",
            "Training loss (for one batch) at step 535: 0.3747\n",
            "Seen so far: 17152 samples\n",
            "0.80317163\n",
            "Training loss (for one batch) at step 540: 0.1724\n",
            "Seen so far: 17312 samples\n",
            "0.803951\n",
            "Training loss (for one batch) at step 545: 0.5060\n",
            "Seen so far: 17472 samples\n",
            "0.80431545\n",
            "Training loss (for one batch) at step 550: 0.3448\n",
            "Seen so far: 17632 samples\n",
            "0.8050136\n",
            "Training loss (for one batch) at step 555: 0.6468\n",
            "Seen so far: 17792 samples\n",
            "0.8058678\n",
            "Training loss (for one batch) at step 560: 0.6393\n",
            "Seen so far: 17952 samples\n",
            "0.80631685\n",
            "Training loss (for one batch) at step 565: 0.5308\n",
            "Seen so far: 18112 samples\n",
            "0.8068684\n",
            "Training loss (for one batch) at step 570: 0.2866\n",
            "Seen so far: 18272 samples\n",
            "0.8077386\n",
            "Training loss (for one batch) at step 575: 0.2505\n",
            "Seen so far: 18432 samples\n",
            "0.80826825\n",
            "Training loss (for one batch) at step 580: 0.3605\n",
            "Seen so far: 18592 samples\n",
            "0.8085736\n",
            "Training loss (for one batch) at step 585: 0.4418\n",
            "Seen so far: 18752 samples\n",
            "0.80892706\n",
            "Training loss (for one batch) at step 590: 0.2623\n",
            "Seen so far: 18912 samples\n",
            "0.8095389\n",
            "Training loss (for one batch) at step 595: 0.1689\n",
            "Seen so far: 19072 samples\n",
            "0.8100881\n",
            "Training loss (for one batch) at step 600: 0.8084\n",
            "Seen so far: 19232 samples\n",
            "0.81047213\n",
            "Training loss (for one batch) at step 605: 0.5385\n",
            "Seen so far: 19392 samples\n",
            "0.81084985\n",
            "Training loss (for one batch) at step 610: 0.2893\n",
            "Seen so far: 19552 samples\n",
            "0.8113748\n",
            "Training loss (for one batch) at step 615: 0.5603\n",
            "Seen so far: 19712 samples\n",
            "0.8118405\n",
            "Training loss (for one batch) at step 620: 0.3453\n",
            "Seen so far: 19872 samples\n",
            "0.8125\n",
            "Training loss (for one batch) at step 625: 0.4573\n",
            "Seen so far: 20032 samples\n",
            "0.81334865\n",
            "Training loss (for one batch) at step 630: 0.3151\n",
            "Seen so far: 20192 samples\n",
            "0.8138867\n",
            "Training loss (for one batch) at step 635: 0.2193\n",
            "Seen so far: 20352 samples\n",
            "0.8147111\n",
            "Training loss (for one batch) at step 640: 0.2991\n",
            "Seen so far: 20512 samples\n",
            "0.8153276\n",
            "Training loss (for one batch) at step 645: 0.2839\n",
            "Seen so far: 20672 samples\n",
            "0.8158862\n",
            "Training loss (for one batch) at step 650: 0.4060\n",
            "Seen so far: 20832 samples\n",
            "0.8168683\n",
            "Training loss (for one batch) at step 655: 0.2351\n",
            "Seen so far: 20992 samples\n",
            "0.8177877\n",
            "Training loss (for one batch) at step 660: 0.5701\n",
            "Seen so far: 21152 samples\n",
            "0.818646\n",
            "Training loss (for one batch) at step 665: 0.3888\n",
            "Seen so far: 21312 samples\n",
            "0.8192098\n",
            "Training loss (for one batch) at step 670: 0.2592\n",
            "Seen so far: 21472 samples\n",
            "0.8196721\n",
            "Training loss (for one batch) at step 675: 0.0305\n",
            "Seen so far: 21632 samples\n",
            "0.8204974\n",
            "Training loss (for one batch) at step 680: 0.2418\n",
            "Seen so far: 21792 samples\n",
            "0.8209894\n",
            "Training loss (for one batch) at step 685: 0.1518\n",
            "Seen so far: 21952 samples\n",
            "0.8217019\n",
            "Training loss (for one batch) at step 690: 0.2134\n",
            "Seen so far: 22112 samples\n",
            "0.8223589\n",
            "Training loss (for one batch) at step 695: 0.3361\n",
            "Seen so far: 22272 samples\n",
            "0.82296157\n",
            "Training loss (for one batch) at step 700: 0.2431\n",
            "Seen so far: 22432 samples\n",
            "0.82360023\n",
            "Training loss (for one batch) at step 705: 0.2514\n",
            "Seen so far: 22592 samples\n",
            "0.82414126\n",
            "Training loss (for one batch) at step 710: 0.1384\n",
            "Seen so far: 22752 samples\n",
            "0.8247187\n",
            "Training loss (for one batch) at step 715: 0.2616\n",
            "Seen so far: 22912 samples\n",
            "0.825419\n",
            "Training loss (for one batch) at step 720: 0.5791\n",
            "Seen so far: 23072 samples\n",
            "0.8256328\n",
            "Training loss (for one batch) at step 725: 0.1315\n",
            "Seen so far: 23232 samples\n",
            "0.82653236\n",
            "Training loss (for one batch) at step 730: 0.1772\n",
            "Seen so far: 23392 samples\n",
            "0.8268639\n",
            "Training loss (for one batch) at step 735: 0.3967\n",
            "Seen so far: 23552 samples\n",
            "0.8274032\n",
            "Training loss (for one batch) at step 740: 0.1902\n",
            "Seen so far: 23712 samples\n",
            "0.8279352\n",
            "Training loss (for one batch) at step 745: 0.2690\n",
            "Seen so far: 23872 samples\n",
            "0.82837635\n",
            "Training loss (for one batch) at step 750: 0.2744\n",
            "Seen so far: 24032 samples\n",
            "0.8286035\n",
            "Training loss (for one batch) at step 755: 0.8280\n",
            "Seen so far: 24192 samples\n",
            "0.82862103\n",
            "Training loss (for one batch) at step 760: 0.1298\n",
            "Seen so far: 24352 samples\n",
            "0.8288026\n",
            "Training loss (for one batch) at step 765: 0.4152\n",
            "Seen so far: 24512 samples\n",
            "0.8294713\n",
            "Training loss (for one batch) at step 770: 0.2103\n",
            "Seen so far: 24672 samples\n",
            "0.8298476\n",
            "Training loss (for one batch) at step 775: 0.4445\n",
            "Seen so far: 24832 samples\n",
            "0.8303399\n",
            "Training loss (for one batch) at step 780: 0.2516\n",
            "Seen so far: 24992 samples\n",
            "0.83046573\n",
            "Training loss (for one batch) at step 785: 0.3587\n",
            "Seen so far: 25152 samples\n",
            "0.83074903\n",
            "Training loss (for one batch) at step 790: 0.1499\n",
            "Seen so far: 25312 samples\n",
            "0.8313053\n",
            "Training loss (for one batch) at step 795: 0.1463\n",
            "Seen so far: 25472 samples\n",
            "0.8317761\n",
            "Training loss (for one batch) at step 800: 0.1213\n",
            "Seen so far: 25632 samples\n",
            "0.83251405\n",
            "Training loss (for one batch) at step 805: 0.3522\n",
            "Seen so far: 25792 samples\n",
            "0.8330878\n",
            "Training loss (for one batch) at step 810: 0.4236\n",
            "Seen so far: 25952 samples\n",
            "0.83353883\n",
            "Training loss (for one batch) at step 815: 0.3360\n",
            "Seen so far: 26112 samples\n",
            "0.8338312\n",
            "Training loss (for one batch) at step 820: 0.2953\n",
            "Seen so far: 26272 samples\n",
            "0.8345006\n",
            "Training loss (for one batch) at step 825: 0.1392\n",
            "Seen so far: 26432 samples\n",
            "0.8348971\n",
            "Training loss (for one batch) at step 830: 0.2993\n",
            "Seen so far: 26592 samples\n",
            "0.83536404\n",
            "Training loss (for one batch) at step 835: 0.1425\n",
            "Seen so far: 26752 samples\n",
            "0.8359375\n",
            "Training loss (for one batch) at step 840: 0.4610\n",
            "Seen so far: 26912 samples\n",
            "0.8361326\n",
            "Training loss (for one batch) at step 845: 0.6867\n",
            "Seen so far: 27072 samples\n",
            "0.83621454\n",
            "Training loss (for one batch) at step 850: 0.2693\n",
            "Seen so far: 27232 samples\n",
            "0.83666277\n",
            "Training loss (for one batch) at step 855: 0.1856\n",
            "Seen so far: 27392 samples\n",
            "0.8370692\n",
            "Training loss (for one batch) at step 860: 0.4415\n",
            "Seen so far: 27552 samples\n",
            "0.83739835\n",
            "Training loss (for one batch) at step 865: 0.3902\n",
            "Seen so far: 27712 samples\n",
            "0.8378681\n",
            "Training loss (for one batch) at step 870: 0.0704\n",
            "Seen so far: 27872 samples\n",
            "0.83836824\n",
            "Training loss (for one batch) at step 875: 0.2280\n",
            "Seen so far: 28032 samples\n",
            "0.8388627\n",
            "Training loss (for one batch) at step 880: 0.2104\n",
            "Seen so far: 28192 samples\n",
            "0.8393161\n",
            "Training loss (for one batch) at step 885: 0.2437\n",
            "Seen so far: 28352 samples\n",
            "0.83972913\n",
            "Training loss (for one batch) at step 890: 0.3559\n",
            "Seen so far: 28512 samples\n",
            "0.8400673\n",
            "Training loss (for one batch) at step 895: 0.8919\n",
            "Seen so far: 28672 samples\n",
            "0.84043664\n",
            "Training loss (for one batch) at step 900: 0.3272\n",
            "Seen so far: 28832 samples\n",
            "0.84090596\n",
            "Training loss (for one batch) at step 905: 0.0892\n",
            "Seen so far: 28992 samples\n",
            "0.84133554\n",
            "Training loss (for one batch) at step 910: 0.3421\n",
            "Seen so far: 29152 samples\n",
            "0.84169185\n",
            "Training loss (for one batch) at step 915: 0.4425\n",
            "Seen so far: 29312 samples\n",
            "0.84190774\n",
            "Training loss (for one batch) at step 920: 0.3785\n",
            "Seen so far: 29472 samples\n",
            "0.8424267\n",
            "Training loss (for one batch) at step 925: 0.3503\n",
            "Seen so far: 29632 samples\n",
            "0.8429063\n",
            "Training loss (for one batch) at step 930: 0.0923\n",
            "Seen so far: 29792 samples\n",
            "0.84358215\n",
            "Training loss (for one batch) at step 935: 0.2007\n",
            "Seen so far: 29952 samples\n",
            "0.84408385\n",
            "Training loss (for one batch) at step 940: 0.2037\n",
            "Seen so far: 30112 samples\n",
            "0.84454703\n",
            "Training loss (for one batch) at step 945: 0.0625\n",
            "Seen so far: 30272 samples\n",
            "0.84497225\n",
            "Training loss (for one batch) at step 950: 0.3708\n",
            "Seen so far: 30432 samples\n",
            "0.8452616\n",
            "Training loss (for one batch) at step 955: 0.2801\n",
            "Seen so far: 30592 samples\n",
            "0.8457113\n",
            "Training loss (for one batch) at step 960: 0.2286\n",
            "Seen so far: 30752 samples\n",
            "0.84625393\n",
            "Training loss (for one batch) at step 965: 0.0554\n",
            "Seen so far: 30912 samples\n",
            "0.84688795\n",
            "Training loss (for one batch) at step 970: 0.0521\n",
            "Seen so far: 31072 samples\n",
            "0.84751546\n",
            "Training loss (for one batch) at step 975: 0.0351\n",
            "Seen so far: 31232 samples\n",
            "0.84804046\n",
            "Training loss (for one batch) at step 980: 0.0353\n",
            "Seen so far: 31392 samples\n",
            "0.84852827\n",
            "Training loss (for one batch) at step 985: 0.1370\n",
            "Seen so far: 31552 samples\n",
            "0.84907454\n",
            "Training loss (for one batch) at step 990: 0.0255\n",
            "Seen so far: 31712 samples\n",
            "0.84948915\n",
            "Training loss (for one batch) at step 995: 0.0988\n",
            "Seen so far: 31872 samples\n",
            "0.8497741\n",
            "Training loss (for one batch) at step 1000: 0.0726\n",
            "Seen so far: 32032 samples\n",
            "0.8502123\n",
            "Training loss (for one batch) at step 1005: 0.0756\n",
            "Seen so far: 32192 samples\n",
            "0.85070825\n",
            "Training loss (for one batch) at step 1010: 0.0856\n",
            "Seen so far: 32352 samples\n",
            "0.85113746\n",
            "Training loss (for one batch) at step 1015: 0.1189\n",
            "Seen so far: 32512 samples\n",
            "0.85153174\n",
            "Training loss (for one batch) at step 1020: 0.1042\n",
            "Seen so far: 32672 samples\n",
            "0.8518303\n",
            "Training loss (for one batch) at step 1025: 0.1554\n",
            "Seen so far: 32832 samples\n",
            "0.85209554\n",
            "Training loss (for one batch) at step 1030: 0.1951\n",
            "Seen so far: 32992 samples\n",
            "0.8524794\n",
            "Training loss (for one batch) at step 1035: 0.3915\n",
            "Seen so far: 33152 samples\n",
            "0.8529199\n",
            "Training loss (for one batch) at step 1040: 0.3551\n",
            "Seen so far: 33312 samples\n",
            "0.853146\n",
            "Training loss (for one batch) at step 1045: 0.0734\n",
            "Seen so far: 33472 samples\n",
            "0.85348946\n",
            "Training loss (for one batch) at step 1050: 0.4562\n",
            "Seen so far: 33632 samples\n",
            "0.85379994\n",
            "Training loss (for one batch) at step 1055: 0.0944\n",
            "Seen so far: 33792 samples\n",
            "0.8541075\n",
            "Training loss (for one batch) at step 1060: 0.1988\n",
            "Seen so far: 33952 samples\n",
            "0.8544416\n",
            "Training loss (for one batch) at step 1065: 0.2608\n",
            "Seen so far: 34112 samples\n",
            "0.85480183\n",
            "Training loss (for one batch) at step 1070: 0.1298\n",
            "Seen so far: 34272 samples\n",
            "0.8551879\n",
            "Training loss (for one batch) at step 1075: 0.0939\n",
            "Seen so far: 34432 samples\n",
            "0.8555123\n",
            "Training loss (for one batch) at step 1080: 0.1714\n",
            "Seen so far: 34592 samples\n",
            "0.8557759\n",
            "Training loss (for one batch) at step 1085: 0.1702\n",
            "Seen so far: 34752 samples\n",
            "0.8560083\n",
            "Training loss (for one batch) at step 1090: 0.1655\n",
            "Seen so far: 34912 samples\n",
            "0.85618126\n",
            "Training loss (for one batch) at step 1095: 0.3411\n",
            "Seen so far: 35072 samples\n",
            "0.8563812\n",
            "Training loss (for one batch) at step 1100: 0.1388\n",
            "Seen so far: 35232 samples\n",
            "0.8566928\n",
            "Training loss (for one batch) at step 1105: 0.2012\n",
            "Seen so far: 35392 samples\n",
            "0.85697335\n",
            "Training loss (for one batch) at step 1110: 0.2295\n",
            "Seen so far: 35552 samples\n",
            "0.8573639\n",
            "Training loss (for one batch) at step 1115: 0.0957\n",
            "Seen so far: 35712 samples\n",
            "0.85769486\n",
            "Training loss (for one batch) at step 1120: 0.1241\n",
            "Seen so far: 35872 samples\n",
            "0.8580508\n",
            "Training loss (for one batch) at step 1125: 0.6779\n",
            "Seen so far: 36032 samples\n",
            "0.8581539\n",
            "Training loss (for one batch) at step 1130: 0.3110\n",
            "Seen so far: 36192 samples\n",
            "0.8585599\n",
            "Training loss (for one batch) at step 1135: 0.0266\n",
            "Seen so far: 36352 samples\n",
            "0.85887986\n",
            "Training loss (for one batch) at step 1140: 0.0399\n",
            "Seen so far: 36512 samples\n",
            "0.85927916\n",
            "Training loss (for one batch) at step 1145: 0.1881\n",
            "Seen so far: 36672 samples\n",
            "0.85942954\n",
            "Training loss (for one batch) at step 1150: 0.2283\n",
            "Seen so far: 36832 samples\n",
            "0.8597144\n",
            "Training loss (for one batch) at step 1155: 0.4045\n",
            "Seen so far: 36992 samples\n",
            "0.8598616\n",
            "Training loss (for one batch) at step 1160: 0.0574\n",
            "Seen so far: 37152 samples\n",
            "0.86024976\n",
            "Training loss (for one batch) at step 1165: 0.0544\n",
            "Seen so far: 37312 samples\n",
            "0.86068827\n",
            "Training loss (for one batch) at step 1170: 1.1496\n",
            "Seen so far: 37472 samples\n",
            "0.8608561\n",
            "Training loss (for one batch) at step 1175: 0.1534\n",
            "Seen so far: 37632 samples\n",
            "0.8611288\n",
            "Training loss (for one batch) at step 1180: 0.3583\n",
            "Seen so far: 37792 samples\n",
            "0.8611876\n",
            "Training loss (for one batch) at step 1185: 0.1224\n",
            "Seen so far: 37952 samples\n",
            "0.8613512\n",
            "Training loss (for one batch) at step 1190: 0.4974\n",
            "Seen so far: 38112 samples\n",
            "0.86138225\n",
            "Training loss (for one batch) at step 1195: 0.1969\n",
            "Seen so far: 38272 samples\n",
            "0.8616743\n",
            "Training loss (for one batch) at step 1200: 0.2102\n",
            "Seen so far: 38432 samples\n",
            "0.86162573\n",
            "Training loss (for one batch) at step 1205: 0.4463\n",
            "Seen so far: 38592 samples\n",
            "0.8617071\n",
            "Training loss (for one batch) at step 1210: 0.8796\n",
            "Seen so far: 38752 samples\n",
            "0.8618136\n",
            "Training loss (for one batch) at step 1215: 0.7022\n",
            "Seen so far: 38912 samples\n",
            "0.8621248\n",
            "Training loss (for one batch) at step 1220: 0.5280\n",
            "Seen so far: 39072 samples\n",
            "0.86207515\n",
            "Training loss (for one batch) at step 1225: 0.1630\n",
            "Seen so far: 39232 samples\n",
            "0.86235726\n",
            "Training loss (for one batch) at step 1230: 0.5342\n",
            "Seen so far: 39392 samples\n",
            "0.8623071\n",
            "Training loss (for one batch) at step 1235: 0.3702\n",
            "Seen so far: 39552 samples\n",
            "0.8625354\n",
            "Training loss (for one batch) at step 1240: 0.2200\n",
            "Seen so far: 39712 samples\n",
            "0.8626108\n",
            "Training loss (for one batch) at step 1245: 0.1264\n",
            "Seen so far: 39872 samples\n",
            "0.86276084\n",
            "Training loss (for one batch) at step 1250: 0.4719\n",
            "Seen so far: 40032 samples\n",
            "0.8630596\n",
            "Training loss (for one batch) at step 1255: 1.0297\n",
            "Seen so far: 40192 samples\n",
            "0.86308223\n",
            "Training loss (for one batch) at step 1260: 0.2140\n",
            "Seen so far: 40352 samples\n",
            "0.86327815\n",
            "Training loss (for one batch) at step 1265: 0.1195\n",
            "Seen so far: 40512 samples\n",
            "0.8635466\n",
            "Training loss (for one batch) at step 1270: 0.3243\n",
            "Seen so far: 40672 samples\n",
            "0.86364084\n",
            "Training loss (for one batch) at step 1275: 0.0824\n",
            "Seen so far: 40832 samples\n",
            "0.8637588\n",
            "Training loss (for one batch) at step 1280: 0.1468\n",
            "Seen so far: 40992 samples\n",
            "0.8641442\n",
            "Training loss (for one batch) at step 1285: 0.5668\n",
            "Seen so far: 41152 samples\n",
            "0.86430794\n",
            "Training loss (for one batch) at step 1290: 0.0589\n",
            "Seen so far: 41312 samples\n",
            "0.8645672\n",
            "Training loss (for one batch) at step 1295: 0.2304\n",
            "Seen so far: 41472 samples\n",
            "0.86480033\n",
            "Training loss (for one batch) at step 1300: 0.4756\n",
            "Seen so far: 41632 samples\n",
            "0.8649837\n",
            "Training loss (for one batch) at step 1305: 0.3113\n",
            "Seen so far: 41792 samples\n",
            "0.8652852\n",
            "Training loss (for one batch) at step 1310: 0.2310\n",
            "Seen so far: 41952 samples\n",
            "0.8654891\n",
            "Training loss (for one batch) at step 1315: 0.2271\n",
            "Seen so far: 42112 samples\n",
            "0.8656915\n",
            "Training loss (for one batch) at step 1320: 0.6232\n",
            "Seen so far: 42272 samples\n",
            "0.8658923\n",
            "Training loss (for one batch) at step 1325: 0.0473\n",
            "Seen so far: 42432 samples\n",
            "0.86623305\n",
            "Training loss (for one batch) at step 1330: 0.1979\n",
            "Seen so far: 42592 samples\n",
            "0.86624247\n",
            "Training loss (for one batch) at step 1335: 0.1366\n",
            "Seen so far: 42752 samples\n",
            "0.866439\n",
            "Training loss (for one batch) at step 1340: 0.2872\n",
            "Seen so far: 42912 samples\n",
            "0.86658746\n",
            "Training loss (for one batch) at step 1345: 0.2953\n",
            "Seen so far: 43072 samples\n",
            "0.8666883\n",
            "Training loss (for one batch) at step 1350: 0.1102\n",
            "Seen so far: 43232 samples\n",
            "0.86681163\n",
            "Training loss (for one batch) at step 1355: 0.2667\n",
            "Seen so far: 43392 samples\n",
            "0.8668879\n",
            "Training loss (for one batch) at step 1360: 0.2107\n",
            "Seen so far: 43552 samples\n",
            "0.8670325\n",
            "Training loss (for one batch) at step 1365: 0.1455\n",
            "Seen so far: 43712 samples\n",
            "0.86726755\n",
            "Training loss (for one batch) at step 1370: 0.1647\n",
            "Seen so far: 43872 samples\n",
            "0.86729574\n",
            "Training loss (for one batch) at step 1375: 0.0670\n",
            "Seen so far: 44032 samples\n",
            "0.8674827\n",
            "Training loss (for one batch) at step 1380: 0.1984\n",
            "Seen so far: 44192 samples\n",
            "0.867691\n",
            "Training loss (for one batch) at step 1385: 0.2133\n",
            "Seen so far: 44352 samples\n",
            "0.8679203\n",
            "Training loss (for one batch) at step 1390: 0.1760\n",
            "Seen so far: 44512 samples\n",
            "0.8681479\n",
            "Training loss (for one batch) at step 1395: 0.2728\n",
            "Seen so far: 44672 samples\n",
            "0.86832917\n",
            "Training loss (for one batch) at step 1400: 0.2965\n",
            "Seen so far: 44832 samples\n",
            "0.8685314\n",
            "Training loss (for one batch) at step 1405: 0.1325\n",
            "Seen so far: 44992 samples\n",
            "0.86864334\n",
            "Training loss (for one batch) at step 1410: 0.2492\n",
            "Seen so far: 45152 samples\n",
            "0.868843\n",
            "Training loss (for one batch) at step 1415: 0.1783\n",
            "Seen so far: 45312 samples\n",
            "0.8691737\n",
            "Training loss (for one batch) at step 1420: 0.3621\n",
            "Seen so far: 45472 samples\n",
            "0.8692602\n",
            "Training loss (for one batch) at step 1425: 0.3223\n",
            "Seen so far: 45632 samples\n",
            "0.8694337\n",
            "Training loss (for one batch) at step 1430: 0.1115\n",
            "Seen so far: 45792 samples\n",
            "0.8697152\n",
            "Training loss (for one batch) at step 1435: 0.2517\n",
            "Seen so far: 45952 samples\n",
            "0.869886\n",
            "Training loss (for one batch) at step 1440: 0.0653\n",
            "Seen so far: 46112 samples\n",
            "0.87003386\n",
            "Training loss (for one batch) at step 1445: 0.3061\n",
            "Seen so far: 46272 samples\n",
            "0.87013745\n",
            "Training loss (for one batch) at step 1450: 0.1989\n",
            "Seen so far: 46432 samples\n",
            "0.87034804\n",
            "Training loss (for one batch) at step 1455: 0.2864\n",
            "Seen so far: 46592 samples\n",
            "0.87053573\n",
            "Training loss (for one batch) at step 1460: 0.1439\n",
            "Seen so far: 46752 samples\n",
            "0.8707221\n",
            "Training loss (for one batch) at step 1465: 0.1966\n",
            "Seen so far: 46912 samples\n",
            "0.8709285\n",
            "Training loss (for one batch) at step 1470: 0.0897\n",
            "Seen so far: 47072 samples\n",
            "0.87106985\n",
            "Training loss (for one batch) at step 1475: 0.4455\n",
            "Seen so far: 47232 samples\n",
            "0.8712102\n",
            "Training loss (for one batch) at step 1480: 0.0966\n",
            "Seen so far: 47392 samples\n",
            "0.8712652\n",
            "Training loss (for one batch) at step 1485: 0.0812\n",
            "Seen so far: 47552 samples\n",
            "0.87146705\n",
            "Training loss (for one batch) at step 1490: 0.0698\n",
            "Seen so far: 47712 samples\n",
            "0.8716885\n",
            "Training loss (for one batch) at step 1495: 0.2525\n",
            "Seen so far: 47872 samples\n",
            "0.8718458\n",
            "Training loss (for one batch) at step 1500: 0.2836\n",
            "Seen so far: 48032 samples\n",
            "0.8720436\n",
            "Training loss (for one batch) at step 1505: 0.1046\n",
            "Seen so far: 48192 samples\n",
            "0.8721987\n",
            "Training loss (for one batch) at step 1510: 0.2935\n",
            "Seen so far: 48352 samples\n",
            "0.8723734\n",
            "Training loss (for one batch) at step 1515: 0.2783\n",
            "Seen so far: 48512 samples\n",
            "0.87246454\n",
            "Training loss (for one batch) at step 1520: 0.5757\n",
            "Seen so far: 48672 samples\n",
            "0.8725345\n",
            "Training loss (for one batch) at step 1525: 0.1264\n",
            "Seen so far: 48832 samples\n",
            "0.8727269\n",
            "Training loss (for one batch) at step 1530: 0.1270\n",
            "Seen so far: 48992 samples\n",
            "0.8728772\n",
            "Training loss (for one batch) at step 1535: 0.0670\n",
            "Seen so far: 49152 samples\n",
            "0.87323\n",
            "Training loss (for one batch) at step 1540: 0.3298\n",
            "Seen so far: 49312 samples\n",
            "0.87343854\n",
            "Training loss (for one batch) at step 1545: 0.1300\n",
            "Seen so far: 49472 samples\n",
            "0.87370634\n",
            "Training loss (for one batch) at step 1550: 0.0380\n",
            "Seen so far: 49632 samples\n",
            "0.87395227\n",
            "Training loss (for one batch) at step 1555: 0.2834\n",
            "Seen so far: 49792 samples\n",
            "0.8741565\n",
            "Training loss (for one batch) at step 1560: 0.0777\n",
            "Seen so far: 49952 samples\n",
            "0.8744395\n",
            "Training loss (for one batch) at step 1565: 0.1204\n",
            "Seen so far: 50112 samples\n",
            "0.87466073\n",
            "Training loss (for one batch) at step 1570: 0.0651\n",
            "Seen so far: 50272 samples\n",
            "0.8750199\n",
            "Training loss (for one batch) at step 1575: 0.0221\n",
            "Seen so far: 50432 samples\n",
            "0.8752974\n",
            "Training loss (for one batch) at step 1580: 0.1497\n",
            "Seen so far: 50592 samples\n",
            "0.8755337\n",
            "Training loss (for one batch) at step 1585: 0.1123\n",
            "Seen so far: 50752 samples\n",
            "0.8758078\n",
            "Training loss (for one batch) at step 1590: 0.2062\n",
            "Seen so far: 50912 samples\n",
            "0.8760803\n",
            "Training loss (for one batch) at step 1595: 0.0285\n",
            "Seen so far: 51072 samples\n",
            "0.87640977\n",
            "Training loss (for one batch) at step 1600: 0.0214\n",
            "Seen so far: 51232 samples\n",
            "0.8766591\n",
            "Training loss (for one batch) at step 1605: 0.0502\n",
            "Seen so far: 51392 samples\n",
            "0.87690693\n",
            "Training loss (for one batch) at step 1610: 0.0637\n",
            "Seen so far: 51552 samples\n",
            "0.8771338\n",
            "Training loss (for one batch) at step 1615: 0.0660\n",
            "Seen so far: 51712 samples\n",
            "0.8774559\n",
            "Training loss (for one batch) at step 1620: 0.1147\n",
            "Seen so far: 51872 samples\n",
            "0.8777182\n",
            "Training loss (for one batch) at step 1625: 0.0371\n",
            "Seen so far: 52032 samples\n",
            "0.8779213\n",
            "Training loss (for one batch) at step 1630: 0.1527\n",
            "Seen so far: 52192 samples\n",
            "0.87816143\n",
            "Training loss (for one batch) at step 1635: 0.1084\n",
            "Seen so far: 52352 samples\n",
            "0.87838095\n",
            "Training loss (for one batch) at step 1640: 0.0464\n",
            "Seen so far: 52512 samples\n",
            "0.87861824\n",
            "Training loss (for one batch) at step 1645: 0.1357\n",
            "Seen so far: 52672 samples\n",
            "0.87885404\n",
            "Training loss (for one batch) at step 1650: 0.0616\n",
            "Seen so far: 52832 samples\n",
            "0.8791263\n",
            "Training loss (for one batch) at step 1655: 0.0625\n",
            "Seen so far: 52992 samples\n",
            "0.8793969\n",
            "Training loss (for one batch) at step 1660: 0.1846\n",
            "Seen so far: 53152 samples\n",
            "0.8794965\n",
            "Training loss (for one batch) at step 1665: 0.1047\n",
            "Seen so far: 53312 samples\n",
            "0.8796894\n",
            "Training loss (for one batch) at step 1670: 0.1529\n",
            "Seen so far: 53472 samples\n",
            "0.8798811\n",
            "Training loss (for one batch) at step 1675: 0.0830\n",
            "Seen so far: 53632 samples\n",
            "0.8801462\n",
            "Training loss (for one batch) at step 1680: 0.0972\n",
            "Seen so far: 53792 samples\n",
            "0.8803911\n",
            "Training loss (for one batch) at step 1685: 0.2745\n",
            "Seen so far: 53952 samples\n",
            "0.8805976\n",
            "Training loss (for one batch) at step 1690: 0.0624\n",
            "Seen so far: 54112 samples\n",
            "0.88085824\n",
            "Training loss (for one batch) at step 1695: 0.0259\n",
            "Seen so far: 54272 samples\n",
            "0.88113576\n",
            "Training loss (for one batch) at step 1700: 0.2141\n",
            "Seen so far: 54432 samples\n",
            "0.88143003\n",
            "Training loss (for one batch) at step 1705: 0.0622\n",
            "Seen so far: 54592 samples\n",
            "0.881631\n",
            "Training loss (for one batch) at step 1710: 0.0961\n",
            "Seen so far: 54752 samples\n",
            "0.88177603\n",
            "Training loss (for one batch) at step 1715: 0.1631\n",
            "Seen so far: 54912 samples\n",
            "0.8819748\n",
            "Training loss (for one batch) at step 1720: 0.0941\n",
            "Seen so far: 55072 samples\n",
            "0.8822269\n",
            "Training loss (for one batch) at step 1725: 0.0646\n",
            "Seen so far: 55232 samples\n",
            "0.8824051\n",
            "Training loss (for one batch) at step 1730: 0.5889\n",
            "Seen so far: 55392 samples\n",
            "0.88260037\n",
            "Training loss (for one batch) at step 1735: 0.0459\n",
            "Seen so far: 55552 samples\n",
            "0.8828485\n",
            "Training loss (for one batch) at step 1740: 0.1289\n",
            "Seen so far: 55712 samples\n",
            "0.8830952\n",
            "Training loss (for one batch) at step 1745: 0.0985\n",
            "Seen so far: 55872 samples\n",
            "0.8831794\n",
            "Training loss (for one batch) at step 1750: 0.2074\n",
            "Seen so far: 56032 samples\n",
            "0.8833345\n",
            "Training loss (for one batch) at step 1755: 0.1405\n",
            "Seen so far: 56192 samples\n",
            "0.88352436\n",
            "Training loss (for one batch) at step 1760: 0.1758\n",
            "Seen so far: 56352 samples\n",
            "0.8837486\n",
            "Training loss (for one batch) at step 1765: 0.0602\n",
            "Seen so far: 56512 samples\n",
            "0.88391846\n",
            "Training loss (for one batch) at step 1770: 0.0482\n",
            "Seen so far: 56672 samples\n",
            "0.8841403\n",
            "Training loss (for one batch) at step 1775: 0.2624\n",
            "Seen so far: 56832 samples\n",
            "0.88427293\n",
            "Training loss (for one batch) at step 1780: 0.3242\n",
            "Seen so far: 56992 samples\n",
            "0.88436973\n",
            "Training loss (for one batch) at step 1785: 0.1561\n",
            "Seen so far: 57152 samples\n",
            "0.88457096\n",
            "Training loss (for one batch) at step 1790: 0.0988\n",
            "Seen so far: 57312 samples\n",
            "0.8847362\n",
            "Training loss (for one batch) at step 1795: 0.0123\n",
            "Seen so far: 57472 samples\n",
            "0.88497007\n",
            "Training loss (for one batch) at step 1800: 0.1936\n",
            "Seen so far: 57632 samples\n",
            "0.8851853\n",
            "Training loss (for one batch) at step 1805: 0.2921\n",
            "Seen so far: 57792 samples\n",
            "0.8853474\n",
            "Training loss (for one batch) at step 1810: 0.1056\n",
            "Seen so far: 57952 samples\n",
            "0.88549143\n",
            "Training loss (for one batch) at step 1815: 0.0216\n",
            "Seen so far: 58112 samples\n",
            "0.88566905\n",
            "Training loss (for one batch) at step 1820: 0.1423\n",
            "Seen so far: 58272 samples\n",
            "0.88588\n",
            "Training loss (for one batch) at step 1825: 0.2184\n",
            "Seen so far: 58432 samples\n",
            "0.8860385\n",
            "Training loss (for one batch) at step 1830: 0.0416\n",
            "Seen so far: 58592 samples\n",
            "0.8862473\n",
            "Training loss (for one batch) at step 1835: 0.1104\n",
            "Seen so far: 58752 samples\n",
            "0.88640386\n",
            "Training loss (for one batch) at step 1840: 0.0159\n",
            "Seen so far: 58912 samples\n",
            "0.8865766\n",
            "Training loss (for one batch) at step 1845: 0.0621\n",
            "Seen so far: 59072 samples\n",
            "0.88679916\n",
            "Training loss (for one batch) at step 1850: 0.0514\n",
            "Seen so far: 59232 samples\n",
            "0.88696986\n",
            "Training loss (for one batch) at step 1855: 0.0483\n",
            "Seen so far: 59392 samples\n",
            "0.8871902\n",
            "Training loss (for one batch) at step 1860: 0.0963\n",
            "Seen so far: 59552 samples\n",
            "0.8874429\n",
            "Training loss (for one batch) at step 1865: 0.1022\n",
            "Seen so far: 59712 samples\n",
            "0.8876273\n",
            "Training loss (for one batch) at step 1870: 0.3073\n",
            "Seen so far: 59872 samples\n",
            "0.8877606\n",
            "Training loss (for one batch) at step 1875: 0.0347\n",
            "Seen so far: 60032 samples\n",
            "0.8879764\n",
            "Training loss (for one batch) at step 1880: 0.1090\n",
            "Seen so far: 60192 samples\n",
            "0.88817453\n",
            "Training loss (for one batch) at step 1885: 0.0677\n",
            "Seen so far: 60352 samples\n",
            "0.8882887\n",
            "Training loss (for one batch) at step 1890: 0.1097\n",
            "Seen so far: 60512 samples\n",
            "0.88848495\n",
            "Training loss (for one batch) at step 1895: 0.1458\n",
            "Seen so far: 60672 samples\n",
            "0.8886142\n",
            "Training loss (for one batch) at step 1900: 0.2402\n",
            "Seen so far: 60832 samples\n",
            "0.8887592\n",
            "Training loss (for one batch) at step 1905: 0.0603\n",
            "Seen so far: 60992 samples\n",
            "0.88896906\n",
            "Training loss (for one batch) at step 1910: 0.0050\n",
            "Seen so far: 61152 samples\n",
            "0.88921046\n",
            "Training loss (for one batch) at step 1915: 0.1327\n",
            "Seen so far: 61312 samples\n",
            "0.8893365\n",
            "Training loss (for one batch) at step 1920: 0.0726\n",
            "Seen so far: 61472 samples\n",
            "0.88954324\n",
            "Training loss (for one batch) at step 1925: 0.2091\n",
            "Seen so far: 61632 samples\n",
            "0.8896839\n",
            "Training loss (for one batch) at step 1930: 0.4426\n",
            "Seen so far: 61792 samples\n",
            "0.8898725\n",
            "Training loss (for one batch) at step 1935: 0.0159\n",
            "Seen so far: 61952 samples\n",
            "0.89002776\n",
            "Training loss (for one batch) at step 1940: 0.0717\n",
            "Seen so far: 62112 samples\n",
            "0.89016616\n",
            "Training loss (for one batch) at step 1945: 0.0181\n",
            "Seen so far: 62272 samples\n",
            "0.89036804\n",
            "Training loss (for one batch) at step 1950: 0.0546\n",
            "Seen so far: 62432 samples\n",
            "0.8905689\n",
            "Training loss (for one batch) at step 1955: 0.1070\n",
            "Seen so far: 62592 samples\n",
            "0.8906889\n",
            "Training loss (for one batch) at step 1960: 0.2517\n",
            "Seen so far: 62752 samples\n",
            "0.8908879\n",
            "Training loss (for one batch) at step 1965: 0.0094\n",
            "Seen so far: 62912 samples\n",
            "0.89110184\n",
            "Training loss (for one batch) at step 1970: 0.0398\n",
            "Seen so far: 63072 samples\n",
            "0.891283\n",
            "Training loss (for one batch) at step 1975: 0.0322\n",
            "Seen so far: 63232 samples\n",
            "0.8914948\n",
            "Training loss (for one batch) at step 1980: 0.0972\n",
            "Seen so far: 63392 samples\n",
            "0.89165825\n",
            "Training loss (for one batch) at step 1985: 0.0894\n",
            "Seen so far: 63552 samples\n",
            "0.8918523\n",
            "Training loss (for one batch) at step 1990: 0.4032\n",
            "Seen so far: 63712 samples\n",
            "0.89204544\n",
            "Training loss (for one batch) at step 1995: 0.0475\n",
            "Seen so far: 63872 samples\n",
            "0.8922533\n",
            "Training loss (for one batch) at step 2000: 0.0507\n",
            "Seen so far: 64032 samples\n",
            "0.8924288\n",
            "Training loss (for one batch) at step 2005: 0.0444\n",
            "Seen so far: 64192 samples\n",
            "0.8926502\n",
            "Training loss (for one batch) at step 2010: 0.0439\n",
            "Seen so far: 64352 samples\n",
            "0.892886\n",
            "Training loss (for one batch) at step 2015: 0.0117\n",
            "Seen so far: 64512 samples\n",
            "0.89304316\n",
            "Training loss (for one batch) at step 2020: 0.3637\n",
            "Seen so far: 64672 samples\n",
            "0.893215\n",
            "Training loss (for one batch) at step 2025: 0.0406\n",
            "Seen so far: 64832 samples\n",
            "0.8934168\n",
            "Training loss (for one batch) at step 2030: 0.0308\n",
            "Seen so far: 64992 samples\n",
            "0.8935869\n",
            "Training loss (for one batch) at step 2035: 0.0679\n",
            "Seen so far: 65152 samples\n",
            "0.89378685\n",
            "Training loss (for one batch) at step 2040: 0.3362\n",
            "Seen so far: 65312 samples\n",
            "0.89393985\n",
            "Training loss (for one batch) at step 2045: 0.0242\n",
            "Seen so far: 65472 samples\n",
            "0.8940463\n",
            "Training loss (for one batch) at step 2050: 0.0779\n",
            "Seen so far: 65632 samples\n",
            "0.8942284\n",
            "Training loss (for one batch) at step 2055: 0.0779\n",
            "Seen so far: 65792 samples\n",
            "0.89439446\n",
            "Training loss (for one batch) at step 2060: 0.2007\n",
            "Seen so far: 65952 samples\n",
            "0.894499\n",
            "Training loss (for one batch) at step 2065: 0.1821\n",
            "Seen so far: 66112 samples\n",
            "0.89463335\n",
            "Training loss (for one batch) at step 2070: 0.1030\n",
            "Seen so far: 66272 samples\n",
            "0.8948123\n",
            "Training loss (for one batch) at step 2075: 0.1040\n",
            "Seen so far: 66432 samples\n",
            "0.8949302\n",
            "Training loss (for one batch) at step 2080: 0.0612\n",
            "Seen so far: 66592 samples\n",
            "0.8950925\n",
            "Training loss (for one batch) at step 2085: 0.0386\n",
            "Seen so far: 66752 samples\n",
            "0.89511925\n",
            "Training loss (for one batch) at step 2090: 0.1062\n",
            "Seen so far: 66912 samples\n",
            "0.89528036\n",
            "Training loss (for one batch) at step 2095: 0.1123\n",
            "Seen so far: 67072 samples\n",
            "0.895396\n",
            "Training loss (for one batch) at step 2100: 0.0574\n",
            "Seen so far: 67232 samples\n",
            "0.8954962\n",
            "Training loss (for one batch) at step 2105: 0.3011\n",
            "Seen so far: 67392 samples\n",
            "0.89553654\n",
            "Training loss (for one batch) at step 2110: 0.1331\n",
            "Seen so far: 67552 samples\n",
            "0.89568037\n",
            "Training loss (for one batch) at step 2115: 0.0402\n",
            "Seen so far: 67712 samples\n",
            "0.895794\n",
            "Training loss (for one batch) at step 2120: 0.1547\n",
            "Seen so far: 67872 samples\n",
            "0.8959365\n",
            "Training loss (for one batch) at step 2125: 0.0746\n",
            "Seen so far: 68032 samples\n",
            "0.89599013\n",
            "Training loss (for one batch) at step 2130: 0.1726\n",
            "Seen so far: 68192 samples\n",
            "0.89611685\n",
            "Training loss (for one batch) at step 2135: 0.0920\n",
            "Seen so far: 68352 samples\n",
            "0.8962576\n",
            "Training loss (for one batch) at step 2140: 0.0549\n",
            "Seen so far: 68512 samples\n",
            "0.8964123\n",
            "Training loss (for one batch) at step 2145: 0.0280\n",
            "Seen so far: 68672 samples\n",
            "0.89660996\n",
            "Training loss (for one batch) at step 2150: 0.1576\n",
            "Seen so far: 68832 samples\n",
            "0.89670503\n",
            "Training loss (for one batch) at step 2155: 0.0524\n",
            "Seen so far: 68992 samples\n",
            "0.8968866\n",
            "Training loss (for one batch) at step 2160: 0.0241\n",
            "Seen so far: 69152 samples\n",
            "0.8970529\n",
            "Training loss (for one batch) at step 2165: 0.1857\n",
            "Seen so far: 69312 samples\n",
            "0.8971895\n",
            "Training loss (for one batch) at step 2170: 0.0343\n",
            "Seen so far: 69472 samples\n",
            "0.8973687\n",
            "Training loss (for one batch) at step 2175: 0.0477\n",
            "Seen so far: 69632 samples\n",
            "0.89753276\n",
            "Training loss (for one batch) at step 2180: 0.0949\n",
            "Seen so far: 69792 samples\n",
            "0.89765304\n",
            "Training loss (for one batch) at step 2185: 0.1162\n",
            "Seen so far: 69952 samples\n",
            "0.89782995\n",
            "Training loss (for one batch) at step 2190: 0.2352\n",
            "Seen so far: 70112 samples\n",
            "0.898006\n",
            "Training loss (for one batch) at step 2195: 0.0157\n",
            "Seen so far: 70272 samples\n",
            "0.8981102\n",
            "Training loss (for one batch) at step 2200: 0.0277\n",
            "Seen so far: 70432 samples\n",
            "0.8982565\n",
            "Training loss (for one batch) at step 2205: 0.0231\n",
            "Seen so far: 70592 samples\n",
            "0.8983879\n",
            "Training loss (for one batch) at step 2210: 0.0518\n",
            "Seen so far: 70752 samples\n",
            "0.89851874\n",
            "Training loss (for one batch) at step 2215: 0.0102\n",
            "Seen so far: 70912 samples\n",
            "0.8986631\n",
            "Training loss (for one batch) at step 2220: 0.1504\n",
            "Seen so far: 71072 samples\n",
            "0.8987928\n",
            "Training loss (for one batch) at step 2225: 0.2217\n",
            "Seen so far: 71232 samples\n",
            "0.8989078\n",
            "Training loss (for one batch) at step 2230: 0.0859\n",
            "Seen so far: 71392 samples\n",
            "0.8990503\n",
            "Training loss (for one batch) at step 2235: 0.1329\n",
            "Seen so far: 71552 samples\n",
            "0.8991782\n",
            "Training loss (for one batch) at step 2240: 0.2321\n",
            "Seen so far: 71712 samples\n",
            "0.89926374\n",
            "Training loss (for one batch) at step 2245: 0.1990\n",
            "Seen so far: 71872 samples\n",
            "0.8993349\n",
            "Training loss (for one batch) at step 2250: 0.0579\n",
            "Seen so far: 72032 samples\n",
            "0.8994752\n",
            "Training loss (for one batch) at step 2255: 0.0332\n",
            "Seen so far: 72192 samples\n",
            "0.89962876\n",
            "Training loss (for one batch) at step 2260: 0.1066\n",
            "Seen so far: 72352 samples\n",
            "0.89978164\n",
            "Training loss (for one batch) at step 2265: 0.1013\n",
            "Seen so far: 72512 samples\n",
            "0.8999338\n",
            "Training loss (for one batch) at step 2270: 0.0306\n",
            "Seen so far: 72672 samples\n",
            "0.90007156\n",
            "Training loss (for one batch) at step 2275: 0.2133\n",
            "Seen so far: 72832 samples\n",
            "0.9001675\n",
            "Training loss (for one batch) at step 2280: 0.1060\n",
            "Seen so far: 72992 samples\n",
            "0.9002631\n",
            "Training loss (for one batch) at step 2285: 0.2472\n",
            "Seen so far: 73152 samples\n",
            "0.9003855\n",
            "Training loss (for one batch) at step 2290: 0.1400\n",
            "Seen so far: 73312 samples\n",
            "0.90048015\n",
            "Training loss (for one batch) at step 2295: 0.0228\n",
            "Seen so far: 73472 samples\n",
            "0.90060157\n",
            "Training loss (for one batch) at step 2300: 0.1813\n",
            "Seen so far: 73632 samples\n",
            "0.9006682\n",
            "Training loss (for one batch) at step 2305: 0.0041\n",
            "Seen so far: 73792 samples\n",
            "0.9008294\n",
            "Training loss (for one batch) at step 2310: 0.0845\n",
            "Seen so far: 73952 samples\n",
            "0.90093577\n",
            "Training loss (for one batch) at step 2315: 0.0748\n",
            "Seen so far: 74112 samples\n",
            "0.90105516\n",
            "Training loss (for one batch) at step 2320: 0.0815\n",
            "Seen so far: 74272 samples\n",
            "0.9011606\n",
            "Training loss (for one batch) at step 2325: 0.0062\n",
            "Seen so far: 74432 samples\n",
            "0.90133274\n",
            "Training loss (for one batch) at step 2330: 0.3195\n",
            "Seen so far: 74592 samples\n",
            "0.9013835\n",
            "Training loss (for one batch) at step 2335: 0.0432\n",
            "Seen so far: 74752 samples\n",
            "0.9015277\n",
            "Training loss (for one batch) at step 2340: 0.0169\n",
            "Seen so far: 74912 samples\n",
            "0.90168464\n",
            "Training loss (for one batch) at step 2345: 0.0170\n",
            "Seen so far: 75072 samples\n",
            "0.90178764\n",
            "Training loss (for one batch) at step 2350: 0.1278\n",
            "Seen so far: 75232 samples\n",
            "0.90193003\n",
            "Training loss (for one batch) at step 2355: 0.0956\n",
            "Seen so far: 75392 samples\n",
            "0.90209836\n",
            "Training loss (for one batch) at step 2360: 0.0633\n",
            "Seen so far: 75552 samples\n",
            "0.90222627\n",
            "Training loss (for one batch) at step 2365: 0.1087\n",
            "Seen so far: 75712 samples\n",
            "0.9023405\n",
            "Training loss (for one batch) at step 2370: 0.2566\n",
            "Seen so far: 75872 samples\n",
            "0.9023487\n",
            "Training loss (for one batch) at step 2375: 0.0725\n",
            "Seen so far: 76032 samples\n",
            "0.9024884\n",
            "Training loss (for one batch) at step 2380: 0.0869\n",
            "Seen so far: 76192 samples\n",
            "0.90256196\n",
            "Training loss (for one batch) at step 2385: 0.5447\n",
            "Seen so far: 76352 samples\n",
            "0.90270066\n",
            "Training loss (for one batch) at step 2390: 0.1664\n",
            "Seen so far: 76512 samples\n",
            "0.9028518\n",
            "Training loss (for one batch) at step 2395: 0.0994\n",
            "Seen so far: 76672 samples\n",
            "0.9029241\n",
            "Training loss (for one batch) at step 2400: 0.1889\n",
            "Seen so far: 76832 samples\n",
            "0.9030092\n",
            "Training loss (for one batch) at step 2405: 0.2714\n",
            "Seen so far: 76992 samples\n",
            "0.9031588\n",
            "Training loss (for one batch) at step 2410: 0.0366\n",
            "Seen so far: 77152 samples\n",
            "0.90330774\n",
            "Training loss (for one batch) at step 2415: 0.0717\n",
            "Seen so far: 77312 samples\n",
            "0.9034432\n",
            "Training loss (for one batch) at step 2420: 0.2437\n",
            "Seen so far: 77472 samples\n",
            "0.90355223\n",
            "Training loss (for one batch) at step 2425: 0.2132\n",
            "Seen so far: 77632 samples\n",
            "0.9035836\n",
            "Training loss (for one batch) at step 2430: 0.2347\n",
            "Seen so far: 77792 samples\n",
            "0.9036662\n",
            "Training loss (for one batch) at step 2435: 0.0598\n",
            "Seen so far: 77952 samples\n",
            "0.9037998\n",
            "Training loss (for one batch) at step 2440: 0.0134\n",
            "Seen so far: 78112 samples\n",
            "0.9039456\n",
            "Training loss (for one batch) at step 2445: 0.0165\n",
            "Seen so far: 78272 samples\n",
            "0.90405256\n",
            "Training loss (for one batch) at step 2450: 0.2450\n",
            "Seen so far: 78432 samples\n",
            "0.90417176\n",
            "Training loss (for one batch) at step 2455: 0.1294\n",
            "Seen so far: 78592 samples\n",
            "0.90431595\n",
            "Training loss (for one batch) at step 2460: 0.0585\n",
            "Seen so far: 78752 samples\n",
            "0.90443414\n",
            "Training loss (for one batch) at step 2465: 0.3833\n",
            "Seen so far: 78912 samples\n",
            "0.9044632\n",
            "Training loss (for one batch) at step 2470: 0.0678\n",
            "Seen so far: 79072 samples\n",
            "0.90453005\n",
            "Training loss (for one batch) at step 2475: 0.0220\n",
            "Seen so far: 79232 samples\n",
            "0.90471023\n",
            "Training loss (for one batch) at step 2480: 0.0268\n",
            "Seen so far: 79392 samples\n",
            "0.90485185\n",
            "Training loss (for one batch) at step 2485: 0.0655\n",
            "Seen so far: 79552 samples\n",
            "0.9050181\n",
            "Training loss (for one batch) at step 2490: 0.1242\n",
            "Seen so far: 79712 samples\n",
            "0.905146\n",
            "Training loss (for one batch) at step 2495: 0.0034\n",
            "Seen so far: 79872 samples\n",
            "0.905311\n",
            "Training loss (for one batch) at step 2500: 0.0972\n",
            "Seen so far: 80032 samples\n",
            "0.9054253\n",
            "Training loss (for one batch) at step 2505: 0.1237\n",
            "Seen so far: 80192 samples\n",
            "0.90551424\n",
            "Training loss (for one batch) at step 2510: 0.0193\n",
            "Seen so far: 80352 samples\n",
            "0.9056775\n",
            "Training loss (for one batch) at step 2515: 0.2055\n",
            "Seen so far: 80512 samples\n",
            "0.90577805\n",
            "Training loss (for one batch) at step 2520: 0.0115\n",
            "Seen so far: 80672 samples\n",
            "0.9059153\n",
            "Training loss (for one batch) at step 2525: 0.1055\n",
            "Seen so far: 80832 samples\n",
            "0.9060273\n",
            "Training loss (for one batch) at step 2530: 0.0775\n",
            "Seen so far: 80992 samples\n",
            "0.9061636\n",
            "Training loss (for one batch) at step 2535: 0.0543\n",
            "Seen so far: 81152 samples\n",
            "0.9062993\n",
            "Training loss (for one batch) at step 2540: 0.1910\n",
            "Seen so far: 81312 samples\n",
            "0.90644675\n",
            "Training loss (for one batch) at step 2545: 0.0184\n",
            "Seen so far: 81472 samples\n",
            "0.9065937\n",
            "Training loss (for one batch) at step 2550: 0.3250\n",
            "Seen so far: 81632 samples\n",
            "0.9066665\n",
            "Training loss (for one batch) at step 2555: 0.0863\n",
            "Seen so far: 81792 samples\n",
            "0.90672684\n",
            "Training loss (for one batch) at step 2560: 0.1916\n",
            "Seen so far: 81952 samples\n",
            "0.9068113\n",
            "Training loss (for one batch) at step 2565: 0.0494\n",
            "Seen so far: 82112 samples\n",
            "0.9069076\n",
            "Training loss (for one batch) at step 2570: 0.0392\n",
            "Seen so far: 82272 samples\n",
            "0.9070036\n",
            "Training loss (for one batch) at step 2575: 0.0577\n",
            "Seen so far: 82432 samples\n",
            "0.9071113\n",
            "Training loss (for one batch) at step 2580: 0.0582\n",
            "Seen so far: 82592 samples\n",
            "0.90721864\n",
            "Training loss (for one batch) at step 2585: 0.0029\n",
            "Seen so far: 82752 samples\n",
            "0.90727717\n",
            "Training loss (for one batch) at step 2590: 0.0436\n",
            "Seen so far: 82912 samples\n",
            "0.9074079\n",
            "Training loss (for one batch) at step 2595: 0.0029\n",
            "Seen so far: 83072 samples\n",
            "0.90756214\n",
            "Training loss (for one batch) at step 2600: 0.0731\n",
            "Seen so far: 83232 samples\n",
            "0.9075596\n",
            "Training loss (for one batch) at step 2605: 0.4045\n",
            "Seen so far: 83392 samples\n",
            "0.90761703\n",
            "Training loss (for one batch) at step 2610: 0.2167\n",
            "Seen so far: 83552 samples\n",
            "0.9077461\n",
            "Training loss (for one batch) at step 2615: 0.1032\n",
            "Seen so far: 83712 samples\n",
            "0.90786266\n",
            "Training loss (for one batch) at step 2620: 0.0677\n",
            "Seen so far: 83872 samples\n",
            "0.90793115\n",
            "Training loss (for one batch) at step 2625: 0.1989\n",
            "Seen so far: 84032 samples\n",
            "0.907916\n",
            "Training loss (for one batch) at step 2630: 0.2201\n",
            "Seen so far: 84192 samples\n",
            "0.907996\n",
            "Training loss (for one batch) at step 2635: 0.0949\n",
            "Seen so far: 84352 samples\n",
            "0.9080994\n",
            "Training loss (for one batch) at step 2640: 0.0351\n",
            "Seen so far: 84512 samples\n",
            "0.90811956\n",
            "Training loss (for one batch) at step 2645: 0.0300\n",
            "Seen so far: 84672 samples\n",
            "0.9082459\n",
            "Training loss (for one batch) at step 2650: 0.1666\n",
            "Seen so far: 84832 samples\n",
            "0.9083247\n",
            "Training loss (for one batch) at step 2655: 0.1615\n",
            "Seen so far: 84992 samples\n",
            "0.90840316\n",
            "Training loss (for one batch) at step 2660: 0.1052\n",
            "Seen so far: 85152 samples\n",
            "0.9084461\n",
            "Training loss (for one batch) at step 2665: 0.1688\n",
            "Seen so far: 85312 samples\n",
            "0.90860605\n",
            "Training loss (for one batch) at step 2670: 0.0252\n",
            "Seen so far: 85472 samples\n",
            "0.90870696\n",
            "Training loss (for one batch) at step 2675: 0.0319\n",
            "Seen so far: 85632 samples\n",
            "0.9087841\n",
            "Training loss (for one batch) at step 2680: 0.0722\n",
            "Seen so far: 85792 samples\n",
            "0.9089076\n",
            "Training loss (for one batch) at step 2685: 0.1336\n",
            "Seen so far: 85952 samples\n",
            "0.9089608\n",
            "Training loss (for one batch) at step 2690: 0.2700\n",
            "Seen so far: 86112 samples\n",
            "0.90902543\n",
            "Training loss (for one batch) at step 2695: 0.1386\n",
            "Seen so far: 86272 samples\n",
            "0.90907824\n",
            "Training loss (for one batch) at step 2700: 0.1950\n",
            "Seen so far: 86432 samples\n",
            "0.9090152\n",
            "Training loss (for one batch) at step 2705: 0.2400\n",
            "Seen so far: 86592 samples\n",
            "0.9090332\n",
            "Training loss (for one batch) at step 2710: 0.4000\n",
            "Seen so far: 86752 samples\n",
            "0.9090626\n",
            "Training loss (for one batch) at step 2715: 0.3708\n",
            "Seen so far: 86912 samples\n",
            "0.90914947\n",
            "Training loss (for one batch) at step 2720: 0.2102\n",
            "Seen so far: 87072 samples\n",
            "0.90915567\n",
            "Training loss (for one batch) at step 2725: 0.0226\n",
            "Seen so far: 87232 samples\n",
            "0.90916175\n",
            "Training loss (for one batch) at step 2730: 0.1778\n",
            "Seen so far: 87392 samples\n",
            "0.9091908\n",
            "Training loss (for one batch) at step 2735: 0.4482\n",
            "Seen so far: 87552 samples\n",
            "0.90915114\n",
            "Training loss (for one batch) at step 2740: 0.2025\n",
            "Seen so far: 87712 samples\n",
            "0.90916866\n",
            "Training loss (for one batch) at step 2745: 0.0859\n",
            "Seen so far: 87872 samples\n",
            "0.90919745\n",
            "Training loss (for one batch) at step 2750: 0.0585\n",
            "Seen so far: 88032 samples\n",
            "0.909283\n",
            "Training loss (for one batch) at step 2755: 0.2524\n",
            "Seen so far: 88192 samples\n",
            "0.9093342\n",
            "Training loss (for one batch) at step 2760: 0.0794\n",
            "Seen so far: 88352 samples\n",
            "0.9094078\n",
            "Training loss (for one batch) at step 2765: 0.0511\n",
            "Seen so far: 88512 samples\n",
            "0.9094699\n",
            "Training loss (for one batch) at step 2770: 0.1677\n",
            "Seen so far: 88672 samples\n",
            "0.90956557\n",
            "Training loss (for one batch) at step 2775: 0.1031\n",
            "Seen so far: 88832 samples\n",
            "0.90960467\n",
            "Training loss (for one batch) at step 2780: 0.1262\n",
            "Seen so far: 88992 samples\n",
            "0.90966606\n",
            "Training loss (for one batch) at step 2785: 0.1683\n",
            "Seen so far: 89152 samples\n",
            "0.90970474\n",
            "Training loss (for one batch) at step 2790: 0.5073\n",
            "Seen so far: 89312 samples\n",
            "0.9097546\n",
            "Training loss (for one batch) at step 2795: 0.1560\n",
            "Seen so far: 89472 samples\n",
            "0.909793\n",
            "Training loss (for one batch) at step 2800: 0.1560\n",
            "Seen so far: 89632 samples\n",
            "0.9098759\n",
            "Training loss (for one batch) at step 2805: 0.0657\n",
            "Seen so far: 89792 samples\n",
            "0.9098917\n",
            "Training loss (for one batch) at step 2810: 0.0064\n",
            "Seen so far: 89952 samples\n",
            "0.9099742\n",
            "Training loss (for one batch) at step 2815: 0.0543\n",
            "Seen so far: 90112 samples\n",
            "0.9099676\n",
            "Training loss (for one batch) at step 2820: 0.2973\n",
            "Seen so far: 90272 samples\n",
            "0.91002744\n",
            "Training loss (for one batch) at step 2825: 0.4419\n",
            "Seen so far: 90432 samples\n",
            "0.9101314\n",
            "Training loss (for one batch) at step 2830: 0.0273\n",
            "Seen so far: 90592 samples\n",
            "0.9101466\n",
            "Training loss (for one batch) at step 2835: 0.2517\n",
            "Seen so far: 90752 samples\n",
            "0.9102389\n",
            "Training loss (for one batch) at step 2840: 0.3628\n",
            "Seen so far: 90912 samples\n",
            "0.9102979\n",
            "Training loss (for one batch) at step 2845: 0.0488\n",
            "Seen so far: 91072 samples\n",
            "0.9103457\n",
            "Training loss (for one batch) at step 2850: 0.2356\n",
            "Seen so far: 91232 samples\n",
            "0.9103933\n",
            "Training loss (for one batch) at step 2855: 0.1467\n",
            "Seen so far: 91392 samples\n",
            "0.9104517\n",
            "Training loss (for one batch) at step 2860: 0.3232\n",
            "Seen so far: 91552 samples\n",
            "0.910488\n",
            "Training loss (for one batch) at step 2865: 0.0632\n",
            "Seen so far: 91712 samples\n",
            "0.9105679\n",
            "Training loss (for one batch) at step 2870: 0.1548\n",
            "Seen so far: 91872 samples\n",
            "0.91063654\n",
            "Training loss (for one batch) at step 2875: 0.2183\n",
            "Seen so far: 92032 samples\n",
            "0.9107484\n",
            "Training loss (for one batch) at step 2880: 0.0236\n",
            "Seen so far: 92192 samples\n",
            "0.910784\n",
            "Training loss (for one batch) at step 2885: 0.2129\n",
            "Seen so far: 92352 samples\n",
            "0.9108303\n",
            "Training loss (for one batch) at step 2890: 0.1422\n",
            "Seen so far: 92512 samples\n",
            "0.91087645\n",
            "Training loss (for one batch) at step 2895: 0.0599\n",
            "Seen so far: 92672 samples\n",
            "0.910944\n",
            "Training loss (for one batch) at step 2900: 0.4050\n",
            "Seen so far: 92832 samples\n",
            "0.9110113\n",
            "Training loss (for one batch) at step 2905: 0.0233\n",
            "Seen so far: 92992 samples\n",
            "0.9110676\n",
            "Training loss (for one batch) at step 2910: 0.0074\n",
            "Seen so far: 93152 samples\n",
            "0.911113\n",
            "Training loss (for one batch) at step 2915: 0.0715\n",
            "Seen so far: 93312 samples\n",
            "0.9112226\n",
            "Training loss (for one batch) at step 2920: 0.1821\n",
            "Seen so far: 93472 samples\n",
            "0.9112675\n",
            "Training loss (for one batch) at step 2925: 0.0055\n",
            "Seen so far: 93632 samples\n",
            "0.9113017\n",
            "Training loss (for one batch) at step 2930: 0.0610\n",
            "Seen so far: 93792 samples\n",
            "0.91138905\n",
            "Training loss (for one batch) at step 2935: 0.2792\n",
            "Seen so far: 93952 samples\n",
            "0.91142285\n",
            "Training loss (for one batch) at step 2940: 0.2081\n",
            "Seen so far: 94112 samples\n",
            "0.9114459\n",
            "Training loss (for one batch) at step 2945: 0.0294\n",
            "Seen so far: 94272 samples\n",
            "0.91151136\n",
            "Training loss (for one batch) at step 2950: 0.3439\n",
            "Seen so far: 94432 samples\n",
            "0.91153425\n",
            "Training loss (for one batch) at step 2955: 0.0875\n",
            "Seen so far: 94592 samples\n",
            "0.91162044\n",
            "Training loss (for one batch) at step 2960: 0.1394\n",
            "Seen so far: 94752 samples\n",
            "0.9116747\n",
            "Training loss (for one batch) at step 2965: 0.1115\n",
            "Seen so far: 94912 samples\n",
            "0.9117709\n",
            "Training loss (for one batch) at step 2970: 0.1830\n",
            "Seen so far: 95072 samples\n",
            "0.91183525\n",
            "Training loss (for one batch) at step 2975: 0.3105\n",
            "Seen so far: 95232 samples\n",
            "0.91187835\n",
            "Training loss (for one batch) at step 2980: 0.0969\n",
            "Seen so far: 95392 samples\n",
            "0.91190034\n",
            "Training loss (for one batch) at step 2985: 0.0967\n",
            "Seen so far: 95552 samples\n",
            "0.9119642\n",
            "Training loss (for one batch) at step 2990: 0.0587\n",
            "Seen so far: 95712 samples\n",
            "0.91206956\n",
            "Training loss (for one batch) at step 2995: 0.0381\n",
            "Seen so far: 95872 samples\n",
            "0.91216415\n",
            "Training loss (for one batch) at step 3000: 0.0567\n",
            "Seen so far: 96032 samples\n",
            "0.9122688\n",
            "Training loss (for one batch) at step 3005: 0.1794\n",
            "Seen so far: 96192 samples\n",
            "0.9123108\n",
            "Training loss (for one batch) at step 3010: 0.1811\n",
            "Seen so far: 96352 samples\n",
            "0.91237336\n",
            "Training loss (for one batch) at step 3015: 0.6492\n",
            "Seen so far: 96512 samples\n",
            "0.912415\n",
            "Training loss (for one batch) at step 3020: 0.3702\n",
            "Seen so far: 96672 samples\n",
            "0.9124669\n",
            "Training loss (for one batch) at step 3025: 0.0135\n",
            "Seen so far: 96832 samples\n",
            "0.91254956\n",
            "Training loss (for one batch) at step 3030: 0.1481\n",
            "Seen so far: 96992 samples\n",
            "0.9125495\n",
            "Training loss (for one batch) at step 3035: 0.0651\n",
            "Seen so far: 97152 samples\n",
            "0.9126009\n",
            "Training loss (for one batch) at step 3040: 0.2990\n",
            "Seen so far: 97312 samples\n",
            "0.91267264\n",
            "Training loss (for one batch) at step 3045: 0.1857\n",
            "Seen so far: 97472 samples\n",
            "0.9127544\n",
            "Training loss (for one batch) at step 3050: 0.2973\n",
            "Seen so far: 97632 samples\n",
            "0.91278476\n",
            "Training loss (for one batch) at step 3055: 0.2385\n",
            "Seen so far: 97792 samples\n",
            "0.91286606\n",
            "Training loss (for one batch) at step 3060: 0.1665\n",
            "Seen so far: 97952 samples\n",
            "0.91291654\n",
            "Training loss (for one batch) at step 3065: 0.1785\n",
            "Seen so far: 98112 samples\n",
            "0.9129668\n",
            "Training loss (for one batch) at step 3070: 0.1216\n",
            "Seen so far: 98272 samples\n",
            "0.913078\n",
            "Training loss (for one batch) at step 3075: 0.0582\n",
            "Seen so far: 98432 samples\n",
            "0.9131786\n",
            "Training loss (for one batch) at step 3080: 0.0158\n",
            "Seen so far: 98592 samples\n",
            "0.913279\n",
            "Training loss (for one batch) at step 3085: 0.0158\n",
            "Seen so far: 98752 samples\n",
            "0.9133891\n",
            "Training loss (for one batch) at step 3090: 0.0921\n",
            "Seen so far: 98912 samples\n",
            "0.91342807\n",
            "Training loss (for one batch) at step 3095: 0.0106\n",
            "Seen so far: 99072 samples\n",
            "0.91350734\n",
            "Training loss (for one batch) at step 3100: 0.0592\n",
            "Seen so far: 99232 samples\n",
            "0.9136065\n",
            "Training loss (for one batch) at step 3105: 0.0204\n",
            "Seen so far: 99392 samples\n",
            "0.9136751\n",
            "Training loss (for one batch) at step 3110: 0.0600\n",
            "Seen so far: 99552 samples\n",
            "0.91376364\n",
            "Training loss (for one batch) at step 3115: 0.2836\n",
            "Seen so far: 99712 samples\n",
            "0.91386193\n",
            "Training loss (for one batch) at step 3120: 0.0312\n",
            "Seen so far: 99872 samples\n",
            "0.91394985\n",
            "Training loss (for one batch) at step 3125: 0.3636\n",
            "Seen so far: 100032 samples\n",
            "0.9140375\n",
            "Training loss (for one batch) at step 3130: 0.0774\n",
            "Seen so far: 100192 samples\n",
            "0.91410494\n",
            "Training loss (for one batch) at step 3135: 0.0628\n",
            "Seen so far: 100352 samples\n",
            "0.9141721\n",
            "Training loss (for one batch) at step 3140: 0.1045\n",
            "Seen so far: 100512 samples\n",
            "0.91424906\n",
            "Training loss (for one batch) at step 3145: 0.0520\n",
            "Seen so far: 100672 samples\n",
            "0.9143754\n",
            "Training loss (for one batch) at step 3150: 0.0483\n",
            "Seen so far: 100832 samples\n",
            "0.9144319\n",
            "Training loss (for one batch) at step 3155: 0.2094\n",
            "Seen so far: 100992 samples\n",
            "0.914518\n",
            "Training loss (for one batch) at step 3160: 0.0238\n",
            "Seen so far: 101152 samples\n",
            "0.91461366\n",
            "Training loss (for one batch) at step 3165: 0.0094\n",
            "Seen so far: 101312 samples\n",
            "0.91469914\n",
            "Training loss (for one batch) at step 3170: 0.0648\n",
            "Seen so far: 101472 samples\n",
            "0.91476464\n",
            "Training loss (for one batch) at step 3175: 0.2114\n",
            "Seen so far: 101632 samples\n",
            "0.91479063\n",
            "Training loss (for one batch) at step 3180: 0.2914\n",
            "Seen so far: 101792 samples\n",
            "0.9148656\n",
            "Training loss (for one batch) at step 3185: 0.0934\n",
            "Seen so far: 101952 samples\n",
            "0.9148913\n",
            "Training loss (for one batch) at step 3190: 0.0622\n",
            "Seen so far: 102112 samples\n",
            "0.9149659\n",
            "Training loss (for one batch) at step 3195: 0.0272\n",
            "Seen so far: 102272 samples\n",
            "0.9150501\n",
            "Training loss (for one batch) at step 3200: 0.0877\n",
            "Seen so far: 102432 samples\n",
            "0.9150949\n",
            "Training loss (for one batch) at step 3205: 0.0451\n",
            "Seen so far: 102592 samples\n",
            "0.9151883\n",
            "Training loss (for one batch) at step 3210: 0.0123\n",
            "Seen so far: 102752 samples\n",
            "0.9152717\n",
            "Training loss (for one batch) at step 3215: 0.0231\n",
            "Seen so far: 102912 samples\n",
            "0.91535485\n",
            "Training loss (for one batch) at step 3220: 0.1231\n",
            "Seen so far: 103072 samples\n",
            "0.9153795\n",
            "Training loss (for one batch) at step 3225: 0.0438\n",
            "Seen so far: 103232 samples\n",
            "0.9154526\n",
            "Training loss (for one batch) at step 3230: 0.1064\n",
            "Seen so far: 103392 samples\n",
            "0.9155254\n",
            "Training loss (for one batch) at step 3235: 0.1381\n",
            "Seen so far: 103552 samples\n",
            "0.9155883\n",
            "Training loss (for one batch) at step 3240: 0.0224\n",
            "Seen so far: 103712 samples\n",
            "0.9156896\n",
            "Training loss (for one batch) at step 3245: 0.4006\n",
            "Seen so far: 103872 samples\n",
            "0.91575205\n",
            "Training loss (for one batch) at step 3250: 0.2378\n",
            "Seen so far: 104032 samples\n",
            "0.9158432\n",
            "Training loss (for one batch) at step 3255: 0.1875\n",
            "Seen so far: 104192 samples\n",
            "0.91591483\n",
            "Training loss (for one batch) at step 3260: 0.0442\n",
            "Seen so far: 104352 samples\n",
            "0.91600543\n",
            "Training loss (for one batch) at step 3265: 0.2204\n",
            "Seen so far: 104512 samples\n",
            "0.9160766\n",
            "Training loss (for one batch) at step 3270: 0.4092\n",
            "Seen so far: 104672 samples\n",
            "0.91612846\n",
            "Training loss (for one batch) at step 3275: 0.2487\n",
            "Seen so far: 104832 samples\n",
            "0.91619927\n",
            "Training loss (for one batch) at step 3280: 0.1830\n",
            "Seen so far: 104992 samples\n",
            "0.9162412\n",
            "Training loss (for one batch) at step 3285: 0.5343\n",
            "Seen so far: 105152 samples\n",
            "0.9163116\n",
            "Training loss (for one batch) at step 3290: 0.0854\n",
            "Seen so far: 105312 samples\n",
            "0.9163533\n",
            "Training loss (for one batch) at step 3295: 0.0846\n",
            "Seen so far: 105472 samples\n",
            "0.9164423\n",
            "Training loss (for one batch) at step 3300: 0.0746\n",
            "Seen so far: 105632 samples\n",
            "0.9164647\n",
            "Training loss (for one batch) at step 3305: 0.0215\n",
            "Seen so far: 105792 samples\n",
            "0.9165438\n",
            "Training loss (for one batch) at step 3310: 0.0257\n",
            "Seen so far: 105952 samples\n",
            "0.91661316\n",
            "Training loss (for one batch) at step 3315: 0.0471\n",
            "Seen so far: 106112 samples\n",
            "0.9166635\n",
            "Training loss (for one batch) at step 3320: 0.1436\n",
            "Seen so far: 106272 samples\n",
            "0.91668546\n",
            "Training loss (for one batch) at step 3325: 0.0219\n",
            "Seen so far: 106432 samples\n",
            "0.91678256\n",
            "Training loss (for one batch) at step 3330: 0.0414\n",
            "Seen so far: 106592 samples\n",
            "0.91685116\n",
            "Training loss (for one batch) at step 3335: 0.0322\n",
            "Seen so far: 106752 samples\n",
            "0.9169571\n",
            "Training loss (for one batch) at step 3340: 0.3249\n",
            "Seen so far: 106912 samples\n",
            "0.9169878\n",
            "Training loss (for one batch) at step 3345: 0.1427\n",
            "Seen so far: 107072 samples\n",
            "0.9170371\n",
            "Training loss (for one batch) at step 3350: 0.1248\n",
            "Seen so far: 107232 samples\n",
            "0.9171516\n",
            "Training loss (for one batch) at step 3355: 0.0554\n",
            "Seen so far: 107392 samples\n",
            "0.9172564\n",
            "Training loss (for one batch) at step 3360: 0.3206\n",
            "Seen so far: 107552 samples\n",
            "0.9173051\n",
            "Training loss (for one batch) at step 3365: 0.0027\n",
            "Seen so far: 107712 samples\n",
            "0.9174001\n",
            "Training loss (for one batch) at step 3370: 0.0049\n",
            "Seen so far: 107872 samples\n",
            "0.9175041\n",
            "Training loss (for one batch) at step 3375: 0.2068\n",
            "Seen so far: 108032 samples\n",
            "0.9176077\n",
            "Training loss (for one batch) at step 3380: 0.2204\n",
            "Seen so far: 108192 samples\n",
            "0.9176741\n",
            "Training loss (for one batch) at step 3385: 0.0945\n",
            "Seen so far: 108352 samples\n",
            "0.9177496\n",
            "Training loss (for one batch) at step 3390: 0.0942\n",
            "Seen so far: 108512 samples\n",
            "0.91781557\n",
            "Training loss (for one batch) at step 3395: 0.1815\n",
            "Seen so far: 108672 samples\n",
            "0.9178813\n",
            "Training loss (for one batch) at step 3400: 0.0093\n",
            "Seen so far: 108832 samples\n",
            "0.9179837\n",
            "Training loss (for one batch) at step 3405: 0.0077\n",
            "Seen so far: 108992 samples\n",
            "0.91809493\n",
            "Training loss (for one batch) at step 3410: 0.0164\n",
            "Seen so far: 109152 samples\n",
            "0.9181966\n",
            "Training loss (for one batch) at step 3415: 0.0264\n",
            "Seen so far: 109312 samples\n",
            "0.91828895\n",
            "Training loss (for one batch) at step 3420: 0.0069\n",
            "Seen so far: 109472 samples\n",
            "0.918381\n",
            "Training loss (for one batch) at step 3425: 0.1758\n",
            "Seen so far: 109632 samples\n",
            "0.91845447\n",
            "Training loss (for one batch) at step 3430: 0.0920\n",
            "Seen so far: 109792 samples\n",
            "0.9185278\n",
            "Training loss (for one batch) at step 3435: 0.0238\n",
            "Seen so far: 109952 samples\n",
            "0.91861904\n",
            "Training loss (for one batch) at step 3440: 0.1709\n",
            "Seen so far: 110112 samples\n",
            "0.9186919\n",
            "Training loss (for one batch) at step 3445: 0.1073\n",
            "Seen so far: 110272 samples\n",
            "0.9187736\n",
            "Training loss (for one batch) at step 3450: 0.0778\n",
            "Seen so far: 110432 samples\n",
            "0.91883695\n",
            "Training loss (for one batch) at step 3455: 0.0287\n",
            "Seen so far: 110592 samples\n",
            "0.9189001\n",
            "Training loss (for one batch) at step 3460: 0.0127\n",
            "Seen so far: 110752 samples\n",
            "0.91897213\n",
            "Training loss (for one batch) at step 3465: 0.0749\n",
            "Seen so far: 110912 samples\n",
            "0.91905296\n",
            "Training loss (for one batch) at step 3470: 0.2752\n",
            "Seen so far: 111072 samples\n",
            "0.91915154\n",
            "Training loss (for one batch) at step 3475: 0.4031\n",
            "Seen so far: 111232 samples\n",
            "0.9192049\n",
            "Training loss (for one batch) at step 3480: 0.0304\n",
            "Seen so far: 111392 samples\n",
            "0.9192402\n",
            "Training loss (for one batch) at step 3485: 0.2313\n",
            "Seen so far: 111552 samples\n",
            "0.91931117\n",
            "Training loss (for one batch) at step 3490: 0.0119\n",
            "Seen so far: 111712 samples\n",
            "0.9193641\n",
            "Training loss (for one batch) at step 3495: 0.1296\n",
            "Seen so far: 111872 samples\n",
            "0.91941684\n",
            "Training loss (for one batch) at step 3500: 0.2069\n",
            "Seen so far: 112032 samples\n",
            "0.91949624\n",
            "Training loss (for one batch) at step 3505: 0.1610\n",
            "Seen so far: 112192 samples\n",
            "0.9195576\n",
            "Training loss (for one batch) at step 3510: 0.3671\n",
            "Seen so far: 112352 samples\n",
            "0.9196365\n",
            "Training loss (for one batch) at step 3515: 0.0205\n",
            "Seen so far: 112512 samples\n",
            "0.919733\n",
            "Training loss (for one batch) at step 3520: 0.0194\n",
            "Seen so far: 112672 samples\n",
            "0.91982037\n",
            "Training loss (for one batch) at step 3525: 0.2209\n",
            "Seen so far: 112832 samples\n",
            "0.91990745\n",
            "Training loss (for one batch) at step 3530: 0.0156\n",
            "Seen so far: 112992 samples\n",
            "0.9199855\n",
            "Training loss (for one batch) at step 3535: 0.1681\n",
            "Seen so far: 113152 samples\n",
            "0.92007214\n",
            "Training loss (for one batch) at step 3540: 0.1775\n",
            "Seen so far: 113312 samples\n",
            "0.92014086\n",
            "Training loss (for one batch) at step 3545: 0.0300\n",
            "Seen so far: 113472 samples\n",
            "0.9202094\n",
            "Training loss (for one batch) at step 3550: 0.1154\n",
            "Seen so far: 113632 samples\n",
            "0.92029536\n",
            "Training loss (for one batch) at step 3555: 0.0936\n",
            "Seen so far: 113792 samples\n",
            "0.9203635\n",
            "Training loss (for one batch) at step 3560: 0.0833\n",
            "Seen so far: 113952 samples\n",
            "0.9204577\n",
            "Training loss (for one batch) at step 3565: 0.5269\n",
            "Seen so far: 114112 samples\n",
            "0.9205342\n",
            "Training loss (for one batch) at step 3570: 0.0045\n",
            "Seen so far: 114272 samples\n",
            "0.9206367\n",
            "Training loss (for one batch) at step 3575: 0.0093\n",
            "Seen so far: 114432 samples\n",
            "0.9207127\n",
            "Training loss (for one batch) at step 3580: 0.0604\n",
            "Seen so far: 114592 samples\n",
            "0.9207973\n",
            "Training loss (for one batch) at step 3585: 0.0990\n",
            "Seen so far: 114752 samples\n",
            "0.9208641\n",
            "Training loss (for one batch) at step 3590: 0.4243\n",
            "Seen so far: 114912 samples\n",
            "0.9209047\n",
            "Training loss (for one batch) at step 3595: 0.2547\n",
            "Seen so far: 115072 samples\n",
            "0.9209712\n",
            "Training loss (for one batch) at step 3600: 0.0760\n",
            "Seen so far: 115232 samples\n",
            "0.92104626\n",
            "Training loss (for one batch) at step 3605: 0.0651\n",
            "Seen so far: 115392 samples\n",
            "0.92112106\n",
            "Training loss (for one batch) at step 3610: 0.0911\n",
            "Seen so far: 115552 samples\n",
            "0.92117834\n",
            "Training loss (for one batch) at step 3615: 0.0030\n",
            "Seen so far: 115712 samples\n",
            "0.9212614\n",
            "Training loss (for one batch) at step 3620: 0.0814\n",
            "Seen so far: 115872 samples\n",
            "0.92133564\n",
            "Training loss (for one batch) at step 3625: 0.4214\n",
            "Seen so far: 116032 samples\n",
            "0.92138374\n",
            "Training loss (for one batch) at step 3630: 0.1583\n",
            "Seen so far: 116192 samples\n",
            "0.9214576\n",
            "Training loss (for one batch) at step 3635: 0.1473\n",
            "Seen so far: 116352 samples\n",
            "0.9215312\n",
            "Training loss (for one batch) at step 3640: 0.0391\n",
            "Seen so far: 116512 samples\n",
            "0.92160463\n",
            "Training loss (for one batch) at step 3645: 0.0066\n",
            "Seen so far: 116672 samples\n",
            "0.921695\n",
            "Training loss (for one batch) at step 3650: 0.0587\n",
            "Seen so far: 116832 samples\n",
            "0.921768\n",
            "Training loss (for one batch) at step 3655: 0.1534\n",
            "Seen so far: 116992 samples\n",
            "0.9218579\n",
            "Training loss (for one batch) at step 3660: 0.0175\n",
            "Seen so far: 117152 samples\n",
            "0.9218878\n",
            "Training loss (for one batch) at step 3665: 0.3038\n",
            "Seen so far: 117312 samples\n",
            "0.9219517\n",
            "Training loss (for one batch) at step 3670: 0.0351\n",
            "Seen so far: 117472 samples\n",
            "0.9220325\n",
            "Training loss (for one batch) at step 3675: 0.0882\n",
            "Seen so far: 117632 samples\n",
            "0.92210454\n",
            "Training loss (for one batch) at step 3680: 0.1017\n",
            "Seen so far: 117792 samples\n",
            "0.92217636\n",
            "Training loss (for one batch) at step 3685: 0.0218\n",
            "Seen so far: 117952 samples\n",
            "0.922265\n",
            "Training loss (for one batch) at step 3690: 0.0015\n",
            "Seen so far: 118112 samples\n",
            "0.9223534\n",
            "Training loss (for one batch) at step 3695: 0.0129\n",
            "Seen so far: 118272 samples\n",
            "0.92242455\n",
            "Training loss (for one batch) at step 3700: 0.0710\n",
            "Seen so far: 118432 samples\n",
            "0.92250407\n",
            "Training loss (for one batch) at step 3705: 0.0013\n",
            "Seen so far: 118592 samples\n",
            "0.9225749\n",
            "Training loss (for one batch) at step 3710: 0.0142\n",
            "Seen so far: 118752 samples\n",
            "0.9226624\n",
            "Training loss (for one batch) at step 3715: 0.1623\n",
            "Seen so far: 118912 samples\n",
            "0.92269915\n",
            "Training loss (for one batch) at step 3720: 0.0783\n",
            "Seen so far: 119072 samples\n",
            "0.92279464\n",
            "Training loss (for one batch) at step 3725: 0.0491\n",
            "Seen so far: 119232 samples\n",
            "0.9228731\n",
            "Training loss (for one batch) at step 3730: 0.0327\n",
            "Seen so far: 119392 samples\n",
            "0.92293453\n",
            "Training loss (for one batch) at step 3735: 0.0216\n",
            "Seen so far: 119552 samples\n",
            "0.92302096\n",
            "Training loss (for one batch) at step 3740: 0.0803\n",
            "Seen so far: 119712 samples\n",
            "0.92310715\n",
            "Training loss (for one batch) at step 3745: 0.2750\n",
            "Seen so far: 119872 samples\n",
            "0.9231347\n",
            "Training loss (for one batch) at step 3750: 0.0689\n",
            "Seen so far: 120032 samples\n",
            "0.92322046\n",
            "Training loss (for one batch) at step 3755: 0.0063\n",
            "Seen so far: 120192 samples\n",
            "0.92330605\n",
            "Training loss (for one batch) at step 3760: 0.2847\n",
            "Seen so far: 120352 samples\n",
            "0.92334986\n",
            "Training loss (for one batch) at step 3765: 0.0678\n",
            "Seen so far: 120512 samples\n",
            "0.923352\n",
            "Training loss (for one batch) at step 3770: 0.0041\n",
            "Seen so far: 120672 samples\n",
            "0.92343706\n",
            "Training loss (for one batch) at step 3775: 0.0604\n",
            "Seen so far: 120832 samples\n",
            "0.9234971\n",
            "Training loss (for one batch) at step 3780: 0.1113\n",
            "Seen so far: 120992 samples\n",
            "0.9235652\n",
            "Training loss (for one batch) at step 3785: 0.4412\n",
            "Seen so far: 121152 samples\n",
            "0.92360836\n",
            "Training loss (for one batch) at step 3790: 0.0442\n",
            "Seen so far: 121312 samples\n",
            "0.92367613\n",
            "Training loss (for one batch) at step 3795: 0.0068\n",
            "Seen so far: 121472 samples\n",
            "0.92375195\n",
            "Training loss (for one batch) at step 3800: 0.0227\n",
            "Seen so far: 121632 samples\n",
            "0.9238276\n",
            "Training loss (for one batch) at step 3805: 0.0231\n",
            "Seen so far: 121792 samples\n",
            "0.9239195\n",
            "Training loss (for one batch) at step 3810: 0.1297\n",
            "Seen so far: 121952 samples\n",
            "0.9239537\n",
            "Training loss (for one batch) at step 3815: 0.1292\n",
            "Seen so far: 122112 samples\n",
            "0.9240206\n",
            "Training loss (for one batch) at step 3820: 0.0098\n",
            "Seen so far: 122272 samples\n",
            "0.9240464\n",
            "Training loss (for one batch) at step 3825: 0.0065\n",
            "Seen so far: 122432 samples\n",
            "0.92409664\n",
            "Training loss (for one batch) at step 3830: 0.0261\n",
            "Seen so far: 122592 samples\n",
            "0.92413044\n",
            "Training loss (for one batch) at step 3835: 0.0468\n",
            "Seen so far: 122752 samples\n",
            "0.924156\n",
            "Training loss (for one batch) at step 3840: 0.0186\n",
            "Seen so far: 122912 samples\n",
            "0.92422223\n",
            "Training loss (for one batch) at step 3845: 0.0255\n",
            "Seen so far: 123072 samples\n",
            "0.9242476\n",
            "Training loss (for one batch) at step 3850: 0.7010\n",
            "Seen so far: 123232 samples\n",
            "0.92424047\n",
            "Training loss (for one batch) at step 3855: 0.0910\n",
            "Seen so far: 123392 samples\n",
            "0.92429006\n",
            "Training loss (for one batch) at step 3860: 0.0097\n",
            "Seen so far: 123552 samples\n",
            "0.924291\n",
            "Training loss (for one batch) at step 3865: 0.0363\n",
            "Seen so far: 123712 samples\n",
            "0.92431617\n",
            "Training loss (for one batch) at step 3870: 0.1762\n",
            "Seen so far: 123872 samples\n",
            "0.9243574\n",
            "Training loss (for one batch) at step 3875: 0.0776\n",
            "Seen so far: 124032 samples\n",
            "0.9244066\n",
            "Training loss (for one batch) at step 3880: 0.0689\n",
            "Seen so far: 124192 samples\n",
            "0.9244718\n",
            "Training loss (for one batch) at step 3885: 0.0653\n",
            "Seen so far: 124352 samples\n",
            "0.9245127\n",
            "Training loss (for one batch) at step 3890: 0.3147\n",
            "Seen so far: 124512 samples\n",
            "0.9245133\n",
            "Training loss (for one batch) at step 3895: 0.0878\n",
            "Seen so far: 124672 samples\n",
            "0.924546\n",
            "Training loss (for one batch) at step 3900: 0.0350\n",
            "Seen so far: 124832 samples\n",
            "0.9245786\n",
            "Training loss (for one batch) at step 3905: 0.0578\n",
            "Seen so far: 124992 samples\n",
            "0.92461115\n",
            "Training loss (for one batch) at step 3910: 0.0402\n",
            "Seen so far: 125152 samples\n",
            "0.9246756\n",
            "Training loss (for one batch) at step 3915: 0.0527\n",
            "Seen so far: 125312 samples\n",
            "0.92473185\n",
            "Training loss (for one batch) at step 3920: 0.0628\n",
            "Seen so far: 125472 samples\n",
            "0.9247242\n",
            "Training loss (for one batch) at step 3925: 0.9383\n",
            "Seen so far: 125632 samples\n",
            "0.92469275\n",
            "Training loss (for one batch) at step 3930: 0.0909\n",
            "Seen so far: 125792 samples\n",
            "0.92474085\n",
            "Training loss (for one batch) at step 3935: 0.0611\n",
            "Seen so far: 125952 samples\n",
            "0.92474914\n",
            "Training loss (for one batch) at step 3940: 0.1358\n",
            "Seen so far: 126112 samples\n",
            "0.92478114\n",
            "Training loss (for one batch) at step 3945: 0.1687\n",
            "Seen so far: 126272 samples\n",
            "0.924821\n",
            "Training loss (for one batch) at step 3950: 0.1339\n",
            "Seen so far: 126432 samples\n",
            "0.9248687\n",
            "Training loss (for one batch) at step 3955: 0.1699\n",
            "Seen so far: 126592 samples\n",
            "0.9249005\n",
            "Training loss (for one batch) at step 3960: 0.2564\n",
            "Seen so far: 126752 samples\n",
            "0.9249321\n",
            "Training loss (for one batch) at step 3965: 0.1730\n",
            "Seen so far: 126912 samples\n",
            "0.9249559\n",
            "Training loss (for one batch) at step 3970: 0.1910\n",
            "Seen so far: 127072 samples\n",
            "0.92498744\n",
            "Training loss (for one batch) at step 3975: 0.0747\n",
            "Seen so far: 127232 samples\n",
            "0.925066\n",
            "Training loss (for one batch) at step 3980: 0.0777\n",
            "Seen so far: 127392 samples\n",
            "0.92512876\n",
            "Training loss (for one batch) at step 3985: 0.0374\n",
            "Seen so far: 127552 samples\n",
            "0.92515993\n",
            "Training loss (for one batch) at step 3990: 0.2644\n",
            "Seen so far: 127712 samples\n",
            "0.9252067\n",
            "Training loss (for one batch) at step 3995: 0.0338\n",
            "Seen so far: 127872 samples\n",
            "0.9252456\n",
            "Training loss (for one batch) at step 4000: 0.0463\n",
            "Seen so far: 128032 samples\n",
            "0.92529213\n",
            "Training loss (for one batch) at step 4005: 0.0053\n",
            "Seen so far: 128192 samples\n",
            "0.92533857\n",
            "Training loss (for one batch) at step 4010: 0.0249\n",
            "Seen so far: 128352 samples\n",
            "0.92540044\n",
            "Training loss (for one batch) at step 4015: 0.0219\n",
            "Seen so far: 128512 samples\n",
            "0.9254622\n",
            "Training loss (for one batch) at step 4020: 0.1118\n",
            "Seen so far: 128672 samples\n",
            "0.92553157\n",
            "Training loss (for one batch) at step 4025: 0.0774\n",
            "Seen so far: 128832 samples\n",
            "0.9255697\n",
            "Training loss (for one batch) at step 4030: 0.0248\n",
            "Seen so far: 128992 samples\n",
            "0.9256078\n",
            "Training loss (for one batch) at step 4035: 0.1973\n",
            "Seen so far: 129152 samples\n",
            "0.925638\n",
            "Training loss (for one batch) at step 4040: 0.0206\n",
            "Seen so far: 129312 samples\n",
            "0.9257068\n",
            "Training loss (for one batch) at step 4045: 0.0122\n",
            "Seen so far: 129472 samples\n",
            "0.92578316\n",
            "Training loss (for one batch) at step 4050: 0.0014\n",
            "Seen so far: 129632 samples\n",
            "0.92582077\n",
            "Training loss (for one batch) at step 4055: 0.0658\n",
            "Seen so far: 129792 samples\n",
            "0.9258583\n",
            "Training loss (for one batch) at step 4060: 0.0192\n",
            "Seen so far: 129952 samples\n",
            "0.9259111\n",
            "Training loss (for one batch) at step 4065: 0.0498\n",
            "Seen so far: 130112 samples\n",
            "0.92594075\n",
            "Training loss (for one batch) at step 4070: 0.0558\n",
            "Seen so far: 130272 samples\n",
            "0.9259626\n",
            "Training loss (for one batch) at step 4075: 0.0029\n",
            "Seen so far: 130432 samples\n",
            "0.92597675\n",
            "Training loss (for one batch) at step 4080: 0.2475\n",
            "Seen so far: 130592 samples\n",
            "0.9259832\n",
            "Training loss (for one batch) at step 4085: 0.0737\n",
            "Seen so far: 130752 samples\n",
            "0.92602026\n",
            "Training loss (for one batch) at step 4090: 0.0439\n",
            "Seen so far: 130912 samples\n",
            "0.9260725\n",
            "Training loss (for one batch) at step 4095: 0.0589\n",
            "Seen so far: 131072 samples\n",
            "0.9261246\n",
            "Training loss (for one batch) at step 4100: 0.4379\n",
            "Seen so far: 131232 samples\n",
            "0.9261461\n",
            "Training loss (for one batch) at step 4105: 0.0394\n",
            "Seen so far: 131392 samples\n",
            "0.9262056\n",
            "Training loss (for one batch) at step 4110: 0.1091\n",
            "Seen so far: 131552 samples\n",
            "0.9262573\n",
            "Training loss (for one batch) at step 4115: 0.1670\n",
            "Seen so far: 131712 samples\n",
            "0.92627853\n",
            "Training loss (for one batch) at step 4120: 0.0768\n",
            "Seen so far: 131872 samples\n",
            "0.9263225\n",
            "Training loss (for one batch) at step 4125: 0.1492\n",
            "Seen so far: 132032 samples\n",
            "0.92638147\n",
            "Training loss (for one batch) at step 4130: 0.1063\n",
            "Seen so far: 132192 samples\n",
            "0.9264328\n",
            "Training loss (for one batch) at step 4135: 0.1263\n",
            "Seen so far: 132352 samples\n",
            "0.926499\n",
            "Training loss (for one batch) at step 4140: 0.0488\n",
            "Seen so far: 132512 samples\n",
            "0.9265425\n",
            "Training loss (for one batch) at step 4145: 0.0238\n",
            "Seen so far: 132672 samples\n",
            "0.9266085\n",
            "Training loss (for one batch) at step 4150: 0.0316\n",
            "Seen so far: 132832 samples\n",
            "0.9266818\n",
            "Training loss (for one batch) at step 4155: 0.0860\n",
            "Seen so far: 132992 samples\n",
            "0.9267249\n",
            "Training loss (for one batch) at step 4160: 0.0447\n",
            "Seen so far: 133152 samples\n",
            "0.9267904\n",
            "Training loss (for one batch) at step 4165: 0.0422\n",
            "Seen so far: 133312 samples\n",
            "0.9268333\n",
            "Training loss (for one batch) at step 4170: 0.0063\n",
            "Seen so far: 133472 samples\n",
            "0.926891\n",
            "Training loss (for one batch) at step 4175: 0.0345\n",
            "Seen so far: 133632 samples\n",
            "0.9269262\n",
            "Training loss (for one batch) at step 4180: 0.3041\n",
            "Seen so far: 133792 samples\n",
            "0.9269762\n",
            "Training loss (for one batch) at step 4185: 0.0025\n",
            "Seen so far: 133952 samples\n",
            "0.92701864\n",
            "Training loss (for one batch) at step 4190: 0.0359\n",
            "Seen so far: 134112 samples\n",
            "0.92709076\n",
            "Training loss (for one batch) at step 4195: 0.0157\n",
            "Seen so far: 134272 samples\n",
            "0.9271404\n",
            "Training loss (for one batch) at step 4200: 0.2277\n",
            "Seen so far: 134432 samples\n",
            "0.9272123\n",
            "Training loss (for one batch) at step 4205: 0.0049\n",
            "Seen so far: 134592 samples\n",
            "0.92726165\n",
            "Training loss (for one batch) at step 4210: 0.0049\n",
            "Seen so far: 134752 samples\n",
            "0.9273035\n",
            "Training loss (for one batch) at step 4215: 0.2128\n",
            "Seen so far: 134912 samples\n",
            "0.9273378\n",
            "Training loss (for one batch) at step 4220: 0.0106\n",
            "Seen so far: 135072 samples\n",
            "0.9273869\n",
            "Training loss (for one batch) at step 4225: 0.0357\n",
            "Seen so far: 135232 samples\n",
            "0.92739886\n",
            "Training loss (for one batch) at step 4230: 0.0816\n",
            "Seen so far: 135392 samples\n",
            "0.92742556\n",
            "Training loss (for one batch) at step 4235: 0.0220\n",
            "Seen so far: 135552 samples\n",
            "0.92749643\n",
            "Training loss (for one batch) at step 4240: 0.0129\n",
            "Seen so far: 135712 samples\n",
            "0.92755985\n",
            "Training loss (for one batch) at step 4245: 0.0513\n",
            "Seen so far: 135872 samples\n",
            "0.927601\n",
            "Training loss (for one batch) at step 4250: 0.1132\n",
            "Seen so far: 136032 samples\n",
            "0.92764205\n",
            "Training loss (for one batch) at step 4255: 0.0258\n",
            "Seen so far: 136192 samples\n",
            "0.92769766\n",
            "Training loss (for one batch) at step 4260: 0.2814\n",
            "Seen so far: 136352 samples\n",
            "0.9277385\n",
            "Training loss (for one batch) at step 4265: 0.0801\n",
            "Seen so far: 136512 samples\n",
            "0.92777926\n",
            "Training loss (for one batch) at step 4270: 0.0059\n",
            "Seen so far: 136672 samples\n",
            "0.9278345\n",
            "Training loss (for one batch) at step 4275: 0.0469\n",
            "Seen so far: 136832 samples\n",
            "0.9279189\n",
            "Training loss (for one batch) at step 4280: 0.1331\n",
            "Seen so far: 136992 samples\n",
            "0.9279812\n",
            "Training loss (for one batch) at step 4285: 0.0997\n",
            "Seen so far: 137152 samples\n",
            "0.92802876\n",
            "Training loss (for one batch) at step 4290: 0.0039\n",
            "Seen so far: 137312 samples\n",
            "0.9280835\n",
            "Training loss (for one batch) at step 4295: 0.0699\n",
            "Seen so far: 137472 samples\n",
            "0.92814535\n",
            "Training loss (for one batch) at step 4300: 0.0518\n",
            "Seen so far: 137632 samples\n",
            "0.9281853\n",
            "Training loss (for one batch) at step 4305: 0.2285\n",
            "Seen so far: 137792 samples\n",
            "0.92823243\n",
            "Training loss (for one batch) at step 4310: 0.0832\n",
            "Seen so far: 137952 samples\n",
            "0.9282794\n",
            "Training loss (for one batch) at step 4315: 0.0589\n",
            "Seen so far: 138112 samples\n",
            "0.928348\n",
            "Training loss (for one batch) at step 4320: 0.0796\n",
            "Seen so far: 138272 samples\n",
            "0.92839473\n",
            "Training loss (for one batch) at step 4325: 0.0021\n",
            "Seen so far: 138432 samples\n",
            "0.9284558\n",
            "Training loss (for one batch) at step 4330: 0.0766\n",
            "Seen so far: 138592 samples\n",
            "0.92849517\n",
            "Training loss (for one batch) at step 4335: 0.0076\n",
            "Seen so far: 138752 samples\n",
            "0.92854875\n",
            "Training loss (for one batch) at step 4340: 0.3141\n",
            "Seen so far: 138912 samples\n",
            "0.92862386\n",
            "Training loss (for one batch) at step 4345: 0.1200\n",
            "Seen so far: 139072 samples\n",
            "0.92866284\n",
            "Training loss (for one batch) at step 4350: 0.0180\n",
            "Seen so far: 139232 samples\n",
            "0.92873764\n",
            "Training loss (for one batch) at step 4355: 0.0109\n",
            "Seen so far: 139392 samples\n",
            "0.9287836\n",
            "Training loss (for one batch) at step 4360: 0.2890\n",
            "Seen so far: 139552 samples\n",
            "0.9288294\n",
            "Training loss (for one batch) at step 4365: 0.0202\n",
            "Seen so far: 139712 samples\n",
            "0.9288751\n",
            "Training loss (for one batch) at step 4370: 0.0403\n",
            "Seen so far: 139872 samples\n",
            "0.9289279\n",
            "Training loss (for one batch) at step 4375: 0.1212\n",
            "Seen so far: 140032 samples\n",
            "0.9289805\n",
            "Training loss (for one batch) at step 4380: 0.0271\n",
            "Seen so far: 140192 samples\n",
            "0.9290259\n",
            "Training loss (for one batch) at step 4385: 0.0312\n",
            "Seen so far: 140352 samples\n",
            "0.92910683\n",
            "Training loss (for one batch) at step 4390: 0.0451\n",
            "Seen so far: 140512 samples\n",
            "0.9291591\n",
            "Training loss (for one batch) at step 4395: 0.1057\n",
            "Seen so far: 140672 samples\n",
            "0.92921835\n",
            "Training loss (for one batch) at step 4400: 0.0116\n",
            "Seen so far: 140832 samples\n",
            "0.9292774\n",
            "Training loss (for one batch) at step 4405: 0.1315\n",
            "Seen so far: 140992 samples\n",
            "0.92930096\n",
            "Training loss (for one batch) at step 4410: 0.1031\n",
            "Seen so far: 141152 samples\n",
            "0.9293386\n",
            "Training loss (for one batch) at step 4415: 0.0193\n",
            "Seen so far: 141312 samples\n",
            "0.9293903\n",
            "Training loss (for one batch) at step 4420: 0.1647\n",
            "Seen so far: 141472 samples\n",
            "0.92942774\n",
            "Training loss (for one batch) at step 4425: 0.0400\n",
            "Seen so far: 141632 samples\n",
            "0.9294933\n",
            "Training loss (for one batch) at step 4430: 0.2923\n",
            "Seen so far: 141792 samples\n",
            "0.9295235\n",
            "Training loss (for one batch) at step 4435: 0.0287\n",
            "Seen so far: 141952 samples\n",
            "0.9295748\n",
            "Training loss (for one batch) at step 4440: 0.0061\n",
            "Seen so far: 142112 samples\n",
            "0.92963296\n",
            "Training loss (for one batch) at step 4445: 0.1758\n",
            "Seen so far: 142272 samples\n",
            "0.929691\n",
            "Training loss (for one batch) at step 4450: 1.1716\n",
            "Seen so far: 142432 samples\n",
            "0.9296858\n",
            "Training loss (for one batch) at step 4455: 0.0100\n",
            "Seen so far: 142592 samples\n",
            "0.9297646\n",
            "Training loss (for one batch) at step 4460: 0.0011\n",
            "Seen so far: 142752 samples\n",
            "0.92982936\n",
            "Training loss (for one batch) at step 4465: 0.0211\n",
            "Seen so far: 142912 samples\n",
            "0.92990094\n",
            "Training loss (for one batch) at step 4470: 0.1850\n",
            "Seen so far: 143072 samples\n",
            "0.92993736\n",
            "Training loss (for one batch) at step 4475: 0.0403\n",
            "Seen so far: 143232 samples\n",
            "0.9300017\n",
            "Training loss (for one batch) at step 4480: 0.0415\n",
            "Seen so far: 143392 samples\n",
            "0.9300658\n",
            "Training loss (for one batch) at step 4485: 0.0051\n",
            "Seen so far: 143552 samples\n",
            "0.93010896\n",
            "Training loss (for one batch) at step 4490: 0.1053\n",
            "Seen so far: 143712 samples\n",
            "0.930145\n",
            "Training loss (for one batch) at step 4495: 0.0238\n",
            "Seen so far: 143872 samples\n",
            "0.9302018\n",
            "Training loss (for one batch) at step 4500: 0.1260\n",
            "Seen so far: 144032 samples\n",
            "0.9302447\n",
            "Training loss (for one batch) at step 4505: 0.0413\n",
            "Seen so far: 144192 samples\n",
            "0.9302874\n",
            "Training loss (for one batch) at step 4510: 0.2323\n",
            "Seen so far: 144352 samples\n",
            "0.9303508\n",
            "Training loss (for one batch) at step 4515: 0.0062\n",
            "Seen so far: 144512 samples\n",
            "0.93040717\n",
            "Training loss (for one batch) at step 4520: 0.2718\n",
            "Seen so far: 144672 samples\n",
            "0.9304288\n",
            "Training loss (for one batch) at step 4525: 0.0665\n",
            "Seen so far: 144832 samples\n",
            "0.93046427\n",
            "Training loss (for one batch) at step 4530: 0.0223\n",
            "Seen so far: 144992 samples\n",
            "0.9305272\n",
            "Training loss (for one batch) at step 4535: 0.3667\n",
            "Seen so far: 145152 samples\n",
            "0.9305556\n",
            "Training loss (for one batch) at step 4540: 0.0107\n",
            "Seen so far: 145312 samples\n",
            "0.9305976\n",
            "Training loss (for one batch) at step 4545: 0.0272\n",
            "Seen so far: 145472 samples\n",
            "0.93061894\n",
            "Training loss (for one batch) at step 4550: 0.0078\n",
            "Seen so far: 145632 samples\n",
            "0.9306883\n",
            "Training loss (for one batch) at step 4555: 0.2016\n",
            "Seen so far: 145792 samples\n",
            "0.9307301\n",
            "Training loss (for one batch) at step 4560: 0.0273\n",
            "Seen so far: 145952 samples\n",
            "0.9307649\n",
            "Training loss (for one batch) at step 4565: 0.0262\n",
            "Seen so far: 146112 samples\n",
            "0.9308134\n",
            "Training loss (for one batch) at step 4570: 0.1452\n",
            "Seen so far: 146272 samples\n",
            "0.93083435\n",
            "Training loss (for one batch) at step 4575: 0.0950\n",
            "Seen so far: 146432 samples\n",
            "0.9308621\n",
            "Training loss (for one batch) at step 4580: 0.0336\n",
            "Seen so far: 146592 samples\n",
            "0.93088984\n",
            "Training loss (for one batch) at step 4585: 0.0042\n",
            "Seen so far: 146752 samples\n",
            "0.93094474\n",
            "Training loss (for one batch) at step 4590: 0.1633\n",
            "Seen so far: 146912 samples\n",
            "0.9309791\n",
            "Training loss (for one batch) at step 4595: 0.0459\n",
            "Seen so far: 147072 samples\n",
            "0.931027\n",
            "Training loss (for one batch) at step 4600: 0.0102\n",
            "Seen so far: 147232 samples\n",
            "0.931068\n",
            "Training loss (for one batch) at step 4605: 0.0152\n",
            "Seen so far: 147392 samples\n",
            "0.9311224\n",
            "Training loss (for one batch) at step 4610: 0.0114\n",
            "Seen so far: 147552 samples\n",
            "0.9311768\n",
            "Training loss (for one batch) at step 4615: 0.2787\n",
            "Seen so far: 147712 samples\n",
            "0.9312175\n",
            "Training loss (for one batch) at step 4620: 0.0329\n",
            "Seen so far: 147872 samples\n",
            "0.93125135\n",
            "Training loss (for one batch) at step 4625: 0.0043\n",
            "Seen so far: 148032 samples\n",
            "0.9312986\n",
            "Training loss (for one batch) at step 4630: 0.0260\n",
            "Seen so far: 148192 samples\n",
            "0.9313391\n",
            "Training loss (for one batch) at step 4635: 0.1310\n",
            "Seen so far: 148352 samples\n",
            "0.9313592\n",
            "Training loss (for one batch) at step 4640: 0.0145\n",
            "Seen so far: 148512 samples\n",
            "0.9314197\n",
            "Training loss (for one batch) at step 4645: 0.0871\n",
            "Seen so far: 148672 samples\n",
            "0.9314666\n",
            "Training loss (for one batch) at step 4650: 0.4689\n",
            "Seen so far: 148832 samples\n",
            "0.9314932\n",
            "Training loss (for one batch) at step 4655: 0.1456\n",
            "Seen so far: 148992 samples\n",
            "0.9315332\n",
            "Training loss (for one batch) at step 4660: 0.2471\n",
            "Seen so far: 149152 samples\n",
            "0.9315665\n",
            "Training loss (for one batch) at step 4665: 0.0857\n",
            "Seen so far: 149312 samples\n",
            "0.9316063\n",
            "Training loss (for one batch) at step 4670: 0.0224\n",
            "Seen so far: 149472 samples\n",
            "0.9316394\n",
            "Training loss (for one batch) at step 4675: 0.0094\n",
            "Seen so far: 149632 samples\n",
            "0.93168575\n",
            "Training loss (for one batch) at step 4680: 0.0518\n",
            "Seen so far: 149792 samples\n",
            "0.93174535\n",
            "Training loss (for one batch) at step 4685: 0.1584\n",
            "Seen so far: 149952 samples\n",
            "0.93179816\n",
            "Training loss (for one batch) at step 4690: 0.2488\n",
            "Seen so far: 150112 samples\n",
            "0.9318176\n",
            "Training loss (for one batch) at step 4695: 0.0364\n",
            "Seen so far: 150272 samples\n",
            "0.9318702\n",
            "Training loss (for one batch) at step 4700: 0.0145\n",
            "Seen so far: 150432 samples\n",
            "0.93190944\n",
            "Training loss (for one batch) at step 4705: 0.2083\n",
            "Seen so far: 150592 samples\n",
            "0.931922\n",
            "Training loss (for one batch) at step 4710: 0.3467\n",
            "Seen so far: 150752 samples\n",
            "0.9319611\n",
            "Training loss (for one batch) at step 4715: 0.1800\n",
            "Seen so far: 150912 samples\n",
            "0.93198687\n",
            "Training loss (for one batch) at step 4720: 0.0015\n",
            "Seen so far: 151072 samples\n",
            "0.932039\n",
            "Training loss (for one batch) at step 4725: 0.0206\n",
            "Seen so far: 151232 samples\n",
            "0.93209773\n",
            "Training loss (for one batch) at step 4730: 0.5390\n",
            "Seen so far: 151392 samples\n",
            "0.9321166\n",
            "Training loss (for one batch) at step 4735: 0.0639\n",
            "Seen so far: 151552 samples\n",
            "0.9321355\n",
            "Training loss (for one batch) at step 4740: 0.3333\n",
            "Seen so far: 151712 samples\n",
            "0.9321609\n",
            "Training loss (for one batch) at step 4745: 0.1643\n",
            "Seen so far: 151872 samples\n",
            "0.93221265\n",
            "Training loss (for one batch) at step 4750: 0.0756\n",
            "Seen so far: 152032 samples\n",
            "0.9322511\n",
            "Training loss (for one batch) at step 4755: 0.0187\n",
            "Seen so far: 152192 samples\n",
            "0.9323092\n",
            "Training loss (for one batch) at step 4760: 0.0006\n",
            "Seen so far: 152352 samples\n",
            "0.93231463\n",
            "Training loss (for one batch) at step 4765: 0.2312\n",
            "Seen so far: 152512 samples\n",
            "0.9323725\n",
            "Training loss (for one batch) at step 4770: 0.0388\n",
            "Seen so far: 152672 samples\n",
            "0.93241066\n",
            "Training loss (for one batch) at step 4775: 0.1595\n",
            "Seen so far: 152832 samples\n",
            "0.9324225\n",
            "Training loss (for one batch) at step 4780: 0.3933\n",
            "Seen so far: 152992 samples\n",
            "0.9324082\n",
            "Training loss (for one batch) at step 4785: 0.0561\n",
            "Seen so far: 153152 samples\n",
            "0.93245924\n",
            "Training loss (for one batch) at step 4790: 0.5110\n",
            "Seen so far: 153312 samples\n",
            "0.93246454\n",
            "Training loss (for one batch) at step 4795: 0.1406\n",
            "Seen so far: 153472 samples\n",
            "0.93249583\n",
            "Training loss (for one batch) at step 4800: 0.2940\n",
            "Seen so far: 153632 samples\n",
            "0.9325076\n",
            "Training loss (for one batch) at step 4805: 0.1091\n",
            "Seen so far: 153792 samples\n",
            "0.93253875\n",
            "Training loss (for one batch) at step 4810: 0.1461\n",
            "Seen so far: 153952 samples\n",
            "0.9325569\n",
            "Training loss (for one batch) at step 4815: 0.0275\n",
            "Seen so far: 154112 samples\n",
            "0.9326204\n",
            "Training loss (for one batch) at step 4820: 0.0285\n",
            "Seen so far: 154272 samples\n",
            "0.93263847\n",
            "Training loss (for one batch) at step 4825: 0.0642\n",
            "Seen so far: 154432 samples\n",
            "0.9326694\n",
            "Training loss (for one batch) at step 4830: 0.3357\n",
            "Seen so far: 154592 samples\n",
            "0.9326938\n",
            "Training loss (for one batch) at step 4835: 0.0231\n",
            "Seen so far: 154752 samples\n",
            "0.9327117\n",
            "Training loss (for one batch) at step 4840: 0.1472\n",
            "Seen so far: 154912 samples\n",
            "0.9327231\n",
            "Training loss (for one batch) at step 4845: 0.4646\n",
            "Seen so far: 155072 samples\n",
            "0.9327538\n",
            "Training loss (for one batch) at step 4850: 0.1229\n",
            "Seen so far: 155232 samples\n",
            "0.9327651\n",
            "Training loss (for one batch) at step 4855: 0.1733\n",
            "Seen so far: 155392 samples\n",
            "0.9328215\n",
            "Training loss (for one batch) at step 4860: 0.0824\n",
            "Seen so far: 155552 samples\n",
            "0.9328328\n",
            "Training loss (for one batch) at step 4865: 0.3468\n",
            "Seen so far: 155712 samples\n",
            "0.93286324\n",
            "Training loss (for one batch) at step 4870: 0.0186\n",
            "Seen so far: 155872 samples\n",
            "0.9329065\n",
            "Training loss (for one batch) at step 4875: 0.2951\n",
            "Seen so far: 156032 samples\n",
            "0.9329304\n",
            "Training loss (for one batch) at step 4880: 0.4821\n",
            "Seen so far: 156192 samples\n",
            "0.9329543\n",
            "Training loss (for one batch) at step 4885: 0.1273\n",
            "Seen so far: 156352 samples\n",
            "0.93299097\n",
            "Training loss (for one batch) at step 4890: 0.0086\n",
            "Seen so far: 156512 samples\n",
            "0.9330339\n",
            "Training loss (for one batch) at step 4895: 0.2963\n",
            "Seen so far: 156672 samples\n",
            "0.93307036\n",
            "Training loss (for one batch) at step 4900: 0.0560\n",
            "Seen so far: 156832 samples\n",
            "0.9331004\n",
            "Training loss (for one batch) at step 4905: 0.0445\n",
            "Seen so far: 156992 samples\n",
            "0.93315583\n",
            "Training loss (for one batch) at step 4910: 0.0287\n",
            "Seen so far: 157152 samples\n",
            "0.93321115\n",
            "Training loss (for one batch) at step 4915: 0.0147\n",
            "Seen so far: 157312 samples\n",
            "0.9332473\n",
            "Training loss (for one batch) at step 4920: 0.0720\n",
            "Seen so far: 157472 samples\n",
            "0.9332961\n",
            "Training loss (for one batch) at step 4925: 0.0143\n",
            "Seen so far: 157632 samples\n",
            "0.9333448\n",
            "Training loss (for one batch) at step 4930: 0.0131\n",
            "Seen so far: 157792 samples\n",
            "0.93337435\n",
            "Training loss (for one batch) at step 4935: 0.0075\n",
            "Seen so far: 157952 samples\n",
            "0.9334355\n",
            "Training loss (for one batch) at step 4940: 0.1547\n",
            "Seen so far: 158112 samples\n",
            "0.93349016\n",
            "Training loss (for one batch) at step 4945: 0.0910\n",
            "Seen so far: 158272 samples\n",
            "0.9335258\n",
            "Training loss (for one batch) at step 4950: 0.0136\n",
            "Seen so far: 158432 samples\n",
            "0.93358666\n",
            "Training loss (for one batch) at step 4955: 0.0125\n",
            "Seen so far: 158592 samples\n",
            "0.93363476\n",
            "Training loss (for one batch) at step 4960: 0.0963\n",
            "Seen so far: 158752 samples\n",
            "0.9336764\n",
            "Training loss (for one batch) at step 4965: 0.0098\n",
            "Seen so far: 158912 samples\n",
            "0.9337432\n",
            "Training loss (for one batch) at step 4970: 0.0475\n",
            "Seen so far: 159072 samples\n",
            "0.9337973\n",
            "Training loss (for one batch) at step 4975: 0.0037\n",
            "Seen so far: 159232 samples\n",
            "0.933845\n",
            "Training loss (for one batch) at step 4980: 0.0007\n",
            "Seen so far: 159392 samples\n",
            "0.9338988\n",
            "Training loss (for one batch) at step 4985: 0.0121\n",
            "Seen so far: 159552 samples\n",
            "0.9339463\n",
            "Training loss (for one batch) at step 4990: 0.0786\n",
            "Seen so far: 159712 samples\n",
            "0.93396866\n",
            "Training loss (for one batch) at step 4995: 0.0011\n",
            "Seen so far: 159872 samples\n",
            "0.9339972\n",
            "Training loss (for one batch) at step 5000: 0.0818\n",
            "Seen so far: 160032 samples\n",
            "0.9340257\n",
            "Training loss (for one batch) at step 5005: 0.1662\n",
            "Seen so far: 160192 samples\n",
            "0.93405414\n",
            "Training loss (for one batch) at step 5010: 0.0588\n",
            "Seen so far: 160352 samples\n",
            "0.9340763\n",
            "Training loss (for one batch) at step 5015: 0.1327\n",
            "Seen so far: 160512 samples\n",
            "0.93409836\n",
            "Training loss (for one batch) at step 5020: 0.0543\n",
            "Seen so far: 160672 samples\n",
            "0.9341267\n",
            "Training loss (for one batch) at step 5025: 0.2227\n",
            "Seen so far: 160832 samples\n",
            "0.9341611\n",
            "Training loss (for one batch) at step 5030: 0.0325\n",
            "Seen so far: 160992 samples\n",
            "0.93418306\n",
            "Training loss (for one batch) at step 5035: 0.2982\n",
            "Seen so far: 161152 samples\n",
            "0.9341988\n",
            "Training loss (for one batch) at step 5040: 0.0684\n",
            "Seen so far: 161312 samples\n",
            "0.93424547\n",
            "Training loss (for one batch) at step 5045: 0.0659\n",
            "Seen so far: 161472 samples\n",
            "0.934292\n",
            "Training loss (for one batch) at step 5050: 0.1648\n",
            "Seen so far: 161632 samples\n",
            "0.9343138\n",
            "Training loss (for one batch) at step 5055: 0.3375\n",
            "Seen so far: 161792 samples\n",
            "0.9343231\n",
            "Training loss (for one batch) at step 5060: 0.1427\n",
            "Seen so far: 161952 samples\n",
            "0.9343509\n",
            "Training loss (for one batch) at step 5065: 0.2452\n",
            "Seen so far: 162112 samples\n",
            "0.93437254\n",
            "Training loss (for one batch) at step 5070: 0.1315\n",
            "Seen so far: 162272 samples\n",
            "0.93440026\n",
            "Training loss (for one batch) at step 5075: 0.0594\n",
            "Seen so far: 162432 samples\n",
            "0.9344279\n",
            "Training loss (for one batch) at step 5080: 0.3518\n",
            "Seen so far: 162592 samples\n",
            "0.934474\n",
            "Training loss (for one batch) at step 5085: 0.0428\n",
            "Seen so far: 162752 samples\n",
            "0.93452\n",
            "Training loss (for one batch) at step 5090: 0.0699\n",
            "Seen so far: 162912 samples\n",
            "0.9345352\n",
            "Training loss (for one batch) at step 5095: 0.0901\n",
            "Seen so far: 163072 samples\n",
            "0.9345626\n",
            "Training loss (for one batch) at step 5100: 0.1775\n",
            "Seen so far: 163232 samples\n",
            "0.93459004\n",
            "Training loss (for one batch) at step 5105: 0.9819\n",
            "Seen so far: 163392 samples\n",
            "0.93461126\n",
            "Training loss (for one batch) at step 5110: 0.1229\n",
            "Seen so far: 163552 samples\n",
            "0.9346202\n",
            "Training loss (for one batch) at step 5115: 0.0251\n",
            "Seen so far: 163712 samples\n",
            "0.93461686\n",
            "Training loss (for one batch) at step 5120: 0.2685\n",
            "Seen so far: 163872 samples\n",
            "0.9346319\n",
            "Training loss (for one batch) at step 5125: 0.0136\n",
            "Seen so far: 164032 samples\n",
            "0.93467736\n",
            "Training loss (for one batch) at step 5130: 0.1199\n",
            "Seen so far: 164192 samples\n",
            "0.93471056\n",
            "Training loss (for one batch) at step 5135: 0.0344\n",
            "Seen so far: 164352 samples\n",
            "0.93472546\n",
            "Training loss (for one batch) at step 5140: 0.0335\n",
            "Seen so far: 164512 samples\n",
            "0.9347403\n",
            "Training loss (for one batch) at step 5145: 0.1171\n",
            "Seen so far: 164672 samples\n",
            "0.9347734\n",
            "Training loss (for one batch) at step 5150: 0.0286\n",
            "Seen so far: 164832 samples\n",
            "0.9347942\n",
            "Training loss (for one batch) at step 5155: 0.0272\n",
            "Seen so far: 164992 samples\n",
            "0.93480897\n",
            "Training loss (for one batch) at step 5160: 0.0230\n",
            "Seen so far: 165152 samples\n",
            "0.9348479\n",
            "Training loss (for one batch) at step 5165: 0.1507\n",
            "Seen so far: 165312 samples\n",
            "0.93486255\n",
            "Training loss (for one batch) at step 5170: 0.1937\n",
            "Seen so far: 165472 samples\n",
            "0.93488926\n",
            "Training loss (for one batch) at step 5175: 0.1852\n",
            "Seen so far: 165632 samples\n",
            "0.93489784\n",
            "Training loss (for one batch) at step 5180: 0.1017\n",
            "Seen so far: 165792 samples\n",
            "0.9349245\n",
            "Training loss (for one batch) at step 5185: 0.0530\n",
            "Seen so far: 165952 samples\n",
            "0.9349571\n",
            "Training loss (for one batch) at step 5190: 0.0421\n",
            "Seen so far: 166112 samples\n",
            "0.9350017\n",
            "Training loss (for one batch) at step 5195: 0.0169\n",
            "Seen so far: 166272 samples\n",
            "0.93503416\n",
            "Training loss (for one batch) at step 5200: 0.0516\n",
            "Seen so far: 166432 samples\n",
            "0.9350906\n",
            "Training loss (for one batch) at step 5205: 0.0355\n",
            "Seen so far: 166592 samples\n",
            "0.93511695\n",
            "Training loss (for one batch) at step 5210: 0.0839\n",
            "Seen so far: 166752 samples\n",
            "0.9351492\n",
            "Training loss (for one batch) at step 5215: 0.0358\n",
            "Seen so far: 166912 samples\n",
            "0.9351934\n",
            "Training loss (for one batch) at step 5220: 0.0166\n",
            "Seen so far: 167072 samples\n",
            "0.93522555\n",
            "Training loss (for one batch) at step 5225: 0.0014\n",
            "Seen so far: 167232 samples\n",
            "0.9352636\n",
            "Training loss (for one batch) at step 5230: 0.1418\n",
            "Seen so far: 167392 samples\n",
            "0.9352717\n",
            "Training loss (for one batch) at step 5235: 0.0571\n",
            "Seen so far: 167552 samples\n",
            "0.93530965\n",
            "Training loss (for one batch) at step 5240: 0.0587\n",
            "Seen so far: 167712 samples\n",
            "0.9353475\n",
            "Training loss (for one batch) at step 5245: 0.0072\n",
            "Seen so far: 167872 samples\n",
            "0.93539125\n",
            "Training loss (for one batch) at step 5250: 0.1143\n",
            "Seen so far: 168032 samples\n",
            "0.935429\n",
            "Training loss (for one batch) at step 5255: 0.0030\n",
            "Seen so far: 168192 samples\n",
            "0.9354785\n",
            "Training loss (for one batch) at step 5260: 0.1440\n",
            "Seen so far: 168352 samples\n",
            "0.93549824\n",
            "Training loss (for one batch) at step 5265: 0.0231\n",
            "Seen so far: 168512 samples\n",
            "0.9355476\n",
            "Training loss (for one batch) at step 5270: 0.0288\n",
            "Seen so far: 168672 samples\n",
            "0.93557316\n",
            "Training loss (for one batch) at step 5275: 0.2952\n",
            "Seen so far: 168832 samples\n",
            "0.93561053\n",
            "Training loss (for one batch) at step 5280: 0.0799\n",
            "Seen so far: 168992 samples\n",
            "0.9356242\n",
            "Training loss (for one batch) at step 5285: 0.0965\n",
            "Seen so far: 169152 samples\n",
            "0.93566734\n",
            "Training loss (for one batch) at step 5290: 0.2233\n",
            "Seen so far: 169312 samples\n",
            "0.93568087\n",
            "Training loss (for one batch) at step 5295: 0.0191\n",
            "Seen so far: 169472 samples\n",
            "0.9357003\n",
            "Training loss (for one batch) at step 5300: 0.0705\n",
            "Seen so far: 169632 samples\n",
            "0.9357315\n",
            "Training loss (for one batch) at step 5305: 0.2876\n",
            "Seen so far: 169792 samples\n",
            "0.93572724\n",
            "Training loss (for one batch) at step 5310: 0.0615\n",
            "Seen so far: 169952 samples\n",
            "0.93575835\n",
            "Training loss (for one batch) at step 5315: 0.0940\n",
            "Seen so far: 170112 samples\n",
            "0.93579525\n",
            "Training loss (for one batch) at step 5320: 0.0595\n",
            "Seen so far: 170272 samples\n",
            "0.9358262\n",
            "Training loss (for one batch) at step 5325: 0.1433\n",
            "Seen so far: 170432 samples\n",
            "0.93583953\n",
            "Training loss (for one batch) at step 5330: 0.0898\n",
            "Seen so far: 170592 samples\n",
            "0.93587625\n",
            "Training loss (for one batch) at step 5335: 0.0612\n",
            "Seen so far: 170752 samples\n",
            "0.93590117\n",
            "Training loss (for one batch) at step 5340: 0.0034\n",
            "Seen so far: 170912 samples\n",
            "0.93594366\n",
            "Training loss (for one batch) at step 5345: 0.0109\n",
            "Seen so far: 171072 samples\n",
            "0.93598604\n",
            "Training loss (for one batch) at step 5350: 0.0391\n",
            "Seen so far: 171232 samples\n",
            "0.93600494\n",
            "Training loss (for one batch) at step 5355: 0.0688\n",
            "Seen so far: 171392 samples\n",
            "0.93604136\n",
            "Training loss (for one batch) at step 5360: 0.1392\n",
            "Seen so far: 171552 samples\n",
            "0.93606603\n",
            "Training loss (for one batch) at step 5365: 0.1356\n",
            "Seen so far: 171712 samples\n",
            "0.93610233\n",
            "Training loss (for one batch) at step 5370: 0.1882\n",
            "Seen so far: 171872 samples\n",
            "0.9361327\n",
            "Training loss (for one batch) at step 5375: 0.0331\n",
            "Seen so far: 172032 samples\n",
            "0.93616307\n",
            "Training loss (for one batch) at step 5380: 0.0612\n",
            "Seen so far: 172192 samples\n",
            "0.93619335\n",
            "Training loss (for one batch) at step 5385: 0.1894\n",
            "Seen so far: 172352 samples\n",
            "0.93622357\n",
            "Training loss (for one batch) at step 5390: 0.0404\n",
            "Seen so far: 172512 samples\n",
            "0.9362537\n",
            "Training loss (for one batch) at step 5395: 0.1072\n",
            "Seen so far: 172672 samples\n",
            "0.9363012\n",
            "Training loss (for one batch) at step 5400: 0.2482\n",
            "Seen so far: 172832 samples\n",
            "0.93632543\n",
            "Training loss (for one batch) at step 5405: 0.1158\n",
            "Seen so far: 172992 samples\n",
            "0.93637276\n",
            "Training loss (for one batch) at step 5410: 0.0168\n",
            "Seen so far: 173152 samples\n",
            "0.9363796\n",
            "Training loss (for one batch) at step 5415: 0.0311\n",
            "Seen so far: 173312 samples\n",
            "0.9363922\n",
            "Training loss (for one batch) at step 5420: 0.0861\n",
            "Seen so far: 173472 samples\n",
            "0.9364278\n",
            "Training loss (for one batch) at step 5425: 0.0684\n",
            "Seen so far: 173632 samples\n",
            "0.9364691\n",
            "Training loss (for one batch) at step 5430: 0.0766\n",
            "Seen so far: 173792 samples\n",
            "0.93650454\n",
            "Training loss (for one batch) at step 5435: 0.2368\n",
            "Seen so far: 173952 samples\n",
            "0.93655723\n",
            "Training loss (for one batch) at step 5440: 0.1379\n",
            "Seen so far: 174112 samples\n",
            "0.9365868\n",
            "Training loss (for one batch) at step 5445: 0.0223\n",
            "Seen so far: 174272 samples\n",
            "0.9366335\n",
            "Training loss (for one batch) at step 5450: 0.0460\n",
            "Seen so far: 174432 samples\n",
            "0.936663\n",
            "Training loss (for one batch) at step 5455: 0.0123\n",
            "Seen so far: 174592 samples\n",
            "0.93670386\n",
            "Training loss (for one batch) at step 5460: 0.1040\n",
            "Seen so far: 174752 samples\n",
            "0.9367103\n",
            "Training loss (for one batch) at step 5465: 0.2068\n",
            "Seen so far: 174912 samples\n",
            "0.93674535\n",
            "Training loss (for one batch) at step 5470: 0.0189\n",
            "Seen so far: 175072 samples\n",
            "0.936786\n",
            "Training loss (for one batch) at step 5475: 0.0169\n",
            "Seen so far: 175232 samples\n",
            "0.9368209\n",
            "Training loss (for one batch) at step 5480: 0.0341\n",
            "Seen so far: 175392 samples\n",
            "0.93685\n",
            "Training loss (for one batch) at step 5485: 0.0974\n",
            "Seen so far: 175552 samples\n",
            "0.9368962\n",
            "Training loss (for one batch) at step 5490: 0.0230\n",
            "Seen so far: 175712 samples\n",
            "0.9369309\n",
            "Training loss (for one batch) at step 5495: 0.2354\n",
            "Seen so far: 175872 samples\n",
            "0.9369769\n",
            "Training loss (for one batch) at step 5500: 0.0490\n",
            "Seen so far: 176032 samples\n",
            "0.9370115\n",
            "Training loss (for one batch) at step 5505: 0.1914\n",
            "Seen so far: 176192 samples\n",
            "0.9370346\n",
            "Training loss (for one batch) at step 5510: 0.1288\n",
            "Seen so far: 176352 samples\n",
            "0.93706906\n",
            "Training loss (for one batch) at step 5515: 0.0131\n",
            "Seen so far: 176512 samples\n",
            "0.9371148\n",
            "Training loss (for one batch) at step 5520: 0.0926\n",
            "Seen so far: 176672 samples\n",
            "0.9371604\n",
            "Training loss (for one batch) at step 5525: 0.0270\n",
            "Seen so far: 176832 samples\n",
            "0.9372059\n",
            "Training loss (for one batch) at step 5530: 0.1299\n",
            "Seen so far: 176992 samples\n",
            "0.93723446\n",
            "Training loss (for one batch) at step 5535: 0.0259\n",
            "Seen so far: 177152 samples\n",
            "0.9372855\n",
            "Training loss (for one batch) at step 5540: 0.0236\n",
            "Seen so far: 177312 samples\n",
            "0.93733644\n",
            "Training loss (for one batch) at step 5545: 0.0579\n",
            "Seen so far: 177472 samples\n",
            "0.9373704\n",
            "Training loss (for one batch) at step 5550: 0.0103\n",
            "Seen so far: 177632 samples\n",
            "0.93741554\n",
            "Training loss (for one batch) at step 5555: 0.1193\n",
            "Seen so far: 177792 samples\n",
            "0.93744373\n",
            "Training loss (for one batch) at step 5560: 0.0209\n",
            "Seen so far: 177952 samples\n",
            "0.9374719\n",
            "Training loss (for one batch) at step 5565: 0.0017\n",
            "Seen so far: 178112 samples\n",
            "0.9375\n",
            "Training loss (for one batch) at step 5570: 0.0460\n",
            "Seen so far: 178272 samples\n",
            "0.9375449\n",
            "Training loss (for one batch) at step 5575: 0.0283\n",
            "Seen so far: 178432 samples\n",
            "0.93759525\n",
            "Training loss (for one batch) at step 5580: 0.0518\n",
            "Seen so far: 178592 samples\n",
            "0.937612\n",
            "Training loss (for one batch) at step 5585: 0.0045\n",
            "Seen so far: 178752 samples\n",
            "0.93765104\n",
            "Training loss (for one batch) at step 5590: 0.0343\n",
            "Seen so far: 178912 samples\n",
            "0.9376956\n",
            "Training loss (for one batch) at step 5595: 0.0003\n",
            "Seen so far: 179072 samples\n",
            "0.93773454\n",
            "Training loss (for one batch) at step 5600: 0.0034\n",
            "Seen so far: 179232 samples\n",
            "0.93777895\n",
            "Training loss (for one batch) at step 5605: 0.2138\n",
            "Seen so far: 179392 samples\n",
            "0.93781775\n",
            "Training loss (for one batch) at step 5610: 0.0117\n",
            "Seen so far: 179552 samples\n",
            "0.93786204\n",
            "Training loss (for one batch) at step 5615: 0.0012\n",
            "Seen so far: 179712 samples\n",
            "0.9379062\n",
            "Training loss (for one batch) at step 5620: 0.6361\n",
            "Seen so far: 179872 samples\n",
            "0.93791693\n",
            "Training loss (for one batch) at step 5625: 0.0982\n",
            "Seen so far: 180032 samples\n",
            "0.9379388\n",
            "Training loss (for one batch) at step 5630: 0.0385\n",
            "Seen so far: 180192 samples\n",
            "0.9379606\n",
            "Training loss (for one batch) at step 5635: 0.2402\n",
            "Seen so far: 180352 samples\n",
            "0.9379713\n",
            "Training loss (for one batch) at step 5640: 0.1899\n",
            "Seen so far: 180512 samples\n",
            "0.93800414\n",
            "Training loss (for one batch) at step 5645: 0.0612\n",
            "Seen so far: 180672 samples\n",
            "0.93801475\n",
            "Training loss (for one batch) at step 5650: 0.2938\n",
            "Seen so far: 180832 samples\n",
            "0.9380198\n",
            "Training loss (for one batch) at step 5655: 0.1257\n",
            "Seen so far: 180992 samples\n",
            "0.93804145\n",
            "Training loss (for one batch) at step 5660: 0.2782\n",
            "Seen so far: 181152 samples\n",
            "0.93806857\n",
            "Training loss (for one batch) at step 5665: 0.0039\n",
            "Seen so far: 181312 samples\n",
            "0.93811774\n",
            "Training loss (for one batch) at step 5670: 0.2567\n",
            "Seen so far: 181472 samples\n",
            "0.9381282\n",
            "Training loss (for one batch) at step 5675: 0.1423\n",
            "Seen so far: 181632 samples\n",
            "0.9381497\n",
            "Training loss (for one batch) at step 5680: 0.0827\n",
            "Seen so far: 181792 samples\n",
            "0.9381766\n",
            "Training loss (for one batch) at step 5685: 0.0158\n",
            "Seen so far: 181952 samples\n",
            "0.93821996\n",
            "Training loss (for one batch) at step 5690: 0.0168\n",
            "Seen so far: 182112 samples\n",
            "0.9382523\n",
            "Training loss (for one batch) at step 5695: 0.1808\n",
            "Seen so far: 182272 samples\n",
            "0.93827355\n",
            "Training loss (for one batch) at step 5700: 0.2488\n",
            "Seen so far: 182432 samples\n",
            "0.9383003\n",
            "Training loss (for one batch) at step 5705: 0.3310\n",
            "Seen so far: 182592 samples\n",
            "0.9382996\n",
            "Training loss (for one batch) at step 5710: 0.0186\n",
            "Seen so far: 182752 samples\n",
            "0.9383536\n",
            "Training loss (for one batch) at step 5715: 0.1582\n",
            "Seen so far: 182912 samples\n",
            "0.9383583\n",
            "Training loss (for one batch) at step 5720: 0.1557\n",
            "Seen so far: 183072 samples\n",
            "0.9383521\n",
            "Training loss (for one batch) at step 5725: 0.1132\n",
            "Seen so far: 183232 samples\n",
            "0.9383732\n",
            "Training loss (for one batch) at step 5730: 0.1810\n",
            "Seen so far: 183392 samples\n",
            "0.9383888\n",
            "Training loss (for one batch) at step 5735: 0.0458\n",
            "Seen so far: 183552 samples\n",
            "0.9384207\n",
            "Training loss (for one batch) at step 5740: 0.1838\n",
            "Seen so far: 183712 samples\n",
            "0.93842536\n",
            "Training loss (for one batch) at step 5745: 0.0251\n",
            "Seen so far: 183872 samples\n",
            "0.93844086\n",
            "Training loss (for one batch) at step 5750: 0.2755\n",
            "Seen so far: 184032 samples\n",
            "0.93845093\n",
            "Training loss (for one batch) at step 5755: 0.0469\n",
            "Seen so far: 184192 samples\n",
            "0.9384718\n",
            "Training loss (for one batch) at step 5760: 0.5863\n",
            "Seen so far: 184352 samples\n",
            "0.9384764\n",
            "Training loss (for one batch) at step 5765: 0.1754\n",
            "Seen so far: 184512 samples\n",
            "0.93850267\n",
            "Training loss (for one batch) at step 5770: 0.0139\n",
            "Seen so far: 184672 samples\n",
            "0.93853426\n",
            "Training loss (for one batch) at step 5775: 0.2033\n",
            "Seen so far: 184832 samples\n",
            "0.9385496\n",
            "Training loss (for one batch) at step 5780: 0.1640\n",
            "Seen so far: 184992 samples\n",
            "0.93854326\n",
            "Training loss (for one batch) at step 5785: 0.2255\n",
            "Seen so far: 185152 samples\n",
            "0.9385586\n",
            "Training loss (for one batch) at step 5790: 0.0056\n",
            "Seen so far: 185312 samples\n",
            "0.93859005\n",
            "Training loss (for one batch) at step 5795: 0.0461\n",
            "Seen so far: 185472 samples\n",
            "0.9386161\n",
            "Training loss (for one batch) at step 5800: 0.2286\n",
            "Seen so far: 185632 samples\n",
            "0.9386205\n",
            "Training loss (for one batch) at step 5805: 0.3040\n",
            "Seen so far: 185792 samples\n",
            "0.9386303\n",
            "Training loss (for one batch) at step 5810: 0.1470\n",
            "Seen so far: 185952 samples\n",
            "0.9386616\n",
            "Training loss (for one batch) at step 5815: 0.1290\n",
            "Seen so far: 186112 samples\n",
            "0.93869823\n",
            "Training loss (for one batch) at step 5820: 0.0896\n",
            "Seen so far: 186272 samples\n",
            "0.9387187\n",
            "Training loss (for one batch) at step 5825: 0.1989\n",
            "Seen so far: 186432 samples\n",
            "0.9387605\n",
            "Training loss (for one batch) at step 5830: 0.1147\n",
            "Seen so far: 186592 samples\n",
            "0.93879694\n",
            "Training loss (for one batch) at step 5835: 0.0530\n",
            "Seen so far: 186752 samples\n",
            "0.9388333\n",
            "Training loss (for one batch) at step 5840: 0.0128\n",
            "Seen so far: 186912 samples\n",
            "0.93886966\n",
            "Training loss (for one batch) at step 5845: 0.2236\n",
            "Seen so far: 187072 samples\n",
            "0.93886846\n",
            "Training loss (for one batch) at step 5850: 0.0164\n",
            "Seen so far: 187232 samples\n",
            "0.93891\n",
            "Training loss (for one batch) at step 5855: 0.0563\n",
            "Seen so far: 187392 samples\n",
            "0.93893015\n",
            "Training loss (for one batch) at step 5860: 0.3040\n",
            "Seen so far: 187552 samples\n",
            "0.9389609\n",
            "Training loss (for one batch) at step 5865: 0.1268\n",
            "Seen so far: 187712 samples\n",
            "0.938981\n",
            "Training loss (for one batch) at step 5870: 0.1003\n",
            "Seen so far: 187872 samples\n",
            "0.9390117\n",
            "Training loss (for one batch) at step 5875: 0.0890\n",
            "Seen so far: 188032 samples\n",
            "0.93904763\n",
            "Training loss (for one batch) at step 5880: 0.0017\n",
            "Seen so far: 188192 samples\n",
            "0.9390888\n",
            "Training loss (for one batch) at step 5885: 0.0414\n",
            "Seen so far: 188352 samples\n",
            "0.93912995\n",
            "Training loss (for one batch) at step 5890: 0.2908\n",
            "Seen so far: 188512 samples\n",
            "0.93914443\n",
            "Training loss (for one batch) at step 5895: 0.1034\n",
            "Seen so far: 188672 samples\n",
            "0.9391696\n",
            "Training loss (for one batch) at step 5900: 0.2086\n",
            "Seen so far: 188832 samples\n",
            "0.9392052\n",
            "Training loss (for one batch) at step 5905: 0.1085\n",
            "Seen so far: 188992 samples\n",
            "0.9392355\n",
            "Training loss (for one batch) at step 5910: 0.0128\n",
            "Seen so far: 189152 samples\n",
            "0.9392658\n",
            "Training loss (for one batch) at step 5915: 0.0222\n",
            "Seen so far: 189312 samples\n",
            "0.93929595\n",
            "Training loss (for one batch) at step 5920: 0.0437\n",
            "Seen so far: 189472 samples\n",
            "0.93933666\n",
            "Training loss (for one batch) at step 5925: 0.0395\n",
            "Seen so far: 189632 samples\n",
            "0.9393615\n",
            "Training loss (for one batch) at step 5930: 0.0199\n",
            "Seen so far: 189792 samples\n",
            "0.9394021\n",
            "Training loss (for one batch) at step 5935: 0.1258\n",
            "Seen so far: 189952 samples\n",
            "0.93940574\n",
            "Training loss (for one batch) at step 5940: 0.0057\n",
            "Seen so far: 190112 samples\n",
            "0.9394462\n",
            "Training loss (for one batch) at step 5945: 0.0130\n",
            "Seen so far: 190272 samples\n",
            "0.93947613\n",
            "Training loss (for one batch) at step 5950: 0.0216\n",
            "Seen so far: 190432 samples\n",
            "0.9395165\n",
            "Training loss (for one batch) at step 5955: 0.2958\n",
            "Seen so far: 190592 samples\n",
            "0.939541\n",
            "Training loss (for one batch) at step 5960: 0.1958\n",
            "Seen so far: 190752 samples\n",
            "0.93958646\n",
            "Training loss (for one batch) at step 5965: 0.0131\n",
            "Seen so far: 190912 samples\n",
            "0.9396214\n",
            "Training loss (for one batch) at step 5970: 0.1605\n",
            "Seen so far: 191072 samples\n",
            "0.939651\n",
            "Training loss (for one batch) at step 5975: 0.0061\n",
            "Seen so far: 191232 samples\n",
            "0.93969107\n",
            "Training loss (for one batch) at step 5980: 0.4853\n",
            "Seen so far: 191392 samples\n",
            "0.9397153\n",
            "Training loss (for one batch) at step 5985: 0.0086\n",
            "Seen so far: 191552 samples\n",
            "0.93975\n",
            "Training loss (for one batch) at step 5990: 0.0053\n",
            "Seen so far: 191712 samples\n",
            "0.9397742\n",
            "Training loss (for one batch) at step 5995: 0.2393\n",
            "Seen so far: 191872 samples\n",
            "0.9398036\n",
            "Training loss (for one batch) at step 6000: 0.0311\n",
            "Seen so far: 192032 samples\n",
            "0.93984336\n",
            "Training loss (for one batch) at step 6005: 0.4204\n",
            "Seen so far: 192192 samples\n",
            "0.9398726\n",
            "Training loss (for one batch) at step 6010: 0.0755\n",
            "Seen so far: 192352 samples\n",
            "0.9398863\n",
            "Training loss (for one batch) at step 6015: 0.1120\n",
            "Seen so far: 192512 samples\n",
            "0.93990505\n",
            "Training loss (for one batch) at step 6020: 0.1560\n",
            "Seen so far: 192672 samples\n",
            "0.93991864\n",
            "Training loss (for one batch) at step 6025: 0.0136\n",
            "Seen so far: 192832 samples\n",
            "0.9399529\n",
            "Training loss (for one batch) at step 6030: 0.0053\n",
            "Seen so far: 192992 samples\n",
            "0.9399923\n",
            "Training loss (for one batch) at step 6035: 0.0290\n",
            "Seen so far: 193152 samples\n",
            "0.9400265\n",
            "Training loss (for one batch) at step 6040: 0.2581\n",
            "Seen so far: 193312 samples\n",
            "0.9400451\n",
            "Training loss (for one batch) at step 6045: 0.1667\n",
            "Seen so far: 193472 samples\n",
            "0.940074\n",
            "Training loss (for one batch) at step 6050: 0.0091\n",
            "Seen so far: 193632 samples\n",
            "0.9401132\n",
            "Training loss (for one batch) at step 6055: 0.2269\n",
            "Seen so far: 193792 samples\n",
            "0.94013685\n",
            "Training loss (for one batch) at step 6060: 0.0499\n",
            "Seen so far: 193952 samples\n",
            "0.9401759\n",
            "Training loss (for one batch) at step 6065: 0.0048\n",
            "Seen so far: 194112 samples\n",
            "0.94021493\n",
            "Training loss (for one batch) at step 6070: 0.0393\n",
            "Seen so far: 194272 samples\n",
            "0.9402333\n",
            "Training loss (for one batch) at step 6075: 0.0574\n",
            "Seen so far: 194432 samples\n",
            "0.94027215\n",
            "Training loss (for one batch) at step 6080: 0.0666\n",
            "Seen so far: 194592 samples\n",
            "0.940311\n",
            "Training loss (for one batch) at step 6085: 0.0075\n",
            "Seen so far: 194752 samples\n",
            "0.94034976\n",
            "Training loss (for one batch) at step 6090: 0.0953\n",
            "Seen so far: 194912 samples\n",
            "0.94037306\n",
            "Training loss (for one batch) at step 6095: 0.3407\n",
            "Seen so far: 195072 samples\n",
            "0.94039124\n",
            "Training loss (for one batch) at step 6100: 0.0111\n",
            "Seen so far: 195232 samples\n",
            "0.940435\n",
            "Training loss (for one batch) at step 6105: 0.0165\n",
            "Seen so far: 195392 samples\n",
            "0.94045305\n",
            "Training loss (for one batch) at step 6110: 0.1752\n",
            "Seen so far: 195552 samples\n",
            "0.9404813\n",
            "Training loss (for one batch) at step 6115: 0.0069\n",
            "Seen so far: 195712 samples\n",
            "0.94051975\n",
            "Training loss (for one batch) at step 6120: 0.0004\n",
            "Seen so far: 195872 samples\n",
            "0.9405632\n",
            "Training loss (for one batch) at step 6125: 0.0464\n",
            "Seen so far: 196032 samples\n",
            "0.9406015\n",
            "Training loss (for one batch) at step 6130: 0.1045\n",
            "Seen so far: 196192 samples\n",
            "0.94063467\n",
            "Training loss (for one batch) at step 6135: 0.1522\n",
            "Seen so far: 196352 samples\n",
            "0.9406729\n",
            "Training loss (for one batch) at step 6140: 0.0129\n",
            "Seen so far: 196512 samples\n",
            "0.94072115\n",
            "Training loss (for one batch) at step 6145: 0.0290\n",
            "Seen so far: 196672 samples\n",
            "0.94075924\n",
            "Training loss (for one batch) at step 6150: 0.0296\n",
            "Seen so far: 196832 samples\n",
            "0.9407871\n",
            "Training loss (for one batch) at step 6155: 0.0371\n",
            "Seen so far: 196992 samples\n",
            "0.94081485\n",
            "Training loss (for one batch) at step 6160: 0.1138\n",
            "Seen so far: 197152 samples\n",
            "0.94084257\n",
            "Training loss (for one batch) at step 6165: 0.1182\n",
            "Seen so far: 197312 samples\n",
            "0.9408703\n",
            "Training loss (for one batch) at step 6170: 0.0298\n",
            "Seen so far: 197472 samples\n",
            "0.94091314\n",
            "Training loss (for one batch) at step 6175: 0.0016\n",
            "Seen so far: 197632 samples\n",
            "0.94094074\n",
            "Training loss (for one batch) at step 6180: 0.0196\n",
            "Seen so far: 197792 samples\n",
            "0.9409784\n",
            "Training loss (for one batch) at step 6185: 0.2539\n",
            "Seen so far: 197952 samples\n",
            "0.9410211\n",
            "Training loss (for one batch) at step 6190: 0.0019\n",
            "Seen so far: 198112 samples\n",
            "0.9410687\n",
            "Training loss (for one batch) at step 6195: 0.0086\n",
            "Seen so far: 198272 samples\n",
            "0.9411112\n",
            "Training loss (for one batch) at step 6200: 0.0016\n",
            "Seen so far: 198432 samples\n",
            "0.9411587\n",
            "Training loss (for one batch) at step 6205: 0.0060\n",
            "Seen so far: 198592 samples\n",
            "0.94119096\n",
            "Training loss (for one batch) at step 6210: 0.1092\n",
            "Seen so far: 198752 samples\n",
            "0.9412182\n",
            "Training loss (for one batch) at step 6215: 0.0255\n",
            "Seen so far: 198912 samples\n",
            "0.9412504\n",
            "Training loss (for one batch) at step 6220: 0.0167\n",
            "Seen so far: 199072 samples\n",
            "0.9412826\n",
            "Training loss (for one batch) at step 6225: 0.0057\n",
            "Seen so far: 199232 samples\n",
            "0.94130963\n",
            "Training loss (for one batch) at step 6230: 0.0302\n",
            "Seen so far: 199392 samples\n",
            "0.9413517\n",
            "Training loss (for one batch) at step 6235: 0.0140\n",
            "Seen so far: 199552 samples\n",
            "0.9413586\n",
            "Training loss (for one batch) at step 6240: 0.0213\n",
            "Seen so far: 199712 samples\n",
            "0.9413956\n",
            "Training loss (for one batch) at step 6245: 0.1240\n",
            "Seen so far: 199872 samples\n",
            "0.9414175\n",
            "Training loss (for one batch) at step 6250: 0.0389\n",
            "Seen so far: 200032 samples\n",
            "0.94145435\n",
            "Training loss (for one batch) at step 6255: 0.0013\n",
            "Seen so far: 200192 samples\n",
            "0.9414912\n",
            "Training loss (for one batch) at step 6260: 0.0151\n",
            "Seen so far: 200352 samples\n",
            "0.94150794\n",
            "Training loss (for one batch) at step 6265: 0.0381\n",
            "Seen so far: 200512 samples\n",
            "0.94154465\n",
            "Training loss (for one batch) at step 6270: 0.0099\n",
            "Seen so far: 200672 samples\n",
            "0.9415813\n",
            "Training loss (for one batch) at step 6275: 0.1645\n",
            "Seen so far: 200832 samples\n",
            "0.941593\n",
            "Training loss (for one batch) at step 6280: 0.0080\n",
            "Seen so far: 200992 samples\n",
            "0.9416345\n",
            "Training loss (for one batch) at step 6285: 0.4588\n",
            "Seen so far: 201152 samples\n",
            "0.9416511\n",
            "Training loss (for one batch) at step 6290: 0.0054\n",
            "Seen so far: 201312 samples\n",
            "0.9416826\n",
            "Training loss (for one batch) at step 6295: 0.0195\n",
            "Seen so far: 201472 samples\n",
            "0.94171894\n",
            "Training loss (for one batch) at step 6300: 0.0196\n",
            "Seen so far: 201632 samples\n",
            "0.9417503\n",
            "Training loss (for one batch) at step 6305: 0.1555\n",
            "Seen so far: 201792 samples\n",
            "0.9417668\n",
            "Training loss (for one batch) at step 6310: 0.0434\n",
            "Seen so far: 201952 samples\n",
            "0.94178814\n",
            "Training loss (for one batch) at step 6315: 0.0747\n",
            "Seen so far: 202112 samples\n",
            "0.9418095\n",
            "Training loss (for one batch) at step 6320: 0.0007\n",
            "Seen so far: 202272 samples\n",
            "0.94184566\n",
            "Training loss (for one batch) at step 6325: 0.0580\n",
            "Seen so far: 202432 samples\n",
            "0.94187677\n",
            "Training loss (for one batch) at step 6330: 0.0810\n",
            "Seen so far: 202592 samples\n",
            "0.94190294\n",
            "Training loss (for one batch) at step 6335: 0.1643\n",
            "Seen so far: 202752 samples\n",
            "0.9419241\n",
            "Training loss (for one batch) at step 6340: 0.2245\n",
            "Seen so far: 202912 samples\n",
            "0.9419354\n",
            "Training loss (for one batch) at step 6345: 0.0248\n",
            "Seen so far: 203072 samples\n",
            "0.94195163\n",
            "Training loss (for one batch) at step 6350: 0.3161\n",
            "Seen so far: 203232 samples\n",
            "0.94194317\n",
            "Training loss (for one batch) at step 6355: 0.0829\n",
            "Seen so far: 203392 samples\n",
            "0.9419594\n",
            "Training loss (for one batch) at step 6360: 0.1617\n",
            "Seen so far: 203552 samples\n",
            "0.9419657\n",
            "Training loss (for one batch) at step 6365: 0.0893\n",
            "Seen so far: 203712 samples\n",
            "0.9419769\n",
            "Training loss (for one batch) at step 6370: 0.0221\n",
            "Seen so far: 203872 samples\n",
            "0.941993\n",
            "Training loss (for one batch) at step 6375: 0.0119\n",
            "Seen so far: 204032 samples\n",
            "0.9420238\n",
            "Training loss (for one batch) at step 6380: 0.0402\n",
            "Seen so far: 204192 samples\n",
            "0.94206434\n",
            "Training loss (for one batch) at step 6385: 0.0482\n",
            "Seen so far: 204352 samples\n",
            "0.9420852\n",
            "Training loss (for one batch) at step 6390: 0.1528\n",
            "Seen so far: 204512 samples\n",
            "0.9420963\n",
            "Training loss (for one batch) at step 6395: 0.0303\n",
            "Seen so far: 204672 samples\n",
            "0.9421074\n",
            "Training loss (for one batch) at step 6400: 0.0522\n",
            "Seen so far: 204832 samples\n",
            "0.9421233\n",
            "Training loss (for one batch) at step 6405: 0.1491\n",
            "Seen so far: 204992 samples\n",
            "0.9421441\n",
            "Training loss (for one batch) at step 6410: 0.0578\n",
            "Seen so far: 205152 samples\n",
            "0.94215024\n",
            "Training loss (for one batch) at step 6415: 0.0446\n",
            "Seen so far: 205312 samples\n",
            "0.9421515\n",
            "Training loss (for one batch) at step 6420: 0.3928\n",
            "Seen so far: 205472 samples\n",
            "0.94217217\n",
            "Training loss (for one batch) at step 6425: 0.0744\n",
            "Seen so far: 205632 samples\n",
            "0.94218796\n",
            "Training loss (for one batch) at step 6430: 0.0066\n",
            "Seen so far: 205792 samples\n",
            "0.9422232\n",
            "Training loss (for one batch) at step 6435: 0.1236\n",
            "Seen so far: 205952 samples\n",
            "0.9422487\n",
            "Training loss (for one batch) at step 6440: 0.0190\n",
            "Seen so far: 206112 samples\n",
            "0.94228864\n",
            "Training loss (for one batch) at step 6445: 0.0634\n",
            "Seen so far: 206272 samples\n",
            "0.94228494\n",
            "Training loss (for one batch) at step 6450: 0.6543\n",
            "Seen so far: 206432 samples\n",
            "0.9422764\n",
            "Training loss (for one batch) at step 6455: 0.8051\n",
            "Seen so far: 206592 samples\n",
            "0.9422824\n",
            "Training loss (for one batch) at step 6460: 0.1733\n",
            "Seen so far: 206752 samples\n",
            "0.94229317\n",
            "Training loss (for one batch) at step 6465: 0.5105\n",
            "Seen so far: 206912 samples\n",
            "0.9422895\n",
            "Training loss (for one batch) at step 6470: 0.0056\n",
            "Seen so far: 207072 samples\n",
            "0.94229543\n",
            "Training loss (for one batch) at step 6475: 0.0059\n",
            "Seen so far: 207232 samples\n",
            "0.94231105\n",
            "Training loss (for one batch) at step 6480: 0.2463\n",
            "Seen so far: 207392 samples\n",
            "0.9423025\n",
            "Training loss (for one batch) at step 6485: 0.0940\n",
            "Seen so far: 207552 samples\n",
            "0.9422892\n",
            "Training loss (for one batch) at step 6490: 0.0927\n",
            "Seen so far: 207712 samples\n",
            "0.9422999\n",
            "Training loss (for one batch) at step 6495: 0.0903\n",
            "Seen so far: 207872 samples\n",
            "0.9422866\n",
            "Training loss (for one batch) at step 6500: 0.4419\n",
            "Seen so far: 208032 samples\n",
            "0.9422829\n",
            "Training loss (for one batch) at step 6505: 0.6588\n",
            "Seen so far: 208192 samples\n",
            "0.94226485\n",
            "Training loss (for one batch) at step 6510: 0.6506\n",
            "Seen so far: 208352 samples\n",
            "0.94226116\n",
            "Training loss (for one batch) at step 6515: 0.0736\n",
            "Seen so far: 208512 samples\n",
            "0.94223833\n",
            "Training loss (for one batch) at step 6520: 0.1926\n",
            "Seen so far: 208672 samples\n",
            "0.9422251\n",
            "Training loss (for one batch) at step 6525: 0.0862\n",
            "Seen so far: 208832 samples\n",
            "0.9422215\n",
            "Training loss (for one batch) at step 6530: 0.4318\n",
            "Seen so far: 208992 samples\n",
            "0.9422035\n",
            "Training loss (for one batch) at step 6535: 0.1759\n",
            "Seen so far: 209152 samples\n",
            "0.94219995\n",
            "Training loss (for one batch) at step 6540: 0.5581\n",
            "Seen so far: 209312 samples\n",
            "0.942182\n",
            "Training loss (for one batch) at step 6545: 0.6402\n",
            "Seen so far: 209472 samples\n",
            "0.94217366\n",
            "Training loss (for one batch) at step 6550: 0.0451\n",
            "Seen so far: 209632 samples\n",
            "0.9421653\n",
            "Training loss (for one batch) at step 6555: 0.2951\n",
            "Seen so far: 209792 samples\n",
            "0.9421713\n",
            "Training loss (for one batch) at step 6560: 0.0416\n",
            "Seen so far: 209952 samples\n",
            "0.942182\n",
            "Training loss (for one batch) at step 6565: 0.7586\n",
            "Seen so far: 210112 samples\n",
            "0.94215465\n",
            "Training loss (for one batch) at step 6570: 0.1478\n",
            "Seen so far: 210272 samples\n",
            "0.9421511\n",
            "Training loss (for one batch) at step 6575: 0.2299\n",
            "Seen so far: 210432 samples\n",
            "0.94214755\n",
            "Training loss (for one batch) at step 6580: 0.6067\n",
            "Seen so far: 210592 samples\n",
            "0.9421488\n",
            "Training loss (for one batch) at step 6585: 0.1167\n",
            "Seen so far: 210752 samples\n",
            "0.94213575\n",
            "Training loss (for one batch) at step 6590: 0.3441\n",
            "Seen so far: 210912 samples\n",
            "0.94213223\n",
            "Training loss (for one batch) at step 6595: 0.3737\n",
            "Seen so far: 211072 samples\n",
            "0.94211453\n",
            "Training loss (for one batch) at step 6600: 0.3263\n",
            "Seen so far: 211232 samples\n",
            "0.942111\n",
            "Training loss (for one batch) at step 6605: 0.0693\n",
            "Seen so far: 211392 samples\n",
            "0.9421312\n",
            "Training loss (for one batch) at step 6610: 0.2250\n",
            "Seen so far: 211552 samples\n",
            "0.9421182\n",
            "Training loss (for one batch) at step 6615: 0.1688\n",
            "Seen so far: 211712 samples\n",
            "0.94213367\n",
            "Training loss (for one batch) at step 6620: 0.1292\n",
            "Seen so far: 211872 samples\n",
            "0.94215375\n",
            "Training loss (for one batch) at step 6625: 0.0565\n",
            "Seen so far: 212032 samples\n",
            "0.94215494\n",
            "Training loss (for one batch) at step 6630: 0.1635\n",
            "Seen so far: 212192 samples\n",
            "0.94217503\n",
            "Training loss (for one batch) at step 6635: 0.3586\n",
            "Seen so far: 212352 samples\n",
            "0.94218564\n",
            "Training loss (for one batch) at step 6640: 0.0397\n",
            "Seen so far: 212512 samples\n",
            "0.9421915\n",
            "Training loss (for one batch) at step 6645: 0.1017\n",
            "Seen so far: 212672 samples\n",
            "0.9422021\n",
            "Training loss (for one batch) at step 6650: 0.0345\n",
            "Seen so far: 212832 samples\n",
            "0.94222206\n",
            "Training loss (for one batch) at step 6655: 0.1665\n",
            "Seen so far: 212992 samples\n",
            "0.9422138\n",
            "Training loss (for one batch) at step 6660: 0.5123\n",
            "Seen so far: 213152 samples\n",
            "0.9421962\n",
            "Training loss (for one batch) at step 6665: 0.0483\n",
            "Seen so far: 213312 samples\n",
            "0.94220674\n",
            "Training loss (for one batch) at step 6670: 0.0235\n",
            "Seen so far: 213472 samples\n",
            "0.9422126\n",
            "Training loss (for one batch) at step 6675: 0.0686\n",
            "Seen so far: 213632 samples\n",
            "0.94219965\n",
            "Training loss (for one batch) at step 6680: 0.4084\n",
            "Seen so far: 213792 samples\n",
            "0.9421681\n",
            "Training loss (for one batch) at step 6685: 0.4367\n",
            "Seen so far: 213952 samples\n",
            "0.9421459\n",
            "Training loss (for one batch) at step 6690: 0.0739\n",
            "Seen so far: 214112 samples\n",
            "0.94211906\n",
            "Training loss (for one batch) at step 6695: 0.0159\n",
            "Seen so far: 214272 samples\n",
            "0.94213897\n",
            "Training loss (for one batch) at step 6700: 0.0084\n",
            "Seen so far: 214432 samples\n",
            "0.9421448\n",
            "Training loss (for one batch) at step 6705: 0.1299\n",
            "Seen so far: 214592 samples\n",
            "0.94215536\n",
            "Training loss (for one batch) at step 6710: 0.0460\n",
            "Seen so far: 214752 samples\n",
            "0.94214255\n",
            "Training loss (for one batch) at step 6715: 0.0196\n",
            "Seen so far: 214912 samples\n",
            "0.9421717\n",
            "Training loss (for one batch) at step 6720: 0.0093\n",
            "Seen so far: 215072 samples\n",
            "0.9421542\n",
            "Training loss (for one batch) at step 6725: 0.1222\n",
            "Seen so far: 215232 samples\n",
            "0.94216007\n",
            "Training loss (for one batch) at step 6730: 0.0136\n",
            "Seen so far: 215392 samples\n",
            "0.94219375\n",
            "Training loss (for one batch) at step 6735: 0.1145\n",
            "Seen so far: 215552 samples\n",
            "0.9422088\n",
            "Training loss (for one batch) at step 6740: 0.0765\n",
            "Seen so far: 215712 samples\n",
            "0.9422239\n",
            "Training loss (for one batch) at step 6745: 0.0975\n",
            "Seen so far: 215872 samples\n",
            "0.9422436\n",
            "Training loss (for one batch) at step 6750: 0.0385\n",
            "Seen so far: 216032 samples\n",
            "0.9422771\n",
            "Training loss (for one batch) at step 6755: 0.0937\n",
            "Seen so far: 216192 samples\n",
            "0.94231516\n",
            "Training loss (for one batch) at step 6760: 0.0333\n",
            "Seen so far: 216352 samples\n",
            "0.9423347\n",
            "Training loss (for one batch) at step 6765: 0.1537\n",
            "Seen so far: 216512 samples\n",
            "0.942345\n",
            "Training loss (for one batch) at step 6770: 0.0784\n",
            "Seen so far: 216672 samples\n",
            "0.9423691\n",
            "Training loss (for one batch) at step 6775: 0.0940\n",
            "Seen so far: 216832 samples\n",
            "0.9424024\n",
            "Training loss (for one batch) at step 6780: 0.0079\n",
            "Seen so far: 216992 samples\n",
            "0.9424172\n",
            "Training loss (for one batch) at step 6785: 0.2540\n",
            "Seen so far: 217152 samples\n",
            "0.94245505\n",
            "Training loss (for one batch) at step 6790: 0.0342\n",
            "Seen so far: 217312 samples\n",
            "0.942479\n",
            "Training loss (for one batch) at step 6795: 0.2663\n",
            "Seen so far: 217472 samples\n",
            "0.9425029\n",
            "Training loss (for one batch) at step 6800: 0.0020\n",
            "Seen so far: 217632 samples\n",
            "0.94250846\n",
            "Training loss (for one batch) at step 6805: 0.0499\n",
            "Seen so far: 217792 samples\n",
            "0.9425369\n",
            "Training loss (for one batch) at step 6810: 0.0768\n",
            "Seen so far: 217952 samples\n",
            "0.9425699\n",
            "Training loss (for one batch) at step 6815: 0.0060\n",
            "Seen so far: 218112 samples\n",
            "0.9426029\n",
            "Training loss (for one batch) at step 6820: 0.1939\n",
            "Seen so far: 218272 samples\n",
            "0.9426175\n",
            "Training loss (for one batch) at step 6825: 0.1040\n",
            "Seen so far: 218432 samples\n",
            "0.942632\n",
            "Training loss (for one batch) at step 6830: 0.0720\n",
            "Seen so far: 218592 samples\n",
            "0.9426603\n",
            "Training loss (for one batch) at step 6835: 0.0031\n",
            "Seen so far: 218752 samples\n",
            "0.9426931\n",
            "Training loss (for one batch) at step 6840: 0.0056\n",
            "Seen so far: 218912 samples\n",
            "0.9427304\n",
            "Training loss (for one batch) at step 6845: 0.0183\n",
            "Seen so far: 219072 samples\n",
            "0.9427722\n",
            "Training loss (for one batch) at step 6850: 0.0014\n",
            "Seen so far: 219232 samples\n",
            "0.94280034\n",
            "Training loss (for one batch) at step 6855: 0.0365\n",
            "Seen so far: 219392 samples\n",
            "0.94282836\n",
            "Training loss (for one batch) at step 6860: 0.1074\n",
            "Seen so far: 219552 samples\n",
            "0.94283813\n",
            "Training loss (for one batch) at step 6865: 0.0006\n",
            "Seen so far: 219712 samples\n",
            "0.942857\n",
            "Training loss (for one batch) at step 6870: 0.0103\n",
            "Seen so far: 219872 samples\n",
            "0.94289404\n",
            "Training loss (for one batch) at step 6875: 0.0270\n",
            "Seen so far: 220032 samples\n",
            "0.9429174\n",
            "Training loss (for one batch) at step 6880: 0.0387\n",
            "Seen so far: 220192 samples\n",
            "0.9429498\n",
            "Training loss (for one batch) at step 6885: 0.0108\n",
            "Seen so far: 220352 samples\n",
            "0.9429731\n",
            "Training loss (for one batch) at step 6890: 0.2094\n",
            "Seen so far: 220512 samples\n",
            "0.9429872\n",
            "Training loss (for one batch) at step 6895: 0.0064\n",
            "Seen so far: 220672 samples\n",
            "0.943015\n",
            "Training loss (for one batch) at step 6900: 0.0129\n",
            "Seen so far: 220832 samples\n",
            "0.94303817\n",
            "Training loss (for one batch) at step 6905: 0.1509\n",
            "Seen so far: 220992 samples\n",
            "0.94305223\n",
            "Training loss (for one batch) at step 6910: 0.0307\n",
            "Seen so far: 221152 samples\n",
            "0.94307536\n",
            "Training loss (for one batch) at step 6915: 0.0190\n",
            "Seen so far: 221312 samples\n",
            "0.94310296\n",
            "Training loss (for one batch) at step 6920: 0.0779\n",
            "Seen so far: 221472 samples\n",
            "0.9431305\n",
            "Training loss (for one batch) at step 6925: 0.0367\n",
            "Seen so far: 221632 samples\n",
            "0.9431535\n",
            "Training loss (for one batch) at step 6930: 0.0105\n",
            "Seen so far: 221792 samples\n",
            "0.9431855\n",
            "Training loss (for one batch) at step 6935: 0.0025\n",
            "Seen so far: 221952 samples\n",
            "0.943222\n",
            "Training loss (for one batch) at step 6940: 0.0868\n",
            "Seen so far: 222112 samples\n",
            "0.9432359\n",
            "Training loss (for one batch) at step 6945: 0.3124\n",
            "Seen so far: 222272 samples\n",
            "0.94326323\n",
            "Training loss (for one batch) at step 6950: 0.1089\n",
            "Seen so far: 222432 samples\n",
            "0.94327706\n",
            "Training loss (for one batch) at step 6955: 0.0046\n",
            "Seen so far: 222592 samples\n",
            "0.94330883\n",
            "Training loss (for one batch) at step 6960: 0.0007\n",
            "Seen so far: 222752 samples\n",
            "0.9433406\n",
            "Training loss (for one batch) at step 6965: 0.0008\n",
            "Seen so far: 222912 samples\n",
            "0.94337225\n",
            "Training loss (for one batch) at step 6970: 0.2404\n",
            "Seen so far: 223072 samples\n",
            "0.943386\n",
            "Training loss (for one batch) at step 6975: 0.0242\n",
            "Seen so far: 223232 samples\n",
            "0.94341314\n",
            "Training loss (for one batch) at step 6980: 0.1332\n",
            "Seen so far: 223392 samples\n",
            "0.9434492\n",
            "Training loss (for one batch) at step 6985: 0.0519\n",
            "Seen so far: 223552 samples\n",
            "0.9434852\n",
            "Training loss (for one batch) at step 6990: 0.0264\n",
            "Seen so far: 223712 samples\n",
            "0.9435122\n",
            "Training loss (for one batch) at step 6995: 0.0482\n",
            "Seen so far: 223872 samples\n",
            "0.94353914\n",
            "Training loss (for one batch) at step 7000: 0.0147\n",
            "Seen so far: 224032 samples\n",
            "0.9435616\n",
            "Training loss (for one batch) at step 7005: 0.0133\n",
            "Seen so far: 224192 samples\n",
            "0.9436019\n",
            "Training loss (for one batch) at step 7010: 0.2641\n",
            "Seen so far: 224352 samples\n",
            "0.94361985\n",
            "Training loss (for one batch) at step 7015: 0.0801\n",
            "Seen so far: 224512 samples\n",
            "0.94364667\n",
            "Training loss (for one batch) at step 7020: 0.0662\n",
            "Seen so far: 224672 samples\n",
            "0.94367343\n",
            "Training loss (for one batch) at step 7025: 0.1928\n",
            "Seen so far: 224832 samples\n",
            "0.9436957\n",
            "Training loss (for one batch) at step 7030: 0.0024\n",
            "Seen so far: 224992 samples\n",
            "0.943718\n",
            "Training loss (for one batch) at step 7035: 0.0772\n",
            "Seen so far: 225152 samples\n",
            "0.94374466\n",
            "Training loss (for one batch) at step 7040: 0.0069\n",
            "Seen so far: 225312 samples\n",
            "0.9437846\n",
            "Training loss (for one batch) at step 7045: 0.0024\n",
            "Seen so far: 225472 samples\n",
            "0.94381565\n",
            "Training loss (for one batch) at step 7050: 0.0004\n",
            "Seen so far: 225632 samples\n",
            "0.9438422\n",
            "Training loss (for one batch) at step 7055: 0.0319\n",
            "Seen so far: 225792 samples\n",
            "0.9438731\n",
            "Training loss (for one batch) at step 7060: 0.1308\n",
            "Seen so far: 225952 samples\n",
            "0.94389075\n",
            "Training loss (for one batch) at step 7065: 0.0056\n",
            "Seen so far: 226112 samples\n",
            "0.9439216\n",
            "Training loss (for one batch) at step 7070: 0.0044\n",
            "Seen so far: 226272 samples\n",
            "0.9439524\n",
            "Training loss (for one batch) at step 7075: 0.0014\n",
            "Seen so far: 226432 samples\n",
            "0.9439832\n",
            "Training loss (for one batch) at step 7080: 0.0308\n",
            "Seen so far: 226592 samples\n",
            "0.9440095\n",
            "Training loss (for one batch) at step 7085: 0.0097\n",
            "Seen so far: 226752 samples\n",
            "0.94403577\n",
            "Training loss (for one batch) at step 7090: 0.0052\n",
            "Seen so far: 226912 samples\n",
            "0.9440708\n",
            "Training loss (for one batch) at step 7095: 0.0077\n",
            "Seen so far: 227072 samples\n",
            "0.94410586\n",
            "Training loss (for one batch) at step 7100: 0.0168\n",
            "Seen so far: 227232 samples\n",
            "0.9441452\n",
            "Training loss (for one batch) at step 7105: 0.0465\n",
            "Seen so far: 227392 samples\n",
            "0.9441757\n",
            "Training loss (for one batch) at step 7110: 0.0329\n",
            "Seen so far: 227552 samples\n",
            "0.94419736\n",
            "Training loss (for one batch) at step 7115: 0.0129\n",
            "Seen so far: 227712 samples\n",
            "0.9442278\n",
            "Training loss (for one batch) at step 7120: 0.0170\n",
            "Seen so far: 227872 samples\n",
            "0.94426256\n",
            "Training loss (for one batch) at step 7125: 0.2882\n",
            "Seen so far: 228032 samples\n",
            "0.94428414\n",
            "Training loss (for one batch) at step 7130: 0.0134\n",
            "Seen so far: 228192 samples\n",
            "0.9442969\n",
            "Training loss (for one batch) at step 7135: 0.0566\n",
            "Seen so far: 228352 samples\n",
            "0.9443272\n",
            "Training loss (for one batch) at step 7140: 0.0837\n",
            "Seen so far: 228512 samples\n",
            "0.9443574\n",
            "Training loss (for one batch) at step 7145: 0.0709\n",
            "Seen so far: 228672 samples\n",
            "0.9443832\n",
            "Training loss (for one batch) at step 7150: 0.0097\n",
            "Seen so far: 228832 samples\n",
            "0.9444177\n",
            "Training loss (for one batch) at step 7155: 0.0172\n",
            "Seen so far: 228992 samples\n",
            "0.9444478\n",
            "Training loss (for one batch) at step 7160: 0.0094\n",
            "Seen so far: 229152 samples\n",
            "0.9444779\n",
            "Training loss (for one batch) at step 7165: 0.0010\n",
            "Seen so far: 229312 samples\n",
            "0.94450355\n",
            "Training loss (for one batch) at step 7170: 0.0056\n",
            "Seen so far: 229472 samples\n",
            "0.9445292\n",
            "Training loss (for one batch) at step 7175: 0.0226\n",
            "Seen so far: 229632 samples\n",
            "0.9445504\n",
            "Training loss (for one batch) at step 7180: 0.0051\n",
            "Seen so far: 229792 samples\n",
            "0.9445803\n",
            "Training loss (for one batch) at step 7185: 0.0280\n",
            "Seen so far: 229952 samples\n",
            "0.9446102\n",
            "Training loss (for one batch) at step 7190: 0.0156\n",
            "Seen so far: 230112 samples\n",
            "0.94464433\n",
            "Training loss (for one batch) at step 7195: 0.0141\n",
            "Seen so far: 230272 samples\n",
            "0.94468284\n",
            "Training loss (for one batch) at step 7200: 0.0221\n",
            "Seen so far: 230432 samples\n",
            "0.9447212\n",
            "Training loss (for one batch) at step 7205: 0.1843\n",
            "Seen so far: 230592 samples\n",
            "0.9447422\n",
            "Training loss (for one batch) at step 7210: 0.0082\n",
            "Seen so far: 230752 samples\n",
            "0.9447719\n",
            "Training loss (for one batch) at step 7215: 0.0613\n",
            "Seen so far: 230912 samples\n",
            "0.9448015\n",
            "Training loss (for one batch) at step 7220: 0.0035\n",
            "Seen so far: 231072 samples\n",
            "0.9448311\n",
            "Training loss (for one batch) at step 7225: 0.0271\n",
            "Seen so far: 231232 samples\n",
            "0.94486487\n",
            "Training loss (for one batch) at step 7230: 0.0122\n",
            "Seen so far: 231392 samples\n",
            "0.94488573\n",
            "Training loss (for one batch) at step 7235: 0.0195\n",
            "Seen so far: 231552 samples\n",
            "0.94490224\n",
            "Training loss (for one batch) at step 7240: 0.0024\n",
            "Seen so far: 231712 samples\n",
            "0.9449187\n",
            "Training loss (for one batch) at step 7245: 0.0039\n",
            "Seen so far: 231872 samples\n",
            "0.94495237\n",
            "Training loss (for one batch) at step 7250: 0.1850\n",
            "Seen so far: 232032 samples\n",
            "0.94496447\n",
            "Training loss (for one batch) at step 7255: 0.1805\n",
            "Seen so far: 232192 samples\n",
            "0.9449938\n",
            "Training loss (for one batch) at step 7260: 0.0913\n",
            "Seen so far: 232352 samples\n",
            "0.94502306\n",
            "Training loss (for one batch) at step 7265: 0.0595\n",
            "Seen so far: 232512 samples\n",
            "0.945048\n",
            "Training loss (for one batch) at step 7270: 0.0032\n",
            "Seen so far: 232672 samples\n",
            "0.94508576\n",
            "Training loss (for one batch) at step 7275: 0.0122\n",
            "Seen so far: 232832 samples\n",
            "0.9451149\n",
            "Training loss (for one batch) at step 7280: 0.0077\n",
            "Seen so far: 232992 samples\n",
            "0.94514406\n",
            "Training loss (for one batch) at step 7285: 0.0533\n",
            "Seen so far: 233152 samples\n",
            "0.9451645\n",
            "Training loss (for one batch) at step 7290: 0.0098\n",
            "Seen so far: 233312 samples\n",
            "0.9451978\n",
            "Training loss (for one batch) at step 7295: 0.0003\n",
            "Seen so far: 233472 samples\n",
            "0.94523543\n",
            "Training loss (for one batch) at step 7300: 0.0149\n",
            "Seen so far: 233632 samples\n",
            "0.94526005\n",
            "Training loss (for one batch) at step 7305: 0.0025\n",
            "Seen so far: 233792 samples\n",
            "0.94528896\n",
            "Training loss (for one batch) at step 7310: 0.2139\n",
            "Seen so far: 233952 samples\n",
            "0.9453093\n",
            "Training loss (for one batch) at step 7315: 0.1229\n",
            "Seen so far: 234112 samples\n",
            "0.94533813\n",
            "Training loss (for one batch) at step 7320: 0.0382\n",
            "Seen so far: 234272 samples\n",
            "0.9453499\n",
            "Training loss (for one batch) at step 7325: 0.0053\n",
            "Seen so far: 234432 samples\n",
            "0.9453829\n",
            "Training loss (for one batch) at step 7330: 0.0321\n",
            "Seen so far: 234592 samples\n",
            "0.9454116\n",
            "Training loss (for one batch) at step 7335: 0.0221\n",
            "Seen so far: 234752 samples\n",
            "0.9454488\n",
            "Training loss (for one batch) at step 7340: 0.0008\n",
            "Seen so far: 234912 samples\n",
            "0.9454774\n",
            "Training loss (for one batch) at step 7345: 0.0074\n",
            "Seen so far: 235072 samples\n",
            "0.94551456\n",
            "Training loss (for one batch) at step 7350: 0.0088\n",
            "Seen so far: 235232 samples\n",
            "0.94555163\n",
            "Training loss (for one batch) at step 7355: 0.0040\n",
            "Seen so far: 235392 samples\n",
            "0.9455844\n",
            "Training loss (for one batch) at step 7360: 0.0029\n",
            "Seen so far: 235552 samples\n",
            "0.94560015\n",
            "Training loss (for one batch) at step 7365: 0.0019\n",
            "Seen so far: 235712 samples\n",
            "0.94563705\n",
            "Training loss (for one batch) at step 7370: 0.0153\n",
            "Seen so far: 235872 samples\n",
            "0.94567394\n",
            "Training loss (for one batch) at step 7375: 0.0035\n",
            "Seen so far: 236032 samples\n",
            "0.9457108\n",
            "Training loss (for one batch) at step 7380: 0.0019\n",
            "Seen so far: 236192 samples\n",
            "0.9457348\n",
            "Training loss (for one batch) at step 7385: 0.0114\n",
            "Seen so far: 236352 samples\n",
            "0.9457631\n",
            "Training loss (for one batch) at step 7390: 0.0357\n",
            "Seen so far: 236512 samples\n",
            "0.94579554\n",
            "Training loss (for one batch) at step 7395: 0.0008\n",
            "Seen so far: 236672 samples\n",
            "0.94582796\n",
            "Training loss (for one batch) at step 7400: 0.0265\n",
            "Seen so far: 236832 samples\n",
            "0.94584346\n",
            "Training loss (for one batch) at step 7405: 0.0062\n",
            "Seen so far: 236992 samples\n",
            "0.9458716\n",
            "Training loss (for one batch) at step 7410: 0.1081\n",
            "Seen so far: 237152 samples\n",
            "0.94589126\n",
            "Training loss (for one batch) at step 7415: 0.0041\n",
            "Seen so far: 237312 samples\n",
            "0.9459151\n",
            "Training loss (for one batch) at step 7420: 0.0011\n",
            "Seen so far: 237472 samples\n",
            "0.9459473\n",
            "Training loss (for one batch) at step 7425: 0.0054\n",
            "Seen so far: 237632 samples\n",
            "0.9459669\n",
            "Training loss (for one batch) at step 7430: 0.0369\n",
            "Seen so far: 237792 samples\n",
            "0.9459822\n",
            "Training loss (for one batch) at step 7435: 0.0009\n",
            "Seen so far: 237952 samples\n",
            "0.94601434\n",
            "Training loss (for one batch) at step 7440: 0.0008\n",
            "Seen so far: 238112 samples\n",
            "0.9460422\n",
            "Training loss (for one batch) at step 7445: 0.0193\n",
            "Seen so far: 238272 samples\n",
            "0.94607425\n",
            "Training loss (for one batch) at step 7450: 0.0829\n",
            "Seen so far: 238432 samples\n",
            "0.94609785\n",
            "Training loss (for one batch) at step 7455: 0.1266\n",
            "Seen so far: 238592 samples\n",
            "0.9461256\n",
            "Training loss (for one batch) at step 7460: 0.1692\n",
            "Seen so far: 238752 samples\n",
            "0.94614494\n",
            "Training loss (for one batch) at step 7465: 0.0729\n",
            "Seen so far: 238912 samples\n",
            "0.9461601\n",
            "Training loss (for one batch) at step 7470: 0.1162\n",
            "Seen so far: 239072 samples\n",
            "0.94619197\n",
            "Training loss (for one batch) at step 7475: 0.2872\n",
            "Seen so far: 239232 samples\n",
            "0.9462154\n",
            "Training loss (for one batch) at step 7480: 0.0018\n",
            "Seen so far: 239392 samples\n",
            "0.9462388\n",
            "Training loss (for one batch) at step 7485: 0.0093\n",
            "Seen so far: 239552 samples\n",
            "0.9462705\n",
            "Training loss (for one batch) at step 7490: 0.0033\n",
            "Seen so far: 239712 samples\n",
            "0.94630224\n",
            "Training loss (for one batch) at step 7495: 0.0358\n",
            "Seen so far: 239872 samples\n",
            "0.9463339\n",
            "Training loss (for one batch) at step 7500: 0.0033\n",
            "Seen so far: 240032 samples\n",
            "0.94636965\n",
            "Training loss (for one batch) at step 7505: 0.0055\n",
            "Seen so far: 240192 samples\n",
            "0.94639707\n",
            "Training loss (for one batch) at step 7510: 0.0230\n",
            "Seen so far: 240352 samples\n",
            "0.9464286\n",
            "Training loss (for one batch) at step 7515: 0.0071\n",
            "Seen so far: 240512 samples\n",
            "0.9464559\n",
            "Training loss (for one batch) at step 7520: 0.0180\n",
            "Seen so far: 240672 samples\n",
            "0.9464832\n",
            "Training loss (for one batch) at step 7525: 0.0606\n",
            "Seen so far: 240832 samples\n",
            "0.9465146\n",
            "Training loss (for one batch) at step 7530: 0.0082\n",
            "Seen so far: 240992 samples\n",
            "0.9465418\n",
            "Training loss (for one batch) at step 7535: 0.0920\n",
            "Seen so far: 241152 samples\n",
            "0.9465482\n",
            "Training loss (for one batch) at step 7540: 0.0150\n",
            "Seen so far: 241312 samples\n",
            "0.94657123\n",
            "Training loss (for one batch) at step 7545: 0.0640\n",
            "Seen so far: 241472 samples\n",
            "0.94659835\n",
            "Training loss (for one batch) at step 7550: 0.0219\n",
            "Seen so far: 241632 samples\n",
            "0.9466255\n",
            "Training loss (for one batch) at step 7555: 0.0004\n",
            "Seen so far: 241792 samples\n",
            "0.94664425\n",
            "Training loss (for one batch) at step 7560: 0.0448\n",
            "Seen so far: 241952 samples\n",
            "0.94666713\n",
            "Training loss (for one batch) at step 7565: 0.0033\n",
            "Seen so far: 242112 samples\n",
            "0.94670236\n",
            "Training loss (for one batch) at step 7570: 0.1704\n",
            "Seen so far: 242272 samples\n",
            "0.9467169\n",
            "Training loss (for one batch) at step 7575: 0.1104\n",
            "Seen so far: 242432 samples\n",
            "0.94673973\n",
            "Training loss (for one batch) at step 7580: 0.0070\n",
            "Seen so far: 242592 samples\n",
            "0.9467666\n",
            "Training loss (for one batch) at step 7585: 0.1443\n",
            "Seen so far: 242752 samples\n",
            "0.9467893\n",
            "Training loss (for one batch) at step 7590: 0.0547\n",
            "Seen so far: 242912 samples\n",
            "0.9468079\n",
            "Training loss (for one batch) at step 7595: 0.2009\n",
            "Seen so far: 243072 samples\n",
            "0.9468306\n",
            "Training loss (for one batch) at step 7600: 0.1094\n",
            "Seen so far: 243232 samples\n",
            "0.94685733\n",
            "Training loss (for one batch) at step 7605: 0.0307\n",
            "Seen so far: 243392 samples\n",
            "0.9468635\n",
            "Training loss (for one batch) at step 7610: 0.0298\n",
            "Seen so far: 243552 samples\n",
            "0.94688606\n",
            "Training loss (for one batch) at step 7615: 0.0094\n",
            "Seen so far: 243712 samples\n",
            "0.9469169\n",
            "Training loss (for one batch) at step 7620: 0.0009\n",
            "Seen so far: 243872 samples\n",
            "0.9469312\n",
            "Training loss (for one batch) at step 7625: 0.0011\n",
            "Seen so far: 244032 samples\n",
            "0.94695777\n",
            "Training loss (for one batch) at step 7630: 0.0210\n",
            "Seen so far: 244192 samples\n",
            "0.94698024\n",
            "Training loss (for one batch) at step 7635: 0.0297\n",
            "Seen so far: 244352 samples\n",
            "0.9469986\n",
            "Training loss (for one batch) at step 7640: 0.0059\n",
            "Seen so far: 244512 samples\n",
            "0.94701284\n",
            "Training loss (for one batch) at step 7645: 0.0002\n",
            "Seen so far: 244672 samples\n",
            "0.9470352\n",
            "Training loss (for one batch) at step 7650: 0.0050\n",
            "Seen so far: 244832 samples\n",
            "0.9470535\n",
            "Training loss (for one batch) at step 7655: 0.0245\n",
            "Seen so far: 244992 samples\n",
            "0.9470677\n",
            "Training loss (for one batch) at step 7660: 0.0097\n",
            "Seen so far: 245152 samples\n",
            "0.9471022\n",
            "Training loss (for one batch) at step 7665: 0.0027\n",
            "Seen so far: 245312 samples\n",
            "0.94712853\n",
            "Training loss (for one batch) at step 7670: 0.0324\n",
            "Seen so far: 245472 samples\n",
            "0.9471467\n",
            "Training loss (for one batch) at step 7675: 0.0022\n",
            "Seen so far: 245632 samples\n",
            "0.94717705\n",
            "Training loss (for one batch) at step 7680: 0.0627\n",
            "Seen so far: 245792 samples\n",
            "0.9471952\n",
            "Training loss (for one batch) at step 7685: 0.0104\n",
            "Seen so far: 245952 samples\n",
            "0.94721735\n",
            "Training loss (for one batch) at step 7690: 0.0414\n",
            "Seen so far: 246112 samples\n",
            "0.94723946\n",
            "Training loss (for one batch) at step 7695: 0.0021\n",
            "Seen so far: 246272 samples\n",
            "0.9472656\n",
            "Training loss (for one batch) at step 7700: 0.0009\n",
            "Seen so far: 246432 samples\n",
            "0.94729984\n",
            "Training loss (for one batch) at step 7705: 0.1930\n",
            "Seen so far: 246592 samples\n",
            "0.94731784\n",
            "Training loss (for one batch) at step 7710: 0.0002\n",
            "Seen so far: 246752 samples\n",
            "0.94734794\n",
            "Training loss (for one batch) at step 7715: 0.0327\n",
            "Seen so far: 246912 samples\n",
            "0.94737804\n",
            "Training loss (for one batch) at step 7720: 0.0012\n",
            "Seen so far: 247072 samples\n",
            "0.947408\n",
            "Training loss (for one batch) at step 7725: 0.1635\n",
            "Seen so far: 247232 samples\n",
            "0.94742185\n",
            "Training loss (for one batch) at step 7730: 0.0024\n",
            "Seen so far: 247392 samples\n",
            "0.9474559\n",
            "Training loss (for one batch) at step 7735: 0.0857\n",
            "Seen so far: 247552 samples\n",
            "0.9474777\n",
            "Training loss (for one batch) at step 7740: 0.0000\n",
            "Seen so far: 247712 samples\n",
            "0.9475116\n",
            "Training loss (for one batch) at step 7745: 0.0025\n",
            "Seen so far: 247872 samples\n",
            "0.9475415\n",
            "Training loss (for one batch) at step 7750: 0.0002\n",
            "Seen so far: 248032 samples\n",
            "0.9475713\n",
            "Training loss (for one batch) at step 7755: 0.2093\n",
            "Seen so far: 248192 samples\n",
            "0.947589\n",
            "Training loss (for one batch) at step 7760: 0.0200\n",
            "Seen so far: 248352 samples\n",
            "0.9476227\n",
            "Training loss (for one batch) at step 7765: 0.0938\n",
            "Seen so far: 248512 samples\n",
            "0.9476484\n",
            "Training loss (for one batch) at step 7770: 0.0020\n",
            "Seen so far: 248672 samples\n",
            "0.94767404\n",
            "Training loss (for one batch) at step 7775: 0.1787\n",
            "Seen so far: 248832 samples\n",
            "0.9476956\n",
            "Training loss (for one batch) at step 7780: 0.0011\n",
            "Seen so far: 248992 samples\n",
            "0.94772923\n",
            "Training loss (for one batch) at step 7785: 0.0129\n",
            "Seen so far: 249152 samples\n",
            "0.94775075\n",
            "Training loss (for one batch) at step 7790: 0.0028\n",
            "Seen so far: 249312 samples\n",
            "0.94777226\n",
            "Training loss (for one batch) at step 7795: 0.0697\n",
            "Seen so far: 249472 samples\n",
            "0.94780177\n",
            "Training loss (for one batch) at step 7800: 0.3022\n",
            "Seen so far: 249632 samples\n",
            "0.94782317\n",
            "Training loss (for one batch) at step 7805: 0.0775\n",
            "Seen so far: 249792 samples\n",
            "0.9478446\n",
            "Training loss (for one batch) at step 7810: 0.4996\n",
            "Seen so far: 249952 samples\n",
            "0.947858\n",
            "Training loss (for one batch) at step 7815: 0.3017\n",
            "Seen so far: 250112 samples\n",
            "0.9478794\n",
            "Training loss (for one batch) at step 7820: 0.0999\n",
            "Seen so far: 250272 samples\n",
            "0.9479087\n",
            "Training loss (for one batch) at step 7825: 0.0965\n",
            "Seen so far: 250432 samples\n",
            "0.947934\n",
            "Training loss (for one batch) at step 7830: 0.0007\n",
            "Seen so far: 250592 samples\n",
            "0.94796324\n",
            "Training loss (for one batch) at step 7835: 0.0444\n",
            "Seen so far: 250752 samples\n",
            "0.9479725\n",
            "Training loss (for one batch) at step 7840: 0.1236\n",
            "Seen so far: 250912 samples\n",
            "0.9479937\n",
            "Training loss (for one batch) at step 7845: 0.4171\n",
            "Seen so far: 251072 samples\n",
            "0.947991\n",
            "Training loss (for one batch) at step 7850: 0.3821\n",
            "Seen so far: 251232 samples\n",
            "0.94800824\n",
            "Training loss (for one batch) at step 7855: 0.0608\n",
            "Seen so far: 251392 samples\n",
            "0.9480135\n",
            "Training loss (for one batch) at step 7860: 0.0613\n",
            "Seen so far: 251552 samples\n",
            "0.9480346\n",
            "Training loss (for one batch) at step 7865: 0.0201\n",
            "Seen so far: 251712 samples\n",
            "0.9480676\n",
            "Training loss (for one batch) at step 7870: 0.1378\n",
            "Seen so far: 251872 samples\n",
            "0.9480927\n",
            "Training loss (for one batch) at step 7875: 0.0896\n",
            "Seen so far: 252032 samples\n",
            "0.94810975\n",
            "Training loss (for one batch) at step 7880: 0.0577\n",
            "Seen so far: 252192 samples\n",
            "0.9481348\n",
            "Training loss (for one batch) at step 7885: 0.1237\n",
            "Seen so far: 252352 samples\n",
            "0.94815576\n",
            "Training loss (for one batch) at step 7890: 0.0080\n",
            "Seen so far: 252512 samples\n",
            "0.9481886\n",
            "Training loss (for one batch) at step 7895: 0.0543\n",
            "Seen so far: 252672 samples\n",
            "0.9482056\n",
            "Training loss (for one batch) at step 7900: 0.5233\n",
            "Seen so far: 252832 samples\n",
            "0.9482265\n",
            "Training loss (for one batch) at step 7905: 0.2940\n",
            "Seen so far: 252992 samples\n",
            "0.94823945\n",
            "Training loss (for one batch) at step 7910: 0.1424\n",
            "Seen so far: 253152 samples\n",
            "0.9482603\n",
            "Training loss (for one batch) at step 7915: 0.0634\n",
            "Seen so far: 253312 samples\n",
            "0.9482851\n",
            "Training loss (for one batch) at step 7920: 0.1117\n",
            "Seen so far: 253472 samples\n",
            "0.9482941\n",
            "Training loss (for one batch) at step 7925: 0.0496\n",
            "Seen so far: 253632 samples\n",
            "0.9483149\n",
            "Training loss (for one batch) at step 7930: 0.0694\n",
            "Seen so far: 253792 samples\n",
            "0.9483199\n",
            "Training loss (for one batch) at step 7935: 0.0011\n",
            "Seen so far: 253952 samples\n",
            "0.9483446\n",
            "Training loss (for one batch) at step 7940: 0.0472\n",
            "Seen so far: 254112 samples\n",
            "0.94834954\n",
            "Training loss (for one batch) at step 7945: 0.0087\n",
            "Seen so far: 254272 samples\n",
            "0.94837415\n",
            "Training loss (for one batch) at step 7950: 0.3283\n",
            "Seen so far: 254432 samples\n",
            "0.94838697\n",
            "Training loss (for one batch) at step 7955: 0.0043\n",
            "Seen so far: 254592 samples\n",
            "0.9484037\n",
            "Training loss (for one batch) at step 7960: 0.0179\n",
            "Seen so far: 254752 samples\n",
            "0.9484322\n",
            "Training loss (for one batch) at step 7965: 0.0417\n",
            "Seen so far: 254912 samples\n",
            "0.948441\n",
            "Training loss (for one batch) at step 7970: 0.0287\n",
            "Seen so far: 255072 samples\n",
            "0.9484655\n",
            "Training loss (for one batch) at step 7975: 0.0729\n",
            "Seen so far: 255232 samples\n",
            "0.9484861\n",
            "Training loss (for one batch) at step 7980: 0.1060\n",
            "Seen so far: 255392 samples\n",
            "0.9484909\n",
            "Training loss (for one batch) at step 7985: 0.1004\n",
            "Seen so far: 255552 samples\n",
            "0.94851536\n",
            "Training loss (for one batch) at step 7990: 0.0021\n",
            "Seen so far: 255712 samples\n",
            "0.94854367\n",
            "Training loss (for one batch) at step 7995: 0.2358\n",
            "Seen so far: 255872 samples\n",
            "0.9485524\n",
            "Training loss (for one batch) at step 8000: 0.0149\n",
            "Seen so far: 256032 samples\n",
            "0.9485728\n",
            "Training loss (for one batch) at step 8005: 0.0660\n",
            "Seen so far: 256192 samples\n",
            "0.94859713\n",
            "Training loss (for one batch) at step 8010: 0.1191\n",
            "Seen so far: 256352 samples\n",
            "0.94860584\n",
            "Training loss (for one batch) at step 8015: 0.0038\n",
            "Seen so far: 256512 samples\n",
            "0.94862616\n",
            "Training loss (for one batch) at step 8020: 0.0407\n",
            "Seen so far: 256672 samples\n",
            "0.9486309\n",
            "Training loss (for one batch) at step 8025: 0.0162\n",
            "Seen so far: 256832 samples\n",
            "0.94864345\n",
            "Training loss (for one batch) at step 8030: 0.0957\n",
            "Seen so far: 256992 samples\n",
            "0.9486599\n",
            "Training loss (for one batch) at step 8035: 0.2532\n",
            "Seen so far: 257152 samples\n",
            "0.94866073\n",
            "Training loss (for one batch) at step 8040: 0.0860\n",
            "Seen so far: 257312 samples\n",
            "0.94867706\n",
            "Training loss (for one batch) at step 8045: 0.0213\n",
            "Seen so far: 257472 samples\n",
            "0.9487051\n",
            "Training loss (for one batch) at step 8050: 0.0076\n",
            "Seen so far: 257632 samples\n",
            "0.94871366\n",
            "Training loss (for one batch) at step 8055: 0.1762\n",
            "Seen so far: 257792 samples\n",
            "0.94873387\n",
            "Training loss (for one batch) at step 8060: 0.0012\n",
            "Seen so far: 257952 samples\n",
            "0.9487579\n",
            "Training loss (for one batch) at step 8065: 0.0386\n",
            "Seen so far: 258112 samples\n",
            "0.9487664\n",
            "Training loss (for one batch) at step 8070: 0.0329\n",
            "Seen so far: 258272 samples\n",
            "0.9487827\n",
            "Training loss (for one batch) at step 8075: 0.0050\n",
            "Seen so far: 258432 samples\n",
            "0.94878733\n",
            "Training loss (for one batch) at step 8080: 0.0710\n",
            "Seen so far: 258592 samples\n",
            "0.94880354\n",
            "Training loss (for one batch) at step 8085: 0.0268\n",
            "Seen so far: 258752 samples\n",
            "0.9488197\n",
            "Training loss (for one batch) at step 8090: 0.0632\n",
            "Seen so far: 258912 samples\n",
            "0.9488359\n",
            "Training loss (for one batch) at step 8095: 0.1529\n",
            "Seen so far: 259072 samples\n",
            "0.9488443\n",
            "Training loss (for one batch) at step 8100: 0.0187\n",
            "Seen so far: 259232 samples\n",
            "0.9488528\n",
            "Training loss (for one batch) at step 8105: 0.0156\n",
            "Seen so far: 259392 samples\n",
            "0.9488766\n",
            "Training loss (for one batch) at step 8110: 0.0334\n",
            "Seen so far: 259552 samples\n",
            "0.9489004\n",
            "Training loss (for one batch) at step 8115: 0.0153\n",
            "Seen so far: 259712 samples\n",
            "0.9489165\n",
            "Training loss (for one batch) at step 8120: 0.0056\n",
            "Seen so far: 259872 samples\n",
            "0.9489364\n",
            "Training loss (for one batch) at step 8125: 0.1016\n",
            "Seen so far: 260032 samples\n",
            "0.9489563\n",
            "Training loss (for one batch) at step 8130: 0.0731\n",
            "Seen so far: 260192 samples\n",
            "0.9489723\n",
            "Training loss (for one batch) at step 8135: 0.0123\n",
            "Seen so far: 260352 samples\n",
            "0.94899595\n",
            "Training loss (for one batch) at step 8140: 0.0981\n",
            "Seen so far: 260512 samples\n",
            "0.9490119\n",
            "Training loss (for one batch) at step 8145: 0.0074\n",
            "Seen so far: 260672 samples\n",
            "0.9490126\n",
            "Training loss (for one batch) at step 8150: 0.0344\n",
            "Seen so far: 260832 samples\n",
            "0.9490285\n",
            "Training loss (for one batch) at step 8155: 0.0609\n",
            "Seen so far: 260992 samples\n",
            "0.9490444\n",
            "Training loss (for one batch) at step 8160: 0.0040\n",
            "Seen so far: 261152 samples\n",
            "0.94906795\n",
            "Training loss (for one batch) at step 8165: 0.2897\n",
            "Seen so far: 261312 samples\n",
            "0.94906473\n",
            "Training loss (for one batch) at step 8170: 0.0332\n",
            "Seen so far: 261472 samples\n",
            "0.9490844\n",
            "Training loss (for one batch) at step 8175: 0.1723\n",
            "Seen so far: 261632 samples\n",
            "0.94909644\n",
            "Training loss (for one batch) at step 8180: 0.0859\n",
            "Seen so far: 261792 samples\n",
            "0.9491161\n",
            "Training loss (for one batch) at step 8185: 0.0066\n",
            "Seen so far: 261952 samples\n",
            "0.9491357\n",
            "Training loss (for one batch) at step 8190: 0.0447\n",
            "Seen so far: 262112 samples\n",
            "0.94915915\n",
            "Training loss (for one batch) at step 8195: 0.0081\n",
            "Seen so far: 262272 samples\n",
            "0.9491749\n",
            "Training loss (for one batch) at step 8200: 0.0173\n",
            "Seen so far: 262432 samples\n",
            "0.9492059\n",
            "Training loss (for one batch) at step 8205: 0.0026\n",
            "Seen so far: 262592 samples\n",
            "0.9492216\n",
            "Training loss (for one batch) at step 8210: 0.0282\n",
            "Seen so far: 262752 samples\n",
            "0.9492373\n",
            "Training loss (for one batch) at step 8215: 0.0924\n",
            "Seen so far: 262912 samples\n",
            "0.94925296\n",
            "Training loss (for one batch) at step 8220: 0.1155\n",
            "Seen so far: 263072 samples\n",
            "0.94926864\n",
            "Training loss (for one batch) at step 8225: 0.0647\n",
            "Seen so far: 263232 samples\n",
            "0.9492881\n",
            "Training loss (for one batch) at step 8230: 0.3066\n",
            "Seen so far: 263392 samples\n",
            "0.9493037\n",
            "Training loss (for one batch) at step 8235: 0.0004\n",
            "Seen so far: 263552 samples\n",
            "0.9493231\n",
            "Training loss (for one batch) at step 8240: 0.0038\n",
            "Seen so far: 263712 samples\n",
            "0.94934624\n",
            "Training loss (for one batch) at step 8245: 0.0451\n",
            "Seen so far: 263872 samples\n",
            "0.9493656\n",
            "Training loss (for one batch) at step 8250: 0.0605\n",
            "Seen so far: 264032 samples\n",
            "0.9493849\n",
            "Training loss (for one batch) at step 8255: 0.0262\n",
            "Seen so far: 264192 samples\n",
            "0.9494118\n",
            "Training loss (for one batch) at step 8260: 0.4338\n",
            "Seen so far: 264352 samples\n",
            "0.9494273\n",
            "Training loss (for one batch) at step 8265: 0.0058\n",
            "Seen so far: 264512 samples\n",
            "0.9494579\n",
            "Training loss (for one batch) at step 8270: 0.0798\n",
            "Seen so far: 264672 samples\n",
            "0.94948465\n",
            "Training loss (for one batch) at step 8275: 0.2309\n",
            "Seen so far: 264832 samples\n",
            "0.94949627\n",
            "Training loss (for one batch) at step 8280: 0.0075\n",
            "Seen so far: 264992 samples\n",
            "0.9495079\n",
            "Training loss (for one batch) at step 8285: 0.0038\n",
            "Seen so far: 265152 samples\n",
            "0.9495346\n",
            "Training loss (for one batch) at step 8290: 0.0244\n",
            "Seen so far: 265312 samples\n",
            "0.9495537\n",
            "Training loss (for one batch) at step 8295: 0.0018\n",
            "Seen so far: 265472 samples\n",
            "0.9495766\n",
            "Training loss (for one batch) at step 8300: 0.0004\n",
            "Seen so far: 265632 samples\n",
            "0.94959944\n",
            "Training loss (for one batch) at step 8305: 0.0382\n",
            "Seen so far: 265792 samples\n",
            "0.94961476\n",
            "Training loss (for one batch) at step 8310: 0.0600\n",
            "Seen so far: 265952 samples\n",
            "0.94962627\n",
            "Training loss (for one batch) at step 8315: 0.0024\n",
            "Seen so far: 266112 samples\n",
            "0.94964904\n",
            "Training loss (for one batch) at step 8320: 0.0425\n",
            "Seen so far: 266272 samples\n",
            "0.94966424\n",
            "Training loss (for one batch) at step 8325: 0.0072\n",
            "Seen so far: 266432 samples\n",
            "0.949687\n",
            "Training loss (for one batch) at step 8330: 0.0751\n",
            "Seen so far: 266592 samples\n",
            "0.9496984\n",
            "Training loss (for one batch) at step 8335: 0.0429\n",
            "Seen so far: 266752 samples\n",
            "0.9497023\n",
            "Training loss (for one batch) at step 8340: 0.0021\n",
            "Seen so far: 266912 samples\n",
            "0.9497213\n",
            "Training loss (for one batch) at step 8345: 0.2181\n",
            "Seen so far: 267072 samples\n",
            "0.9497402\n",
            "Training loss (for one batch) at step 8350: 0.0347\n",
            "Seen so far: 267232 samples\n",
            "0.94976276\n",
            "Training loss (for one batch) at step 8355: 0.1782\n",
            "Seen so far: 267392 samples\n",
            "0.94978905\n",
            "Training loss (for one batch) at step 8360: 0.0705\n",
            "Seen so far: 267552 samples\n",
            "0.94981164\n",
            "Training loss (for one batch) at step 8365: 0.0069\n",
            "Seen so far: 267712 samples\n",
            "0.9498304\n",
            "Training loss (for one batch) at step 8370: 0.0086\n",
            "Seen so far: 267872 samples\n",
            "0.9498492\n",
            "Training loss (for one batch) at step 8375: 0.0138\n",
            "Seen so far: 268032 samples\n",
            "0.9498754\n",
            "Training loss (for one batch) at step 8380: 0.0748\n",
            "Seen so far: 268192 samples\n",
            "0.9499016\n",
            "Training loss (for one batch) at step 8385: 0.0020\n",
            "Seen so far: 268352 samples\n",
            "0.94991654\n",
            "Training loss (for one batch) at step 8390: 0.0567\n",
            "Seen so far: 268512 samples\n",
            "0.9499389\n",
            "Training loss (for one batch) at step 8395: 0.0531\n",
            "Seen so far: 268672 samples\n",
            "0.9499501\n",
            "Training loss (for one batch) at step 8400: 0.1787\n",
            "Seen so far: 268832 samples\n",
            "0.9499613\n",
            "Training loss (for one batch) at step 8405: 0.0499\n",
            "Seen so far: 268992 samples\n",
            "0.94998735\n",
            "Training loss (for one batch) at step 8410: 0.1531\n",
            "Seen so far: 269152 samples\n",
            "0.9499985\n",
            "Training loss (for one batch) at step 8415: 0.0412\n",
            "Seen so far: 269312 samples\n",
            "0.9500208\n",
            "Training loss (for one batch) at step 8420: 0.0003\n",
            "Seen so far: 269472 samples\n",
            "0.950043\n",
            "Training loss (for one batch) at step 8425: 0.0245\n",
            "Seen so far: 269632 samples\n",
            "0.9500727\n",
            "Training loss (for one batch) at step 8430: 0.1139\n",
            "Seen so far: 269792 samples\n",
            "0.9500875\n",
            "Training loss (for one batch) at step 8435: 0.0133\n",
            "Seen so far: 269952 samples\n",
            "0.95011336\n",
            "Training loss (for one batch) at step 8440: 0.0104\n",
            "Seen so far: 270112 samples\n",
            "0.9501355\n",
            "Training loss (for one batch) at step 8445: 0.0420\n",
            "Seen so far: 270272 samples\n",
            "0.95015764\n",
            "Training loss (for one batch) at step 8450: 0.0073\n",
            "Seen so far: 270432 samples\n",
            "0.9501834\n",
            "Training loss (for one batch) at step 8455: 0.0380\n",
            "Seen so far: 270592 samples\n",
            "0.9502092\n",
            "Training loss (for one batch) at step 8460: 0.0026\n",
            "Seen so far: 270752 samples\n",
            "0.9502238\n",
            "Training loss (for one batch) at step 8465: 0.0146\n",
            "Seen so far: 270912 samples\n",
            "0.95024216\n",
            "Training loss (for one batch) at step 8470: 0.0720\n",
            "Seen so far: 271072 samples\n",
            "0.95026785\n",
            "Training loss (for one batch) at step 8475: 0.0070\n",
            "Seen so far: 271232 samples\n",
            "0.9502935\n",
            "Training loss (for one batch) at step 8480: 0.3554\n",
            "Seen so far: 271392 samples\n",
            "0.9503117\n",
            "Training loss (for one batch) at step 8485: 0.0175\n",
            "Seen so far: 271552 samples\n",
            "0.95033365\n",
            "Training loss (for one batch) at step 8490: 0.0067\n",
            "Seen so far: 271712 samples\n",
            "0.9503555\n",
            "Training loss (for one batch) at step 8495: 0.0321\n",
            "Seen so far: 271872 samples\n",
            "0.950359\n",
            "Training loss (for one batch) at step 8500: 0.1055\n",
            "Seen so far: 272032 samples\n",
            "0.95036983\n",
            "Training loss (for one batch) at step 8505: 0.0054\n",
            "Seen so far: 272192 samples\n",
            "0.95039165\n",
            "Training loss (for one batch) at step 8510: 0.0298\n",
            "Seen so far: 272352 samples\n",
            "0.9504171\n",
            "Training loss (for one batch) at step 8515: 0.1476\n",
            "Seen so far: 272512 samples\n",
            "0.9504352\n",
            "Training loss (for one batch) at step 8520: 0.0097\n",
            "Seen so far: 272672 samples\n",
            "0.950457\n",
            "Training loss (for one batch) at step 8525: 0.0175\n",
            "Seen so far: 272832 samples\n",
            "0.9504677\n",
            "Training loss (for one batch) at step 8530: 0.1036\n",
            "Seen so far: 272992 samples\n",
            "0.95047474\n",
            "Training loss (for one batch) at step 8535: 0.2545\n",
            "Seen so far: 273152 samples\n",
            "0.95048547\n",
            "Training loss (for one batch) at step 8540: 0.0012\n",
            "Seen so far: 273312 samples\n",
            "0.95050347\n",
            "Training loss (for one batch) at step 8545: 0.0054\n",
            "Seen so far: 273472 samples\n",
            "0.95052874\n",
            "Training loss (for one batch) at step 8550: 0.0039\n",
            "Seen so far: 273632 samples\n",
            "0.9505504\n",
            "Training loss (for one batch) at step 8555: 0.0733\n",
            "Seen so far: 273792 samples\n",
            "0.9505683\n",
            "Training loss (for one batch) at step 8560: 0.2385\n",
            "Seen so far: 273952 samples\n",
            "0.9505753\n",
            "Training loss (for one batch) at step 8565: 0.0003\n",
            "Seen so far: 274112 samples\n",
            "0.95058954\n",
            "Training loss (for one batch) at step 8570: 0.0028\n",
            "Seen so far: 274272 samples\n",
            "0.9506147\n",
            "Training loss (for one batch) at step 8575: 0.0321\n",
            "Seen so far: 274432 samples\n",
            "0.9506253\n",
            "Training loss (for one batch) at step 8580: 0.0085\n",
            "Seen so far: 274592 samples\n",
            "0.9506395\n",
            "Training loss (for one batch) at step 8585: 0.0210\n",
            "Seen so far: 274752 samples\n",
            "0.95066094\n",
            "Training loss (for one batch) at step 8590: 0.1471\n",
            "Seen so far: 274912 samples\n",
            "0.95067877\n",
            "Training loss (for one batch) at step 8595: 0.0010\n",
            "Seen so far: 275072 samples\n",
            "0.9506965\n",
            "Training loss (for one batch) at step 8600: 0.0037\n",
            "Seen so far: 275232 samples\n",
            "0.95072156\n",
            "Training loss (for one batch) at step 8605: 0.0392\n",
            "Seen so far: 275392 samples\n",
            "0.9507466\n",
            "Training loss (for one batch) at step 8610: 0.3248\n",
            "Seen so far: 275552 samples\n",
            "0.9507534\n",
            "Training loss (for one batch) at step 8615: 0.0971\n",
            "Seen so far: 275712 samples\n",
            "0.9507711\n",
            "Training loss (for one batch) at step 8620: 0.1009\n",
            "Seen so far: 275872 samples\n",
            "0.95078516\n",
            "Training loss (for one batch) at step 8625: 0.0002\n",
            "Seen so far: 276032 samples\n",
            "0.95080644\n",
            "Training loss (for one batch) at step 8630: 0.0132\n",
            "Seen so far: 276192 samples\n",
            "0.9508241\n",
            "Training loss (for one batch) at step 8635: 0.0167\n",
            "Seen so far: 276352 samples\n",
            "0.9508453\n",
            "Training loss (for one batch) at step 8640: 0.0046\n",
            "Seen so far: 276512 samples\n",
            "0.9508629\n",
            "Training loss (for one batch) at step 8645: 0.0034\n",
            "Seen so far: 276672 samples\n",
            "0.95087326\n",
            "Training loss (for one batch) at step 8650: 0.0346\n",
            "Seen so far: 276832 samples\n",
            "0.9508908\n",
            "Training loss (for one batch) at step 8655: 0.0198\n",
            "Seen so far: 276992 samples\n",
            "0.9509047\n",
            "Training loss (for one batch) at step 8660: 0.0847\n",
            "Seen so far: 277152 samples\n",
            "0.9509186\n",
            "Training loss (for one batch) at step 8665: 0.0146\n",
            "Seen so far: 277312 samples\n",
            "0.9509325\n",
            "Training loss (for one batch) at step 8670: 0.0091\n",
            "Seen so far: 277472 samples\n",
            "0.95095\n",
            "Training loss (for one batch) at step 8675: 0.0007\n",
            "Seen so far: 277632 samples\n",
            "0.9509783\n",
            "Training loss (for one batch) at step 8680: 0.0001\n",
            "Seen so far: 277792 samples\n",
            "0.9510029\n",
            "Training loss (for one batch) at step 8685: 0.0368\n",
            "Seen so far: 277952 samples\n",
            "0.9510203\n",
            "Training loss (for one batch) at step 8690: 0.0899\n",
            "Seen so far: 278112 samples\n",
            "0.9510341\n",
            "Training loss (for one batch) at step 8695: 0.0443\n",
            "Seen so far: 278272 samples\n",
            "0.9510551\n",
            "Training loss (for one batch) at step 8700: 0.0292\n",
            "Seen so far: 278432 samples\n",
            "0.9510796\n",
            "Training loss (for one batch) at step 8705: 0.0005\n",
            "Seen so far: 278592 samples\n",
            "0.9510934\n",
            "Training loss (for one batch) at step 8710: 0.0189\n",
            "Seen so far: 278752 samples\n",
            "0.95111066\n",
            "Training loss (for one batch) at step 8715: 0.0721\n",
            "Seen so far: 278912 samples\n",
            "0.95112437\n",
            "Training loss (for one batch) at step 8720: 0.0309\n",
            "Seen so far: 279072 samples\n",
            "0.9511488\n",
            "Training loss (for one batch) at step 8725: 0.2183\n",
            "Seen so far: 279232 samples\n",
            "0.95116246\n",
            "Training loss (for one batch) at step 8730: 0.0065\n",
            "Seen so far: 279392 samples\n",
            "0.95116895\n",
            "Training loss (for one batch) at step 8735: 0.0015\n",
            "Seen so far: 279552 samples\n",
            "0.95119333\n",
            "Training loss (for one batch) at step 8740: 0.0673\n",
            "Seen so far: 279712 samples\n",
            "0.9512034\n",
            "Training loss (for one batch) at step 8745: 0.0048\n",
            "Seen so far: 279872 samples\n",
            "0.9512206\n",
            "Training loss (for one batch) at step 8750: 0.0904\n",
            "Seen so far: 280032 samples\n",
            "0.95124483\n",
            "Training loss (for one batch) at step 8755: 0.0262\n",
            "Seen so far: 280192 samples\n",
            "0.95126915\n",
            "Training loss (for one batch) at step 8760: 0.0791\n",
            "Seen so far: 280352 samples\n",
            "0.95128626\n",
            "Training loss (for one batch) at step 8765: 0.1362\n",
            "Seen so far: 280512 samples\n",
            "0.95128906\n",
            "Training loss (for one batch) at step 8770: 0.0622\n",
            "Seen so far: 280672 samples\n",
            "0.951299\n",
            "Training loss (for one batch) at step 8775: 0.0054\n",
            "Seen so far: 280832 samples\n",
            "0.95131963\n",
            "Training loss (for one batch) at step 8780: 0.0449\n",
            "Seen so far: 280992 samples\n",
            "0.951326\n",
            "Training loss (for one batch) at step 8785: 0.0464\n",
            "Seen so far: 281152 samples\n",
            "0.9513324\n",
            "Training loss (for one batch) at step 8790: 0.0028\n",
            "Seen so far: 281312 samples\n",
            "0.9513387\n",
            "Training loss (for one batch) at step 8795: 0.2841\n",
            "Seen so far: 281472 samples\n",
            "0.9513415\n",
            "Training loss (for one batch) at step 8800: 0.0259\n",
            "Seen so far: 281632 samples\n",
            "0.951355\n",
            "Training loss (for one batch) at step 8805: 0.0013\n",
            "Seen so far: 281792 samples\n",
            "0.9513826\n",
            "Training loss (for one batch) at step 8810: 0.1270\n",
            "Seen so far: 281952 samples\n",
            "0.9513924\n",
            "Training loss (for one batch) at step 8815: 0.0213\n",
            "Seen so far: 282112 samples\n",
            "0.95141643\n",
            "Training loss (for one batch) at step 8820: 0.0033\n",
            "Seen so far: 282272 samples\n",
            "0.95142275\n",
            "Training loss (for one batch) at step 8825: 0.0022\n",
            "Seen so far: 282432 samples\n",
            "0.9514503\n",
            "Training loss (for one batch) at step 8830: 0.0610\n",
            "Seen so far: 282592 samples\n",
            "0.9514636\n",
            "Training loss (for one batch) at step 8835: 0.1411\n",
            "Seen so far: 282752 samples\n",
            "0.95147336\n",
            "Training loss (for one batch) at step 8840: 0.0233\n",
            "Seen so far: 282912 samples\n",
            "0.95149374\n",
            "Training loss (for one batch) at step 8845: 0.0579\n",
            "Seen so far: 283072 samples\n",
            "0.9514929\n",
            "Training loss (for one batch) at step 8850: 0.0320\n",
            "Seen so far: 283232 samples\n",
            "0.9515097\n",
            "Training loss (for one batch) at step 8855: 0.0569\n",
            "Seen so far: 283392 samples\n",
            "0.9515159\n",
            "Training loss (for one batch) at step 8860: 0.0256\n",
            "Seen so far: 283552 samples\n",
            "0.95153975\n",
            "Training loss (for one batch) at step 8865: 0.0271\n",
            "Seen so far: 283712 samples\n",
            "0.9515495\n",
            "Training loss (for one batch) at step 8870: 0.1684\n",
            "Seen so far: 283872 samples\n",
            "0.95157325\n",
            "Training loss (for one batch) at step 8875: 0.0121\n",
            "Seen so far: 284032 samples\n",
            "0.951597\n",
            "Training loss (for one batch) at step 8880: 0.0607\n",
            "Seen so far: 284192 samples\n",
            "0.9516102\n",
            "Training loss (for one batch) at step 8885: 0.0103\n",
            "Seen so far: 284352 samples\n",
            "0.9516339\n",
            "Training loss (for one batch) at step 8890: 0.0198\n",
            "Seen so far: 284512 samples\n",
            "0.9516576\n",
            "Training loss (for one batch) at step 8895: 0.0035\n",
            "Seen so far: 284672 samples\n",
            "0.95167774\n",
            "Training loss (for one batch) at step 8900: 0.0013\n",
            "Seen so far: 284832 samples\n",
            "0.95170134\n",
            "Training loss (for one batch) at step 8905: 0.0341\n",
            "Seen so far: 284992 samples\n",
            "0.951718\n",
            "Training loss (for one batch) at step 8910: 0.0057\n",
            "Seen so far: 285152 samples\n",
            "0.9517275\n",
            "Training loss (for one batch) at step 8915: 0.0224\n",
            "Seen so far: 285312 samples\n",
            "0.95173705\n",
            "Training loss (for one batch) at step 8920: 0.1300\n",
            "Seen so far: 285472 samples\n",
            "0.9517536\n",
            "Training loss (for one batch) at step 8925: 0.0457\n",
            "Seen so far: 285632 samples\n",
            "0.9517771\n",
            "Training loss (for one batch) at step 8930: 0.0118\n",
            "Seen so far: 285792 samples\n",
            "0.9518006\n",
            "Training loss (for one batch) at step 8935: 0.0660\n",
            "Seen so far: 285952 samples\n",
            "0.9518171\n",
            "Training loss (for one batch) at step 8940: 0.0269\n",
            "Seen so far: 286112 samples\n",
            "0.9518405\n",
            "Training loss (for one batch) at step 8945: 0.1499\n",
            "Seen so far: 286272 samples\n",
            "0.951857\n",
            "Training loss (for one batch) at step 8950: 0.0708\n",
            "Seen so far: 286432 samples\n",
            "0.9518594\n",
            "Training loss (for one batch) at step 8955: 0.0175\n",
            "Seen so far: 286592 samples\n",
            "0.95187587\n",
            "Training loss (for one batch) at step 8960: 0.0528\n",
            "Seen so far: 286752 samples\n",
            "0.9518957\n",
            "Training loss (for one batch) at step 8965: 0.0031\n",
            "Seen so far: 286912 samples\n",
            "0.9519121\n",
            "Training loss (for one batch) at step 8970: 0.0265\n",
            "Seen so far: 287072 samples\n",
            "0.951925\n",
            "Training loss (for one batch) at step 8975: 0.0895\n",
            "Seen so far: 287232 samples\n",
            "0.95193434\n",
            "Training loss (for one batch) at step 8980: 0.0108\n",
            "Seen so far: 287392 samples\n",
            "0.9519611\n",
            "Training loss (for one batch) at step 8985: 0.1385\n",
            "Seen so far: 287552 samples\n",
            "0.9519774\n",
            "Training loss (for one batch) at step 8990: 0.1250\n",
            "Seen so far: 287712 samples\n",
            "0.9519902\n",
            "Training loss (for one batch) at step 8995: 0.0020\n",
            "Seen so far: 287872 samples\n",
            "0.9519995\n",
            "Training loss (for one batch) at step 9000: 0.0328\n",
            "Seen so far: 288032 samples\n",
            "0.9520123\n",
            "Training loss (for one batch) at step 9005: 0.0955\n",
            "Seen so far: 288192 samples\n",
            "0.9520181\n",
            "Training loss (for one batch) at step 9010: 0.0214\n",
            "Seen so far: 288352 samples\n",
            "0.95203084\n",
            "Training loss (for one batch) at step 9015: 0.0044\n",
            "Seen so far: 288512 samples\n",
            "0.9520436\n",
            "Training loss (for one batch) at step 9020: 0.0015\n",
            "Seen so far: 288672 samples\n",
            "0.95206326\n",
            "Training loss (for one batch) at step 9025: 0.0014\n",
            "Seen so far: 288832 samples\n",
            "0.9520794\n",
            "Training loss (for one batch) at step 9030: 0.0463\n",
            "Seen so far: 288992 samples\n",
            "0.9520921\n",
            "Training loss (for one batch) at step 9035: 0.0040\n",
            "Seen so far: 289152 samples\n",
            "0.9521082\n",
            "Training loss (for one batch) at step 9040: 0.1226\n",
            "Seen so far: 289312 samples\n",
            "0.95211744\n",
            "Training loss (for one batch) at step 9045: 0.0139\n",
            "Seen so far: 289472 samples\n",
            "0.952137\n",
            "Training loss (for one batch) at step 9050: 0.2944\n",
            "Seen so far: 289632 samples\n",
            "0.95213926\n",
            "Training loss (for one batch) at step 9055: 0.0051\n",
            "Seen so far: 289792 samples\n",
            "0.9521519\n",
            "Training loss (for one batch) at step 9060: 0.0071\n",
            "Seen so far: 289952 samples\n",
            "0.9521645\n",
            "Training loss (for one batch) at step 9065: 0.1394\n",
            "Seen so far: 290112 samples\n",
            "0.95217365\n",
            "Training loss (for one batch) at step 9070: 0.0140\n",
            "Seen so far: 290272 samples\n",
            "0.9521793\n",
            "Training loss (for one batch) at step 9075: 0.1494\n",
            "Seen so far: 290432 samples\n",
            "0.9521781\n",
            "Training loss (for one batch) at step 9080: 0.0591\n",
            "Seen so far: 290592 samples\n",
            "0.95218384\n",
            "Training loss (for one batch) at step 9085: 0.0271\n",
            "Seen so far: 290752 samples\n",
            "0.95219636\n",
            "Training loss (for one batch) at step 9090: 0.2757\n",
            "Seen so far: 290912 samples\n",
            "0.9522055\n",
            "Training loss (for one batch) at step 9095: 0.0080\n",
            "Seen so far: 291072 samples\n",
            "0.95221114\n",
            "Training loss (for one batch) at step 9100: 0.3290\n",
            "Seen so far: 291232 samples\n",
            "0.9522065\n",
            "Training loss (for one batch) at step 9105: 0.0054\n",
            "Seen so far: 291392 samples\n",
            "0.9522087\n",
            "Training loss (for one batch) at step 9110: 0.0016\n",
            "Seen so far: 291552 samples\n",
            "0.9522109\n",
            "Training loss (for one batch) at step 9115: 0.1146\n",
            "Seen so far: 291712 samples\n",
            "0.95222\n",
            "Training loss (for one batch) at step 9120: 0.1343\n",
            "Seen so far: 291872 samples\n",
            "0.9522291\n",
            "Training loss (for one batch) at step 9125: 0.0495\n",
            "Seen so far: 292032 samples\n",
            "0.9522381\n",
            "Training loss (for one batch) at step 9130: 0.3589\n",
            "Seen so far: 292192 samples\n",
            "0.9522369\n",
            "Training loss (for one batch) at step 9135: 0.0713\n",
            "Seen so far: 292352 samples\n",
            "0.95223224\n",
            "Training loss (for one batch) at step 9140: 0.1422\n",
            "Seen so far: 292512 samples\n",
            "0.95223784\n",
            "Training loss (for one batch) at step 9145: 0.0273\n",
            "Seen so far: 292672 samples\n",
            "0.9522298\n",
            "Training loss (for one batch) at step 9150: 0.3454\n",
            "Seen so far: 292832 samples\n",
            "0.9522354\n",
            "Training loss (for one batch) at step 9155: 0.2534\n",
            "Seen so far: 292992 samples\n",
            "0.952241\n",
            "Training loss (for one batch) at step 9160: 0.1724\n",
            "Seen so far: 293152 samples\n",
            "0.9522398\n",
            "Training loss (for one batch) at step 9165: 0.0008\n",
            "Seen so far: 293312 samples\n",
            "0.9522454\n",
            "Training loss (for one batch) at step 9170: 0.0993\n",
            "Seen so far: 293472 samples\n",
            "0.9522578\n",
            "Training loss (for one batch) at step 9175: 0.0067\n",
            "Seen so far: 293632 samples\n",
            "0.9522838\n",
            "Training loss (for one batch) at step 9180: 0.2416\n",
            "Seen so far: 293792 samples\n",
            "0.95228255\n",
            "Training loss (for one batch) at step 9185: 0.1447\n",
            "Seen so far: 293952 samples\n",
            "0.95229155\n",
            "Training loss (for one batch) at step 9190: 0.0722\n",
            "Seen so far: 294112 samples\n",
            "0.9523039\n",
            "Training loss (for one batch) at step 9195: 0.0410\n",
            "Seen so far: 294272 samples\n",
            "0.9523196\n",
            "Training loss (for one batch) at step 9200: 0.0013\n",
            "Seen so far: 294432 samples\n",
            "0.95232856\n",
            "Training loss (for one batch) at step 9205: 0.1131\n",
            "Seen so far: 294592 samples\n",
            "0.95233744\n",
            "Training loss (for one batch) at step 9210: 0.0048\n",
            "Seen so far: 294752 samples\n",
            "0.9523532\n",
            "Training loss (for one batch) at step 9215: 0.0408\n",
            "Seen so far: 294912 samples\n",
            "0.95237225\n",
            "Training loss (for one batch) at step 9220: 0.1683\n",
            "Seen so far: 295072 samples\n",
            "0.95238453\n",
            "Training loss (for one batch) at step 9225: 0.0101\n",
            "Seen so far: 295232 samples\n",
            "0.9523866\n",
            "Training loss (for one batch) at step 9230: 0.0171\n",
            "Seen so far: 295392 samples\n",
            "0.9523921\n",
            "Training loss (for one batch) at step 9235: 0.0016\n",
            "Seen so far: 295552 samples\n",
            "0.9523975\n",
            "Training loss (for one batch) at step 9240: 0.1810\n",
            "Seen so far: 295712 samples\n",
            "0.9524064\n",
            "Training loss (for one batch) at step 9245: 0.1094\n",
            "Seen so far: 295872 samples\n",
            "0.9524186\n",
            "Training loss (for one batch) at step 9250: 0.0626\n",
            "Seen so far: 296032 samples\n",
            "0.95242745\n",
            "Training loss (for one batch) at step 9255: 0.0847\n",
            "Seen so far: 296192 samples\n",
            "0.9524396\n",
            "Training loss (for one batch) at step 9260: 0.2480\n",
            "Seen so far: 296352 samples\n",
            "0.9524451\n",
            "Training loss (for one batch) at step 9265: 0.2602\n",
            "Seen so far: 296512 samples\n",
            "0.9524437\n",
            "Training loss (for one batch) at step 9270: 0.0423\n",
            "Seen so far: 296672 samples\n",
            "0.9524627\n",
            "Training loss (for one batch) at step 9275: 0.0029\n",
            "Seen so far: 296832 samples\n",
            "0.95248157\n",
            "Training loss (for one batch) at step 9280: 0.2046\n",
            "Seen so far: 296992 samples\n",
            "0.95249367\n",
            "Training loss (for one batch) at step 9285: 0.0496\n",
            "Seen so far: 297152 samples\n",
            "0.9525125\n",
            "Training loss (for one batch) at step 9290: 0.0334\n",
            "Seen so far: 297312 samples\n",
            "0.9525381\n",
            "Training loss (for one batch) at step 9295: 0.1548\n",
            "Seen so far: 297472 samples\n",
            "0.9525535\n",
            "Training loss (for one batch) at step 9300: 0.0224\n",
            "Seen so far: 297632 samples\n",
            "0.9525723\n",
            "Training loss (for one batch) at step 9305: 0.0395\n",
            "Seen so far: 297792 samples\n",
            "0.9525944\n",
            "Training loss (for one batch) at step 9310: 0.0049\n",
            "Seen so far: 297952 samples\n",
            "0.9526132\n",
            "Training loss (for one batch) at step 9315: 0.0022\n",
            "Seen so far: 298112 samples\n",
            "0.9526185\n",
            "Training loss (for one batch) at step 9320: 0.0006\n",
            "Seen so far: 298272 samples\n",
            "0.95264053\n",
            "Training loss (for one batch) at step 9325: 0.1333\n",
            "Seen so far: 298432 samples\n",
            "0.95265585\n",
            "Training loss (for one batch) at step 9330: 0.0419\n",
            "Seen so far: 298592 samples\n",
            "0.95267457\n",
            "Training loss (for one batch) at step 9335: 0.0066\n",
            "Seen so far: 298752 samples\n",
            "0.9526899\n",
            "Training loss (for one batch) at step 9340: 0.1004\n",
            "Seen so far: 298912 samples\n",
            "0.9527018\n",
            "Training loss (for one batch) at step 9345: 0.0718\n",
            "Seen so far: 299072 samples\n",
            "0.9527137\n",
            "Training loss (for one batch) at step 9350: 0.0010\n",
            "Seen so far: 299232 samples\n",
            "0.9527323\n",
            "Training loss (for one batch) at step 9355: 0.0159\n",
            "Seen so far: 299392 samples\n",
            "0.9527476\n",
            "Training loss (for one batch) at step 9360: 0.0130\n",
            "Seen so far: 299552 samples\n",
            "0.95275944\n",
            "Training loss (for one batch) at step 9365: 0.0025\n",
            "Seen so far: 299712 samples\n",
            "0.95276797\n",
            "Training loss (for one batch) at step 9370: 0.0671\n",
            "Seen so far: 299872 samples\n",
            "0.9527798\n",
            "Training loss (for one batch) at step 9375: 0.0514\n",
            "Seen so far: 300032 samples\n",
            "0.952795\n",
            "Training loss (for one batch) at step 9380: 0.1645\n",
            "Seen so far: 300192 samples\n",
            "0.95281684\n",
            "Training loss (for one batch) at step 9385: 0.0098\n",
            "Seen so far: 300352 samples\n",
            "0.952832\n",
            "Training loss (for one batch) at step 9390: 0.0494\n",
            "Seen so far: 300512 samples\n",
            "0.9528538\n",
            "Training loss (for one batch) at step 9395: 0.0126\n",
            "Seen so far: 300672 samples\n",
            "0.95287555\n",
            "Training loss (for one batch) at step 9400: 0.0096\n",
            "Seen so far: 300832 samples\n",
            "0.9528873\n",
            "Training loss (for one batch) at step 9405: 0.0006\n",
            "Seen so far: 300992 samples\n",
            "0.9528991\n",
            "Training loss (for one batch) at step 9410: 0.1135\n",
            "Seen so far: 301152 samples\n",
            "0.9529009\n",
            "Training loss (for one batch) at step 9415: 0.0351\n",
            "Seen so far: 301312 samples\n",
            "0.95291257\n",
            "Training loss (for one batch) at step 9420: 0.0018\n",
            "Seen so far: 301472 samples\n",
            "0.95293427\n",
            "Training loss (for one batch) at step 9425: 0.0566\n",
            "Seen so far: 301632 samples\n",
            "0.9529526\n",
            "Training loss (for one batch) at step 9430: 0.1447\n",
            "Seen so far: 301792 samples\n",
            "0.9529676\n",
            "Training loss (for one batch) at step 9435: 0.0021\n",
            "Seen so far: 301952 samples\n",
            "0.9529826\n",
            "Training loss (for one batch) at step 9440: 0.0736\n",
            "Seen so far: 302112 samples\n",
            "0.95299757\n",
            "Training loss (for one batch) at step 9445: 0.1878\n",
            "Seen so far: 302272 samples\n",
            "0.9530026\n",
            "Training loss (for one batch) at step 9450: 0.0104\n",
            "Seen so far: 302432 samples\n",
            "0.95301753\n",
            "Training loss (for one batch) at step 9455: 0.0217\n",
            "Seen so far: 302592 samples\n",
            "0.9530358\n",
            "Training loss (for one batch) at step 9460: 0.0020\n",
            "Seen so far: 302752 samples\n",
            "0.9530573\n",
            "Training loss (for one batch) at step 9465: 0.0120\n",
            "Seen so far: 302912 samples\n",
            "0.95306885\n",
            "Training loss (for one batch) at step 9470: 0.0006\n",
            "Seen so far: 303072 samples\n",
            "0.9530805\n",
            "Training loss (for one batch) at step 9475: 0.0398\n",
            "Seen so far: 303232 samples\n",
            "0.95310193\n",
            "Training loss (for one batch) at step 9480: 0.0114\n",
            "Seen so far: 303392 samples\n",
            "0.95311016\n",
            "Training loss (for one batch) at step 9485: 0.0179\n",
            "Seen so far: 303552 samples\n",
            "0.9531283\n",
            "Training loss (for one batch) at step 9490: 0.1066\n",
            "Seen so far: 303712 samples\n",
            "0.9531332\n",
            "Training loss (for one batch) at step 9495: 0.2020\n",
            "Seen so far: 303872 samples\n",
            "0.95313156\n",
            "Training loss (for one batch) at step 9500: 0.0691\n",
            "Seen so far: 304032 samples\n",
            "0.9531464\n",
            "Training loss (for one batch) at step 9505: 0.0070\n",
            "Seen so far: 304192 samples\n",
            "0.9531612\n",
            "Training loss (for one batch) at step 9510: 0.0698\n",
            "Seen so far: 304352 samples\n",
            "0.95317924\n",
            "Training loss (for one batch) at step 9515: 0.0138\n",
            "Seen so far: 304512 samples\n",
            "0.9532005\n",
            "Training loss (for one batch) at step 9520: 0.0125\n",
            "Seen so far: 304672 samples\n",
            "0.95321524\n",
            "Training loss (for one batch) at step 9525: 0.0032\n",
            "Seen so far: 304832 samples\n",
            "0.9532365\n",
            "Training loss (for one batch) at step 9530: 0.0160\n",
            "Seen so far: 304992 samples\n",
            "0.9532578\n",
            "Training loss (for one batch) at step 9535: 0.0088\n",
            "Seen so far: 305152 samples\n",
            "0.9532692\n",
            "Training loss (for one batch) at step 9540: 0.0071\n",
            "Seen so far: 305312 samples\n",
            "0.9532773\n",
            "Training loss (for one batch) at step 9545: 0.0102\n",
            "Seen so far: 305472 samples\n",
            "0.95329523\n",
            "Training loss (for one batch) at step 9550: 0.1455\n",
            "Seen so far: 305632 samples\n",
            "0.95330006\n",
            "Training loss (for one batch) at step 9555: 0.0031\n",
            "Seen so far: 305792 samples\n",
            "0.9533114\n",
            "Training loss (for one batch) at step 9560: 0.0543\n",
            "Seen so far: 305952 samples\n",
            "0.9533162\n",
            "Training loss (for one batch) at step 9565: 0.2899\n",
            "Seen so far: 306112 samples\n",
            "0.95332754\n",
            "Training loss (for one batch) at step 9570: 0.1910\n",
            "Seen so far: 306272 samples\n",
            "0.95333886\n",
            "Training loss (for one batch) at step 9575: 0.0021\n",
            "Seen so far: 306432 samples\n",
            "0.95335996\n",
            "Training loss (for one batch) at step 9580: 0.6602\n",
            "Seen so far: 306592 samples\n",
            "0.953368\n",
            "Training loss (for one batch) at step 9585: 0.0935\n",
            "Seen so far: 306752 samples\n",
            "0.9533728\n",
            "Training loss (for one batch) at step 9590: 0.0040\n",
            "Seen so far: 306912 samples\n",
            "0.95338404\n",
            "Training loss (for one batch) at step 9595: 0.0264\n",
            "Seen so far: 307072 samples\n",
            "0.9533953\n",
            "Training loss (for one batch) at step 9600: 0.4851\n",
            "Seen so far: 307232 samples\n",
            "0.9534\n",
            "Training loss (for one batch) at step 9605: 0.2928\n",
            "Seen so far: 307392 samples\n",
            "0.9533983\n",
            "Training loss (for one batch) at step 9610: 0.0147\n",
            "Seen so far: 307552 samples\n",
            "0.9534128\n",
            "Training loss (for one batch) at step 9615: 0.0954\n",
            "Seen so far: 307712 samples\n",
            "0.9534305\n",
            "Training loss (for one batch) at step 9620: 0.1109\n",
            "Seen so far: 307872 samples\n",
            "0.9534417\n",
            "Training loss (for one batch) at step 9625: 0.1614\n",
            "Seen so far: 308032 samples\n",
            "0.9534594\n",
            "Training loss (for one batch) at step 9630: 0.0039\n",
            "Seen so far: 308192 samples\n",
            "0.9534673\n",
            "Training loss (for one batch) at step 9635: 0.0768\n",
            "Seen so far: 308352 samples\n",
            "0.95346874\n",
            "Training loss (for one batch) at step 9640: 0.1922\n",
            "Seen so far: 308512 samples\n",
            "0.95347667\n",
            "Training loss (for one batch) at step 9645: 0.1543\n",
            "Seen so far: 308672 samples\n",
            "0.9534781\n",
            "Training loss (for one batch) at step 9650: 0.0005\n",
            "Seen so far: 308832 samples\n",
            "0.9534925\n",
            "Training loss (for one batch) at step 9655: 0.1528\n",
            "Seen so far: 308992 samples\n",
            "0.9535004\n",
            "Training loss (for one batch) at step 9660: 0.3019\n",
            "Seen so far: 309152 samples\n",
            "0.9535018\n",
            "Training loss (for one batch) at step 9665: 0.0399\n",
            "Seen so far: 309312 samples\n",
            "0.95350975\n",
            "Training loss (for one batch) at step 9670: 0.4663\n",
            "Seen so far: 309472 samples\n",
            "0.9535111\n",
            "Training loss (for one batch) at step 9675: 0.0642\n",
            "Seen so far: 309632 samples\n",
            "0.9535255\n",
            "Training loss (for one batch) at step 9680: 0.0834\n",
            "Seen so far: 309792 samples\n",
            "0.95353013\n",
            "Training loss (for one batch) at step 9685: 0.0166\n",
            "Seen so far: 309952 samples\n",
            "0.95354444\n",
            "Training loss (for one batch) at step 9690: 0.0339\n",
            "Seen so far: 310112 samples\n",
            "0.95356196\n",
            "Training loss (for one batch) at step 9695: 0.0017\n",
            "Seen so far: 310272 samples\n",
            "0.95356655\n",
            "Training loss (for one batch) at step 9700: 0.0264\n",
            "Seen so far: 310432 samples\n",
            "0.9535808\n",
            "Training loss (for one batch) at step 9705: 0.5137\n",
            "Seen so far: 310592 samples\n",
            "0.9535918\n",
            "Training loss (for one batch) at step 9710: 0.0226\n",
            "Seen so far: 310752 samples\n",
            "0.95360285\n",
            "Training loss (for one batch) at step 9715: 0.0069\n",
            "Seen so far: 310912 samples\n",
            "0.95360744\n",
            "Training loss (for one batch) at step 9720: 0.0417\n",
            "Seen so far: 311072 samples\n",
            "0.9536217\n",
            "Training loss (for one batch) at step 9725: 0.0055\n",
            "Seen so far: 311232 samples\n",
            "0.95363265\n",
            "Training loss (for one batch) at step 9730: 0.1653\n",
            "Seen so far: 311392 samples\n",
            "0.9536533\n",
            "Training loss (for one batch) at step 9735: 0.0064\n",
            "Seen so far: 311552 samples\n",
            "0.95366424\n",
            "Training loss (for one batch) at step 9740: 0.0216\n",
            "Seen so far: 311712 samples\n",
            "0.953688\n",
            "Training loss (for one batch) at step 9745: 0.0880\n",
            "Seen so far: 311872 samples\n",
            "0.9537086\n",
            "Training loss (for one batch) at step 9750: 0.0795\n",
            "Seen so far: 312032 samples\n",
            "0.9537195\n",
            "Training loss (for one batch) at step 9755: 0.0117\n",
            "Seen so far: 312192 samples\n",
            "0.9537272\n",
            "Training loss (for one batch) at step 9760: 0.0021\n",
            "Seen so far: 312352 samples\n",
            "0.9537445\n",
            "Training loss (for one batch) at step 9765: 0.0118\n",
            "Seen so far: 312512 samples\n",
            "0.9537394\n",
            "Training loss (for one batch) at step 9770: 0.4257\n",
            "Seen so far: 312672 samples\n",
            "0.9537343\n",
            "Training loss (for one batch) at step 9775: 0.1764\n",
            "Seen so far: 312832 samples\n",
            "0.95374197\n",
            "Training loss (for one batch) at step 9780: 0.0405\n",
            "Seen so far: 312992 samples\n",
            "0.9537592\n",
            "Training loss (for one batch) at step 9785: 0.0171\n",
            "Seen so far: 313152 samples\n",
            "0.9537764\n",
            "Training loss (for one batch) at step 9790: 0.0032\n",
            "Seen so far: 313312 samples\n",
            "0.95379364\n",
            "Training loss (for one batch) at step 9795: 0.0243\n",
            "Seen so far: 313472 samples\n",
            "0.9538013\n",
            "Training loss (for one batch) at step 9800: 0.0582\n",
            "Seen so far: 313632 samples\n",
            "0.95380574\n",
            "Training loss (for one batch) at step 9805: 0.0468\n",
            "Seen so far: 313792 samples\n",
            "0.9538229\n",
            "Training loss (for one batch) at step 9810: 0.0064\n",
            "Seen so far: 313952 samples\n",
            "0.95384324\n",
            "Training loss (for one batch) at step 9815: 0.0051\n",
            "Seen so far: 314112 samples\n",
            "0.9538604\n",
            "Training loss (for one batch) at step 9820: 0.0027\n",
            "Seen so far: 314272 samples\n",
            "0.9538807\n",
            "Training loss (for one batch) at step 9825: 0.0069\n",
            "Seen so far: 314432 samples\n",
            "0.953901\n",
            "Training loss (for one batch) at step 9830: 0.0026\n",
            "Seen so far: 314592 samples\n",
            "0.9539181\n",
            "Training loss (for one batch) at step 9835: 0.0112\n",
            "Seen so far: 314752 samples\n",
            "0.953932\n",
            "Training loss (for one batch) at step 9840: 0.1848\n",
            "Seen so far: 314912 samples\n",
            "0.95394903\n",
            "Training loss (for one batch) at step 9845: 0.1699\n",
            "Seen so far: 315072 samples\n",
            "0.9539629\n",
            "Training loss (for one batch) at step 9850: 0.0066\n",
            "Seen so far: 315232 samples\n",
            "0.9539799\n",
            "Training loss (for one batch) at step 9855: 0.0319\n",
            "Seen so far: 315392 samples\n",
            "0.95399696\n",
            "Training loss (for one batch) at step 9860: 0.0263\n",
            "Seen so far: 315552 samples\n",
            "0.9540171\n",
            "Training loss (for one batch) at step 9865: 0.0118\n",
            "Seen so far: 315712 samples\n",
            "0.95403725\n",
            "Training loss (for one batch) at step 9870: 0.1076\n",
            "Seen so far: 315872 samples\n",
            "0.95404786\n",
            "Training loss (for one batch) at step 9875: 0.0003\n",
            "Seen so far: 316032 samples\n",
            "0.9540648\n",
            "Training loss (for one batch) at step 9880: 0.0015\n",
            "Seen so far: 316192 samples\n",
            "0.95407856\n",
            "Training loss (for one batch) at step 9885: 0.0013\n",
            "Seen so far: 316352 samples\n",
            "0.9540986\n",
            "Training loss (for one batch) at step 9890: 0.0355\n",
            "Seen so far: 316512 samples\n",
            "0.9541155\n",
            "Training loss (for one batch) at step 9895: 0.0073\n",
            "Seen so far: 316672 samples\n",
            "0.9541292\n",
            "Training loss (for one batch) at step 9900: 0.1367\n",
            "Seen so far: 316832 samples\n",
            "0.95413655\n",
            "Training loss (for one batch) at step 9905: 0.0116\n",
            "Seen so far: 316992 samples\n",
            "0.9541534\n",
            "Training loss (for one batch) at step 9910: 0.0074\n",
            "Seen so far: 317152 samples\n",
            "0.95416707\n",
            "Training loss (for one batch) at step 9915: 0.5228\n",
            "Seen so far: 317312 samples\n",
            "0.95416814\n",
            "Training loss (for one batch) at step 9920: 0.0134\n",
            "Seen so far: 317472 samples\n",
            "0.9541692\n",
            "Training loss (for one batch) at step 9925: 0.0008\n",
            "Seen so far: 317632 samples\n",
            "0.95418596\n",
            "Training loss (for one batch) at step 9930: 0.0013\n",
            "Seen so far: 317792 samples\n",
            "0.9542059\n",
            "Training loss (for one batch) at step 9935: 0.0334\n",
            "Seen so far: 317952 samples\n",
            "0.95421636\n",
            "Training loss (for one batch) at step 9940: 0.0019\n",
            "Seen so far: 318112 samples\n",
            "0.9542268\n",
            "Training loss (for one batch) at step 9945: 0.0034\n",
            "Seen so far: 318272 samples\n",
            "0.9542498\n",
            "Training loss (for one batch) at step 9950: 0.0289\n",
            "Seen so far: 318432 samples\n",
            "0.95425713\n",
            "Training loss (for one batch) at step 9955: 0.0113\n",
            "Seen so far: 318592 samples\n",
            "0.9542644\n",
            "Training loss (for one batch) at step 9960: 0.0030\n",
            "Seen so far: 318752 samples\n",
            "0.95428735\n",
            "Training loss (for one batch) at step 9965: 0.0406\n",
            "Seen so far: 318912 samples\n",
            "0.954304\n",
            "Training loss (for one batch) at step 9970: 0.0236\n",
            "Seen so far: 319072 samples\n",
            "0.95432067\n",
            "Training loss (for one batch) at step 9975: 0.0018\n",
            "Seen so far: 319232 samples\n",
            "0.9543373\n",
            "Training loss (for one batch) at step 9980: 0.3288\n",
            "Seen so far: 319392 samples\n",
            "0.95435077\n",
            "Training loss (for one batch) at step 9985: 0.0077\n",
            "Seen so far: 319552 samples\n",
            "0.95436734\n",
            "Training loss (for one batch) at step 9990: 0.0398\n",
            "Seen so far: 319712 samples\n",
            "0.95438707\n",
            "Training loss (for one batch) at step 9995: 0.0549\n",
            "Seen so far: 319872 samples\n",
            "0.95440674\n",
            "Training loss (for one batch) at step 10000: 0.0017\n",
            "Seen so far: 320032 samples\n",
            "0.95442957\n",
            "Training loss (for one batch) at step 10005: 0.0111\n",
            "Seen so far: 320192 samples\n",
            "0.9544492\n",
            "Training loss (for one batch) at step 10010: 0.0782\n",
            "Seen so far: 320352 samples\n",
            "0.9544626\n",
            "Training loss (for one batch) at step 10015: 0.0823\n",
            "Seen so far: 320512 samples\n",
            "0.9544791\n",
            "Training loss (for one batch) at step 10020: 0.0620\n",
            "Seen so far: 320672 samples\n",
            "0.95449245\n",
            "Training loss (for one batch) at step 10025: 0.0013\n",
            "Seen so far: 320832 samples\n",
            "0.9545089\n",
            "Training loss (for one batch) at step 10030: 0.0003\n",
            "Seen so far: 320992 samples\n",
            "0.95452535\n",
            "Training loss (for one batch) at step 10035: 0.0080\n",
            "Seen so far: 321152 samples\n",
            "0.95453864\n",
            "Training loss (for one batch) at step 10040: 0.2798\n",
            "Seen so far: 321312 samples\n",
            "0.95455194\n",
            "Training loss (for one batch) at step 10045: 0.0119\n",
            "Seen so far: 321472 samples\n",
            "0.9545652\n",
            "Training loss (for one batch) at step 10050: 0.0014\n",
            "Seen so far: 321632 samples\n",
            "0.9545754\n",
            "Training loss (for one batch) at step 10055: 0.0900\n",
            "Seen so far: 321792 samples\n",
            "0.95458865\n",
            "Training loss (for one batch) at step 10060: 0.0001\n",
            "Seen so far: 321952 samples\n",
            "0.95459884\n",
            "Training loss (for one batch) at step 10065: 0.0268\n",
            "Seen so far: 322112 samples\n",
            "0.9546183\n",
            "Training loss (for one batch) at step 10070: 0.0043\n",
            "Seen so far: 322272 samples\n",
            "0.9546377\n",
            "Training loss (for one batch) at step 10075: 0.0114\n",
            "Seen so far: 322432 samples\n",
            "0.9546478\n",
            "Training loss (for one batch) at step 10080: 0.0123\n",
            "Seen so far: 322592 samples\n",
            "0.9546641\n",
            "Training loss (for one batch) at step 10085: 0.0028\n",
            "Seen so far: 322752 samples\n",
            "0.9546742\n",
            "Training loss (for one batch) at step 10090: 0.0696\n",
            "Seen so far: 322912 samples\n",
            "0.95469046\n",
            "Training loss (for one batch) at step 10095: 0.0063\n",
            "Seen so far: 323072 samples\n",
            "0.95470667\n",
            "Training loss (for one batch) at step 10100: 0.0107\n",
            "Seen so far: 323232 samples\n",
            "0.95472604\n",
            "Training loss (for one batch) at step 10105: 0.0382\n",
            "Seen so far: 323392 samples\n",
            "0.95474535\n",
            "Training loss (for one batch) at step 10110: 0.0002\n",
            "Seen so far: 323552 samples\n",
            "0.9547615\n",
            "Training loss (for one batch) at step 10115: 0.0039\n",
            "Seen so far: 323712 samples\n",
            "0.9547808\n",
            "Training loss (for one batch) at step 10120: 0.0662\n",
            "Seen so far: 323872 samples\n",
            "0.9547939\n",
            "Training loss (for one batch) at step 10125: 0.0277\n",
            "Seen so far: 324032 samples\n",
            "0.9548131\n",
            "Training loss (for one batch) at step 10130: 0.0747\n",
            "Seen so far: 324192 samples\n",
            "0.9548323\n",
            "Training loss (for one batch) at step 10135: 0.0216\n",
            "Seen so far: 324352 samples\n",
            "0.9548546\n",
            "Training loss (for one batch) at step 10140: 0.0014\n",
            "Seen so far: 324512 samples\n",
            "0.95486146\n",
            "Training loss (for one batch) at step 10145: 0.0066\n",
            "Seen so far: 324672 samples\n",
            "0.95487446\n",
            "Training loss (for one batch) at step 10150: 0.0007\n",
            "Seen so far: 324832 samples\n",
            "0.95489055\n",
            "Training loss (for one batch) at step 10155: 0.0081\n",
            "Seen so far: 324992 samples\n",
            "0.9549097\n",
            "Training loss (for one batch) at step 10160: 0.0106\n",
            "Seen so far: 325152 samples\n",
            "0.9549257\n",
            "Training loss (for one batch) at step 10165: 0.0023\n",
            "Seen so far: 325312 samples\n",
            "0.9549448\n",
            "Training loss (for one batch) at step 10170: 0.2912\n",
            "Seen so far: 325472 samples\n",
            "0.9549485\n",
            "Training loss (for one batch) at step 10175: 0.0035\n",
            "Seen so far: 325632 samples\n",
            "0.95496756\n",
            "Training loss (for one batch) at step 10180: 0.0054\n",
            "Seen so far: 325792 samples\n",
            "0.95498663\n",
            "Training loss (for one batch) at step 10185: 0.0068\n",
            "Seen so far: 325952 samples\n",
            "0.95500565\n",
            "Training loss (for one batch) at step 10190: 0.0071\n",
            "Seen so far: 326112 samples\n",
            "0.95502156\n",
            "Training loss (for one batch) at step 10195: 0.0868\n",
            "Seen so far: 326272 samples\n",
            "0.95503753\n",
            "Training loss (for one batch) at step 10200: 0.0013\n",
            "Seen so far: 326432 samples\n",
            "0.95505345\n",
            "Training loss (for one batch) at step 10205: 0.0025\n",
            "Seen so far: 326592 samples\n",
            "0.95506626\n",
            "Training loss (for one batch) at step 10210: 0.1150\n",
            "Seen so far: 326752 samples\n",
            "0.9550791\n",
            "Training loss (for one batch) at step 10215: 0.0016\n",
            "Seen so far: 326912 samples\n",
            "0.95509493\n",
            "Training loss (for one batch) at step 10220: 0.1989\n",
            "Seen so far: 327072 samples\n",
            "0.9551108\n",
            "Training loss (for one batch) at step 10225: 0.0016\n",
            "Seen so far: 327232 samples\n",
            "0.95512664\n",
            "Training loss (for one batch) at step 10230: 0.0450\n",
            "Seen so far: 327392 samples\n",
            "0.95513636\n",
            "Training loss (for one batch) at step 10235: 0.0061\n",
            "Seen so far: 327552 samples\n",
            "0.95515215\n",
            "Training loss (for one batch) at step 10240: 0.0059\n",
            "Seen so far: 327712 samples\n",
            "0.95516795\n",
            "Training loss (for one batch) at step 10245: 0.1803\n",
            "Seen so far: 327872 samples\n",
            "0.95518374\n",
            "Training loss (for one batch) at step 10250: 0.0274\n",
            "Seen so far: 328032 samples\n",
            "0.9551934\n",
            "Training loss (for one batch) at step 10255: 0.0703\n",
            "Seen so far: 328192 samples\n",
            "0.9552122\n",
            "Training loss (for one batch) at step 10260: 0.0432\n",
            "Seen so far: 328352 samples\n",
            "0.955234\n",
            "Training loss (for one batch) at step 10265: 0.0003\n",
            "Seen so far: 328512 samples\n",
            "0.9552497\n",
            "Training loss (for one batch) at step 10270: 0.0005\n",
            "Seen so far: 328672 samples\n",
            "0.95527154\n",
            "Training loss (for one batch) at step 10275: 0.0037\n",
            "Seen so far: 328832 samples\n",
            "0.9552933\n",
            "Training loss (for one batch) at step 10280: 0.1079\n",
            "Seen so far: 328992 samples\n",
            "0.9553059\n",
            "Training loss (for one batch) at step 10285: 0.0021\n",
            "Seen so far: 329152 samples\n",
            "0.9553246\n",
            "Training loss (for one batch) at step 10290: 0.0041\n",
            "Seen so far: 329312 samples\n",
            "0.95533717\n",
            "Training loss (for one batch) at step 10295: 0.0076\n",
            "Seen so far: 329472 samples\n",
            "0.9553528\n",
            "Training loss (for one batch) at step 10300: 0.0048\n",
            "Seen so far: 329632 samples\n",
            "0.9553684\n",
            "Training loss (for one batch) at step 10305: 0.0057\n",
            "Seen so far: 329792 samples\n",
            "0.95538706\n",
            "Training loss (for one batch) at step 10310: 0.0271\n",
            "Seen so far: 329952 samples\n",
            "0.9554026\n",
            "Training loss (for one batch) at step 10315: 0.0002\n",
            "Seen so far: 330112 samples\n",
            "0.9554151\n",
            "Training loss (for one batch) at step 10320: 0.1975\n",
            "Seen so far: 330272 samples\n",
            "0.95542157\n",
            "Training loss (for one batch) at step 10325: 0.0482\n",
            "Seen so far: 330432 samples\n",
            "0.95543104\n",
            "Training loss (for one batch) at step 10330: 0.0268\n",
            "Seen so far: 330592 samples\n",
            "0.95544964\n",
            "Training loss (for one batch) at step 10335: 0.0014\n",
            "Seen so far: 330752 samples\n",
            "0.95546514\n",
            "Training loss (for one batch) at step 10340: 0.0004\n",
            "Seen so far: 330912 samples\n",
            "0.95548064\n",
            "Training loss (for one batch) at step 10345: 0.0038\n",
            "Seen so far: 331072 samples\n",
            "0.9554961\n",
            "Training loss (for one batch) at step 10350: 0.0096\n",
            "Seen so far: 331232 samples\n",
            "0.95551455\n",
            "Training loss (for one batch) at step 10355: 0.0003\n",
            "Seen so far: 331392 samples\n",
            "0.95553\n",
            "Training loss (for one batch) at step 10360: 0.1687\n",
            "Seen so far: 331552 samples\n",
            "0.9555394\n",
            "Training loss (for one batch) at step 10365: 0.0352\n",
            "Seen so far: 331712 samples\n",
            "0.9555518\n",
            "Training loss (for one batch) at step 10370: 0.0130\n",
            "Seen so far: 331872 samples\n",
            "0.9555642\n",
            "Training loss (for one batch) at step 10375: 0.0015\n",
            "Seen so far: 332032 samples\n",
            "0.9555705\n",
            "Training loss (for one batch) at step 10380: 0.1375\n",
            "Seen so far: 332192 samples\n",
            "0.9555799\n",
            "Training loss (for one batch) at step 10385: 0.0804\n",
            "Seen so far: 332352 samples\n",
            "0.95558625\n",
            "Training loss (for one batch) at step 10390: 0.0968\n",
            "Seen so far: 332512 samples\n",
            "0.9555986\n",
            "Training loss (for one batch) at step 10395: 0.0082\n",
            "Seen so far: 332672 samples\n",
            "0.9556139\n",
            "Training loss (for one batch) at step 10400: 0.0186\n",
            "Seen so far: 332832 samples\n",
            "0.95563227\n",
            "Training loss (for one batch) at step 10405: 0.0270\n",
            "Seen so far: 332992 samples\n",
            "0.95564157\n",
            "Training loss (for one batch) at step 10410: 0.0006\n",
            "Seen so far: 333152 samples\n",
            "0.9556569\n",
            "Training loss (for one batch) at step 10415: 0.0293\n",
            "Seen so far: 333312 samples\n",
            "0.95567214\n",
            "Training loss (for one batch) at step 10420: 0.0042\n",
            "Seen so far: 333472 samples\n",
            "0.95567846\n",
            "Training loss (for one batch) at step 10425: 0.0095\n",
            "Seen so far: 333632 samples\n",
            "0.9556967\n",
            "Training loss (for one batch) at step 10430: 0.0701\n",
            "Seen so far: 333792 samples\n",
            "0.95571196\n",
            "Training loss (for one batch) at step 10435: 0.0270\n",
            "Seen so far: 333952 samples\n",
            "0.95572716\n",
            "Training loss (for one batch) at step 10440: 0.0095\n",
            "Seen so far: 334112 samples\n",
            "0.9557454\n",
            "Training loss (for one batch) at step 10445: 0.1051\n",
            "Seen so far: 334272 samples\n",
            "0.9557486\n",
            "Training loss (for one batch) at step 10450: 0.0098\n",
            "Seen so far: 334432 samples\n",
            "0.9557638\n",
            "Training loss (for one batch) at step 10455: 0.0378\n",
            "Seen so far: 334592 samples\n",
            "0.95577896\n",
            "Training loss (for one batch) at step 10460: 0.0507\n",
            "Seen so far: 334752 samples\n",
            "0.95579714\n",
            "Training loss (for one batch) at step 10465: 0.0010\n",
            "Seen so far: 334912 samples\n",
            "0.95581824\n",
            "Training loss (for one batch) at step 10470: 0.0639\n",
            "Seen so far: 335072 samples\n",
            "0.95583636\n",
            "Training loss (for one batch) at step 10475: 0.1317\n",
            "Seen so far: 335232 samples\n",
            "0.9558395\n",
            "Training loss (for one batch) at step 10480: 0.0839\n",
            "Seen so far: 335392 samples\n",
            "0.95585763\n",
            "Training loss (for one batch) at step 10485: 0.0685\n",
            "Seen so far: 335552 samples\n",
            "0.9558727\n",
            "Training loss (for one batch) at step 10490: 0.0148\n",
            "Seen so far: 335712 samples\n",
            "0.9558908\n",
            "Training loss (for one batch) at step 10495: 0.0009\n",
            "Seen so far: 335872 samples\n",
            "0.9559088\n",
            "Training loss (for one batch) at step 10500: 0.2077\n",
            "Seen so far: 336032 samples\n",
            "0.9559179\n",
            "Training loss (for one batch) at step 10505: 0.0018\n",
            "Seen so far: 336192 samples\n",
            "0.95592695\n",
            "Training loss (for one batch) at step 10510: 0.0066\n",
            "Seen so far: 336352 samples\n",
            "0.955942\n",
            "Training loss (for one batch) at step 10515: 0.2683\n",
            "Seen so far: 336512 samples\n",
            "0.95594805\n",
            "Training loss (for one batch) at step 10520: 0.0077\n",
            "Seen so far: 336672 samples\n",
            "0.95596606\n",
            "Training loss (for one batch) at step 10525: 0.0073\n",
            "Seen so far: 336832 samples\n",
            "0.955981\n",
            "Training loss (for one batch) at step 10530: 0.0304\n",
            "Seen so far: 336992 samples\n",
            "0.9559871\n",
            "Training loss (for one batch) at step 10535: 0.0103\n",
            "Seen so far: 337152 samples\n",
            "0.9559902\n",
            "Training loss (for one batch) at step 10540: 0.0948\n",
            "Seen so far: 337312 samples\n",
            "0.9560022\n",
            "Training loss (for one batch) at step 10545: 0.0226\n",
            "Seen so far: 337472 samples\n",
            "0.9560112\n",
            "Training loss (for one batch) at step 10550: 0.1156\n",
            "Seen so far: 337632 samples\n",
            "0.9560202\n",
            "Training loss (for one batch) at step 10555: 0.0020\n",
            "Seen so far: 337792 samples\n",
            "0.9560351\n",
            "Training loss (for one batch) at step 10560: 0.0468\n",
            "Seen so far: 337952 samples\n",
            "0.95605296\n",
            "Training loss (for one batch) at step 10565: 0.0002\n",
            "Seen so far: 338112 samples\n",
            "0.9560619\n",
            "Training loss (for one batch) at step 10570: 0.1558\n",
            "Seen so far: 338272 samples\n",
            "0.95607084\n",
            "Training loss (for one batch) at step 10575: 0.2331\n",
            "Seen so far: 338432 samples\n",
            "0.95607096\n",
            "Training loss (for one batch) at step 10580: 0.2025\n",
            "Seen so far: 338592 samples\n",
            "0.9560858\n",
            "Training loss (for one batch) at step 10585: 0.0014\n",
            "Seen so far: 338752 samples\n",
            "0.95609176\n",
            "Training loss (for one batch) at step 10590: 0.0924\n",
            "Seen so far: 338912 samples\n",
            "0.9561066\n",
            "Training loss (for one batch) at step 10595: 0.0792\n",
            "Seen so far: 339072 samples\n",
            "0.95610666\n",
            "Training loss (for one batch) at step 10600: 0.0024\n",
            "Seen so far: 339232 samples\n",
            "0.9561156\n",
            "Training loss (for one batch) at step 10605: 0.0338\n",
            "Seen so far: 339392 samples\n",
            "0.9561304\n",
            "Training loss (for one batch) at step 10610: 0.0579\n",
            "Seen so far: 339552 samples\n",
            "0.9561422\n",
            "Training loss (for one batch) at step 10615: 0.1008\n",
            "Seen so far: 339712 samples\n",
            "0.95615107\n",
            "Training loss (for one batch) at step 10620: 0.2595\n",
            "Seen so far: 339872 samples\n",
            "0.95615995\n",
            "Training loss (for one batch) at step 10625: 0.0223\n",
            "Seen so far: 340032 samples\n",
            "0.95616883\n",
            "Training loss (for one batch) at step 10630: 0.0410\n",
            "Seen so far: 340192 samples\n",
            "0.9561777\n",
            "Training loss (for one batch) at step 10635: 0.0060\n",
            "Seen so far: 340352 samples\n",
            "0.95618945\n",
            "Training loss (for one batch) at step 10640: 0.0307\n",
            "Seen so far: 340512 samples\n",
            "0.9562071\n",
            "Training loss (for one batch) at step 10645: 0.0133\n",
            "Seen so far: 340672 samples\n",
            "0.9562189\n",
            "Training loss (for one batch) at step 10650: 0.0211\n",
            "Seen so far: 340832 samples\n",
            "0.9562277\n",
            "Training loss (for one batch) at step 10655: 0.0187\n",
            "Seen so far: 340992 samples\n",
            "0.9562365\n",
            "Training loss (for one batch) at step 10660: 0.0031\n",
            "Seen so far: 341152 samples\n",
            "0.9562453\n",
            "Training loss (for one batch) at step 10665: 0.0059\n",
            "Seen so far: 341312 samples\n",
            "0.95625997\n",
            "Training loss (for one batch) at step 10670: 0.1614\n",
            "Seen so far: 341472 samples\n",
            "0.9562629\n",
            "Training loss (for one batch) at step 10675: 0.0079\n",
            "Seen so far: 341632 samples\n",
            "0.95628047\n",
            "Training loss (for one batch) at step 10680: 0.0583\n",
            "Seen so far: 341792 samples\n",
            "0.95629215\n",
            "Training loss (for one batch) at step 10685: 0.0040\n",
            "Seen so far: 341952 samples\n",
            "0.95629793\n",
            "Training loss (for one batch) at step 10690: 0.3220\n",
            "Seen so far: 342112 samples\n",
            "0.95630085\n",
            "Training loss (for one batch) at step 10695: 0.0068\n",
            "Seen so far: 342272 samples\n",
            "0.9563184\n",
            "Training loss (for one batch) at step 10700: 0.0142\n",
            "Seen so far: 342432 samples\n",
            "0.95632124\n",
            "Training loss (for one batch) at step 10705: 0.0006\n",
            "Seen so far: 342592 samples\n",
            "0.95632416\n",
            "Training loss (for one batch) at step 10710: 0.0134\n",
            "Seen so far: 342752 samples\n",
            "0.9563358\n",
            "Training loss (for one batch) at step 10715: 0.0098\n",
            "Seen so far: 342912 samples\n",
            "0.9563503\n",
            "Training loss (for one batch) at step 10720: 0.0076\n",
            "Seen so far: 343072 samples\n",
            "0.95636773\n",
            "Training loss (for one batch) at step 10725: 0.0078\n",
            "Seen so far: 343232 samples\n",
            "0.95637643\n",
            "Training loss (for one batch) at step 10730: 0.0236\n",
            "Seen so far: 343392 samples\n",
            "0.9563822\n",
            "Training loss (for one batch) at step 10735: 0.0531\n",
            "Seen so far: 343552 samples\n",
            "0.9563938\n",
            "Training loss (for one batch) at step 10740: 0.0167\n",
            "Seen so far: 343712 samples\n",
            "0.9564141\n",
            "Training loss (for one batch) at step 10745: 0.0432\n",
            "Seen so far: 343872 samples\n",
            "0.95642275\n",
            "Training loss (for one batch) at step 10750: 0.0037\n",
            "Seen so far: 344032 samples\n",
            "0.95642847\n",
            "Training loss (for one batch) at step 10755: 0.0143\n",
            "Seen so far: 344192 samples\n",
            "0.9564429\n",
            "Training loss (for one batch) at step 10760: 0.0188\n",
            "Seen so far: 344352 samples\n",
            "0.95646024\n",
            "Training loss (for one batch) at step 10765: 0.0592\n",
            "Seen so far: 344512 samples\n",
            "0.95647466\n",
            "Training loss (for one batch) at step 10770: 0.0128\n",
            "Seen so far: 344672 samples\n",
            "0.95649195\n",
            "Training loss (for one batch) at step 10775: 0.0010\n",
            "Seen so far: 344832 samples\n",
            "0.95650923\n",
            "Training loss (for one batch) at step 10780: 0.0019\n",
            "Seen so far: 344992 samples\n",
            "0.9565265\n",
            "Training loss (for one batch) at step 10785: 0.0010\n",
            "Seen so far: 345152 samples\n",
            "0.95653796\n",
            "Training loss (for one batch) at step 10790: 0.0081\n",
            "Seen so far: 345312 samples\n",
            "0.95654947\n",
            "Training loss (for one batch) at step 10795: 0.0620\n",
            "Seen so far: 345472 samples\n",
            "0.95656085\n",
            "Training loss (for one batch) at step 10800: 0.1173\n",
            "Seen so far: 345632 samples\n",
            "0.95656943\n",
            "Training loss (for one batch) at step 10805: 0.1610\n",
            "Seen so far: 345792 samples\n",
            "0.95658374\n",
            "Training loss (for one batch) at step 10810: 0.0110\n",
            "Seen so far: 345952 samples\n",
            "0.9566009\n",
            "Training loss (for one batch) at step 10815: 0.0612\n",
            "Seen so far: 346112 samples\n",
            "0.9566152\n",
            "Training loss (for one batch) at step 10820: 0.0877\n",
            "Seen so far: 346272 samples\n",
            "0.9566237\n",
            "Training loss (for one batch) at step 10825: 0.0059\n",
            "Seen so far: 346432 samples\n",
            "0.95663506\n",
            "Training loss (for one batch) at step 10830: 0.0047\n",
            "Seen so far: 346592 samples\n",
            "0.9566493\n",
            "Training loss (for one batch) at step 10835: 0.0048\n",
            "Seen so far: 346752 samples\n",
            "0.9566607\n",
            "Training loss (for one batch) at step 10840: 0.0037\n",
            "Seen so far: 346912 samples\n",
            "0.9566749\n",
            "Training loss (for one batch) at step 10845: 0.0643\n",
            "Seen so far: 347072 samples\n",
            "0.956692\n",
            "Training loss (for one batch) at step 10850: 0.1302\n",
            "Seen so far: 347232 samples\n",
            "0.95670044\n",
            "Training loss (for one batch) at step 10855: 0.1119\n",
            "Seen so far: 347392 samples\n",
            "0.9567002\n",
            "Training loss (for one batch) at step 10860: 0.2657\n",
            "Seen so far: 347552 samples\n",
            "0.95671153\n",
            "Training loss (for one batch) at step 10865: 0.0721\n",
            "Seen so far: 347712 samples\n",
            "0.95672566\n",
            "Training loss (for one batch) at step 10870: 0.0943\n",
            "Seen so far: 347872 samples\n",
            "0.95672834\n",
            "Training loss (for one batch) at step 10875: 0.0866\n",
            "Seen so far: 348032 samples\n",
            "0.9567396\n",
            "Training loss (for one batch) at step 10880: 0.0067\n",
            "Seen so far: 348192 samples\n",
            "0.9567566\n",
            "Training loss (for one batch) at step 10885: 0.2332\n",
            "Seen so far: 348352 samples\n",
            "0.9567593\n",
            "Training loss (for one batch) at step 10890: 0.0184\n",
            "Seen so far: 348512 samples\n",
            "0.95677334\n",
            "Training loss (for one batch) at step 10895: 0.0867\n",
            "Seen so far: 348672 samples\n",
            "0.9567674\n",
            "Training loss (for one batch) at step 10900: 0.0629\n",
            "Seen so far: 348832 samples\n",
            "0.95677\n",
            "Training loss (for one batch) at step 10905: 0.0089\n",
            "Seen so far: 348992 samples\n",
            "0.9567755\n",
            "Training loss (for one batch) at step 10910: 0.0100\n",
            "Seen so far: 349152 samples\n",
            "0.956781\n",
            "Training loss (for one batch) at step 10915: 0.1041\n",
            "Seen so far: 349312 samples\n",
            "0.9567894\n",
            "Training loss (for one batch) at step 10920: 0.0964\n",
            "Seen so far: 349472 samples\n",
            "0.9568005\n",
            "Training loss (for one batch) at step 10925: 0.0012\n",
            "Seen so far: 349632 samples\n",
            "0.9568117\n",
            "Training loss (for one batch) at step 10930: 0.0390\n",
            "Seen so far: 349792 samples\n",
            "0.9568258\n",
            "Training loss (for one batch) at step 10935: 0.0280\n",
            "Seen so far: 349952 samples\n",
            "0.95683694\n",
            "Training loss (for one batch) at step 10940: 0.0259\n",
            "Seen so far: 350112 samples\n",
            "0.95685667\n",
            "Training loss (for one batch) at step 10945: 0.0334\n",
            "Seen so far: 350272 samples\n",
            "0.95687354\n",
            "Training loss (for one batch) at step 10950: 0.1749\n",
            "Seen so far: 350432 samples\n",
            "0.9568818\n",
            "Training loss (for one batch) at step 10955: 0.0170\n",
            "Seen so far: 350592 samples\n",
            "0.9568872\n",
            "Training loss (for one batch) at step 10960: 0.0324\n",
            "Seen so far: 350752 samples\n",
            "0.95688975\n",
            "Training loss (for one batch) at step 10965: 0.2090\n",
            "Seen so far: 350912 samples\n",
            "0.9568923\n",
            "Training loss (for one batch) at step 10970: 0.5098\n",
            "Seen so far: 351072 samples\n",
            "0.9568892\n",
            "Training loss (for one batch) at step 10975: 0.0762\n",
            "Seen so far: 351232 samples\n",
            "0.95689744\n",
            "Training loss (for one batch) at step 10980: 0.1242\n",
            "Seen so far: 351392 samples\n",
            "0.9569114\n",
            "Training loss (for one batch) at step 10985: 0.4762\n",
            "Seen so far: 351552 samples\n",
            "0.9569082\n",
            "Training loss (for one batch) at step 10990: 0.0561\n",
            "Seen so far: 351712 samples\n",
            "0.95691645\n",
            "Training loss (for one batch) at step 10995: 0.0854\n",
            "Seen so far: 351872 samples\n",
            "0.9568991\n",
            "Training loss (for one batch) at step 11000: 0.2417\n",
            "Seen so far: 352032 samples\n",
            "0.95690167\n",
            "Training loss (for one batch) at step 11005: 0.0718\n",
            "Seen so far: 352192 samples\n",
            "0.95690703\n",
            "Training loss (for one batch) at step 11010: 0.1186\n",
            "Seen so far: 352352 samples\n",
            "0.9569209\n",
            "Training loss (for one batch) at step 11015: 0.2760\n",
            "Seen so far: 352512 samples\n",
            "0.9569234\n",
            "Training loss (for one batch) at step 11020: 0.0180\n",
            "Seen so far: 352672 samples\n",
            "0.9569345\n",
            "Training loss (for one batch) at step 11025: 0.1841\n",
            "Seen so far: 352832 samples\n",
            "0.95693135\n",
            "Training loss (for one batch) at step 11030: 0.1296\n",
            "Seen so far: 352992 samples\n",
            "0.95693105\n",
            "Training loss (for one batch) at step 11035: 0.2132\n",
            "Seen so far: 353152 samples\n",
            "0.95692223\n",
            "Training loss (for one batch) at step 11040: 0.0459\n",
            "Seen so far: 353312 samples\n",
            "0.9569191\n",
            "Training loss (for one batch) at step 11045: 0.0511\n",
            "Seen so far: 353472 samples\n",
            "0.9569188\n",
            "Training loss (for one batch) at step 11050: 0.1789\n",
            "Seen so far: 353632 samples\n",
            "0.9569157\n",
            "Training loss (for one batch) at step 11055: 0.0865\n",
            "Seen so far: 353792 samples\n",
            "0.95692104\n",
            "Training loss (for one batch) at step 11060: 0.2156\n",
            "Seen so far: 353952 samples\n",
            "0.9569207\n",
            "Training loss (for one batch) at step 11065: 0.2570\n",
            "Seen so far: 354112 samples\n",
            "0.95692325\n",
            "Training loss (for one batch) at step 11070: 0.0243\n",
            "Seen so far: 354272 samples\n",
            "0.9569314\n",
            "Training loss (for one batch) at step 11075: 0.3732\n",
            "Seen so far: 354432 samples\n",
            "0.9569396\n",
            "Training loss (for one batch) at step 11080: 0.1232\n",
            "Seen so far: 354592 samples\n",
            "0.9569364\n",
            "Training loss (for one batch) at step 11085: 0.3441\n",
            "Seen so far: 354752 samples\n",
            "0.9569333\n",
            "Training loss (for one batch) at step 11090: 0.0522\n",
            "Seen so far: 354912 samples\n",
            "0.9569386\n",
            "Training loss (for one batch) at step 11095: 0.0807\n",
            "Seen so far: 355072 samples\n",
            "0.9569439\n",
            "Training loss (for one batch) at step 11100: 0.4149\n",
            "Seen so far: 355232 samples\n",
            "0.95694363\n",
            "Training loss (for one batch) at step 11105: 0.1920\n",
            "Seen so far: 355392 samples\n",
            "0.95694613\n",
            "Training loss (for one batch) at step 11110: 0.2417\n",
            "Seen so far: 355552 samples\n",
            "0.95694584\n",
            "Training loss (for one batch) at step 11115: 0.2308\n",
            "Seen so far: 355712 samples\n",
            "0.95694834\n",
            "Training loss (for one batch) at step 11120: 0.3686\n",
            "Seen so far: 355872 samples\n",
            "0.956948\n",
            "Training loss (for one batch) at step 11125: 0.0243\n",
            "Seen so far: 356032 samples\n",
            "0.95696175\n",
            "Training loss (for one batch) at step 11130: 0.1853\n",
            "Seen so far: 356192 samples\n",
            "0.9569586\n",
            "Training loss (for one batch) at step 11135: 0.0215\n",
            "Seen so far: 356352 samples\n",
            "0.9569639\n",
            "Training loss (for one batch) at step 11140: 0.0467\n",
            "Seen so far: 356512 samples\n",
            "0.9569692\n",
            "Training loss (for one batch) at step 11145: 0.1564\n",
            "Seen so far: 356672 samples\n",
            "0.95696884\n",
            "Training loss (for one batch) at step 11150: 0.0247\n",
            "Seen so far: 356832 samples\n",
            "0.95698255\n",
            "Training loss (for one batch) at step 11155: 0.0965\n",
            "Seen so far: 356992 samples\n",
            "0.95698786\n",
            "Training loss (for one batch) at step 11160: 0.0442\n",
            "Seen so far: 357152 samples\n",
            "0.9570071\n",
            "Training loss (for one batch) at step 11165: 0.3241\n",
            "Seen so far: 357312 samples\n",
            "0.95702076\n",
            "Training loss (for one batch) at step 11170: 0.3052\n",
            "Seen so far: 357472 samples\n",
            "0.9570288\n",
            "Training loss (for one batch) at step 11175: 0.0528\n",
            "Seen so far: 357632 samples\n",
            "0.95703685\n",
            "Training loss (for one batch) at step 11180: 0.0103\n",
            "Seen so far: 357792 samples\n",
            "0.9570449\n",
            "Training loss (for one batch) at step 11185: 0.0006\n",
            "Seen so far: 357952 samples\n",
            "0.9570585\n",
            "Training loss (for one batch) at step 11190: 0.2672\n",
            "Seen so far: 358112 samples\n",
            "0.9570693\n",
            "Training loss (for one batch) at step 11195: 0.0145\n",
            "Seen so far: 358272 samples\n",
            "0.95708287\n",
            "Training loss (for one batch) at step 11200: 0.1080\n",
            "Seen so far: 358432 samples\n",
            "0.95709366\n",
            "Training loss (for one batch) at step 11205: 0.0150\n",
            "Seen so far: 358592 samples\n",
            "0.95710164\n",
            "Training loss (for one batch) at step 11210: 0.1096\n",
            "Seen so far: 358752 samples\n",
            "0.95710963\n",
            "Training loss (for one batch) at step 11215: 0.0072\n",
            "Seen so far: 358912 samples\n",
            "0.95712596\n",
            "Training loss (for one batch) at step 11220: 0.0002\n",
            "Seen so far: 359072 samples\n",
            "0.95713675\n",
            "Training loss (for one batch) at step 11225: 0.0486\n",
            "Seen so far: 359232 samples\n",
            "0.9571475\n",
            "Training loss (for one batch) at step 11230: 0.1939\n",
            "Seen so far: 359392 samples\n",
            "0.95715266\n",
            "Training loss (for one batch) at step 11235: 0.0027\n",
            "Seen so far: 359552 samples\n",
            "0.9571717\n",
            "Training loss (for one batch) at step 11240: 0.0271\n",
            "Seen so far: 359712 samples\n",
            "0.95717686\n",
            "Training loss (for one batch) at step 11245: 0.0002\n",
            "Seen so far: 359872 samples\n",
            "0.957182\n",
            "Training loss (for one batch) at step 11250: 0.1315\n",
            "Seen so far: 360032 samples\n",
            "0.9571899\n",
            "Training loss (for one batch) at step 11255: 0.3978\n",
            "Seen so far: 360192 samples\n",
            "0.9572006\n",
            "Training loss (for one batch) at step 11260: 0.1608\n",
            "Seen so far: 360352 samples\n",
            "0.9572085\n",
            "Training loss (for one batch) at step 11265: 0.0699\n",
            "Seen so far: 360512 samples\n",
            "0.95721364\n",
            "Training loss (for one batch) at step 11270: 0.0363\n",
            "Seen so far: 360672 samples\n",
            "0.9572243\n",
            "Training loss (for one batch) at step 11275: 0.0197\n",
            "Seen so far: 360832 samples\n",
            "0.95724326\n",
            "Training loss (for one batch) at step 11280: 0.1154\n",
            "Seen so far: 360992 samples\n",
            "0.9572539\n",
            "Training loss (for one batch) at step 11285: 0.2056\n",
            "Seen so far: 361152 samples\n",
            "0.95726454\n",
            "Training loss (for one batch) at step 11290: 0.0090\n",
            "Seen so far: 361312 samples\n",
            "0.9572807\n",
            "Training loss (for one batch) at step 11295: 0.0808\n",
            "Seen so far: 361472 samples\n",
            "0.957283\n",
            "Training loss (for one batch) at step 11300: 0.0055\n",
            "Seen so far: 361632 samples\n",
            "0.9572964\n",
            "Training loss (for one batch) at step 11305: 0.0896\n",
            "Seen so far: 361792 samples\n",
            "0.9573042\n",
            "Training loss (for one batch) at step 11310: 0.1788\n",
            "Seen so far: 361952 samples\n",
            "0.95731753\n",
            "Training loss (for one batch) at step 11315: 0.0018\n",
            "Seen so far: 362112 samples\n",
            "0.9573309\n",
            "Training loss (for one batch) at step 11320: 0.0003\n",
            "Seen so far: 362272 samples\n",
            "0.957347\n",
            "Training loss (for one batch) at step 11325: 0.0013\n",
            "Seen so far: 362432 samples\n",
            "0.95736027\n",
            "Training loss (for one batch) at step 11330: 0.0145\n",
            "Seen so far: 362592 samples\n",
            "0.95737356\n",
            "Training loss (for one batch) at step 11335: 0.0037\n",
            "Seen so far: 362752 samples\n",
            "0.95738137\n",
            "Training loss (for one batch) at step 11340: 0.0006\n",
            "Seen so far: 362912 samples\n",
            "0.95740014\n",
            "Training loss (for one batch) at step 11345: 0.0140\n",
            "Seen so far: 363072 samples\n",
            "0.9574079\n",
            "Training loss (for one batch) at step 11350: 0.0855\n",
            "Seen so far: 363232 samples\n",
            "0.9574211\n",
            "Training loss (for one batch) at step 11355: 0.0417\n",
            "Seen so far: 363392 samples\n",
            "0.9574344\n",
            "Training loss (for one batch) at step 11360: 0.0005\n",
            "Seen so far: 363552 samples\n",
            "0.9574504\n",
            "Training loss (for one batch) at step 11365: 0.0002\n",
            "Seen so far: 363712 samples\n",
            "0.9574636\n",
            "Training loss (for one batch) at step 11370: 0.0158\n",
            "Seen so far: 363872 samples\n",
            "0.9574768\n",
            "Training loss (for one batch) at step 11375: 0.0034\n",
            "Seen so far: 364032 samples\n",
            "0.95749\n",
            "Training loss (for one batch) at step 11380: 0.0227\n",
            "Seen so far: 364192 samples\n",
            "0.95750046\n",
            "Training loss (for one batch) at step 11385: 0.0011\n",
            "Seen so far: 364352 samples\n",
            "0.9575109\n",
            "Training loss (for one batch) at step 11390: 0.0007\n",
            "Seen so far: 364512 samples\n",
            "0.95752406\n",
            "Training loss (for one batch) at step 11395: 0.0027\n",
            "Seen so far: 364672 samples\n",
            "0.95752895\n",
            "Training loss (for one batch) at step 11400: 0.0028\n",
            "Seen so far: 364832 samples\n",
            "0.9575421\n",
            "Training loss (for one batch) at step 11405: 0.0180\n",
            "Seen so far: 364992 samples\n",
            "0.957558\n",
            "Training loss (for one batch) at step 11410: 0.0208\n",
            "Seen so far: 365152 samples\n",
            "0.95757383\n",
            "Training loss (for one batch) at step 11415: 0.0062\n",
            "Seen so far: 365312 samples\n",
            "0.9575787\n",
            "Training loss (for one batch) at step 11420: 0.0135\n",
            "Seen so far: 365472 samples\n",
            "0.9575891\n",
            "Training loss (for one batch) at step 11425: 0.1741\n",
            "Seen so far: 365632 samples\n",
            "0.9576049\n",
            "Training loss (for one batch) at step 11430: 0.0600\n",
            "Seen so far: 365792 samples\n",
            "0.95761526\n",
            "Training loss (for one batch) at step 11435: 0.0529\n",
            "Seen so far: 365952 samples\n",
            "0.95763105\n",
            "Training loss (for one batch) at step 11440: 0.0063\n",
            "Seen so far: 366112 samples\n",
            "0.9576441\n",
            "Training loss (for one batch) at step 11445: 0.0011\n",
            "Seen so far: 366272 samples\n",
            "0.9576544\n",
            "Training loss (for one batch) at step 11450: 0.0012\n",
            "Seen so far: 366432 samples\n",
            "0.9576456\n",
            "Training loss (for one batch) at step 11455: 0.0002\n",
            "Seen so far: 366592 samples\n",
            "0.95765865\n",
            "Training loss (for one batch) at step 11460: 0.0019\n",
            "Seen so far: 366752 samples\n",
            "0.9576662\n",
            "Training loss (for one batch) at step 11465: 0.1983\n",
            "Seen so far: 366912 samples\n",
            "0.95768195\n",
            "Training loss (for one batch) at step 11470: 0.0003\n",
            "Seen so far: 367072 samples\n",
            "0.9576922\n",
            "Training loss (for one batch) at step 11475: 0.0073\n",
            "Seen so far: 367232 samples\n",
            "0.95770794\n",
            "Training loss (for one batch) at step 11480: 0.0019\n",
            "Seen so far: 367392 samples\n",
            "0.95772094\n",
            "Training loss (for one batch) at step 11485: 0.0067\n",
            "Seen so far: 367552 samples\n",
            "0.95773387\n",
            "Training loss (for one batch) at step 11490: 0.0011\n",
            "Seen so far: 367712 samples\n",
            "0.9577523\n",
            "Training loss (for one batch) at step 11495: 0.0049\n",
            "Seen so far: 367872 samples\n",
            "0.9577652\n",
            "Training loss (for one batch) at step 11500: 0.1534\n",
            "Seen so far: 368032 samples\n",
            "0.95777816\n",
            "Training loss (for one batch) at step 11505: 0.1482\n",
            "Seen so far: 368192 samples\n",
            "0.9577802\n",
            "Training loss (for one batch) at step 11510: 0.0474\n",
            "Seen so far: 368352 samples\n",
            "0.9577931\n",
            "Training loss (for one batch) at step 11515: 0.0385\n",
            "Seen so far: 368512 samples\n",
            "0.95780325\n",
            "Training loss (for one batch) at step 11520: 0.0004\n",
            "Seen so far: 368672 samples\n",
            "0.95781887\n",
            "Training loss (for one batch) at step 11525: 0.0312\n",
            "Seen so far: 368832 samples\n",
            "0.9578345\n",
            "Training loss (for one batch) at step 11530: 0.1313\n",
            "Seen so far: 368992 samples\n",
            "0.9578446\n",
            "Training loss (for one batch) at step 11535: 0.0096\n",
            "Seen so far: 369152 samples\n",
            "0.95785475\n",
            "Training loss (for one batch) at step 11540: 0.1667\n",
            "Seen so far: 369312 samples\n",
            "0.9578622\n",
            "Training loss (for one batch) at step 11545: 0.0437\n",
            "Seen so far: 369472 samples\n",
            "0.9578696\n",
            "Training loss (for one batch) at step 11550: 0.0087\n",
            "Seen so far: 369632 samples\n",
            "0.95788246\n",
            "Training loss (for one batch) at step 11555: 0.0756\n",
            "Seen so far: 369792 samples\n",
            "0.9578953\n",
            "Training loss (for one batch) at step 11560: 0.0045\n",
            "Seen so far: 369952 samples\n",
            "0.95790535\n",
            "Training loss (for one batch) at step 11565: 0.1097\n",
            "Seen so far: 370112 samples\n",
            "0.95791817\n",
            "Training loss (for one batch) at step 11570: 0.0169\n",
            "Seen so far: 370272 samples\n",
            "0.95792013\n",
            "Training loss (for one batch) at step 11575: 0.0006\n",
            "Seen so far: 370432 samples\n",
            "0.9579356\n",
            "Training loss (for one batch) at step 11580: 0.1023\n",
            "Seen so far: 370592 samples\n",
            "0.95794564\n",
            "Training loss (for one batch) at step 11585: 0.0019\n",
            "Seen so far: 370752 samples\n",
            "0.9579584\n",
            "Training loss (for one batch) at step 11590: 0.2117\n",
            "Seen so far: 370912 samples\n",
            "0.9579685\n",
            "Training loss (for one batch) at step 11595: 0.0069\n",
            "Seen so far: 371072 samples\n",
            "0.9579839\n",
            "Training loss (for one batch) at step 11600: 0.0292\n",
            "Seen so far: 371232 samples\n",
            "0.9579966\n",
            "Training loss (for one batch) at step 11605: 0.0672\n",
            "Seen so far: 371392 samples\n",
            "0.9580066\n",
            "Training loss (for one batch) at step 11610: 0.0041\n",
            "Seen so far: 371552 samples\n",
            "0.958022\n",
            "Training loss (for one batch) at step 11615: 0.0050\n",
            "Seen so far: 371712 samples\n",
            "0.9580401\n",
            "Training loss (for one batch) at step 11620: 0.0039\n",
            "Seen so far: 371872 samples\n",
            "0.95805544\n",
            "Training loss (for one batch) at step 11625: 0.0101\n",
            "Seen so far: 372032 samples\n",
            "0.95806813\n",
            "Training loss (for one batch) at step 11630: 0.1227\n",
            "Seen so far: 372192 samples\n",
            "0.95808077\n",
            "Training loss (for one batch) at step 11635: 0.0122\n",
            "Seen so far: 372352 samples\n",
            "0.9580961\n",
            "Training loss (for one batch) at step 11640: 0.0150\n",
            "Seen so far: 372512 samples\n",
            "0.9581087\n",
            "Training loss (for one batch) at step 11645: 0.0007\n",
            "Seen so far: 372672 samples\n",
            "0.95812404\n",
            "Training loss (for one batch) at step 11650: 0.0002\n",
            "Seen so far: 372832 samples\n",
            "0.95813125\n",
            "Training loss (for one batch) at step 11655: 0.0077\n",
            "Seen so far: 372992 samples\n",
            "0.9581439\n",
            "Training loss (for one batch) at step 11660: 0.0003\n",
            "Seen so far: 373152 samples\n",
            "0.9581538\n",
            "Training loss (for one batch) at step 11665: 0.0004\n",
            "Seen so far: 373312 samples\n",
            "0.9581637\n",
            "Training loss (for one batch) at step 11670: 0.0947\n",
            "Seen so far: 373472 samples\n",
            "0.9581736\n",
            "Training loss (for one batch) at step 11675: 0.0007\n",
            "Seen so far: 373632 samples\n",
            "0.95818883\n",
            "Training loss (for one batch) at step 11680: 0.0056\n",
            "Seen so far: 373792 samples\n",
            "0.95820403\n",
            "Training loss (for one batch) at step 11685: 0.3075\n",
            "Seen so far: 373952 samples\n",
            "0.95821387\n",
            "Training loss (for one batch) at step 11690: 0.0002\n",
            "Seen so far: 374112 samples\n",
            "0.95822644\n",
            "Training loss (for one batch) at step 11695: 0.1033\n",
            "Seen so far: 374272 samples\n",
            "0.9582389\n",
            "Training loss (for one batch) at step 11700: 0.0008\n",
            "Seen so far: 374432 samples\n",
            "0.9582514\n",
            "Training loss (for one batch) at step 11705: 0.0438\n",
            "Seen so far: 374592 samples\n",
            "0.95826393\n",
            "Training loss (for one batch) at step 11710: 0.0023\n",
            "Seen so far: 374752 samples\n",
            "0.95828176\n",
            "Training loss (for one batch) at step 11715: 0.0283\n",
            "Seen so far: 374912 samples\n",
            "0.9582969\n",
            "Training loss (for one batch) at step 11720: 0.0159\n",
            "Seen so far: 375072 samples\n",
            "0.958312\n",
            "Training loss (for one batch) at step 11725: 0.0084\n",
            "Seen so far: 375232 samples\n",
            "0.9583271\n",
            "Training loss (for one batch) at step 11730: 0.0999\n",
            "Seen so far: 375392 samples\n",
            "0.9583396\n",
            "Training loss (for one batch) at step 11735: 0.0039\n",
            "Seen so far: 375552 samples\n",
            "0.95835197\n",
            "Training loss (for one batch) at step 11740: 0.0653\n",
            "Seen so far: 375712 samples\n",
            "0.95836437\n",
            "Training loss (for one batch) at step 11745: 0.0569\n",
            "Seen so far: 375872 samples\n",
            "0.95837945\n",
            "Training loss (for one batch) at step 11750: 0.0643\n",
            "Seen so far: 376032 samples\n",
            "0.95838916\n",
            "Training loss (for one batch) at step 11755: 0.1077\n",
            "Seen so far: 376192 samples\n",
            "0.95839095\n",
            "Training loss (for one batch) at step 11760: 0.0081\n",
            "Seen so far: 376352 samples\n",
            "0.95840067\n",
            "Training loss (for one batch) at step 11765: 0.1127\n",
            "Seen so far: 376512 samples\n",
            "0.9584157\n",
            "Training loss (for one batch) at step 11770: 0.1135\n",
            "Seen so far: 376672 samples\n",
            "0.95843065\n",
            "Training loss (for one batch) at step 11775: 0.1221\n",
            "Seen so far: 376832 samples\n",
            "0.95844036\n",
            "Training loss (for one batch) at step 11780: 0.0010\n",
            "Seen so far: 376992 samples\n",
            "0.9584527\n",
            "Training loss (for one batch) at step 11785: 0.0116\n",
            "Seen so far: 377152 samples\n",
            "0.95846766\n",
            "Training loss (for one batch) at step 11790: 0.0011\n",
            "Seen so far: 377312 samples\n",
            "0.9584853\n",
            "Training loss (for one batch) at step 11795: 0.1239\n",
            "Seen so far: 377472 samples\n",
            "0.95849496\n",
            "Training loss (for one batch) at step 11800: 0.0211\n",
            "Seen so far: 377632 samples\n",
            "0.95850724\n",
            "Training loss (for one batch) at step 11805: 0.0048\n",
            "Seen so far: 377792 samples\n",
            "0.9585195\n",
            "Training loss (for one batch) at step 11810: 0.0256\n",
            "Seen so far: 377952 samples\n",
            "0.9585344\n",
            "Training loss (for one batch) at step 11815: 0.0195\n",
            "Seen so far: 378112 samples\n",
            "0.9585493\n",
            "Training loss (for one batch) at step 11820: 0.0014\n",
            "Seen so far: 378272 samples\n",
            "0.95856154\n",
            "Training loss (for one batch) at step 11825: 0.0138\n",
            "Seen so far: 378432 samples\n",
            "0.95857644\n",
            "Training loss (for one batch) at step 11830: 0.1485\n",
            "Seen so far: 378592 samples\n",
            "0.95858604\n",
            "Training loss (for one batch) at step 11835: 0.1439\n",
            "Seen so far: 378752 samples\n",
            "0.9585956\n",
            "Training loss (for one batch) at step 11840: 0.0003\n",
            "Seen so far: 378912 samples\n",
            "0.9586052\n",
            "Training loss (for one batch) at step 11845: 0.0015\n",
            "Seen so far: 379072 samples\n",
            "0.9586121\n",
            "Training loss (for one batch) at step 11850: 0.0113\n",
            "Seen so far: 379232 samples\n",
            "0.9586269\n",
            "Training loss (for one batch) at step 11855: 0.0008\n",
            "Seen so far: 379392 samples\n",
            "0.95863384\n",
            "Training loss (for one batch) at step 11860: 0.0060\n",
            "Seen so far: 379552 samples\n",
            "0.9586486\n",
            "Training loss (for one batch) at step 11865: 0.0420\n",
            "Seen so far: 379712 samples\n",
            "0.95865554\n",
            "Training loss (for one batch) at step 11870: 0.1694\n",
            "Seen so far: 379872 samples\n",
            "0.958665\n",
            "Training loss (for one batch) at step 11875: 0.0043\n",
            "Seen so far: 380032 samples\n",
            "0.9586798\n",
            "Training loss (for one batch) at step 11880: 0.1986\n",
            "Seen so far: 380192 samples\n",
            "0.9586788\n",
            "Training loss (for one batch) at step 11885: 0.0764\n",
            "Seen so far: 380352 samples\n",
            "0.95868826\n",
            "Training loss (for one batch) at step 11890: 0.0016\n",
            "Seen so far: 380512 samples\n",
            "0.95869774\n",
            "Training loss (for one batch) at step 11895: 0.2364\n",
            "Seen so far: 380672 samples\n",
            "0.9586967\n",
            "Training loss (for one batch) at step 11900: 0.0030\n",
            "Seen so far: 380832 samples\n",
            "0.95871145\n",
            "Training loss (for one batch) at step 11905: 0.0596\n",
            "Seen so far: 380992 samples\n",
            "0.95872355\n",
            "Training loss (for one batch) at step 11910: 0.0077\n",
            "Seen so far: 381152 samples\n",
            "0.9587304\n",
            "Training loss (for one batch) at step 11915: 0.2558\n",
            "Seen so far: 381312 samples\n",
            "0.9587398\n",
            "Training loss (for one batch) at step 11920: 0.0491\n",
            "Seen so far: 381472 samples\n",
            "0.9587467\n",
            "Training loss (for one batch) at step 11925: 0.0037\n",
            "Seen so far: 381632 samples\n",
            "0.9587587\n",
            "Training loss (for one batch) at step 11930: 0.0001\n",
            "Seen so far: 381792 samples\n",
            "0.95877075\n",
            "Training loss (for one batch) at step 11935: 0.0656\n",
            "Seen so far: 381952 samples\n",
            "0.9587749\n",
            "Training loss (for one batch) at step 11940: 0.0151\n",
            "Seen so far: 382112 samples\n",
            "0.9587896\n",
            "Training loss (for one batch) at step 11945: 0.0103\n",
            "Seen so far: 382272 samples\n",
            "0.95880157\n",
            "Training loss (for one batch) at step 11950: 0.0796\n",
            "Seen so far: 382432 samples\n",
            "0.95880836\n",
            "Training loss (for one batch) at step 11955: 0.0325\n",
            "Seen so far: 382592 samples\n",
            "0.95882034\n",
            "Training loss (for one batch) at step 11960: 0.1328\n",
            "Seen so far: 382752 samples\n",
            "0.95882714\n",
            "Training loss (for one batch) at step 11965: 0.0071\n",
            "Seen so far: 382912 samples\n",
            "0.9588339\n",
            "Training loss (for one batch) at step 11970: 0.0035\n",
            "Seen so far: 383072 samples\n",
            "0.9588511\n",
            "Training loss (for one batch) at step 11975: 0.0148\n",
            "Seen so far: 383232 samples\n",
            "0.95886564\n",
            "Training loss (for one batch) at step 11980: 0.0320\n",
            "Seen so far: 383392 samples\n",
            "0.958875\n",
            "Training loss (for one batch) at step 11985: 0.0285\n",
            "Seen so far: 383552 samples\n",
            "0.9588843\n",
            "Training loss (for one batch) at step 11990: 0.0450\n",
            "Seen so far: 383712 samples\n",
            "0.9588963\n",
            "Training loss (for one batch) at step 11995: 0.1284\n",
            "Seen so far: 383872 samples\n",
            "0.9589082\n",
            "Training loss (for one batch) at step 12000: 0.1388\n",
            "Seen so far: 384032 samples\n",
            "0.95892006\n",
            "Training loss (for one batch) at step 12005: 0.0258\n",
            "Seen so far: 384192 samples\n",
            "0.95892936\n",
            "Training loss (for one batch) at step 12010: 0.0387\n",
            "Seen so far: 384352 samples\n",
            "0.9589413\n",
            "Training loss (for one batch) at step 12015: 0.0206\n",
            "Seen so far: 384512 samples\n",
            "0.9589584\n",
            "Training loss (for one batch) at step 12020: 0.0021\n",
            "Seen so far: 384672 samples\n",
            "0.9589676\n",
            "Training loss (for one batch) at step 12025: 0.0233\n",
            "Seen so far: 384832 samples\n",
            "0.9589821\n",
            "Training loss (for one batch) at step 12030: 0.0162\n",
            "Seen so far: 384992 samples\n",
            "0.95899135\n",
            "Training loss (for one batch) at step 12035: 0.1950\n",
            "Seen so far: 385152 samples\n",
            "0.9590006\n",
            "Training loss (for one batch) at step 12040: 0.0002\n",
            "Seen so far: 385312 samples\n",
            "0.95900726\n",
            "Training loss (for one batch) at step 12045: 0.0002\n",
            "Seen so far: 385472 samples\n",
            "0.9590087\n",
            "Training loss (for one batch) at step 12050: 0.1056\n",
            "Seen so far: 385632 samples\n",
            "0.9590205\n",
            "Training loss (for one batch) at step 12055: 0.0050\n",
            "Seen so far: 385792 samples\n",
            "0.95902455\n",
            "Training loss (for one batch) at step 12060: 0.0019\n",
            "Seen so far: 385952 samples\n",
            "0.9590338\n",
            "Training loss (for one batch) at step 12065: 0.0429\n",
            "Seen so far: 386112 samples\n",
            "0.95904297\n",
            "Training loss (for one batch) at step 12070: 0.0085\n",
            "Seen so far: 386272 samples\n",
            "0.95905477\n",
            "Training loss (for one batch) at step 12075: 0.1197\n",
            "Seen so far: 386432 samples\n",
            "0.9590614\n",
            "Training loss (for one batch) at step 12080: 0.0600\n",
            "Seen so far: 386592 samples\n",
            "0.9590731\n",
            "Training loss (for one batch) at step 12085: 0.0265\n",
            "Seen so far: 386752 samples\n",
            "0.95908487\n",
            "Training loss (for one batch) at step 12090: 0.1523\n",
            "Seen so far: 386912 samples\n",
            "0.95909405\n",
            "Training loss (for one batch) at step 12095: 0.0311\n",
            "Seen so far: 387072 samples\n",
            "0.9591058\n",
            "Training loss (for one batch) at step 12100: 0.0207\n",
            "Seen so far: 387232 samples\n",
            "0.95911235\n",
            "Training loss (for one batch) at step 12105: 0.3585\n",
            "Seen so far: 387392 samples\n",
            "0.9591189\n",
            "Training loss (for one batch) at step 12110: 0.0141\n",
            "Seen so far: 387552 samples\n",
            "0.9591281\n",
            "Training loss (for one batch) at step 12115: 0.0376\n",
            "Seen so far: 387712 samples\n",
            "0.95913976\n",
            "Training loss (for one batch) at step 12120: 0.0190\n",
            "Seen so far: 387872 samples\n",
            "0.9591489\n",
            "Training loss (for one batch) at step 12125: 0.0347\n",
            "Seen so far: 388032 samples\n",
            "0.95916057\n",
            "Training loss (for one batch) at step 12130: 0.0003\n",
            "Seen so far: 388192 samples\n",
            "0.95917225\n",
            "Training loss (for one batch) at step 12135: 0.0314\n",
            "Seen so far: 388352 samples\n",
            "0.95918137\n",
            "Training loss (for one batch) at step 12140: 0.0216\n",
            "Seen so far: 388512 samples\n",
            "0.9591853\n",
            "Training loss (for one batch) at step 12145: 0.0697\n",
            "Seen so far: 388672 samples\n",
            "0.95918924\n",
            "Training loss (for one batch) at step 12150: 0.0348\n",
            "Seen so far: 388832 samples\n",
            "0.95918286\n",
            "Training loss (for one batch) at step 12155: 0.2001\n",
            "Seen so far: 388992 samples\n",
            "0.9591868\n",
            "Training loss (for one batch) at step 12160: 0.0102\n",
            "Seen so far: 389152 samples\n",
            "0.95918816\n",
            "Training loss (for one batch) at step 12165: 0.0033\n",
            "Seen so far: 389312 samples\n",
            "0.9591793\n",
            "Training loss (for one batch) at step 12170: 0.0050\n",
            "Seen so far: 389472 samples\n",
            "0.9591909\n",
            "Training loss (for one batch) at step 12175: 0.0068\n",
            "Seen so far: 389632 samples\n",
            "0.95919484\n",
            "Training loss (for one batch) at step 12180: 0.0203\n",
            "Seen so far: 389792 samples\n",
            "0.95919365\n",
            "Training loss (for one batch) at step 12185: 0.0467\n",
            "Seen so far: 389952 samples\n",
            "0.9592052\n",
            "Training loss (for one batch) at step 12190: 0.0792\n",
            "Seen so far: 390112 samples\n",
            "0.9592066\n",
            "Training loss (for one batch) at step 12195: 0.3955\n",
            "Seen so far: 390272 samples\n",
            "0.9592131\n",
            "Training loss (for one batch) at step 12200: 0.0043\n",
            "Seen so far: 390432 samples\n",
            "0.9592272\n",
            "Training loss (for one batch) at step 12205: 0.0755\n",
            "Seen so far: 390592 samples\n",
            "0.959226\n",
            "Training loss (for one batch) at step 12210: 0.0061\n",
            "Seen so far: 390752 samples\n",
            "0.95923245\n",
            "Training loss (for one batch) at step 12215: 0.1078\n",
            "Seen so far: 390912 samples\n",
            "0.9592389\n",
            "Training loss (for one batch) at step 12220: 0.0372\n",
            "Seen so far: 391072 samples\n",
            "0.9592428\n",
            "Training loss (for one batch) at step 12225: 0.0323\n",
            "Seen so far: 391232 samples\n",
            "0.95925945\n",
            "Training loss (for one batch) at step 12230: 0.0587\n",
            "Seen so far: 391392 samples\n",
            "0.95926845\n",
            "Training loss (for one batch) at step 12235: 0.0072\n",
            "Seen so far: 391552 samples\n",
            "0.9592826\n",
            "Training loss (for one batch) at step 12240: 0.0140\n",
            "Seen so far: 391712 samples\n",
            "0.9592915\n",
            "Training loss (for one batch) at step 12245: 0.0017\n",
            "Seen so far: 391872 samples\n",
            "0.9592928\n",
            "Training loss (for one batch) at step 12250: 0.0183\n",
            "Seen so far: 392032 samples\n",
            "0.95930433\n",
            "Training loss (for one batch) at step 12255: 0.0006\n",
            "Seen so far: 392192 samples\n",
            "0.95931077\n",
            "Training loss (for one batch) at step 12260: 0.1309\n",
            "Seen so far: 392352 samples\n",
            "0.9593197\n",
            "Training loss (for one batch) at step 12265: 0.0117\n",
            "Seen so far: 392512 samples\n",
            "0.9593337\n",
            "Training loss (for one batch) at step 12270: 0.0314\n",
            "Seen so far: 392672 samples\n",
            "0.95934266\n",
            "Training loss (for one batch) at step 12275: 0.3679\n",
            "Seen so far: 392832 samples\n",
            "0.95934397\n",
            "Training loss (for one batch) at step 12280: 0.0003\n",
            "Seen so far: 392992 samples\n",
            "0.9593554\n",
            "Training loss (for one batch) at step 12285: 0.0111\n",
            "Seen so far: 393152 samples\n",
            "0.9593643\n",
            "Training loss (for one batch) at step 12290: 0.0134\n",
            "Seen so far: 393312 samples\n",
            "0.9593707\n",
            "Training loss (for one batch) at step 12295: 0.0174\n",
            "Seen so far: 393472 samples\n",
            "0.9593821\n",
            "Training loss (for one batch) at step 12300: 0.0093\n",
            "Seen so far: 393632 samples\n",
            "0.95938337\n",
            "Training loss (for one batch) at step 12305: 0.0867\n",
            "Seen so far: 393792 samples\n",
            "0.95939225\n",
            "Training loss (for one batch) at step 12310: 0.0748\n",
            "Seen so far: 393952 samples\n",
            "0.9594037\n",
            "Training loss (for one batch) at step 12315: 0.0281\n",
            "Seen so far: 394112 samples\n",
            "0.95941764\n",
            "Training loss (for one batch) at step 12320: 0.0039\n",
            "Seen so far: 394272 samples\n",
            "0.9594316\n",
            "Training loss (for one batch) at step 12325: 0.0850\n",
            "Seen so far: 394432 samples\n",
            "0.959443\n",
            "Training loss (for one batch) at step 12330: 0.0330\n",
            "Seen so far: 394592 samples\n",
            "0.9594467\n",
            "Training loss (for one batch) at step 12335: 0.0232\n",
            "Seen so far: 394752 samples\n",
            "0.95945305\n",
            "Training loss (for one batch) at step 12340: 0.0091\n",
            "Seen so far: 394912 samples\n",
            "0.95946187\n",
            "Training loss (for one batch) at step 12345: 0.0217\n",
            "Seen so far: 395072 samples\n",
            "0.9594732\n",
            "Training loss (for one batch) at step 12350: 0.0254\n",
            "Seen so far: 395232 samples\n",
            "0.9594871\n",
            "Training loss (for one batch) at step 12355: 0.0657\n",
            "Seen so far: 395392 samples\n",
            "0.95949334\n",
            "Training loss (for one batch) at step 12360: 0.0006\n",
            "Seen so far: 395552 samples\n",
            "0.95950216\n",
            "Training loss (for one batch) at step 12365: 0.0881\n",
            "Seen so far: 395712 samples\n",
            "0.9595059\n",
            "Training loss (for one batch) at step 12370: 0.0006\n",
            "Seen so far: 395872 samples\n",
            "0.9595122\n",
            "Training loss (for one batch) at step 12375: 0.0040\n",
            "Seen so far: 396032 samples\n",
            "0.9595285\n",
            "Training loss (for one batch) at step 12380: 0.0035\n",
            "Seen so far: 396192 samples\n",
            "0.95954233\n",
            "Training loss (for one batch) at step 12385: 0.0774\n",
            "Seen so far: 396352 samples\n",
            "0.9595461\n",
            "Training loss (for one batch) at step 12390: 0.0006\n",
            "Seen so far: 396512 samples\n",
            "0.95955986\n",
            "Training loss (for one batch) at step 12395: 0.0042\n",
            "Seen so far: 396672 samples\n",
            "0.95956355\n",
            "Training loss (for one batch) at step 12400: 0.0220\n",
            "Seen so far: 396832 samples\n",
            "0.9595774\n",
            "Training loss (for one batch) at step 12405: 0.0043\n",
            "Seen so far: 396992 samples\n",
            "0.9595886\n",
            "Training loss (for one batch) at step 12410: 0.0822\n",
            "Seen so far: 397152 samples\n",
            "0.95959735\n",
            "Training loss (for one batch) at step 12415: 0.0010\n",
            "Seen so far: 397312 samples\n",
            "0.95960104\n",
            "Training loss (for one batch) at step 12420: 0.0651\n",
            "Seen so far: 397472 samples\n",
            "0.95961225\n",
            "Training loss (for one batch) at step 12425: 0.0158\n",
            "Seen so far: 397632 samples\n",
            "0.9596285\n",
            "Training loss (for one batch) at step 12430: 0.0006\n",
            "Seen so far: 397792 samples\n",
            "0.95964223\n",
            "Training loss (for one batch) at step 12435: 0.0089\n",
            "Seen so far: 397952 samples\n",
            "0.95965844\n",
            "Training loss (for one batch) at step 12440: 0.1369\n",
            "Seen so far: 398112 samples\n",
            "0.95966965\n",
            "Training loss (for one batch) at step 12445: 0.0573\n",
            "Seen so far: 398272 samples\n",
            "0.9596758\n",
            "Training loss (for one batch) at step 12450: 0.1680\n",
            "Seen so far: 398432 samples\n",
            "0.9596845\n",
            "Training loss (for one batch) at step 12455: 0.1873\n",
            "Seen so far: 398592 samples\n",
            "0.95969313\n",
            "Training loss (for one batch) at step 12460: 0.0014\n",
            "Seen so far: 398752 samples\n",
            "0.9597068\n",
            "Training loss (for one batch) at step 12465: 0.0023\n",
            "Seen so far: 398912 samples\n",
            "0.9597154\n",
            "Training loss (for one batch) at step 12470: 0.0135\n",
            "Seen so far: 399072 samples\n",
            "0.9597291\n",
            "Training loss (for one batch) at step 12475: 0.0291\n",
            "Seen so far: 399232 samples\n",
            "0.9597352\n",
            "Training loss (for one batch) at step 12480: 0.0288\n",
            "Seen so far: 399392 samples\n",
            "0.9597363\n",
            "Training loss (for one batch) at step 12485: 0.0065\n",
            "Seen so far: 399552 samples\n",
            "0.9597399\n",
            "Training loss (for one batch) at step 12490: 0.1060\n",
            "Seen so far: 399712 samples\n",
            "0.9597435\n",
            "Training loss (for one batch) at step 12495: 0.0214\n",
            "Seen so far: 399872 samples\n",
            "0.95975465\n",
            "Training loss (for one batch) at step 12500: 0.0199\n",
            "Seen so far: 400032 samples\n",
            "0.95976573\n",
            "Training loss (for one batch) at step 12505: 0.4413\n",
            "Seen so far: 400192 samples\n",
            "0.9597743\n",
            "Training loss (for one batch) at step 12510: 0.0790\n",
            "Seen so far: 400352 samples\n",
            "0.9597829\n",
            "Training loss (for one batch) at step 12515: 0.0229\n",
            "Seen so far: 400512 samples\n",
            "0.959794\n",
            "Training loss (for one batch) at step 12520: 0.0108\n",
            "Seen so far: 400672 samples\n",
            "0.95979756\n",
            "Training loss (for one batch) at step 12525: 0.0299\n",
            "Seen so far: 400832 samples\n",
            "0.9598111\n",
            "Training loss (for one batch) at step 12530: 0.0572\n",
            "Seen so far: 400992 samples\n",
            "0.9598197\n",
            "Training loss (for one batch) at step 12535: 0.0177\n",
            "Seen so far: 401152 samples\n",
            "0.9598332\n",
            "Training loss (for one batch) at step 12540: 0.0305\n",
            "Seen so far: 401312 samples\n",
            "0.9598417\n",
            "Training loss (for one batch) at step 12545: 0.0119\n",
            "Seen so far: 401472 samples\n",
            "0.9598577\n",
            "Training loss (for one batch) at step 12550: 0.0007\n",
            "Seen so far: 401632 samples\n",
            "0.95987123\n",
            "Training loss (for one batch) at step 12555: 0.0008\n",
            "Seen so far: 401792 samples\n",
            "0.95987976\n",
            "Training loss (for one batch) at step 12560: 0.0244\n",
            "Seen so far: 401952 samples\n",
            "0.95989573\n",
            "Training loss (for one batch) at step 12565: 0.0262\n",
            "Seen so far: 402112 samples\n",
            "0.95991164\n",
            "Training loss (for one batch) at step 12570: 0.0112\n",
            "Seen so far: 402272 samples\n",
            "0.95992017\n",
            "Training loss (for one batch) at step 12575: 0.0015\n",
            "Seen so far: 402432 samples\n",
            "0.95993114\n",
            "Training loss (for one batch) at step 12580: 0.0403\n",
            "Seen so far: 402592 samples\n",
            "0.95994455\n",
            "Training loss (for one batch) at step 12585: 0.0003\n",
            "Seen so far: 402752 samples\n",
            "0.959953\n",
            "Training loss (for one batch) at step 12590: 0.0234\n",
            "Seen so far: 402912 samples\n",
            "0.9599664\n",
            "Training loss (for one batch) at step 12595: 0.0052\n",
            "Seen so far: 403072 samples\n",
            "0.9599774\n",
            "Training loss (for one batch) at step 12600: 0.0006\n",
            "Seen so far: 403232 samples\n",
            "0.9599883\n",
            "Training loss (for one batch) at step 12605: 0.0697\n",
            "Seen so far: 403392 samples\n",
            "0.9599967\n",
            "Training loss (for one batch) at step 12610: 0.0508\n",
            "Seen so far: 403552 samples\n",
            "0.96000266\n",
            "Training loss (for one batch) at step 12615: 0.0010\n",
            "Seen so far: 403712 samples\n",
            "0.96001357\n",
            "Training loss (for one batch) at step 12620: 0.0018\n",
            "Seen so far: 403872 samples\n",
            "0.9600245\n",
            "Training loss (for one batch) at step 12625: 0.0404\n",
            "Seen so far: 404032 samples\n",
            "0.9600329\n",
            "Training loss (for one batch) at step 12630: 0.0323\n",
            "Seen so far: 404192 samples\n",
            "0.9600487\n",
            "Training loss (for one batch) at step 12635: 0.1791\n",
            "Seen so far: 404352 samples\n",
            "0.9600595\n",
            "Training loss (for one batch) at step 12640: 0.0007\n",
            "Seen so far: 404512 samples\n",
            "0.9600729\n",
            "Training loss (for one batch) at step 12645: 0.0167\n",
            "Seen so far: 404672 samples\n",
            "0.9600887\n",
            "Training loss (for one batch) at step 12650: 0.0614\n",
            "Seen so far: 404832 samples\n",
            "0.96010196\n",
            "Training loss (for one batch) at step 12655: 0.0147\n",
            "Seen so far: 404992 samples\n",
            "0.96011525\n",
            "Training loss (for one batch) at step 12660: 0.0003\n",
            "Seen so far: 405152 samples\n",
            "0.96012855\n",
            "Training loss (for one batch) at step 12665: 0.0014\n",
            "Seen so far: 405312 samples\n",
            "0.96013933\n",
            "Training loss (for one batch) at step 12670: 0.0119\n",
            "Seen so far: 405472 samples\n",
            "0.9601477\n",
            "Training loss (for one batch) at step 12675: 0.0008\n",
            "Seen so far: 405632 samples\n",
            "0.96015847\n",
            "Training loss (for one batch) at step 12680: 0.0148\n",
            "Seen so far: 405792 samples\n",
            "0.9601717\n",
            "Training loss (for one batch) at step 12685: 0.0055\n",
            "Seen so far: 405952 samples\n",
            "0.96018004\n",
            "Training loss (for one batch) at step 12690: 0.0172\n",
            "Seen so far: 406112 samples\n",
            "0.9601957\n",
            "Training loss (for one batch) at step 12695: 0.0144\n",
            "Seen so far: 406272 samples\n",
            "0.96020895\n",
            "Training loss (for one batch) at step 12700: 0.0100\n",
            "Seen so far: 406432 samples\n",
            "0.96022457\n",
            "Training loss (for one batch) at step 12705: 0.0162\n",
            "Seen so far: 406592 samples\n",
            "0.9602378\n",
            "Training loss (for one batch) at step 12710: 0.0054\n",
            "Seen so far: 406752 samples\n",
            "0.96024853\n",
            "Training loss (for one batch) at step 12715: 0.0004\n",
            "Seen so far: 406912 samples\n",
            "0.9602617\n",
            "Training loss (for one batch) at step 12720: 0.0025\n",
            "Seen so far: 407072 samples\n",
            "0.9602724\n",
            "Training loss (for one batch) at step 12725: 0.0077\n",
            "Seen so far: 407232 samples\n",
            "0.960288\n",
            "Training loss (for one batch) at step 12730: 0.0011\n",
            "Seen so far: 407392 samples\n",
            "0.9602913\n",
            "Training loss (for one batch) at step 12735: 0.0066\n",
            "Seen so far: 407552 samples\n",
            "0.960302\n",
            "Training loss (for one batch) at step 12740: 0.0255\n",
            "Seen so far: 407712 samples\n",
            "0.9603151\n",
            "Training loss (for one batch) at step 12745: 0.2268\n",
            "Seen so far: 407872 samples\n",
            "0.9603258\n",
            "Training loss (for one batch) at step 12750: 0.0020\n",
            "Seen so far: 408032 samples\n",
            "0.96033645\n",
            "Training loss (for one batch) at step 12755: 0.0004\n",
            "Seen so far: 408192 samples\n",
            "0.960352\n",
            "Training loss (for one batch) at step 12760: 0.0362\n",
            "Seen so far: 408352 samples\n",
            "0.96036017\n",
            "Training loss (for one batch) at step 12765: 0.0014\n",
            "Seen so far: 408512 samples\n",
            "0.9603757\n",
            "Training loss (for one batch) at step 12770: 0.0020\n",
            "Seen so far: 408672 samples\n",
            "0.9603888\n",
            "Training loss (for one batch) at step 12775: 0.0014\n",
            "Seen so far: 408832 samples\n",
            "0.96039695\n",
            "Training loss (for one batch) at step 12780: 0.0005\n",
            "Seen so far: 408992 samples\n",
            "0.96041244\n",
            "Training loss (for one batch) at step 12785: 0.1717\n",
            "Seen so far: 409152 samples\n",
            "0.96042055\n",
            "Training loss (for one batch) at step 12790: 0.0003\n",
            "Seen so far: 409312 samples\n",
            "0.9604263\n",
            "Training loss (for one batch) at step 12795: 0.0671\n",
            "Seen so far: 409472 samples\n",
            "0.96043444\n",
            "Training loss (for one batch) at step 12800: 0.0510\n",
            "Seen so far: 409632 samples\n",
            "0.96044254\n",
            "Training loss (for one batch) at step 12805: 0.0008\n",
            "Seen so far: 409792 samples\n",
            "0.96045554\n",
            "Training loss (for one batch) at step 12810: 0.1170\n",
            "Seen so far: 409952 samples\n",
            "0.96046364\n",
            "Training loss (for one batch) at step 12815: 0.0016\n",
            "Seen so far: 410112 samples\n",
            "0.9604791\n",
            "Training loss (for one batch) at step 12820: 0.0114\n",
            "Seen so far: 410272 samples\n",
            "0.96048963\n",
            "Training loss (for one batch) at step 12825: 0.1519\n",
            "Seen so far: 410432 samples\n",
            "0.9605002\n",
            "Training loss (for one batch) at step 12830: 0.0101\n",
            "Seen so far: 410592 samples\n",
            "0.96051556\n",
            "Training loss (for one batch) at step 12835: 0.0515\n",
            "Seen so far: 410752 samples\n",
            "0.96052605\n",
            "Training loss (for one batch) at step 12840: 0.0745\n",
            "Seen so far: 410912 samples\n",
            "0.960539\n",
            "Training loss (for one batch) at step 12845: 0.0001\n",
            "Seen so far: 411072 samples\n",
            "0.9605495\n",
            "Training loss (for one batch) at step 12850: 0.0236\n",
            "Seen so far: 411232 samples\n",
            "0.9605624\n",
            "Training loss (for one batch) at step 12855: 0.0043\n",
            "Seen so far: 411392 samples\n",
            "0.96057534\n",
            "Training loss (for one batch) at step 12860: 0.0012\n",
            "Seen so far: 411552 samples\n",
            "0.9605858\n",
            "Training loss (for one batch) at step 12865: 0.0003\n",
            "Seen so far: 411712 samples\n",
            "0.96058893\n",
            "Training loss (for one batch) at step 12870: 0.0120\n",
            "Seen so far: 411872 samples\n",
            "0.96060425\n",
            "Training loss (for one batch) at step 12875: 0.0094\n",
            "Seen so far: 412032 samples\n",
            "0.96061957\n",
            "Training loss (for one batch) at step 12880: 0.0190\n",
            "Seen so far: 412192 samples\n",
            "0.9606348\n",
            "Training loss (for one batch) at step 12885: 0.0435\n",
            "Seen so far: 412352 samples\n",
            "0.96064043\n",
            "Training loss (for one batch) at step 12890: 0.0022\n",
            "Seen so far: 412512 samples\n",
            "0.96065325\n",
            "Training loss (for one batch) at step 12895: 0.0011\n",
            "Seen so far: 412672 samples\n",
            "0.9606685\n",
            "Training loss (for one batch) at step 12900: 0.0243\n",
            "Seen so far: 412832 samples\n",
            "0.9606813\n",
            "Training loss (for one batch) at step 12905: 0.0083\n",
            "Seen so far: 412992 samples\n",
            "0.96069413\n",
            "Training loss (for one batch) at step 12910: 0.0200\n",
            "Seen so far: 413152 samples\n",
            "0.9607045\n",
            "Training loss (for one batch) at step 12915: 0.0001\n",
            "Seen so far: 413312 samples\n",
            "0.96071976\n",
            "Training loss (for one batch) at step 12920: 0.0065\n",
            "Seen so far: 413472 samples\n",
            "0.9607325\n",
            "Training loss (for one batch) at step 12925: 0.0001\n",
            "Seen so far: 413632 samples\n",
            "0.9607477\n",
            "Training loss (for one batch) at step 12930: 0.0029\n",
            "Seen so far: 413792 samples\n",
            "0.9607629\n",
            "Training loss (for one batch) at step 12935: 0.0022\n",
            "Seen so far: 413952 samples\n",
            "0.9607732\n",
            "Training loss (for one batch) at step 12940: 0.0183\n",
            "Seen so far: 414112 samples\n",
            "0.96078837\n",
            "Training loss (for one batch) at step 12945: 0.0078\n",
            "Seen so far: 414272 samples\n",
            "0.9608035\n",
            "Training loss (for one batch) at step 12950: 0.1437\n",
            "Seen so far: 414432 samples\n",
            "0.9608138\n",
            "Training loss (for one batch) at step 12955: 0.0035\n",
            "Seen so far: 414592 samples\n",
            "0.96082896\n",
            "Training loss (for one batch) at step 12960: 0.0084\n",
            "Seen so far: 414752 samples\n",
            "0.96084166\n",
            "Training loss (for one batch) at step 12965: 0.0011\n",
            "Seen so far: 414912 samples\n",
            "0.96085435\n",
            "Training loss (for one batch) at step 12970: 0.0101\n",
            "Seen so far: 415072 samples\n",
            "0.96086943\n",
            "Training loss (for one batch) at step 12975: 0.1340\n",
            "Seen so far: 415232 samples\n",
            "0.9608773\n",
            "Training loss (for one batch) at step 12980: 0.2342\n",
            "Seen so far: 415392 samples\n",
            "0.96088755\n",
            "Training loss (for one batch) at step 12985: 0.0057\n",
            "Seen so far: 415552 samples\n",
            "0.96090263\n",
            "Training loss (for one batch) at step 12990: 0.0011\n",
            "Seen so far: 415712 samples\n",
            "0.9609128\n",
            "Training loss (for one batch) at step 12995: 0.0030\n",
            "Seen so far: 415872 samples\n",
            "0.9609279\n",
            "Training loss (for one batch) at step 13000: 0.2007\n",
            "Seen so far: 416032 samples\n",
            "0.9609381\n",
            "Training loss (for one batch) at step 13005: 0.1425\n",
            "Seen so far: 416192 samples\n",
            "0.9609483\n",
            "Training loss (for one batch) at step 13010: 0.0121\n",
            "Seen so far: 416352 samples\n",
            "0.9609609\n",
            "Training loss (for one batch) at step 13015: 0.0178\n",
            "Seen so far: 416512 samples\n",
            "0.9609735\n",
            "Training loss (for one batch) at step 13020: 0.0355\n",
            "Seen so far: 416672 samples\n",
            "0.9609837\n",
            "Training loss (for one batch) at step 13025: 0.0660\n",
            "Seen so far: 416832 samples\n",
            "0.96098906\n",
            "Training loss (for one batch) at step 13030: 0.0031\n",
            "Seen so far: 416992 samples\n",
            "0.96099925\n",
            "Training loss (for one batch) at step 13035: 0.0235\n",
            "Seen so far: 417152 samples\n",
            "0.96100944\n",
            "Training loss (for one batch) at step 13040: 0.0285\n",
            "Seen so far: 417312 samples\n",
            "0.9610172\n",
            "Training loss (for one batch) at step 13045: 0.0029\n",
            "Seen so far: 417472 samples\n",
            "0.9610273\n",
            "Training loss (for one batch) at step 13050: 0.0009\n",
            "Seen so far: 417632 samples\n",
            "0.96103984\n",
            "Training loss (for one batch) at step 13055: 0.0005\n",
            "Seen so far: 417792 samples\n",
            "0.96105\n",
            "Training loss (for one batch) at step 13060: 0.0255\n",
            "Seen so far: 417952 samples\n",
            "0.9610577\n",
            "Training loss (for one batch) at step 13065: 0.0622\n",
            "Seen so far: 418112 samples\n",
            "0.96107024\n",
            "Training loss (for one batch) at step 13070: 0.1596\n",
            "Seen so far: 418272 samples\n",
            "0.9610708\n",
            "Training loss (for one batch) at step 13075: 0.0633\n",
            "Seen so far: 418432 samples\n",
            "0.9610689\n",
            "Training loss (for one batch) at step 13080: 0.1432\n",
            "Seen so far: 418592 samples\n",
            "0.9610719\n",
            "Training loss (for one batch) at step 13085: 0.2123\n",
            "Seen so far: 418752 samples\n",
            "0.9610772\n",
            "Training loss (for one batch) at step 13090: 0.5900\n",
            "Seen so far: 418912 samples\n",
            "0.96107775\n",
            "Training loss (for one batch) at step 13095: 0.0186\n",
            "Seen so far: 419072 samples\n",
            "0.96108544\n",
            "Training loss (for one batch) at step 13100: 0.0308\n",
            "Seen so far: 419232 samples\n",
            "0.9610955\n",
            "Training loss (for one batch) at step 13105: 0.0206\n",
            "Seen so far: 419392 samples\n",
            "0.9611032\n",
            "Training loss (for one batch) at step 13110: 0.0560\n",
            "Seen so far: 419552 samples\n",
            "0.9611061\n",
            "Training loss (for one batch) at step 13115: 0.0054\n",
            "Seen so far: 419712 samples\n",
            "0.9611162\n",
            "Training loss (for one batch) at step 13120: 0.0998\n",
            "Seen so far: 419872 samples\n",
            "0.96111196\n",
            "Training loss (for one batch) at step 13125: 0.2563\n",
            "Seen so far: 420032 samples\n",
            "0.96112204\n",
            "Training loss (for one batch) at step 13130: 0.0100\n",
            "Seen so far: 420192 samples\n",
            "0.96113443\n",
            "Training loss (for one batch) at step 13135: 0.3668\n",
            "Seen so far: 420352 samples\n",
            "0.96113735\n",
            "Training loss (for one batch) at step 13140: 0.0199\n",
            "Seen so far: 420512 samples\n",
            "0.96114975\n",
            "Training loss (for one batch) at step 13145: 0.0269\n",
            "Seen so far: 420672 samples\n",
            "0.9611574\n",
            "Training loss (for one batch) at step 13150: 0.0277\n",
            "Seen so far: 420832 samples\n",
            "0.9611698\n",
            "Training loss (for one batch) at step 13155: 0.2440\n",
            "Seen so far: 420992 samples\n",
            "0.961175\n",
            "Training loss (for one batch) at step 13160: 0.0395\n",
            "Seen so far: 421152 samples\n",
            "0.96118504\n",
            "Training loss (for one batch) at step 13165: 0.0099\n",
            "Seen so far: 421312 samples\n",
            "0.9611974\n",
            "Training loss (for one batch) at step 13170: 0.0061\n",
            "Seen so far: 421472 samples\n",
            "0.96121216\n",
            "Training loss (for one batch) at step 13175: 0.0005\n",
            "Seen so far: 421632 samples\n",
            "0.9612221\n",
            "Training loss (for one batch) at step 13180: 0.2121\n",
            "Seen so far: 421792 samples\n",
            "0.9612297\n",
            "Training loss (for one batch) at step 13185: 0.0152\n",
            "Seen so far: 421952 samples\n",
            "0.961242\n",
            "Training loss (for one batch) at step 13190: 0.0861\n",
            "Seen so far: 422112 samples\n",
            "0.9612449\n",
            "Training loss (for one batch) at step 13195: 0.0608\n",
            "Seen so far: 422272 samples\n",
            "0.96124774\n",
            "Training loss (for one batch) at step 13200: 0.1130\n",
            "Seen so far: 422432 samples\n",
            "0.96124345\n",
            "Training loss (for one batch) at step 13205: 0.0065\n",
            "Seen so far: 422592 samples\n",
            "0.9612487\n",
            "Training loss (for one batch) at step 13210: 0.0021\n",
            "Seen so far: 422752 samples\n",
            "0.961261\n",
            "Training loss (for one batch) at step 13215: 0.0035\n",
            "Seen so far: 422912 samples\n",
            "0.96127564\n",
            "Training loss (for one batch) at step 13220: 0.0044\n",
            "Seen so far: 423072 samples\n",
            "0.9612903\n",
            "Training loss (for one batch) at step 13225: 0.0622\n",
            "Seen so far: 423232 samples\n",
            "0.9612955\n",
            "Training loss (for one batch) at step 13230: 0.0125\n",
            "Seen so far: 423392 samples\n",
            "0.9613054\n",
            "Training loss (for one batch) at step 13235: 0.0185\n",
            "Seen so far: 423552 samples\n",
            "0.9613129\n",
            "Training loss (for one batch) at step 13240: 0.0266\n",
            "Seen so far: 423712 samples\n",
            "0.9613228\n",
            "Training loss (for one batch) at step 13245: 0.0102\n",
            "Seen so far: 423872 samples\n",
            "0.961335\n",
            "Training loss (for one batch) at step 13250: 0.0074\n",
            "Seen so far: 424032 samples\n",
            "0.9613473\n",
            "Training loss (for one batch) at step 13255: 0.0598\n",
            "Seen so far: 424192 samples\n",
            "0.9613571\n",
            "Training loss (for one batch) at step 13260: 0.0348\n",
            "Seen so far: 424352 samples\n",
            "0.9613646\n",
            "Training loss (for one batch) at step 13265: 0.0181\n",
            "Seen so far: 424512 samples\n",
            "0.96137685\n",
            "Training loss (for one batch) at step 13270: 0.0001\n",
            "Seen so far: 424672 samples\n",
            "0.9613843\n",
            "Training loss (for one batch) at step 13275: 0.0330\n",
            "Seen so far: 424832 samples\n",
            "0.9613894\n",
            "Training loss (for one batch) at step 13280: 0.0736\n",
            "Seen so far: 424992 samples\n",
            "0.96139693\n",
            "Training loss (for one batch) at step 13285: 0.0057\n",
            "Seen so far: 425152 samples\n",
            "0.9614044\n",
            "Training loss (for one batch) at step 13290: 0.0107\n",
            "Seen so far: 425312 samples\n",
            "0.9614095\n",
            "Training loss (for one batch) at step 13295: 0.4342\n",
            "Seen so far: 425472 samples\n",
            "0.96142167\n",
            "Training loss (for one batch) at step 13300: 0.0910\n",
            "Seen so far: 425632 samples\n",
            "0.9614268\n",
            "Training loss (for one batch) at step 13305: 0.1403\n",
            "Seen so far: 425792 samples\n",
            "0.96143425\n",
            "Training loss (for one batch) at step 13310: 0.0420\n",
            "Seen so far: 425952 samples\n",
            "0.9614393\n",
            "Training loss (for one batch) at step 13315: 0.2496\n",
            "Seen so far: 426112 samples\n",
            "0.96144444\n",
            "Training loss (for one batch) at step 13320: 0.0758\n",
            "Seen so far: 426272 samples\n",
            "0.9614495\n",
            "Training loss (for one batch) at step 13325: 0.0021\n",
            "Seen so far: 426432 samples\n",
            "0.9614593\n",
            "Training loss (for one batch) at step 13330: 0.0155\n",
            "Seen so far: 426592 samples\n",
            "0.96146905\n",
            "Training loss (for one batch) at step 13335: 0.0172\n",
            "Seen so far: 426752 samples\n",
            "0.96147645\n",
            "Training loss (for one batch) at step 13340: 0.1039\n",
            "Seen so far: 426912 samples\n",
            "0.96147686\n",
            "Training loss (for one batch) at step 13345: 0.0101\n",
            "Seen so far: 427072 samples\n",
            "0.9614772\n",
            "Training loss (for one batch) at step 13350: 0.0403\n",
            "Seen so far: 427232 samples\n",
            "0.9614893\n",
            "Training loss (for one batch) at step 13355: 0.0773\n",
            "Seen so far: 427392 samples\n",
            "0.9614897\n",
            "Training loss (for one batch) at step 13360: 0.1143\n",
            "Seen so far: 427552 samples\n",
            "0.96149707\n",
            "Training loss (for one batch) at step 13365: 0.0144\n",
            "Seen so far: 427712 samples\n",
            "0.96150213\n",
            "Training loss (for one batch) at step 13370: 0.0018\n",
            "Seen so far: 427872 samples\n",
            "0.9615142\n",
            "Training loss (for one batch) at step 13375: 0.0347\n",
            "Seen so far: 428032 samples\n",
            "0.96152157\n",
            "Training loss (for one batch) at step 13380: 0.0097\n",
            "Seen so far: 428192 samples\n",
            "0.9615336\n",
            "Training loss (for one batch) at step 13385: 0.0019\n",
            "Seen so far: 428352 samples\n",
            "0.9615433\n",
            "Training loss (for one batch) at step 13390: 0.1107\n",
            "Seen so far: 428512 samples\n",
            "0.9615437\n",
            "Training loss (for one batch) at step 13395: 0.0018\n",
            "Seen so far: 428672 samples\n",
            "0.96155566\n",
            "Training loss (for one batch) at step 13400: 0.0023\n",
            "Seen so far: 428832 samples\n",
            "0.961556\n",
            "Training loss (for one batch) at step 13405: 0.1779\n",
            "Seen so far: 428992 samples\n",
            "0.9615587\n",
            "Training loss (for one batch) at step 13410: 0.0290\n",
            "Seen so far: 429152 samples\n",
            "0.9615661\n",
            "Training loss (for one batch) at step 13415: 0.0015\n",
            "Seen so far: 429312 samples\n",
            "0.96156406\n",
            "Training loss (for one batch) at step 13420: 0.1306\n",
            "Seen so far: 429472 samples\n",
            "0.96156675\n",
            "Training loss (for one batch) at step 13425: 0.0960\n",
            "Seen so far: 429632 samples\n",
            "0.9615671\n",
            "Training loss (for one batch) at step 13430: 0.0479\n",
            "Seen so far: 429792 samples\n",
            "0.9615698\n",
            "Training loss (for one batch) at step 13435: 0.1191\n",
            "Seen so far: 429952 samples\n",
            "0.9615678\n",
            "Training loss (for one batch) at step 13440: 0.0331\n",
            "Seen so far: 430112 samples\n",
            "0.9615705\n",
            "Training loss (for one batch) at step 13445: 0.1219\n",
            "Seen so far: 430272 samples\n",
            "0.9615778\n",
            "Training loss (for one batch) at step 13450: 0.1108\n",
            "Seen so far: 430432 samples\n",
            "0.96157116\n",
            "Training loss (for one batch) at step 13455: 0.0970\n",
            "Seen so far: 430592 samples\n",
            "0.9615692\n",
            "Training loss (for one batch) at step 13460: 0.0895\n",
            "Seen so far: 430752 samples\n",
            "0.9615742\n",
            "Training loss (for one batch) at step 13465: 0.0384\n",
            "Seen so far: 430912 samples\n",
            "0.96157914\n",
            "Training loss (for one batch) at step 13470: 0.0064\n",
            "Seen so far: 431072 samples\n",
            "0.9615865\n",
            "Training loss (for one batch) at step 13475: 0.2135\n",
            "Seen so far: 431232 samples\n",
            "0.9615891\n",
            "Training loss (for one batch) at step 13480: 0.0140\n",
            "Seen so far: 431392 samples\n",
            "0.96159875\n",
            "Training loss (for one batch) at step 13485: 0.1246\n",
            "Seen so far: 431552 samples\n",
            "0.9616037\n",
            "Training loss (for one batch) at step 13490: 0.0210\n",
            "Seen so far: 431712 samples\n",
            "0.9616133\n",
            "Training loss (for one batch) at step 13495: 0.1537\n",
            "Seen so far: 431872 samples\n",
            "0.9616159\n",
            "Training loss (for one batch) at step 13500: 0.0045\n",
            "Seen so far: 432032 samples\n",
            "0.9616255\n",
            "Training loss (for one batch) at step 13505: 0.0178\n",
            "Seen so far: 432192 samples\n",
            "0.96163046\n",
            "Training loss (for one batch) at step 13510: 0.0759\n",
            "Seen so far: 432352 samples\n",
            "0.96163774\n",
            "Training loss (for one batch) at step 13515: 0.1213\n",
            "Seen so far: 432512 samples\n",
            "0.9616427\n",
            "Training loss (for one batch) at step 13520: 0.0754\n",
            "Seen so far: 432672 samples\n",
            "0.961643\n",
            "Training loss (for one batch) at step 13525: 0.0021\n",
            "Seen so far: 432832 samples\n",
            "0.96165717\n",
            "Training loss (for one batch) at step 13530: 0.0487\n",
            "Seen so far: 432992 samples\n",
            "0.9616621\n",
            "Training loss (for one batch) at step 13535: 0.0432\n",
            "Seen so far: 433152 samples\n",
            "0.96166474\n",
            "Training loss (for one batch) at step 13540: 0.0130\n",
            "Seen so far: 433312 samples\n",
            "0.9616766\n",
            "Training loss (for one batch) at step 13545: 0.0109\n",
            "Seen so far: 433472 samples\n",
            "0.9616838\n",
            "Training loss (for one batch) at step 13550: 0.0016\n",
            "Seen so far: 433632 samples\n",
            "0.961691\n",
            "Training loss (for one batch) at step 13555: 0.0030\n",
            "Seen so far: 433792 samples\n",
            "0.96170056\n",
            "Training loss (for one batch) at step 13560: 0.0794\n",
            "Seen so far: 433952 samples\n",
            "0.96169853\n",
            "Training loss (for one batch) at step 13565: 0.0575\n",
            "Seen so far: 434112 samples\n",
            "0.96170574\n",
            "Training loss (for one batch) at step 13570: 0.0071\n",
            "Seen so far: 434272 samples\n",
            "0.96171063\n",
            "Training loss (for one batch) at step 13575: 0.1113\n",
            "Seen so far: 434432 samples\n",
            "0.9617155\n",
            "Training loss (for one batch) at step 13580: 0.0710\n",
            "Seen so far: 434592 samples\n",
            "0.961725\n",
            "Training loss (for one batch) at step 13585: 0.0629\n",
            "Seen so far: 434752 samples\n",
            "0.9617322\n",
            "Training loss (for one batch) at step 13590: 0.0025\n",
            "Seen so far: 434912 samples\n",
            "0.9617417\n",
            "Training loss (for one batch) at step 13595: 0.0719\n",
            "Seen so far: 435072 samples\n",
            "0.961742\n",
            "Training loss (for one batch) at step 13600: 0.0942\n",
            "Seen so far: 435232 samples\n",
            "0.96174914\n",
            "Training loss (for one batch) at step 13605: 0.0053\n",
            "Seen so far: 435392 samples\n",
            "0.9617632\n",
            "Training loss (for one batch) at step 13610: 0.2124\n",
            "Seen so far: 435552 samples\n",
            "0.96177495\n",
            "Training loss (for one batch) at step 13615: 0.0007\n",
            "Seen so far: 435712 samples\n",
            "0.96178436\n",
            "Training loss (for one batch) at step 13620: 0.0003\n",
            "Seen so far: 435872 samples\n",
            "0.9617915\n",
            "Training loss (for one batch) at step 13625: 0.0029\n",
            "Seen so far: 436032 samples\n",
            "0.9617964\n",
            "Training loss (for one batch) at step 13630: 0.0011\n",
            "Seen so far: 436192 samples\n",
            "0.9618081\n",
            "Training loss (for one batch) at step 13635: 0.1005\n",
            "Seen so far: 436352 samples\n",
            "0.96181065\n",
            "Training loss (for one batch) at step 13640: 0.3588\n",
            "Seen so far: 436512 samples\n",
            "0.9618155\n",
            "Training loss (for one batch) at step 13645: 0.0011\n",
            "Seen so far: 436672 samples\n",
            "0.9618249\n",
            "Training loss (for one batch) at step 13650: 0.0019\n",
            "Seen so far: 436832 samples\n",
            "0.9618366\n",
            "Training loss (for one batch) at step 13655: 0.0042\n",
            "Seen so far: 436992 samples\n",
            "0.961846\n",
            "Training loss (for one batch) at step 13660: 0.0103\n",
            "Seen so far: 437152 samples\n",
            "0.96185994\n",
            "Training loss (for one batch) at step 13665: 0.0830\n",
            "Seen so far: 437312 samples\n",
            "0.96186703\n",
            "Training loss (for one batch) at step 13670: 0.0881\n",
            "Seen so far: 437472 samples\n",
            "0.96187186\n",
            "Training loss (for one batch) at step 13675: 0.1446\n",
            "Seen so far: 437632 samples\n",
            "0.9618812\n",
            "Training loss (for one batch) at step 13680: 0.0061\n",
            "Seen so far: 437792 samples\n",
            "0.96189284\n",
            "Training loss (for one batch) at step 13685: 0.0176\n",
            "Seen so far: 437952 samples\n",
            "0.96189994\n",
            "Training loss (for one batch) at step 13690: 0.0335\n",
            "Seen so far: 438112 samples\n",
            "0.9619002\n",
            "Training loss (for one batch) at step 13695: 0.0057\n",
            "Seen so far: 438272 samples\n",
            "0.9619118\n",
            "Training loss (for one batch) at step 13700: 0.0123\n",
            "Seen so far: 438432 samples\n",
            "0.9619234\n",
            "Training loss (for one batch) at step 13705: 0.1522\n",
            "Seen so far: 438592 samples\n",
            "0.96193045\n",
            "Training loss (for one batch) at step 13710: 0.0018\n",
            "Seen so far: 438752 samples\n",
            "0.9619375\n",
            "Training loss (for one batch) at step 13715: 0.0098\n",
            "Seen so far: 438912 samples\n",
            "0.9619445\n",
            "Training loss (for one batch) at step 13720: 0.0128\n",
            "Seen so far: 439072 samples\n",
            "0.96195614\n",
            "Training loss (for one batch) at step 13725: 0.0697\n",
            "Seen so far: 439232 samples\n",
            "0.96196085\n",
            "Training loss (for one batch) at step 13730: 0.0246\n",
            "Seen so far: 439392 samples\n",
            "0.9619725\n",
            "Training loss (for one batch) at step 13735: 0.0144\n",
            "Seen so far: 439552 samples\n",
            "0.96198404\n",
            "Training loss (for one batch) at step 13740: 0.0106\n",
            "Seen so far: 439712 samples\n",
            "0.9619956\n",
            "Training loss (for one batch) at step 13745: 0.2483\n",
            "Seen so far: 439872 samples\n",
            "0.9620026\n",
            "Training loss (for one batch) at step 13750: 0.0001\n",
            "Seen so far: 440032 samples\n",
            "0.96201414\n",
            "Training loss (for one batch) at step 13755: 0.0038\n",
            "Seen so far: 440192 samples\n",
            "0.9620279\n",
            "Training loss (for one batch) at step 13760: 0.0812\n",
            "Seen so far: 440352 samples\n",
            "0.96203494\n",
            "Training loss (for one batch) at step 13765: 0.0034\n",
            "Seen so far: 440512 samples\n",
            "0.96204644\n",
            "Training loss (for one batch) at step 13770: 0.0004\n",
            "Seen so far: 440672 samples\n",
            "0.9620557\n",
            "Training loss (for one batch) at step 13775: 0.0003\n",
            "Seen so far: 440832 samples\n",
            "0.9620604\n",
            "Training loss (for one batch) at step 13780: 0.0186\n",
            "Seen so far: 440992 samples\n",
            "0.96206737\n",
            "Training loss (for one batch) at step 13785: 0.0019\n",
            "Seen so far: 441152 samples\n",
            "0.9620788\n",
            "Training loss (for one batch) at step 13790: 0.0028\n",
            "Seen so far: 441312 samples\n",
            "0.9620903\n",
            "Training loss (for one batch) at step 13795: 0.1223\n",
            "Seen so far: 441472 samples\n",
            "0.9620972\n",
            "Training loss (for one batch) at step 13800: 0.0058\n",
            "Seen so far: 441632 samples\n",
            "0.96210647\n",
            "Training loss (for one batch) at step 13805: 0.0607\n",
            "Seen so far: 441792 samples\n",
            "0.9621134\n",
            "Training loss (for one batch) at step 13810: 0.0502\n",
            "Seen so far: 441952 samples\n",
            "0.9621203\n",
            "Training loss (for one batch) at step 13815: 0.0015\n",
            "Seen so far: 442112 samples\n",
            "0.962134\n",
            "Training loss (for one batch) at step 13820: 0.0027\n",
            "Seen so far: 442272 samples\n",
            "0.9621432\n",
            "Training loss (for one batch) at step 13825: 0.0129\n",
            "Seen so far: 442432 samples\n",
            "0.9621569\n",
            "Training loss (for one batch) at step 13830: 0.0900\n",
            "Seen so far: 442592 samples\n",
            "0.96216834\n",
            "Training loss (for one batch) at step 13835: 0.0018\n",
            "Seen so far: 442752 samples\n",
            "0.9621797\n",
            "Training loss (for one batch) at step 13840: 0.1689\n",
            "Seen so far: 442912 samples\n",
            "0.9621889\n",
            "Training loss (for one batch) at step 13845: 0.0362\n",
            "Seen so far: 443072 samples\n",
            "0.962198\n",
            "Training loss (for one batch) at step 13850: 0.0360\n",
            "Seen so far: 443232 samples\n",
            "0.96220714\n",
            "Training loss (for one batch) at step 13855: 0.0194\n",
            "Seen so far: 443392 samples\n",
            "0.96220726\n",
            "Training loss (for one batch) at step 13860: 0.2960\n",
            "Seen so far: 443552 samples\n",
            "0.9622074\n",
            "Training loss (for one batch) at step 13865: 0.0141\n",
            "Seen so far: 443712 samples\n",
            "0.96221876\n",
            "Training loss (for one batch) at step 13870: 0.1297\n",
            "Seen so far: 443872 samples\n",
            "0.96222335\n",
            "Training loss (for one batch) at step 13875: 0.3129\n",
            "Seen so far: 444032 samples\n",
            "0.9622302\n",
            "Training loss (for one batch) at step 13880: 0.0093\n",
            "Seen so far: 444192 samples\n",
            "0.9622393\n",
            "Training loss (for one batch) at step 13885: 0.2272\n",
            "Seen so far: 444352 samples\n",
            "0.9622439\n",
            "Training loss (for one batch) at step 13890: 0.0018\n",
            "Seen so far: 444512 samples\n",
            "0.9622575\n",
            "Training loss (for one batch) at step 13895: 0.0099\n",
            "Seen so far: 444672 samples\n",
            "0.96226656\n",
            "Training loss (for one batch) at step 13900: 0.0005\n",
            "Seen so far: 444832 samples\n",
            "0.9622779\n",
            "Training loss (for one batch) at step 13905: 0.0008\n",
            "Seen so far: 444992 samples\n",
            "0.9622915\n",
            "Training loss (for one batch) at step 13910: 0.0014\n",
            "Seen so far: 445152 samples\n",
            "0.962305\n",
            "Training loss (for one batch) at step 13915: 0.0021\n",
            "Seen so far: 445312 samples\n",
            "0.9623096\n",
            "Training loss (for one batch) at step 13920: 0.0009\n",
            "Seen so far: 445472 samples\n",
            "0.9623231\n",
            "Training loss (for one batch) at step 13925: 0.1385\n",
            "Seen so far: 445632 samples\n",
            "0.96232766\n",
            "Training loss (for one batch) at step 13930: 0.0516\n",
            "Seen so far: 445792 samples\n",
            "0.96233445\n",
            "Training loss (for one batch) at step 13935: 0.1657\n",
            "Seen so far: 445952 samples\n",
            "0.96234125\n",
            "Training loss (for one batch) at step 13940: 0.0073\n",
            "Seen so far: 446112 samples\n",
            "0.96234804\n",
            "Training loss (for one batch) at step 13945: 0.0220\n",
            "Seen so far: 446272 samples\n",
            "0.96235704\n",
            "Training loss (for one batch) at step 13950: 0.0007\n",
            "Seen so far: 446432 samples\n",
            "0.96236604\n",
            "Training loss (for one batch) at step 13955: 0.0301\n",
            "Seen so far: 446592 samples\n",
            "0.96237284\n",
            "Training loss (for one batch) at step 13960: 0.0208\n",
            "Seen so far: 446752 samples\n",
            "0.9623773\n",
            "Training loss (for one batch) at step 13965: 0.0149\n",
            "Seen so far: 446912 samples\n",
            "0.9623863\n",
            "Training loss (for one batch) at step 13970: 0.0791\n",
            "Seen so far: 447072 samples\n",
            "0.9623931\n",
            "Training loss (for one batch) at step 13975: 0.0153\n",
            "Seen so far: 447232 samples\n",
            "0.96240205\n",
            "Training loss (for one batch) at step 13980: 0.0028\n",
            "Seen so far: 447392 samples\n",
            "0.9624066\n",
            "Training loss (for one batch) at step 13985: 0.0026\n",
            "Seen so far: 447552 samples\n",
            "0.9624133\n",
            "Training loss (for one batch) at step 13990: 0.0702\n",
            "Seen so far: 447712 samples\n",
            "0.9624156\n",
            "Training loss (for one batch) at step 13995: 0.1205\n",
            "Seen so far: 447872 samples\n",
            "0.96242005\n",
            "Training loss (for one batch) at step 14000: 0.1285\n",
            "Seen so far: 448032 samples\n",
            "0.9624201\n",
            "Training loss (for one batch) at step 14005: 0.0071\n",
            "Seen so far: 448192 samples\n",
            "0.96243125\n",
            "Training loss (for one batch) at step 14010: 0.0234\n",
            "Seen so far: 448352 samples\n",
            "0.9624335\n",
            "Training loss (for one batch) at step 14015: 0.0019\n",
            "Seen so far: 448512 samples\n",
            "0.9624447\n",
            "Training loss (for one batch) at step 14020: 0.0357\n",
            "Seen so far: 448672 samples\n",
            "0.9624447\n",
            "Training loss (for one batch) at step 14025: 0.0899\n",
            "Seen so far: 448832 samples\n",
            "0.9624492\n",
            "Training loss (for one batch) at step 14030: 0.3690\n",
            "Seen so far: 448992 samples\n",
            "0.9624492\n",
            "Training loss (for one batch) at step 14035: 0.0237\n",
            "Seen so far: 449152 samples\n",
            "0.9624559\n",
            "Training loss (for one batch) at step 14040: 0.1091\n",
            "Seen so far: 449312 samples\n",
            "0.9624604\n",
            "Training loss (for one batch) at step 14045: 0.1648\n",
            "Seen so far: 449472 samples\n",
            "0.96246487\n",
            "Training loss (for one batch) at step 14050: 0.0048\n",
            "Seen so far: 449632 samples\n",
            "0.96246487\n",
            "Training loss (for one batch) at step 14055: 0.1498\n",
            "Seen so far: 449792 samples\n",
            "0.96246934\n",
            "Training loss (for one batch) at step 14060: 0.1228\n",
            "Seen so far: 449952 samples\n",
            "0.96246934\n",
            "Training loss (for one batch) at step 14065: 0.0303\n",
            "Seen so far: 450112 samples\n",
            "0.962476\n",
            "Training loss (for one batch) at step 14070: 0.0689\n",
            "Seen so far: 450272 samples\n",
            "0.9624827\n",
            "Training loss (for one batch) at step 14075: 0.0178\n",
            "Seen so far: 450432 samples\n",
            "0.9624916\n",
            "Training loss (for one batch) at step 14080: 0.0289\n",
            "Seen so far: 450592 samples\n",
            "0.96250045\n",
            "Training loss (for one batch) at step 14085: 0.1042\n",
            "Seen so far: 450752 samples\n",
            "0.9625071\n",
            "Training loss (for one batch) at step 14090: 0.0546\n",
            "Seen so far: 450912 samples\n",
            "0.96250707\n",
            "Training loss (for one batch) at step 14095: 0.0040\n",
            "Seen so far: 451072 samples\n",
            "0.96251374\n",
            "Training loss (for one batch) at step 14100: 0.0119\n",
            "Seen so far: 451232 samples\n",
            "0.96252483\n",
            "Training loss (for one batch) at step 14105: 0.0037\n",
            "Seen so far: 451392 samples\n",
            "0.9625359\n",
            "Training loss (for one batch) at step 14110: 0.0051\n",
            "Seen so far: 451552 samples\n",
            "0.96254253\n",
            "Training loss (for one batch) at step 14115: 0.0613\n",
            "Seen so far: 451712 samples\n",
            "0.96255356\n",
            "Training loss (for one batch) at step 14120: 0.1729\n",
            "Seen so far: 451872 samples\n",
            "0.9625602\n",
            "Training loss (for one batch) at step 14125: 0.0102\n",
            "Seen so far: 452032 samples\n",
            "0.962569\n",
            "Training loss (for one batch) at step 14130: 0.2248\n",
            "Seen so far: 452192 samples\n",
            "0.9625668\n",
            "Training loss (for one batch) at step 14135: 0.0219\n",
            "Seen so far: 452352 samples\n",
            "0.9625756\n",
            "Training loss (for one batch) at step 14140: 0.0152\n",
            "Seen so far: 452512 samples\n",
            "0.96258444\n",
            "Training loss (for one batch) at step 14145: 0.0947\n",
            "Seen so far: 452672 samples\n",
            "0.9625866\n",
            "Training loss (for one batch) at step 14150: 0.0358\n",
            "Seen so far: 452832 samples\n",
            "0.9625932\n",
            "Training loss (for one batch) at step 14155: 0.0629\n",
            "Seen so far: 452992 samples\n",
            "0.96259534\n",
            "Training loss (for one batch) at step 14160: 0.0032\n",
            "Seen so far: 453152 samples\n",
            "0.96260196\n",
            "Training loss (for one batch) at step 14165: 0.0874\n",
            "Seen so far: 453312 samples\n",
            "0.9626085\n",
            "Training loss (for one batch) at step 14170: 0.1874\n",
            "Seen so far: 453472 samples\n",
            "0.96261513\n",
            "Training loss (for one batch) at step 14175: 0.0269\n",
            "Seen so far: 453632 samples\n",
            "0.9626239\n",
            "Training loss (for one batch) at step 14180: 0.2252\n",
            "Seen so far: 453792 samples\n",
            "0.96262604\n",
            "Training loss (for one batch) at step 14185: 0.0567\n",
            "Seen so far: 453952 samples\n",
            "0.9626304\n",
            "Training loss (for one batch) at step 14190: 0.0030\n",
            "Seen so far: 454112 samples\n",
            "0.9626282\n",
            "Training loss (for one batch) at step 14195: 0.0070\n",
            "Seen so far: 454272 samples\n",
            "0.96263695\n",
            "Training loss (for one batch) at step 14200: 0.0060\n",
            "Seen so far: 454432 samples\n",
            "0.96264565\n",
            "Training loss (for one batch) at step 14205: 0.3807\n",
            "Seen so far: 454592 samples\n",
            "0.96264344\n",
            "Training loss (for one batch) at step 14210: 0.0152\n",
            "Seen so far: 454752 samples\n",
            "0.96265215\n",
            "Training loss (for one batch) at step 14215: 0.0060\n",
            "Seen so far: 454912 samples\n",
            "0.9626609\n",
            "Training loss (for one batch) at step 14220: 0.0051\n",
            "Seen so far: 455072 samples\n",
            "0.96266305\n",
            "Training loss (for one batch) at step 14225: 0.0809\n",
            "Seen so far: 455232 samples\n",
            "0.9626674\n",
            "Training loss (for one batch) at step 14230: 0.1989\n",
            "Seen so far: 455392 samples\n",
            "0.96266955\n",
            "Training loss (for one batch) at step 14235: 0.2022\n",
            "Seen so far: 455552 samples\n",
            "0.9626695\n",
            "Training loss (for one batch) at step 14240: 0.4618\n",
            "Seen so far: 455712 samples\n",
            "0.9626672\n",
            "Training loss (for one batch) at step 14245: 0.6734\n",
            "Seen so far: 455872 samples\n",
            "0.96266496\n",
            "Training loss (for one batch) at step 14250: 0.0017\n",
            "Seen so far: 456032 samples\n",
            "0.96267587\n",
            "Training loss (for one batch) at step 14255: 0.0123\n",
            "Seen so far: 456192 samples\n",
            "0.96268016\n",
            "Training loss (for one batch) at step 14260: 0.0501\n",
            "Seen so far: 456352 samples\n",
            "0.96267575\n",
            "Training loss (for one batch) at step 14265: 0.0369\n",
            "Seen so far: 456512 samples\n",
            "0.96268225\n",
            "Training loss (for one batch) at step 14270: 0.0563\n",
            "Seen so far: 456672 samples\n",
            "0.96268874\n",
            "Training loss (for one batch) at step 14275: 0.0256\n",
            "Seen so far: 456832 samples\n",
            "0.9626931\n",
            "Training loss (for one batch) at step 14280: 0.0404\n",
            "Seen so far: 456992 samples\n",
            "0.96270174\n",
            "Training loss (for one batch) at step 14285: 0.0987\n",
            "Seen so far: 457152 samples\n",
            "0.96271044\n",
            "Training loss (for one batch) at step 14290: 0.0111\n",
            "Seen so far: 457312 samples\n",
            "0.96271473\n",
            "Training loss (for one batch) at step 14295: 0.1947\n",
            "Seen so far: 457472 samples\n",
            "0.9627147\n",
            "Training loss (for one batch) at step 14300: 0.0209\n",
            "Seen so far: 457632 samples\n",
            "0.9627233\n",
            "Training loss (for one batch) at step 14305: 0.4293\n",
            "Seen so far: 457792 samples\n",
            "0.96272105\n",
            "Training loss (for one batch) at step 14310: 0.0074\n",
            "Seen so far: 457952 samples\n",
            "0.9627232\n",
            "Training loss (for one batch) at step 14315: 0.1497\n",
            "Seen so far: 458112 samples\n",
            "0.96273184\n",
            "Training loss (for one batch) at step 14320: 0.0240\n",
            "Seen so far: 458272 samples\n",
            "0.96272737\n",
            "Training loss (for one batch) at step 14325: 0.0004\n",
            "Seen so far: 458432 samples\n",
            "0.96273386\n",
            "Training loss (for one batch) at step 14330: 0.0122\n",
            "Seen so far: 458592 samples\n",
            "0.9627381\n",
            "Training loss (for one batch) at step 14335: 0.1900\n",
            "Seen so far: 458752 samples\n",
            "0.9627446\n",
            "Training loss (for one batch) at step 14340: 0.0298\n",
            "Seen so far: 458912 samples\n",
            "0.96275103\n",
            "Training loss (for one batch) at step 14345: 0.0417\n",
            "Seen so far: 459072 samples\n",
            "0.9627531\n",
            "Training loss (for one batch) at step 14350: 0.0092\n",
            "Seen so far: 459232 samples\n",
            "0.9627552\n",
            "Training loss (for one batch) at step 14355: 0.0052\n",
            "Seen so far: 459392 samples\n",
            "0.962766\n",
            "Training loss (for one batch) at step 14360: 0.0256\n",
            "Seen so far: 459552 samples\n",
            "0.9627681\n",
            "Training loss (for one batch) at step 14365: 0.0967\n",
            "Seen so far: 459712 samples\n",
            "0.96277016\n",
            "Training loss (for one batch) at step 14370: 0.0610\n",
            "Seen so far: 459872 samples\n",
            "0.96278095\n",
            "Training loss (for one batch) at step 14375: 0.0019\n",
            "Seen so far: 460032 samples\n",
            "0.96278954\n",
            "Training loss (for one batch) at step 14380: 0.0372\n",
            "Seen so far: 460192 samples\n",
            "0.96279377\n",
            "Training loss (for one batch) at step 14385: 0.0006\n",
            "Seen so far: 460352 samples\n",
            "0.96279806\n",
            "Training loss (for one batch) at step 14390: 0.1693\n",
            "Seen so far: 460512 samples\n",
            "0.96280664\n",
            "Training loss (for one batch) at step 14395: 0.0013\n",
            "Seen so far: 460672 samples\n",
            "0.962813\n",
            "Training loss (for one batch) at step 14400: 0.1181\n",
            "Seen so far: 460832 samples\n",
            "0.96282375\n",
            "Training loss (for one batch) at step 14405: 0.0344\n",
            "Seen so far: 460992 samples\n",
            "0.96283233\n",
            "Training loss (for one batch) at step 14410: 0.0042\n",
            "Seen so far: 461152 samples\n",
            "0.9628409\n",
            "Training loss (for one batch) at step 14415: 0.0222\n",
            "Seen so far: 461312 samples\n",
            "0.9628516\n",
            "Training loss (for one batch) at step 14420: 0.1267\n",
            "Seen so far: 461472 samples\n",
            "0.96286017\n",
            "Training loss (for one batch) at step 14425: 0.2166\n",
            "Seen so far: 461632 samples\n",
            "0.96286434\n",
            "Training loss (for one batch) at step 14430: 0.0252\n",
            "Seen so far: 461792 samples\n",
            "0.9628729\n",
            "Training loss (for one batch) at step 14435: 0.3283\n",
            "Seen so far: 461952 samples\n",
            "0.96287924\n",
            "Training loss (for one batch) at step 14440: 0.0190\n",
            "Seen so far: 462112 samples\n",
            "0.9628921\n",
            "Training loss (for one batch) at step 14445: 0.1314\n",
            "Seen so far: 462272 samples\n",
            "0.9628963\n",
            "Training loss (for one batch) at step 14450: 0.0294\n",
            "Seen so far: 462432 samples\n",
            "0.96290916\n",
            "Training loss (for one batch) at step 14455: 0.0014\n",
            "Seen so far: 462592 samples\n",
            "0.96291333\n",
            "Training loss (for one batch) at step 14460: 0.0232\n",
            "Seen so far: 462752 samples\n",
            "0.962924\n",
            "Training loss (for one batch) at step 14465: 0.0046\n",
            "Seen so far: 462912 samples\n",
            "0.96293247\n",
            "Training loss (for one batch) at step 14470: 0.0919\n",
            "Seen so far: 463072 samples\n",
            "0.96294314\n",
            "Training loss (for one batch) at step 14475: 0.0217\n",
            "Seen so far: 463232 samples\n",
            "0.9629473\n",
            "Training loss (for one batch) at step 14480: 0.0840\n",
            "Seen so far: 463392 samples\n",
            "0.9629515\n",
            "Training loss (for one batch) at step 14485: 0.0935\n",
            "Seen so far: 463552 samples\n",
            "0.96295774\n",
            "Training loss (for one batch) at step 14490: 0.0562\n",
            "Seen so far: 463712 samples\n",
            "0.96296406\n",
            "Training loss (for one batch) at step 14495: 0.0005\n",
            "Seen so far: 463872 samples\n",
            "0.9629769\n",
            "Training loss (for one batch) at step 14500: 0.0055\n",
            "Seen so far: 464032 samples\n",
            "0.96298313\n",
            "Training loss (for one batch) at step 14505: 0.0037\n",
            "Seen so far: 464192 samples\n",
            "0.9629916\n",
            "Training loss (for one batch) at step 14510: 0.0179\n",
            "Seen so far: 464352 samples\n",
            "0.96300006\n",
            "Training loss (for one batch) at step 14515: 0.0007\n",
            "Seen so far: 464512 samples\n",
            "0.96300846\n",
            "Training loss (for one batch) at step 14520: 0.1065\n",
            "Seen so far: 464672 samples\n",
            "0.9630169\n",
            "Training loss (for one batch) at step 14525: 0.0240\n",
            "Seen so far: 464832 samples\n",
            "0.96302533\n",
            "Training loss (for one batch) at step 14530: 0.0003\n",
            "Seen so far: 464992 samples\n",
            "0.96302944\n",
            "Training loss (for one batch) at step 14535: 0.0748\n",
            "Seen so far: 465152 samples\n",
            "0.9630379\n",
            "Training loss (for one batch) at step 14540: 0.1163\n",
            "Seen so far: 465312 samples\n",
            "0.96304417\n",
            "Training loss (for one batch) at step 14545: 0.0018\n",
            "Seen so far: 465472 samples\n",
            "0.9630504\n",
            "Training loss (for one batch) at step 14550: 0.0012\n",
            "Seen so far: 465632 samples\n",
            "0.96305454\n",
            "Training loss (for one batch) at step 14555: 0.0015\n",
            "Seen so far: 465792 samples\n",
            "0.9630586\n",
            "Training loss (for one batch) at step 14560: 0.0436\n",
            "Seen so far: 465952 samples\n",
            "0.96306485\n",
            "Training loss (for one batch) at step 14565: 0.0205\n",
            "Seen so far: 466112 samples\n",
            "0.9630754\n",
            "Training loss (for one batch) at step 14570: 0.0259\n",
            "Seen so far: 466272 samples\n",
            "0.96308595\n",
            "Training loss (for one batch) at step 14575: 0.0722\n",
            "Seen so far: 466432 samples\n",
            "0.96309644\n",
            "Training loss (for one batch) at step 14580: 0.1746\n",
            "Seen so far: 466592 samples\n",
            "0.96310264\n",
            "Training loss (for one batch) at step 14585: 0.0064\n",
            "Seen so far: 466752 samples\n",
            "0.9631132\n",
            "Training loss (for one batch) at step 14590: 0.0043\n",
            "Seen so far: 466912 samples\n",
            "0.9631258\n",
            "Training loss (for one batch) at step 14595: 0.0115\n",
            "Seen so far: 467072 samples\n",
            "0.96313417\n",
            "Training loss (for one batch) at step 14600: 0.0001\n",
            "Seen so far: 467232 samples\n",
            "0.9631425\n",
            "Training loss (for one batch) at step 14605: 0.0007\n",
            "Seen so far: 467392 samples\n",
            "0.96315086\n",
            "Training loss (for one batch) at step 14610: 0.0171\n",
            "Seen so far: 467552 samples\n",
            "0.9631506\n",
            "Training loss (for one batch) at step 14615: 0.2243\n",
            "Seen so far: 467712 samples\n",
            "0.9631525\n",
            "Training loss (for one batch) at step 14620: 0.0836\n",
            "Seen so far: 467872 samples\n",
            "0.9631566\n",
            "Training loss (for one batch) at step 14625: 0.0646\n",
            "Seen so far: 468032 samples\n",
            "0.9631628\n",
            "Training loss (for one batch) at step 14630: 0.0099\n",
            "Seen so far: 468192 samples\n",
            "0.9631732\n",
            "Training loss (for one batch) at step 14635: 0.0006\n",
            "Seen so far: 468352 samples\n",
            "0.9631794\n",
            "Training loss (for one batch) at step 14640: 0.0000\n",
            "Seen so far: 468512 samples\n",
            "0.963192\n",
            "Training loss (for one batch) at step 14645: 0.2335\n",
            "Seen so far: 468672 samples\n",
            "0.9631939\n",
            "Training loss (for one batch) at step 14650: 0.0372\n",
            "Seen so far: 468832 samples\n",
            "0.9632043\n",
            "Training loss (for one batch) at step 14655: 0.0147\n",
            "Seen so far: 468992 samples\n",
            "0.9632083\n",
            "Training loss (for one batch) at step 14660: 0.0110\n",
            "Seen so far: 469152 samples\n",
            "0.96321875\n",
            "Training loss (for one batch) at step 14665: 0.0118\n",
            "Seen so far: 469312 samples\n",
            "0.96323127\n",
            "Training loss (for one batch) at step 14670: 0.0964\n",
            "Seen so far: 469472 samples\n",
            "0.9632374\n",
            "Training loss (for one batch) at step 14675: 0.0909\n",
            "Seen so far: 469632 samples\n",
            "0.9632457\n",
            "Training loss (for one batch) at step 14680: 0.0002\n",
            "Seen so far: 469792 samples\n",
            "0.9632518\n",
            "Training loss (for one batch) at step 14685: 0.0254\n",
            "Seen so far: 469952 samples\n",
            "0.96326005\n",
            "Training loss (for one batch) at step 14690: 0.0004\n",
            "Seen so far: 470112 samples\n",
            "0.9632662\n",
            "Training loss (for one batch) at step 14695: 0.0088\n",
            "Seen so far: 470272 samples\n",
            "0.96327657\n",
            "Training loss (for one batch) at step 14700: 0.0189\n",
            "Seen so far: 470432 samples\n",
            "0.96328694\n",
            "Training loss (for one batch) at step 14705: 0.0213\n",
            "Seen so far: 470592 samples\n",
            "0.9632973\n",
            "Training loss (for one batch) at step 14710: 0.0081\n",
            "Seen so far: 470752 samples\n",
            "0.96330553\n",
            "Training loss (for one batch) at step 14715: 0.0001\n",
            "Seen so far: 470912 samples\n",
            "0.96331584\n",
            "Training loss (for one batch) at step 14720: 0.0003\n",
            "Seen so far: 471072 samples\n",
            "0.9633283\n",
            "Training loss (for one batch) at step 14725: 0.1367\n",
            "Seen so far: 471232 samples\n",
            "0.9633323\n",
            "Training loss (for one batch) at step 14730: 0.0004\n",
            "Seen so far: 471392 samples\n",
            "0.96334046\n",
            "Training loss (for one batch) at step 14735: 0.0038\n",
            "Seen so far: 471552 samples\n",
            "0.96335083\n",
            "Training loss (for one batch) at step 14740: 0.0013\n",
            "Seen so far: 471712 samples\n",
            "0.96336323\n",
            "Training loss (for one batch) at step 14745: 0.4416\n",
            "Seen so far: 471872 samples\n",
            "0.9633714\n",
            "Training loss (for one batch) at step 14750: 0.3167\n",
            "Seen so far: 472032 samples\n",
            "0.9633775\n",
            "Training loss (for one batch) at step 14755: 0.0009\n",
            "Seen so far: 472192 samples\n",
            "0.9633878\n",
            "Training loss (for one batch) at step 14760: 0.0167\n",
            "Seen so far: 472352 samples\n",
            "0.9633917\n",
            "Training loss (for one batch) at step 14765: 0.0006\n",
            "Seen so far: 472512 samples\n",
            "0.963402\n",
            "Training loss (for one batch) at step 14770: 0.1235\n",
            "Seen so far: 472672 samples\n",
            "0.96340805\n",
            "Training loss (for one batch) at step 14775: 0.0050\n",
            "Seen so far: 472832 samples\n",
            "0.9634183\n",
            "Training loss (for one batch) at step 14780: 0.0107\n",
            "Seen so far: 472992 samples\n",
            "0.9634265\n",
            "Training loss (for one batch) at step 14785: 0.0856\n",
            "Seen so far: 473152 samples\n",
            "0.9634346\n",
            "Training loss (for one batch) at step 14790: 0.0217\n",
            "Seen so far: 473312 samples\n",
            "0.96344274\n",
            "Training loss (for one batch) at step 14795: 0.0064\n",
            "Seen so far: 473472 samples\n",
            "0.9634466\n",
            "Training loss (for one batch) at step 14800: 0.0023\n",
            "Seen so far: 473632 samples\n",
            "0.96345687\n",
            "Training loss (for one batch) at step 14805: 0.0002\n",
            "Seen so far: 473792 samples\n",
            "0.9634629\n",
            "Training loss (for one batch) at step 14810: 0.0335\n",
            "Seen so far: 473952 samples\n",
            "0.963471\n",
            "Training loss (for one batch) at step 14815: 0.4262\n",
            "Seen so far: 474112 samples\n",
            "0.96347696\n",
            "Training loss (for one batch) at step 14820: 0.0018\n",
            "Seen so far: 474272 samples\n",
            "0.963483\n",
            "Training loss (for one batch) at step 14825: 0.2019\n",
            "Seen so far: 474432 samples\n",
            "0.96348685\n",
            "Training loss (for one batch) at step 14830: 0.1497\n",
            "Seen so far: 474592 samples\n",
            "0.9634929\n",
            "Training loss (for one batch) at step 14835: 0.1989\n",
            "Seen so far: 474752 samples\n",
            "0.96349674\n",
            "Training loss (for one batch) at step 14840: 0.1024\n",
            "Seen so far: 474912 samples\n",
            "0.9634943\n",
            "Training loss (for one batch) at step 14845: 0.0048\n",
            "Seen so far: 475072 samples\n",
            "0.96350235\n",
            "Training loss (for one batch) at step 14850: 0.0007\n",
            "Seen so far: 475232 samples\n",
            "0.96350414\n",
            "Training loss (for one batch) at step 14855: 0.0274\n",
            "Seen so far: 475392 samples\n",
            "0.9635101\n",
            "Training loss (for one batch) at step 14860: 0.1445\n",
            "Seen so far: 475552 samples\n",
            "0.963514\n",
            "Training loss (for one batch) at step 14865: 0.0316\n",
            "Seen so far: 475712 samples\n",
            "0.96351784\n",
            "Training loss (for one batch) at step 14870: 0.0726\n",
            "Seen so far: 475872 samples\n",
            "0.9635217\n",
            "Training loss (for one batch) at step 14875: 0.0944\n",
            "Seen so far: 476032 samples\n",
            "0.96352553\n",
            "Training loss (for one batch) at step 14880: 0.0014\n",
            "Seen so far: 476192 samples\n",
            "0.9635378\n",
            "Training loss (for one batch) at step 14885: 0.0028\n",
            "Seen so far: 476352 samples\n",
            "0.96353954\n",
            "Training loss (for one batch) at step 14890: 0.0044\n",
            "Seen so far: 476512 samples\n",
            "0.96354973\n",
            "Training loss (for one batch) at step 14895: 0.1376\n",
            "Seen so far: 476672 samples\n",
            "0.96354306\n",
            "Training loss (for one batch) at step 14900: 0.2824\n",
            "Seen so far: 476832 samples\n",
            "0.9635427\n",
            "Training loss (for one batch) at step 14905: 0.0486\n",
            "Seen so far: 476992 samples\n",
            "0.96354866\n",
            "Training loss (for one batch) at step 14910: 0.0307\n",
            "Seen so far: 477152 samples\n",
            "0.9635483\n",
            "Training loss (for one batch) at step 14915: 0.0117\n",
            "Seen so far: 477312 samples\n",
            "0.96355635\n",
            "Training loss (for one batch) at step 14920: 0.0069\n",
            "Seen so far: 477472 samples\n",
            "0.9635664\n",
            "Training loss (for one batch) at step 14925: 0.0498\n",
            "Seen so far: 477632 samples\n",
            "0.9635724\n",
            "Training loss (for one batch) at step 14930: 0.0683\n",
            "Seen so far: 477792 samples\n",
            "0.96358037\n",
            "Training loss (for one batch) at step 14935: 0.0047\n",
            "Seen so far: 477952 samples\n",
            "0.9635884\n",
            "Training loss (for one batch) at step 14940: 0.0242\n",
            "Seen so far: 478112 samples\n",
            "0.9635985\n",
            "Training loss (for one batch) at step 14945: 0.1579\n",
            "Seen so far: 478272 samples\n",
            "0.9636044\n",
            "Training loss (for one batch) at step 14950: 0.0479\n",
            "Seen so far: 478432 samples\n",
            "0.9636103\n",
            "Training loss (for one batch) at step 14955: 0.1000\n",
            "Seen so far: 478592 samples\n",
            "0.9636183\n",
            "Training loss (for one batch) at step 14960: 0.0659\n",
            "Seen so far: 478752 samples\n",
            "0.9636221\n",
            "Training loss (for one batch) at step 14965: 0.6449\n",
            "Seen so far: 478912 samples\n",
            "0.963628\n",
            "Training loss (for one batch) at step 14970: 0.0017\n",
            "Seen so far: 479072 samples\n",
            "0.963638\n",
            "Training loss (for one batch) at step 14975: 0.0074\n",
            "Seen so far: 479232 samples\n",
            "0.963646\n",
            "Training loss (for one batch) at step 14980: 0.0183\n",
            "Seen so far: 479392 samples\n",
            "0.96365607\n",
            "Training loss (for one batch) at step 14985: 0.0010\n",
            "Seen so far: 479552 samples\n",
            "0.9636661\n",
            "Training loss (for one batch) at step 14990: 0.0061\n",
            "Seen so far: 479712 samples\n",
            "0.9636699\n",
            "Training loss (for one batch) at step 14995: 0.0212\n",
            "Seen so far: 479872 samples\n",
            "0.96367574\n",
            "Training loss (for one batch) at step 15000: 0.0004\n",
            "Seen so far: 480032 samples\n",
            "0.96368575\n",
            "Training loss (for one batch) at step 15005: 0.1278\n",
            "Seen so far: 480192 samples\n",
            "0.96369576\n",
            "Training loss (for one batch) at step 15010: 0.1507\n",
            "Seen so far: 480352 samples\n",
            "0.9636995\n",
            "Training loss (for one batch) at step 15015: 0.0060\n",
            "Seen so far: 480512 samples\n",
            "0.96370953\n",
            "Training loss (for one batch) at step 15020: 0.2087\n",
            "Seen so far: 480672 samples\n",
            "0.9637112\n",
            "Training loss (for one batch) at step 15025: 0.0040\n",
            "Seen so far: 480832 samples\n",
            "0.9637191\n",
            "Training loss (for one batch) at step 15030: 0.3677\n",
            "Seen so far: 480992 samples\n",
            "0.96372914\n",
            "Training loss (for one batch) at step 15035: 0.0007\n",
            "Seen so far: 481152 samples\n",
            "0.9637412\n",
            "Training loss (for one batch) at step 15040: 0.1722\n",
            "Seen so far: 481312 samples\n",
            "0.9637491\n",
            "Training loss (for one batch) at step 15045: 0.0571\n",
            "Seen so far: 481472 samples\n",
            "0.963757\n",
            "Training loss (for one batch) at step 15050: 0.0042\n",
            "Seen so far: 481632 samples\n",
            "0.96376693\n",
            "Training loss (for one batch) at step 15055: 0.0510\n",
            "Seen so far: 481792 samples\n",
            "0.9637769\n",
            "Training loss (for one batch) at step 15060: 0.0001\n",
            "Seen so far: 481952 samples\n",
            "0.96378064\n",
            "Training loss (for one batch) at step 15065: 0.0839\n",
            "Seen so far: 482112 samples\n",
            "0.9637864\n",
            "Training loss (for one batch) at step 15070: 0.3490\n",
            "Seen so far: 482272 samples\n",
            "0.9637881\n",
            "Training loss (for one batch) at step 15075: 0.0057\n",
            "Seen so far: 482432 samples\n",
            "0.9637939\n",
            "Training loss (for one batch) at step 15080: 0.0310\n",
            "Seen so far: 482592 samples\n",
            "0.96379966\n",
            "Training loss (for one batch) at step 15085: 0.0821\n",
            "Seen so far: 482752 samples\n",
            "0.96380544\n",
            "Training loss (for one batch) at step 15090: 0.0401\n",
            "Seen so far: 482912 samples\n",
            "0.96380913\n",
            "Training loss (for one batch) at step 15095: 0.1105\n",
            "Seen so far: 483072 samples\n",
            "0.9638108\n",
            "Training loss (for one batch) at step 15100: 0.0971\n",
            "Seen so far: 483232 samples\n",
            "0.9638165\n",
            "Training loss (for one batch) at step 15105: 0.1149\n",
            "Seen so far: 483392 samples\n",
            "0.9638203\n",
            "Training loss (for one batch) at step 15110: 0.0532\n",
            "Seen so far: 483552 samples\n",
            "0.9638281\n",
            "Training loss (for one batch) at step 15115: 0.0096\n",
            "Seen so far: 483712 samples\n",
            "0.96383387\n",
            "Training loss (for one batch) at step 15120: 0.0168\n",
            "Seen so far: 483872 samples\n",
            "0.9638396\n",
            "Training loss (for one batch) at step 15125: 0.0244\n",
            "Seen so far: 484032 samples\n",
            "0.9638454\n",
            "Training loss (for one batch) at step 15130: 0.0050\n",
            "Seen so far: 484192 samples\n",
            "0.9638511\n",
            "Training loss (for one batch) at step 15135: 0.0186\n",
            "Seen so far: 484352 samples\n",
            "0.9638589\n",
            "Training loss (for one batch) at step 15140: 0.0023\n",
            "Seen so far: 484512 samples\n",
            "0.9638523\n",
            "Training loss (for one batch) at step 15145: 0.0479\n",
            "Seen so far: 484672 samples\n",
            "0.9638539\n",
            "Training loss (for one batch) at step 15150: 0.0096\n",
            "Seen so far: 484832 samples\n",
            "0.9638617\n",
            "Training loss (for one batch) at step 15155: 0.0106\n",
            "Seen so far: 484992 samples\n",
            "0.9638716\n",
            "Training loss (for one batch) at step 15160: 0.0285\n",
            "Seen so far: 485152 samples\n",
            "0.96388143\n",
            "Training loss (for one batch) at step 15165: 0.0080\n",
            "Seen so far: 485312 samples\n",
            "0.96388716\n",
            "Training loss (for one batch) at step 15170: 0.0026\n",
            "Seen so far: 485472 samples\n",
            "0.963897\n",
            "Training loss (for one batch) at step 15175: 0.0049\n",
            "Seen so far: 485632 samples\n",
            "0.9639006\n",
            "Training loss (for one batch) at step 15180: 0.0686\n",
            "Seen so far: 485792 samples\n",
            "0.96390843\n",
            "Training loss (for one batch) at step 15185: 0.0009\n",
            "Seen so far: 485952 samples\n",
            "0.9639162\n",
            "Training loss (for one batch) at step 15190: 0.0188\n",
            "Seen so far: 486112 samples\n",
            "0.9639219\n",
            "Training loss (for one batch) at step 15195: 0.1534\n",
            "Seen so far: 486272 samples\n",
            "0.9639214\n",
            "Training loss (for one batch) at step 15200: 0.0403\n",
            "Seen so far: 486432 samples\n",
            "0.96392715\n",
            "Training loss (for one batch) at step 15205: 0.0217\n",
            "Seen so far: 486592 samples\n",
            "0.9639349\n",
            "Training loss (for one batch) at step 15210: 0.0401\n",
            "Seen so far: 486752 samples\n",
            "0.9639447\n",
            "Training loss (for one batch) at step 15215: 0.0021\n",
            "Seen so far: 486912 samples\n",
            "0.9639524\n",
            "Training loss (for one batch) at step 15220: 0.0062\n",
            "Seen so far: 487072 samples\n",
            "0.9639581\n",
            "Training loss (for one batch) at step 15225: 0.1676\n",
            "Seen so far: 487232 samples\n",
            "0.9639556\n",
            "Training loss (for one batch) at step 15230: 0.0037\n",
            "Seen so far: 487392 samples\n",
            "0.96396327\n",
            "Training loss (for one batch) at step 15235: 0.0151\n",
            "Seen so far: 487552 samples\n",
            "0.9639649\n",
            "Training loss (for one batch) at step 15240: 0.0019\n",
            "Seen so far: 487712 samples\n",
            "0.96397465\n",
            "Training loss (for one batch) at step 15245: 0.0003\n",
            "Seen so far: 487872 samples\n",
            "0.96398234\n",
            "Training loss (for one batch) at step 15250: 0.0042\n",
            "Seen so far: 488032 samples\n",
            "0.963986\n",
            "Training loss (for one batch) at step 15255: 0.0545\n",
            "Seen so far: 488192 samples\n",
            "0.9639875\n",
            "Training loss (for one batch) at step 15260: 0.0092\n",
            "Seen so far: 488352 samples\n",
            "0.96398705\n",
            "Training loss (for one batch) at step 15265: 0.1950\n",
            "Seen so far: 488512 samples\n",
            "0.9639866\n",
            "Training loss (for one batch) at step 15270: 0.0010\n",
            "Seen so far: 488672 samples\n",
            "0.9639983\n",
            "Training loss (for one batch) at step 15275: 0.0016\n",
            "Seen so far: 488832 samples\n",
            "0.964004\n",
            "Training loss (for one batch) at step 15280: 0.0008\n",
            "Seen so far: 488992 samples\n",
            "0.9640158\n",
            "Training loss (for one batch) at step 15285: 0.0092\n",
            "Seen so far: 489152 samples\n",
            "0.9640275\n",
            "Training loss (for one batch) at step 15290: 0.0012\n",
            "Seen so far: 489312 samples\n",
            "0.96402705\n",
            "Training loss (for one batch) at step 15295: 0.0003\n",
            "Seen so far: 489472 samples\n",
            "0.96403676\n",
            "Training loss (for one batch) at step 15300: 0.1102\n",
            "Seen so far: 489632 samples\n",
            "0.9640465\n",
            "Training loss (for one batch) at step 15305: 0.0091\n",
            "Seen so far: 489792 samples\n",
            "0.9640562\n",
            "Training loss (for one batch) at step 15310: 0.0008\n",
            "Seen so far: 489952 samples\n",
            "0.9640618\n",
            "Training loss (for one batch) at step 15315: 0.0337\n",
            "Seen so far: 490112 samples\n",
            "0.9640674\n",
            "Training loss (for one batch) at step 15320: 0.0048\n",
            "Seen so far: 490272 samples\n",
            "0.964075\n",
            "Training loss (for one batch) at step 15325: 0.1596\n",
            "Seen so far: 490432 samples\n",
            "0.96408063\n",
            "Training loss (for one batch) at step 15330: 0.0717\n",
            "Seen so far: 490592 samples\n",
            "0.96409035\n",
            "Training loss (for one batch) at step 15335: 0.0159\n",
            "Seen so far: 490752 samples\n",
            "0.96409184\n",
            "Training loss (for one batch) at step 15340: 0.0011\n",
            "Seen so far: 490912 samples\n",
            "0.9641035\n",
            "Training loss (for one batch) at step 15345: 0.0001\n",
            "Seen so far: 491072 samples\n",
            "0.96411115\n",
            "Training loss (for one batch) at step 15350: 0.0358\n",
            "Seen so far: 491232 samples\n",
            "0.9641208\n",
            "Training loss (for one batch) at step 15355: 0.0500\n",
            "Seen so far: 491392 samples\n",
            "0.9641264\n",
            "Training loss (for one batch) at step 15360: 0.0040\n",
            "Seen so far: 491552 samples\n",
            "0.96413404\n",
            "Training loss (for one batch) at step 15365: 0.0468\n",
            "Seen so far: 491712 samples\n",
            "0.9641355\n",
            "Training loss (for one batch) at step 15370: 0.0048\n",
            "Seen so far: 491872 samples\n",
            "0.96413904\n",
            "Training loss (for one batch) at step 15375: 0.0031\n",
            "Seen so far: 492032 samples\n",
            "0.9641466\n",
            "Training loss (for one batch) at step 15380: 0.0005\n",
            "Seen so far: 492192 samples\n",
            "0.96415424\n",
            "Training loss (for one batch) at step 15385: 0.0028\n",
            "Seen so far: 492352 samples\n",
            "0.9641598\n",
            "Training loss (for one batch) at step 15390: 0.0024\n",
            "Seen so far: 492512 samples\n",
            "0.9641694\n",
            "Training loss (for one batch) at step 15395: 0.0003\n",
            "Seen so far: 492672 samples\n",
            "0.964179\n",
            "Training loss (for one batch) at step 15400: 0.0452\n",
            "Seen so far: 492832 samples\n",
            "0.96418864\n",
            "Training loss (for one batch) at step 15405: 0.0004\n",
            "Seen so far: 492992 samples\n",
            "0.96419823\n",
            "Training loss (for one batch) at step 15410: 0.0005\n",
            "Seen so far: 493152 samples\n",
            "0.96420777\n",
            "Training loss (for one batch) at step 15415: 0.0312\n",
            "Seen so far: 493312 samples\n",
            "0.96421736\n",
            "Training loss (for one batch) at step 15420: 0.0607\n",
            "Seen so far: 493472 samples\n",
            "0.9642229\n",
            "Training loss (for one batch) at step 15425: 0.0015\n",
            "Seen so far: 493632 samples\n",
            "0.96423244\n",
            "Training loss (for one batch) at step 15430: 0.0081\n",
            "Seen so far: 493792 samples\n",
            "0.96424\n",
            "Training loss (for one batch) at step 15435: 0.0166\n",
            "Seen so far: 493952 samples\n",
            "0.9642455\n",
            "Training loss (for one batch) at step 15440: 0.0316\n",
            "Seen so far: 494112 samples\n",
            "0.96425307\n",
            "Training loss (for one batch) at step 15445: 0.0239\n",
            "Seen so far: 494272 samples\n",
            "0.9642484\n",
            "Training loss (for one batch) at step 15450: 0.0010\n",
            "Seen so far: 494432 samples\n",
            "0.96425796\n",
            "Training loss (for one batch) at step 15455: 0.0035\n",
            "Seen so far: 494592 samples\n",
            "0.9642695\n",
            "Training loss (for one batch) at step 15460: 0.0037\n",
            "Seen so far: 494752 samples\n",
            "0.96427906\n",
            "Training loss (for one batch) at step 15465: 0.0017\n",
            "Seen so far: 494912 samples\n",
            "0.96428657\n",
            "Training loss (for one batch) at step 15470: 0.0017\n",
            "Seen so far: 495072 samples\n",
            "0.9642981\n",
            "Training loss (for one batch) at step 15475: 0.0538\n",
            "Seen so far: 495232 samples\n",
            "0.96430767\n",
            "Training loss (for one batch) at step 15480: 0.3835\n",
            "Seen so far: 495392 samples\n",
            "0.9643091\n",
            "Training loss (for one batch) at step 15485: 0.0166\n",
            "Seen so far: 495552 samples\n",
            "0.9643186\n",
            "Training loss (for one batch) at step 15490: 0.0034\n",
            "Seen so far: 495712 samples\n",
            "0.96432805\n",
            "Training loss (for one batch) at step 15495: 0.0039\n",
            "Seen so far: 495872 samples\n",
            "0.96433556\n",
            "Training loss (for one batch) at step 15500: 0.0137\n",
            "Seen so far: 496032 samples\n",
            "0.964339\n",
            "Training loss (for one batch) at step 15505: 0.0001\n",
            "Seen so far: 496192 samples\n",
            "0.96434444\n",
            "Training loss (for one batch) at step 15510: 0.0369\n",
            "Seen so far: 496352 samples\n",
            "0.9643519\n",
            "Training loss (for one batch) at step 15515: 0.0083\n",
            "Seen so far: 496512 samples\n",
            "0.96436137\n",
            "Training loss (for one batch) at step 15520: 0.0265\n",
            "Seen so far: 496672 samples\n",
            "0.96437085\n",
            "Training loss (for one batch) at step 15525: 0.1053\n",
            "Seen so far: 496832 samples\n",
            "0.9643763\n",
            "Training loss (for one batch) at step 15530: 0.0699\n",
            "Seen so far: 496992 samples\n",
            "0.9643817\n",
            "Training loss (for one batch) at step 15535: 0.0000\n",
            "Seen so far: 497152 samples\n",
            "0.9643831\n",
            "Training loss (for one batch) at step 15540: 0.2479\n",
            "Seen so far: 497312 samples\n",
            "0.9643825\n",
            "Training loss (for one batch) at step 15545: 0.0613\n",
            "Seen so far: 497472 samples\n",
            "0.9643859\n",
            "Training loss (for one batch) at step 15550: 0.0013\n",
            "Seen so far: 497632 samples\n",
            "0.96438533\n",
            "Training loss (for one batch) at step 15555: 0.0427\n",
            "Seen so far: 497792 samples\n",
            "0.9643787\n",
            "Training loss (for one batch) at step 15560: 0.0009\n",
            "Seen so far: 497952 samples\n",
            "0.96438414\n",
            "Training loss (for one batch) at step 15565: 0.1770\n",
            "Seen so far: 498112 samples\n",
            "0.96438754\n",
            "Training loss (for one batch) at step 15570: 0.0035\n",
            "Seen so far: 498272 samples\n",
            "0.96439695\n",
            "Training loss (for one batch) at step 15575: 0.0114\n",
            "Seen so far: 498432 samples\n",
            "0.9644024\n",
            "Training loss (for one batch) at step 15580: 0.0024\n",
            "Seen so far: 498592 samples\n",
            "0.9644118\n",
            "Training loss (for one batch) at step 15585: 0.0463\n",
            "Seen so far: 498752 samples\n",
            "0.96441317\n",
            "Training loss (for one batch) at step 15590: 0.0015\n",
            "Seen so far: 498912 samples\n",
            "0.96441656\n",
            "Training loss (for one batch) at step 15595: 0.1737\n",
            "Seen so far: 499072 samples\n",
            "0.964422\n",
            "Training loss (for one batch) at step 15600: 0.0007\n",
            "Seen so far: 499232 samples\n",
            "0.96443135\n",
            "Training loss (for one batch) at step 15605: 0.0124\n",
            "Seen so far: 499392 samples\n",
            "0.96444076\n",
            "Training loss (for one batch) at step 15610: 0.3396\n",
            "Seen so far: 499552 samples\n",
            "0.9644461\n",
            "Training loss (for one batch) at step 15615: 0.1534\n",
            "Seen so far: 499712 samples\n",
            "0.9644495\n",
            "Training loss (for one batch) at step 15620: 0.3853\n",
            "Seen so far: 499872 samples\n",
            "0.9644449\n",
            "Training loss (for one batch) at step 15625: 0.0139\n",
            "Seen so far: 500032 samples\n",
            "0.9644543\n",
            "Training loss (for one batch) at step 15630: 0.0077\n",
            "Seen so far: 500192 samples\n",
            "0.96445763\n",
            "Training loss (for one batch) at step 15635: 0.1103\n",
            "Seen so far: 500352 samples\n",
            "0.964465\n",
            "Training loss (for one batch) at step 15640: 0.1162\n",
            "Seen so far: 500512 samples\n",
            "0.9644604\n",
            "Training loss (for one batch) at step 15645: 0.0032\n",
            "Seen so far: 500672 samples\n",
            "0.96446574\n",
            "Training loss (for one batch) at step 15650: 0.0572\n",
            "Seen so far: 500832 samples\n",
            "0.9644671\n",
            "Training loss (for one batch) at step 15655: 0.2259\n",
            "Seen so far: 500992 samples\n",
            "0.9644725\n",
            "Training loss (for one batch) at step 15660: 0.0728\n",
            "Seen so far: 501152 samples\n",
            "0.96447986\n",
            "Training loss (for one batch) at step 15665: 0.2372\n",
            "Seen so far: 501312 samples\n",
            "0.9644832\n",
            "Training loss (for one batch) at step 15670: 0.0156\n",
            "Seen so far: 501472 samples\n",
            "0.96449256\n",
            "Training loss (for one batch) at step 15675: 0.5429\n",
            "Seen so far: 501632 samples\n",
            "0.9644959\n",
            "Training loss (for one batch) at step 15680: 0.0056\n",
            "Seen so far: 501792 samples\n",
            "0.9645032\n",
            "Training loss (for one batch) at step 15685: 0.0156\n",
            "Seen so far: 501952 samples\n",
            "0.96451056\n",
            "Training loss (for one batch) at step 15690: 0.1554\n",
            "Seen so far: 502112 samples\n",
            "0.96451586\n",
            "Training loss (for one batch) at step 15695: 0.0525\n",
            "Seen so far: 502272 samples\n",
            "0.9645192\n",
            "Training loss (for one batch) at step 15700: 0.1469\n",
            "Seen so far: 502432 samples\n",
            "0.96452653\n",
            "Training loss (for one batch) at step 15705: 0.0084\n",
            "Seen so far: 502592 samples\n",
            "0.96453387\n",
            "Training loss (for one batch) at step 15710: 0.0525\n",
            "Seen so far: 502752 samples\n",
            "0.9645352\n",
            "Training loss (for one batch) at step 15715: 0.0398\n",
            "Seen so far: 502912 samples\n",
            "0.9645385\n",
            "Training loss (for one batch) at step 15720: 0.2569\n",
            "Seen so far: 503072 samples\n",
            "0.96454185\n",
            "Training loss (for one batch) at step 15725: 0.0082\n",
            "Seen so far: 503232 samples\n",
            "0.96455115\n",
            "Training loss (for one batch) at step 15730: 0.1706\n",
            "Seen so far: 503392 samples\n",
            "0.96455646\n",
            "Training loss (for one batch) at step 15735: 0.0042\n",
            "Seen so far: 503552 samples\n",
            "0.96456575\n",
            "Training loss (for one batch) at step 15740: 0.0290\n",
            "Seen so far: 503712 samples\n",
            "0.9645651\n",
            "Training loss (for one batch) at step 15745: 0.0208\n",
            "Seen so far: 503872 samples\n",
            "0.96457237\n",
            "Training loss (for one batch) at step 15750: 0.0772\n",
            "Seen so far: 504032 samples\n",
            "0.9645737\n",
            "Training loss (for one batch) at step 15755: 0.4303\n",
            "Seen so far: 504192 samples\n",
            "0.96457106\n",
            "Training loss (for one batch) at step 15760: 0.0075\n",
            "Seen so far: 504352 samples\n",
            "0.9645763\n",
            "Training loss (for one batch) at step 15765: 0.2002\n",
            "Seen so far: 504512 samples\n",
            "0.96457964\n",
            "Training loss (for one batch) at step 15770: 0.0030\n",
            "Seen so far: 504672 samples\n",
            "0.9645889\n",
            "Training loss (for one batch) at step 15775: 0.1280\n",
            "Seen so far: 504832 samples\n",
            "0.9645902\n",
            "Training loss (for one batch) at step 15780: 0.2184\n",
            "Seen so far: 504992 samples\n",
            "0.9645915\n",
            "Training loss (for one batch) at step 15785: 0.1535\n",
            "Seen so far: 505152 samples\n",
            "0.9645869\n",
            "Training loss (for one batch) at step 15790: 0.0292\n",
            "Seen so far: 505312 samples\n",
            "0.9645941\n",
            "Training loss (for one batch) at step 15795: 0.1098\n",
            "Seen so far: 505472 samples\n",
            "0.96460336\n",
            "Training loss (for one batch) at step 15800: 0.0643\n",
            "Seen so far: 505632 samples\n",
            "0.96461064\n",
            "Training loss (for one batch) at step 15805: 0.0771\n",
            "Seen so far: 505792 samples\n",
            "0.9646159\n",
            "Training loss (for one batch) at step 15810: 0.0246\n",
            "Seen so far: 505952 samples\n",
            "0.96462315\n",
            "Training loss (for one batch) at step 15815: 0.2320\n",
            "Seen so far: 506112 samples\n",
            "0.96463037\n",
            "Training loss (for one batch) at step 15820: 0.0444\n",
            "Seen so far: 506272 samples\n",
            "0.96463954\n",
            "Training loss (for one batch) at step 15825: 0.0023\n",
            "Seen so far: 506432 samples\n",
            "0.9646488\n",
            "Training loss (for one batch) at step 15830: 0.0345\n",
            "Seen so far: 506592 samples\n",
            "0.96464807\n",
            "Training loss (for one batch) at step 15835: 0.0273\n",
            "Seen so far: 506752 samples\n",
            "0.9646533\n",
            "Training loss (for one batch) at step 15840: 0.1253\n",
            "Seen so far: 506912 samples\n",
            "0.96465856\n",
            "Training loss (for one batch) at step 15845: 0.0080\n",
            "Seen so far: 507072 samples\n",
            "0.96466774\n",
            "Training loss (for one batch) at step 15850: 0.0139\n",
            "Seen so far: 507232 samples\n",
            "0.96467495\n",
            "Training loss (for one batch) at step 15855: 0.0015\n",
            "Seen so far: 507392 samples\n",
            "0.9646841\n",
            "Training loss (for one batch) at step 15860: 0.0098\n",
            "Seen so far: 507552 samples\n",
            "0.9646952\n",
            "Training loss (for one batch) at step 15865: 0.2959\n",
            "Seen so far: 507712 samples\n",
            "0.9646985\n",
            "Training loss (for one batch) at step 15870: 0.0057\n",
            "Seen so far: 507872 samples\n",
            "0.96470565\n",
            "Training loss (for one batch) at step 15875: 0.0338\n",
            "Seen so far: 508032 samples\n",
            "0.9647148\n",
            "Training loss (for one batch) at step 15880: 0.0113\n",
            "Seen so far: 508192 samples\n",
            "0.96472\n",
            "Training loss (for one batch) at step 15885: 0.0047\n",
            "Seen so far: 508352 samples\n",
            "0.9647233\n",
            "Training loss (for one batch) at step 15890: 0.0035\n",
            "Seen so far: 508512 samples\n",
            "0.9647344\n",
            "Training loss (for one batch) at step 15895: 0.0367\n",
            "Seen so far: 508672 samples\n",
            "0.9647376\n",
            "Training loss (for one batch) at step 15900: 0.0141\n",
            "Seen so far: 508832 samples\n",
            "0.9647428\n",
            "Training loss (for one batch) at step 15905: 0.0042\n",
            "Seen so far: 508992 samples\n",
            "0.96475387\n",
            "Training loss (for one batch) at step 15910: 0.3082\n",
            "Seen so far: 509152 samples\n",
            "0.964763\n",
            "Training loss (for one batch) at step 15915: 0.0014\n",
            "Seen so far: 509312 samples\n",
            "0.9647741\n",
            "Training loss (for one batch) at step 15920: 0.0010\n",
            "Seen so far: 509472 samples\n",
            "0.96478117\n",
            "Training loss (for one batch) at step 15925: 0.0775\n",
            "Seen so far: 509632 samples\n",
            "0.96478635\n",
            "Training loss (for one batch) at step 15930: 0.0055\n",
            "Seen so far: 509792 samples\n",
            "0.9647955\n",
            "Training loss (for one batch) at step 15935: 0.0009\n",
            "Seen so far: 509952 samples\n",
            "0.9648065\n",
            "Training loss (for one batch) at step 15940: 0.0004\n",
            "Seen so far: 510112 samples\n",
            "0.9648175\n",
            "Training loss (for one batch) at step 15945: 0.0250\n",
            "Seen so far: 510272 samples\n",
            "0.9648266\n",
            "Training loss (for one batch) at step 15950: 0.1533\n",
            "Seen so far: 510432 samples\n",
            "0.96483177\n",
            "Training loss (for one batch) at step 15955: 0.0125\n",
            "Seen so far: 510592 samples\n",
            "0.9648369\n",
            "Training loss (for one batch) at step 15960: 0.1257\n",
            "Seen so far: 510752 samples\n",
            "0.96484005\n",
            "Training loss (for one batch) at step 15965: 0.0014\n",
            "Seen so far: 510912 samples\n",
            "0.9648491\n",
            "Training loss (for one batch) at step 15970: 0.0010\n",
            "Seen so far: 511072 samples\n",
            "0.9648562\n",
            "Training loss (for one batch) at step 15975: 0.0670\n",
            "Seen so far: 511232 samples\n",
            "0.9648594\n",
            "Training loss (for one batch) at step 15980: 0.0320\n",
            "Seen so far: 511392 samples\n",
            "0.9648606\n",
            "Training loss (for one batch) at step 15985: 0.0001\n",
            "Seen so far: 511552 samples\n",
            "0.9648677\n",
            "Training loss (for one batch) at step 15990: 0.0040\n",
            "Seen so far: 511712 samples\n",
            "0.9648767\n",
            "Training loss (for one batch) at step 15995: 0.1206\n",
            "Seen so far: 511872 samples\n",
            "0.9648838\n",
            "Training loss (for one batch) at step 16000: 0.0336\n",
            "Seen so far: 512032 samples\n",
            "0.9648928\n",
            "Training loss (for one batch) at step 16005: 0.1971\n",
            "Seen so far: 512192 samples\n",
            "0.96489596\n",
            "Training loss (for one batch) at step 16010: 0.0147\n",
            "Seen so far: 512352 samples\n",
            "0.96490496\n",
            "Training loss (for one batch) at step 16015: 0.0163\n",
            "Seen so far: 512512 samples\n",
            "0.96491206\n",
            "Training loss (for one batch) at step 16020: 0.0128\n",
            "Seen so far: 512672 samples\n",
            "0.96492296\n",
            "Training loss (for one batch) at step 16025: 0.0039\n",
            "Seen so far: 512832 samples\n",
            "0.96493393\n",
            "Training loss (for one batch) at step 16030: 0.0068\n",
            "Seen so far: 512992 samples\n",
            "0.96494097\n",
            "Training loss (for one batch) at step 16035: 0.0003\n",
            "Seen so far: 513152 samples\n",
            "0.96494603\n",
            "Training loss (for one batch) at step 16040: 0.0073\n",
            "Seen so far: 513312 samples\n",
            "0.96495503\n",
            "Training loss (for one batch) at step 16045: 0.0001\n",
            "Seen so far: 513472 samples\n",
            "0.96496207\n",
            "Training loss (for one batch) at step 16050: 0.0007\n",
            "Seen so far: 513632 samples\n",
            "0.964973\n",
            "Training loss (for one batch) at step 16055: 0.0006\n",
            "Seen so far: 513792 samples\n",
            "0.96498\n",
            "Training loss (for one batch) at step 16060: 0.0015\n",
            "Seen so far: 513952 samples\n",
            "0.964987\n",
            "Training loss (for one batch) at step 16065: 0.0078\n",
            "Seen so far: 514112 samples\n",
            "0.964996\n",
            "Training loss (for one batch) at step 16070: 0.0049\n",
            "Seen so far: 514272 samples\n",
            "0.9650049\n",
            "Training loss (for one batch) at step 16075: 0.0750\n",
            "Seen so far: 514432 samples\n",
            "0.96500415\n",
            "Training loss (for one batch) at step 16080: 0.0026\n",
            "Seen so far: 514592 samples\n",
            "0.965015\n",
            "Training loss (for one batch) at step 16085: 0.7566\n",
            "Seen so far: 514752 samples\n",
            "0.96502197\n",
            "Training loss (for one batch) at step 16090: 0.0705\n",
            "Seen so far: 514912 samples\n",
            "0.96502703\n",
            "Training loss (for one batch) at step 16095: 0.0371\n",
            "Seen so far: 515072 samples\n",
            "0.965034\n",
            "Training loss (for one batch) at step 16100: 0.1120\n",
            "Seen so far: 515232 samples\n",
            "0.965041\n",
            "Training loss (for one batch) at step 16105: 0.0080\n",
            "Seen so far: 515392 samples\n",
            "0.96504605\n",
            "Training loss (for one batch) at step 16110: 0.0084\n",
            "Seen so far: 515552 samples\n",
            "0.96505105\n",
            "Training loss (for one batch) at step 16115: 0.0565\n",
            "Seen so far: 515712 samples\n",
            "0.965058\n",
            "Training loss (for one batch) at step 16120: 0.0040\n",
            "Seen so far: 515872 samples\n",
            "0.96505916\n",
            "Training loss (for one batch) at step 16125: 0.0406\n",
            "Seen so far: 516032 samples\n",
            "0.96506613\n",
            "Training loss (for one batch) at step 16130: 0.0057\n",
            "Seen so far: 516192 samples\n",
            "0.96507305\n",
            "Training loss (for one batch) at step 16135: 0.0326\n",
            "Seen so far: 516352 samples\n",
            "0.96508193\n",
            "Training loss (for one batch) at step 16140: 0.0009\n",
            "Seen so far: 516512 samples\n",
            "0.9650908\n",
            "Training loss (for one batch) at step 16145: 0.0005\n",
            "Seen so far: 516672 samples\n",
            "0.9650997\n",
            "Training loss (for one batch) at step 16150: 0.0002\n",
            "Seen so far: 516832 samples\n",
            "0.96510667\n",
            "Training loss (for one batch) at step 16155: 0.0079\n",
            "Seen so far: 516992 samples\n",
            "0.9651117\n",
            "Training loss (for one batch) at step 16160: 0.0489\n",
            "Seen so far: 517152 samples\n",
            "0.9651166\n",
            "Training loss (for one batch) at step 16165: 0.0019\n",
            "Seen so far: 517312 samples\n",
            "0.9651255\n",
            "Training loss (for one batch) at step 16170: 0.1151\n",
            "Seen so far: 517472 samples\n",
            "0.9651343\n",
            "Training loss (for one batch) at step 16175: 0.0211\n",
            "Seen so far: 517632 samples\n",
            "0.9651374\n",
            "Training loss (for one batch) at step 16180: 0.0069\n",
            "Seen so far: 517792 samples\n",
            "0.9651443\n",
            "Training loss (for one batch) at step 16185: 0.0002\n",
            "Seen so far: 517952 samples\n",
            "0.96515316\n",
            "Training loss (for one batch) at step 16190: 0.0024\n",
            "Seen so far: 518112 samples\n",
            "0.9651562\n",
            "Training loss (for one batch) at step 16195: 0.0015\n",
            "Seen so far: 518272 samples\n",
            "0.9651669\n",
            "Training loss (for one batch) at step 16200: 0.0224\n",
            "Seen so far: 518432 samples\n",
            "0.96517384\n",
            "Training loss (for one batch) at step 16205: 0.0009\n",
            "Seen so far: 518592 samples\n",
            "0.9651788\n",
            "Training loss (for one batch) at step 16210: 0.0004\n",
            "Seen so far: 518752 samples\n",
            "0.9651895\n",
            "Training loss (for one batch) at step 16215: 0.0044\n",
            "Seen so far: 518912 samples\n",
            "0.96519446\n",
            "Training loss (for one batch) at step 16220: 0.0020\n",
            "Seen so far: 519072 samples\n",
            "0.9652033\n",
            "Training loss (for one batch) at step 16225: 0.1732\n",
            "Seen so far: 519232 samples\n",
            "0.96521014\n",
            "Training loss (for one batch) at step 16230: 0.0192\n",
            "Seen so far: 519392 samples\n",
            "0.965217\n",
            "Training loss (for one batch) at step 16235: 0.0054\n",
            "Seen so far: 519552 samples\n",
            "0.96522194\n",
            "Training loss (for one batch) at step 16240: 0.0010\n",
            "Seen so far: 519712 samples\n",
            "0.9652327\n",
            "Training loss (for one batch) at step 16245: 0.0893\n",
            "Seen so far: 519872 samples\n",
            "0.9652376\n",
            "Training loss (for one batch) at step 16250: 0.0263\n",
            "Seen so far: 520032 samples\n",
            "0.9652464\n",
            "Training loss (for one batch) at step 16255: 0.0002\n",
            "Seen so far: 520192 samples\n",
            "0.96525514\n",
            "Training loss (for one batch) at step 16260: 0.0001\n",
            "Seen so far: 520352 samples\n",
            "0.9652658\n",
            "Training loss (for one batch) at step 16265: 0.1550\n",
            "Seen so far: 520512 samples\n",
            "0.9652746\n",
            "Training loss (for one batch) at step 16270: 0.0035\n",
            "Seen so far: 520672 samples\n",
            "0.96528333\n",
            "Training loss (for one batch) at step 16275: 0.0391\n",
            "Seen so far: 520832 samples\n",
            "0.9652921\n",
            "Training loss (for one batch) at step 16280: 0.0040\n",
            "Seen so far: 520992 samples\n",
            "0.9653008\n",
            "Training loss (for one batch) at step 16285: 0.0046\n",
            "Seen so far: 521152 samples\n",
            "0.96531147\n",
            "Training loss (for one batch) at step 16290: 0.2348\n",
            "Seen so far: 521312 samples\n",
            "0.96531826\n",
            "Training loss (for one batch) at step 16295: 0.0058\n",
            "Seen so far: 521472 samples\n",
            "0.965327\n",
            "Training loss (for one batch) at step 16300: 0.0404\n",
            "Seen so far: 521632 samples\n",
            "0.9653338\n",
            "Training loss (for one batch) at step 16305: 0.0075\n",
            "Seen so far: 521792 samples\n",
            "0.9653444\n",
            "Training loss (for one batch) at step 16310: 0.0075\n",
            "Seen so far: 521952 samples\n",
            "0.96535313\n",
            "Training loss (for one batch) at step 16315: 0.0423\n",
            "Seen so far: 522112 samples\n",
            "0.96536183\n",
            "Training loss (for one batch) at step 16320: 0.0162\n",
            "Seen so far: 522272 samples\n",
            "0.9653686\n",
            "Training loss (for one batch) at step 16325: 0.0159\n",
            "Seen so far: 522432 samples\n",
            "0.9653754\n",
            "Training loss (for one batch) at step 16330: 0.0033\n",
            "Seen so far: 522592 samples\n",
            "0.96538216\n",
            "Training loss (for one batch) at step 16335: 0.0002\n",
            "Seen so far: 522752 samples\n",
            "0.96538895\n",
            "Training loss (for one batch) at step 16340: 0.2108\n",
            "Seen so far: 522912 samples\n",
            "0.9653957\n",
            "Training loss (for one batch) at step 16345: 0.0010\n",
            "Seen so far: 523072 samples\n",
            "0.9654063\n",
            "Training loss (for one batch) at step 16350: 0.0159\n",
            "Seen so far: 523232 samples\n",
            "0.9654111\n",
            "Training loss (for one batch) at step 16355: 0.0019\n",
            "Seen so far: 523392 samples\n",
            "0.96542174\n",
            "Training loss (for one batch) at step 16360: 0.0035\n",
            "Seen so far: 523552 samples\n",
            "0.9654323\n",
            "Training loss (for one batch) at step 16365: 0.0010\n",
            "Seen so far: 523712 samples\n",
            "0.96544284\n",
            "Training loss (for one batch) at step 16370: 0.0004\n",
            "Seen so far: 523872 samples\n",
            "0.96544766\n",
            "Training loss (for one batch) at step 16375: 0.0003\n",
            "Seen so far: 524032 samples\n",
            "0.9654582\n",
            "Training loss (for one batch) at step 16380: 0.0698\n",
            "Seen so far: 524192 samples\n",
            "0.96546495\n",
            "Training loss (for one batch) at step 16385: 0.0056\n",
            "Seen so far: 524352 samples\n",
            "0.9654755\n",
            "Training loss (for one batch) at step 16390: 0.0000\n",
            "Seen so far: 524512 samples\n",
            "0.9654841\n",
            "Training loss (for one batch) at step 16395: 0.2399\n",
            "Seen so far: 524672 samples\n",
            "0.9654889\n",
            "Training loss (for one batch) at step 16400: 0.0225\n",
            "Seen so far: 524832 samples\n",
            "0.96549565\n",
            "Training loss (for one batch) at step 16405: 0.0022\n",
            "Seen so far: 524992 samples\n",
            "0.96550614\n",
            "Training loss (for one batch) at step 16410: 0.0025\n",
            "Seen so far: 525152 samples\n",
            "0.9655129\n",
            "Training loss (for one batch) at step 16415: 0.0000\n",
            "Seen so far: 525312 samples\n",
            "0.96552145\n",
            "Training loss (for one batch) at step 16420: 0.0491\n",
            "Seen so far: 525472 samples\n",
            "0.96552813\n",
            "Training loss (for one batch) at step 16425: 0.0042\n",
            "Seen so far: 525632 samples\n",
            "0.9655329\n",
            "Training loss (for one batch) at step 16430: 0.0151\n",
            "Seen so far: 525792 samples\n",
            "0.9655415\n",
            "Training loss (for one batch) at step 16435: 0.0061\n",
            "Seen so far: 525952 samples\n",
            "0.965552\n",
            "Training loss (for one batch) at step 16440: 0.0218\n",
            "Seen so far: 526112 samples\n",
            "0.96556246\n",
            "Training loss (for one batch) at step 16445: 0.0002\n",
            "Seen so far: 526272 samples\n",
            "0.96557105\n",
            "Training loss (for one batch) at step 16450: 0.0284\n",
            "Seen so far: 526432 samples\n",
            "0.9655777\n",
            "Training loss (for one batch) at step 16455: 0.0330\n",
            "Seen so far: 526592 samples\n",
            "0.96558434\n",
            "Training loss (for one batch) at step 16460: 0.0024\n",
            "Seen so far: 526752 samples\n",
            "0.9655948\n",
            "Training loss (for one batch) at step 16465: 0.0003\n",
            "Seen so far: 526912 samples\n",
            "0.96560335\n",
            "Training loss (for one batch) at step 16470: 0.0029\n",
            "Seen so far: 527072 samples\n",
            "0.9656138\n",
            "Training loss (for one batch) at step 16475: 0.0042\n",
            "Seen so far: 527232 samples\n",
            "0.96561855\n",
            "Training loss (for one batch) at step 16480: 0.0076\n",
            "Seen so far: 527392 samples\n",
            "0.9656271\n",
            "Training loss (for one batch) at step 16485: 0.0052\n",
            "Seen so far: 527552 samples\n",
            "0.9656375\n",
            "Training loss (for one batch) at step 16490: 0.0170\n",
            "Seen so far: 527712 samples\n",
            "0.9656423\n",
            "Training loss (for one batch) at step 16495: 0.3422\n",
            "Seen so far: 527872 samples\n",
            "0.96565074\n",
            "Training loss (for one batch) at step 16500: 0.0047\n",
            "Seen so far: 528032 samples\n",
            "0.9656555\n",
            "Training loss (for one batch) at step 16505: 0.0010\n",
            "Seen so far: 528192 samples\n",
            "0.9656659\n",
            "Training loss (for one batch) at step 16510: 0.0067\n",
            "Seen so far: 528352 samples\n",
            "0.9656725\n",
            "Training loss (for one batch) at step 16515: 0.0180\n",
            "Seen so far: 528512 samples\n",
            "0.965681\n",
            "Training loss (for one batch) at step 16520: 0.0027\n",
            "Seen so far: 528672 samples\n",
            "0.96568763\n",
            "Training loss (for one batch) at step 16525: 0.0013\n",
            "Seen so far: 528832 samples\n",
            "0.96569043\n",
            "Training loss (for one batch) at step 16530: 0.0610\n",
            "Seen so far: 528992 samples\n",
            "0.96569705\n",
            "Training loss (for one batch) at step 16535: 0.0041\n",
            "Seen so far: 529152 samples\n",
            "0.9657055\n",
            "Training loss (for one batch) at step 16540: 0.3934\n",
            "Seen so far: 529312 samples\n",
            "0.9657121\n",
            "Training loss (for one batch) at step 16545: 0.0232\n",
            "Seen so far: 529472 samples\n",
            "0.9657168\n",
            "Training loss (for one batch) at step 16550: 0.0301\n",
            "Seen so far: 529632 samples\n",
            "0.9657215\n",
            "Training loss (for one batch) at step 16555: 0.0044\n",
            "Seen so far: 529792 samples\n",
            "0.9657262\n",
            "Training loss (for one batch) at step 16560: 0.0101\n",
            "Seen so far: 529952 samples\n",
            "0.96573466\n",
            "Training loss (for one batch) at step 16565: 0.0532\n",
            "Seen so far: 530112 samples\n",
            "0.9657374\n",
            "Training loss (for one batch) at step 16570: 0.0004\n",
            "Seen so far: 530272 samples\n",
            "0.965744\n",
            "Training loss (for one batch) at step 16575: 0.0046\n",
            "Seen so far: 530432 samples\n",
            "0.9657506\n",
            "Training loss (for one batch) at step 16580: 0.0118\n",
            "Seen so far: 530592 samples\n",
            "0.965759\n",
            "Training loss (for one batch) at step 16585: 0.0022\n",
            "Seen so far: 530752 samples\n",
            "0.96576935\n",
            "Training loss (for one batch) at step 16590: 0.0022\n",
            "Seen so far: 530912 samples\n",
            "0.96577966\n",
            "Training loss (for one batch) at step 16595: 0.0870\n",
            "Seen so far: 531072 samples\n",
            "0.96578056\n",
            "Training loss (for one batch) at step 16600: 0.0220\n",
            "Seen so far: 531232 samples\n",
            "0.96578896\n",
            "Training loss (for one batch) at step 16605: 0.2422\n",
            "Seen so far: 531392 samples\n",
            "0.9657936\n",
            "Training loss (for one batch) at step 16610: 0.0111\n",
            "Seen so far: 531552 samples\n",
            "0.965802\n",
            "Training loss (for one batch) at step 16615: 0.0004\n",
            "Seen so far: 531712 samples\n",
            "0.9658104\n",
            "Training loss (for one batch) at step 16620: 0.0135\n",
            "Seen so far: 531872 samples\n",
            "0.9658207\n",
            "Training loss (for one batch) at step 16625: 0.0878\n",
            "Seen so far: 532032 samples\n",
            "0.96582913\n",
            "Training loss (for one batch) at step 16630: 0.0493\n",
            "Seen so far: 532192 samples\n",
            "0.96583754\n",
            "Training loss (for one batch) at step 16635: 0.0030\n",
            "Seen so far: 532352 samples\n",
            "0.9658403\n",
            "Training loss (for one batch) at step 16640: 0.0001\n",
            "Seen so far: 532512 samples\n",
            "0.9658487\n",
            "Training loss (for one batch) at step 16645: 0.1877\n",
            "Seen so far: 532672 samples\n",
            "0.965857\n",
            "Training loss (for one batch) at step 16650: 0.0363\n",
            "Seen so far: 532832 samples\n",
            "0.96586543\n",
            "Training loss (for one batch) at step 16655: 0.0095\n",
            "Seen so far: 532992 samples\n",
            "0.9658738\n",
            "Training loss (for one batch) at step 16660: 0.0001\n",
            "Seen so far: 533152 samples\n",
            "0.9658803\n",
            "Training loss (for one batch) at step 16665: 0.0000\n",
            "Seen so far: 533312 samples\n",
            "0.9658868\n",
            "Training loss (for one batch) at step 16670: 0.0071\n",
            "Seen so far: 533472 samples\n",
            "0.9658951\n",
            "Training loss (for one batch) at step 16675: 0.0869\n",
            "Seen so far: 533632 samples\n",
            "0.96590346\n",
            "Training loss (for one batch) at step 16680: 0.0353\n",
            "Seen so far: 533792 samples\n",
            "0.96590996\n",
            "Training loss (for one batch) at step 16685: 0.0730\n",
            "Seen so far: 533952 samples\n",
            "0.9659183\n",
            "Training loss (for one batch) at step 16690: 0.0000\n",
            "Seen so far: 534112 samples\n",
            "0.96592665\n",
            "Training loss (for one batch) at step 16695: 0.0050\n",
            "Seen so far: 534272 samples\n",
            "0.96593124\n",
            "Training loss (for one batch) at step 16700: 0.0067\n",
            "Seen so far: 534432 samples\n",
            "0.9659395\n",
            "Training loss (for one batch) at step 16705: 0.0023\n",
            "Seen so far: 534592 samples\n",
            "0.96594787\n",
            "Training loss (for one batch) at step 16710: 0.0043\n",
            "Seen so far: 534752 samples\n",
            "0.96595246\n",
            "Training loss (for one batch) at step 16715: 0.0005\n",
            "Seen so far: 534912 samples\n",
            "0.9659589\n",
            "Training loss (for one batch) at step 16720: 0.2701\n",
            "Seen so far: 535072 samples\n",
            "0.9659579\n",
            "Training loss (for one batch) at step 16725: 0.0016\n",
            "Seen so far: 535232 samples\n",
            "0.9659643\n",
            "Training loss (for one batch) at step 16730: 0.0006\n",
            "Seen so far: 535392 samples\n",
            "0.96597075\n",
            "Training loss (for one batch) at step 16735: 0.0714\n",
            "Seen so far: 535552 samples\n",
            "0.96597904\n",
            "Training loss (for one batch) at step 16740: 0.1020\n",
            "Seen so far: 535712 samples\n",
            "0.9659873\n",
            "Training loss (for one batch) at step 16745: 0.0053\n",
            "Seen so far: 535872 samples\n",
            "0.96599746\n",
            "Training loss (for one batch) at step 16750: 0.0022\n",
            "Seen so far: 536032 samples\n",
            "0.9660039\n",
            "Training loss (for one batch) at step 16755: 0.0087\n",
            "Seen so far: 536192 samples\n",
            "0.96601033\n",
            "Training loss (for one batch) at step 16760: 0.0232\n",
            "Seen so far: 536352 samples\n",
            "0.96601856\n",
            "Training loss (for one batch) at step 16765: 0.0051\n",
            "Seen so far: 536512 samples\n",
            "0.96602684\n",
            "Training loss (for one batch) at step 16770: 0.0093\n",
            "Seen so far: 536672 samples\n",
            "0.9660333\n",
            "Training loss (for one batch) at step 16775: 0.0001\n",
            "Seen so far: 536832 samples\n",
            "0.9660415\n",
            "Training loss (for one batch) at step 16780: 0.0006\n",
            "Seen so far: 536992 samples\n",
            "0.96605164\n",
            "Training loss (for one batch) at step 16785: 0.0021\n",
            "Seen so far: 537152 samples\n",
            "0.966058\n",
            "Training loss (for one batch) at step 16790: 0.0640\n",
            "Seen so far: 537312 samples\n",
            "0.96606624\n",
            "Training loss (for one batch) at step 16795: 0.0021\n",
            "Seen so far: 537472 samples\n",
            "0.9660708\n",
            "Training loss (for one batch) at step 16800: 0.0001\n",
            "Seen so far: 537632 samples\n",
            "0.96607715\n",
            "Training loss (for one batch) at step 16805: 0.0001\n",
            "Seen so far: 537792 samples\n",
            "0.9660854\n",
            "Training loss (for one batch) at step 16810: 0.0423\n",
            "Seen so far: 537952 samples\n",
            "0.9660899\n",
            "Training loss (for one batch) at step 16815: 0.1373\n",
            "Seen so far: 538112 samples\n",
            "0.9660907\n",
            "Training loss (for one batch) at step 16820: 0.0001\n",
            "Seen so far: 538272 samples\n",
            "0.96609706\n",
            "Training loss (for one batch) at step 16825: 0.0074\n",
            "Seen so far: 538432 samples\n",
            "0.9661053\n",
            "Training loss (for one batch) at step 16830: 0.0274\n",
            "Seen so far: 538592 samples\n",
            "0.96611536\n",
            "Training loss (for one batch) at step 16835: 0.0299\n",
            "Seen so far: 538752 samples\n",
            "0.96612173\n",
            "Training loss (for one batch) at step 16840: 0.0004\n",
            "Seen so far: 538912 samples\n",
            "0.96612805\n",
            "Training loss (for one batch) at step 16845: 0.0556\n",
            "Seen so far: 539072 samples\n",
            "0.96613437\n",
            "Training loss (for one batch) at step 16850: 0.0036\n",
            "Seen so far: 539232 samples\n",
            "0.96614075\n",
            "Training loss (for one batch) at step 16855: 0.0001\n",
            "Seen so far: 539392 samples\n",
            "0.9661452\n",
            "Training loss (for one batch) at step 16860: 0.0000\n",
            "Seen so far: 539552 samples\n",
            "0.9661534\n",
            "Training loss (for one batch) at step 16865: 0.1476\n",
            "Seen so far: 539712 samples\n",
            "0.9661597\n",
            "Training loss (for one batch) at step 16870: 0.0624\n",
            "Seen so far: 539872 samples\n",
            "0.9661679\n",
            "Training loss (for one batch) at step 16875: 0.0001\n",
            "Seen so far: 540032 samples\n",
            "0.96617794\n",
            "Training loss (for one batch) at step 16880: 0.1002\n",
            "Seen so far: 540192 samples\n",
            "0.9661824\n",
            "Training loss (for one batch) at step 16885: 0.0002\n",
            "Seen so far: 540352 samples\n",
            "0.9661924\n",
            "Training loss (for one batch) at step 16890: 0.0028\n",
            "Seen so far: 540512 samples\n",
            "0.96619874\n",
            "Training loss (for one batch) at step 16895: 0.0690\n",
            "Seen so far: 540672 samples\n",
            "0.96620315\n",
            "Training loss (for one batch) at step 16900: 0.0801\n",
            "Seen so far: 540832 samples\n",
            "0.9662113\n",
            "Training loss (for one batch) at step 16905: 0.1094\n",
            "Seen so far: 540992 samples\n",
            "0.9662195\n",
            "Training loss (for one batch) at step 16910: 0.0039\n",
            "Seen so far: 541152 samples\n",
            "0.9662276\n",
            "Training loss (for one batch) at step 16915: 0.0038\n",
            "Seen so far: 541312 samples\n",
            "0.96623576\n",
            "Training loss (for one batch) at step 16920: 0.0094\n",
            "Seen so far: 541472 samples\n",
            "0.96624017\n",
            "Training loss (for one batch) at step 16925: 0.0001\n",
            "Seen so far: 541632 samples\n",
            "0.9662428\n",
            "Training loss (for one batch) at step 16930: 0.0008\n",
            "Seen so far: 541792 samples\n",
            "0.96624905\n",
            "Training loss (for one batch) at step 16935: 0.0981\n",
            "Seen so far: 541952 samples\n",
            "0.96625346\n",
            "Training loss (for one batch) at step 16940: 0.0764\n",
            "Seen so far: 542112 samples\n",
            "0.96625787\n",
            "Training loss (for one batch) at step 16945: 0.0367\n",
            "Seen so far: 542272 samples\n",
            "0.96626604\n",
            "Training loss (for one batch) at step 16950: 0.0102\n",
            "Seen so far: 542432 samples\n",
            "0.9662723\n",
            "Training loss (for one batch) at step 16955: 0.0061\n",
            "Seen so far: 542592 samples\n",
            "0.9662804\n",
            "Training loss (for one batch) at step 16960: 0.0012\n",
            "Seen so far: 542752 samples\n",
            "0.9662848\n",
            "Training loss (for one batch) at step 16965: 0.0001\n",
            "Seen so far: 542912 samples\n",
            "0.966291\n",
            "Training loss (for one batch) at step 16970: 0.0052\n",
            "Seen so far: 543072 samples\n",
            "0.96630096\n",
            "Training loss (for one batch) at step 16975: 0.0040\n",
            "Seen so far: 543232 samples\n",
            "0.9663072\n",
            "Training loss (for one batch) at step 16980: 0.0058\n",
            "Seen so far: 543392 samples\n",
            "0.9663171\n",
            "Training loss (for one batch) at step 16985: 0.0063\n",
            "Seen so far: 543552 samples\n",
            "0.9663271\n",
            "Training loss (for one batch) at step 16990: 0.0026\n",
            "Seen so far: 543712 samples\n",
            "0.9663314\n",
            "Training loss (for one batch) at step 16995: 0.0001\n",
            "Seen so far: 543872 samples\n",
            "0.9663377\n",
            "Training loss (for one batch) at step 17000: 0.0003\n",
            "Seen so far: 544032 samples\n",
            "0.9663457\n",
            "Training loss (for one batch) at step 17005: 0.0007\n",
            "Seen so far: 544192 samples\n",
            "0.9663519\n",
            "Training loss (for one batch) at step 17010: 0.0354\n",
            "Seen so far: 544352 samples\n",
            "0.966349\n",
            "Training loss (for one batch) at step 17015: 0.0687\n",
            "Seen so far: 544512 samples\n",
            "0.9663552\n",
            "Training loss (for one batch) at step 17020: 0.0011\n",
            "Seen so far: 544672 samples\n",
            "0.9663651\n",
            "Training loss (for one batch) at step 17025: 0.0690\n",
            "Seen so far: 544832 samples\n",
            "0.9663676\n",
            "Training loss (for one batch) at step 17030: 0.0115\n",
            "Seen so far: 544992 samples\n",
            "0.96637017\n",
            "Training loss (for one batch) at step 17035: 0.4027\n",
            "Seen so far: 545152 samples\n",
            "0.96637636\n",
            "Training loss (for one batch) at step 17040: 0.0437\n",
            "Seen so far: 545312 samples\n",
            "0.9663807\n",
            "Training loss (for one batch) at step 17045: 0.0306\n",
            "Seen so far: 545472 samples\n",
            "0.96638876\n",
            "Training loss (for one batch) at step 17050: 0.0044\n",
            "Seen so far: 545632 samples\n",
            "0.9663986\n",
            "Training loss (for one batch) at step 17055: 0.0223\n",
            "Seen so far: 545792 samples\n",
            "0.96640295\n",
            "Training loss (for one batch) at step 17060: 0.0008\n",
            "Seen so far: 545952 samples\n",
            "0.966411\n",
            "Training loss (for one batch) at step 17065: 0.0002\n",
            "Seen so far: 546112 samples\n",
            "0.96641713\n",
            "Training loss (for one batch) at step 17070: 0.0220\n",
            "Seen so far: 546272 samples\n",
            "0.96642697\n",
            "Training loss (for one batch) at step 17075: 0.0906\n",
            "Seen so far: 546432 samples\n",
            "0.96643317\n",
            "Training loss (for one batch) at step 17080: 0.0104\n",
            "Seen so far: 546592 samples\n",
            "0.9664393\n",
            "Training loss (for one batch) at step 17085: 0.0073\n",
            "Seen so far: 546752 samples\n",
            "0.96644914\n",
            "Training loss (for one batch) at step 17090: 0.0072\n",
            "Seen so far: 546912 samples\n",
            "0.966459\n",
            "Training loss (for one batch) at step 17095: 0.0496\n",
            "Seen so far: 547072 samples\n",
            "0.96646327\n",
            "Training loss (for one batch) at step 17100: 0.0005\n",
            "Seen so far: 547232 samples\n",
            "0.9664694\n",
            "Training loss (for one batch) at step 17105: 0.0033\n",
            "Seen so far: 547392 samples\n",
            "0.9664774\n",
            "Training loss (for one batch) at step 17110: 0.0023\n",
            "Seen so far: 547552 samples\n",
            "0.9664854\n",
            "Training loss (for one batch) at step 17115: 0.0001\n",
            "Seen so far: 547712 samples\n",
            "0.96649337\n",
            "Training loss (for one batch) at step 17120: 0.0017\n",
            "Seen so far: 547872 samples\n",
            "0.9665013\n",
            "Training loss (for one batch) at step 17125: 0.2166\n",
            "Seen so far: 548032 samples\n",
            "0.96650195\n",
            "Training loss (for one batch) at step 17130: 0.0022\n",
            "Seen so far: 548192 samples\n",
            "0.9665081\n",
            "Training loss (for one batch) at step 17135: 0.0084\n",
            "Seen so far: 548352 samples\n",
            "0.966516\n",
            "Training loss (for one batch) at step 17140: 0.0009\n",
            "Seen so far: 548512 samples\n",
            "0.966524\n",
            "Training loss (for one batch) at step 17145: 0.0070\n",
            "Seen so far: 548672 samples\n",
            "0.96653193\n",
            "Training loss (for one batch) at step 17150: 0.0237\n",
            "Seen so far: 548832 samples\n",
            "0.96653986\n",
            "Training loss (for one batch) at step 17155: 0.0022\n",
            "Seen so far: 548992 samples\n",
            "0.9665496\n",
            "Training loss (for one batch) at step 17160: 0.0003\n",
            "Seen so far: 549152 samples\n",
            "0.9665575\n",
            "Training loss (for one batch) at step 17165: 0.0640\n",
            "Seen so far: 549312 samples\n",
            "0.96656364\n",
            "Training loss (for one batch) at step 17170: 0.0000\n",
            "Seen so far: 549472 samples\n",
            "0.96657157\n",
            "Training loss (for one batch) at step 17175: 0.0096\n",
            "Seen so far: 549632 samples\n",
            "0.96657944\n",
            "Training loss (for one batch) at step 17180: 0.0023\n",
            "Seen so far: 549792 samples\n",
            "0.96658736\n",
            "Training loss (for one batch) at step 17185: 0.0006\n",
            "Seen so far: 549952 samples\n",
            "0.9665953\n",
            "Training loss (for one batch) at step 17190: 0.1735\n",
            "Seen so far: 550112 samples\n",
            "0.9665959\n",
            "Training loss (for one batch) at step 17195: 0.0003\n",
            "Seen so far: 550272 samples\n",
            "0.96660197\n",
            "Training loss (for one batch) at step 17200: 0.0004\n",
            "Seen so far: 550432 samples\n",
            "0.9666117\n",
            "Training loss (for one batch) at step 17205: 0.1685\n",
            "Seen so far: 550592 samples\n",
            "0.96661955\n",
            "Training loss (for one batch) at step 17210: 0.0106\n",
            "Seen so far: 550752 samples\n",
            "0.96662563\n",
            "Training loss (for one batch) at step 17215: 0.0749\n",
            "Seen so far: 550912 samples\n",
            "0.9666335\n",
            "Training loss (for one batch) at step 17220: 0.0030\n",
            "Seen so far: 551072 samples\n",
            "0.9666432\n",
            "Training loss (for one batch) at step 17225: 0.0259\n",
            "Seen so far: 551232 samples\n",
            "0.96665287\n",
            "Training loss (for one batch) at step 17230: 0.0009\n",
            "Seen so far: 551392 samples\n",
            "0.96666074\n",
            "Training loss (for one batch) at step 17235: 0.1067\n",
            "Seen so far: 551552 samples\n",
            "0.96666676\n",
            "Training loss (for one batch) at step 17240: 0.0081\n",
            "Seen so far: 551712 samples\n",
            "0.9666746\n",
            "Training loss (for one batch) at step 17245: 0.0060\n",
            "Seen so far: 551872 samples\n",
            "0.9666825\n",
            "Training loss (for one batch) at step 17250: 0.0518\n",
            "Seen so far: 552032 samples\n",
            "0.9666849\n",
            "Training loss (for one batch) at step 17255: 0.0061\n",
            "Seen so far: 552192 samples\n",
            "0.96669096\n",
            "Training loss (for one batch) at step 17260: 0.0712\n",
            "Seen so far: 552352 samples\n",
            "0.96669513\n",
            "Training loss (for one batch) at step 17265: 0.0000\n",
            "Seen so far: 552512 samples\n",
            "0.9667048\n",
            "Training loss (for one batch) at step 17270: 0.0230\n",
            "Seen so far: 552672 samples\n",
            "0.9667108\n",
            "Training loss (for one batch) at step 17275: 0.0818\n",
            "Seen so far: 552832 samples\n",
            "0.96670777\n",
            "Training loss (for one batch) at step 17280: 0.2467\n",
            "Seen so far: 552992 samples\n",
            "0.966712\n",
            "Training loss (for one batch) at step 17285: 0.0030\n",
            "Seen so far: 553152 samples\n",
            "0.966718\n",
            "Training loss (for one batch) at step 17290: 0.0004\n",
            "Seen so far: 553312 samples\n",
            "0.9667276\n",
            "Training loss (for one batch) at step 17295: 0.0753\n",
            "Seen so far: 553472 samples\n",
            "0.96673363\n",
            "Training loss (for one batch) at step 17300: 0.2013\n",
            "Seen so far: 553632 samples\n",
            "0.96673423\n",
            "Training loss (for one batch) at step 17305: 0.0021\n",
            "Seen so far: 553792 samples\n",
            "0.96674204\n",
            "Training loss (for one batch) at step 17310: 0.0071\n",
            "Seen so far: 553952 samples\n",
            "0.96674263\n",
            "Training loss (for one batch) at step 17315: 0.0743\n",
            "Seen so far: 554112 samples\n",
            "0.9667432\n",
            "Training loss (for one batch) at step 17320: 0.0086\n",
            "Seen so far: 554272 samples\n",
            "0.966742\n",
            "Training loss (for one batch) at step 17325: 0.0008\n",
            "Seen so far: 554432 samples\n",
            "0.9667497\n",
            "Training loss (for one batch) at step 17330: 0.0106\n",
            "Seen so far: 554592 samples\n",
            "0.96675754\n",
            "Training loss (for one batch) at step 17335: 0.1126\n",
            "Seen so far: 554752 samples\n",
            "0.96676356\n",
            "Training loss (for one batch) at step 17340: 0.0143\n",
            "Seen so far: 554912 samples\n",
            "0.9667641\n",
            "Training loss (for one batch) at step 17345: 0.0747\n",
            "Seen so far: 555072 samples\n",
            "0.96677005\n",
            "Training loss (for one batch) at step 17350: 0.0114\n",
            "Seen so far: 555232 samples\n",
            "0.96677965\n",
            "Training loss (for one batch) at step 17355: 0.0026\n",
            "Seen so far: 555392 samples\n",
            "0.96678925\n",
            "Training loss (for one batch) at step 17360: 0.0421\n",
            "Seen so far: 555552 samples\n",
            "0.966788\n",
            "Training loss (for one batch) at step 17365: 0.0001\n",
            "Seen so far: 555712 samples\n",
            "0.96679395\n",
            "Training loss (for one batch) at step 17370: 0.0122\n",
            "Seen so far: 555872 samples\n",
            "0.9667999\n",
            "Training loss (for one batch) at step 17375: 0.0007\n",
            "Seen so far: 556032 samples\n",
            "0.96680766\n",
            "Training loss (for one batch) at step 17380: 0.0066\n",
            "Seen so far: 556192 samples\n",
            "0.9668136\n",
            "Training loss (for one batch) at step 17385: 0.0135\n",
            "Seen so far: 556352 samples\n",
            "0.96681595\n",
            "Training loss (for one batch) at step 17390: 0.2516\n",
            "Seen so far: 556512 samples\n",
            "0.96681833\n",
            "Training loss (for one batch) at step 17395: 0.0175\n",
            "Seen so far: 556672 samples\n",
            "0.9668243\n",
            "Training loss (for one batch) at step 17400: 0.0174\n",
            "Seen so far: 556832 samples\n",
            "0.9668284\n",
            "Training loss (for one batch) at step 17405: 0.0801\n",
            "Seen so far: 556992 samples\n",
            "0.96682715\n",
            "Training loss (for one batch) at step 17410: 0.0005\n",
            "Seen so far: 557152 samples\n",
            "0.9668331\n",
            "Training loss (for one batch) at step 17415: 0.0165\n",
            "Seen so far: 557312 samples\n",
            "0.96684265\n",
            "Training loss (for one batch) at step 17420: 0.0053\n",
            "Seen so far: 557472 samples\n",
            "0.96684855\n",
            "Training loss (for one batch) at step 17425: 0.0252\n",
            "Seen so far: 557632 samples\n",
            "0.9668509\n",
            "Training loss (for one batch) at step 17430: 0.0020\n",
            "Seen so far: 557792 samples\n",
            "0.9668604\n",
            "Training loss (for one batch) at step 17435: 0.0577\n",
            "Seen so far: 557952 samples\n",
            "0.9668663\n",
            "Training loss (for one batch) at step 17440: 0.0035\n",
            "Seen so far: 558112 samples\n",
            "0.966874\n",
            "Training loss (for one batch) at step 17445: 0.0025\n",
            "Seen so far: 558272 samples\n",
            "0.96688175\n",
            "Training loss (for one batch) at step 17450: 0.0113\n",
            "Seen so far: 558432 samples\n",
            "0.96688944\n",
            "Training loss (for one batch) at step 17455: 0.0023\n",
            "Seen so far: 558592 samples\n",
            "0.9668989\n",
            "Training loss (for one batch) at step 17460: 0.0072\n",
            "Seen so far: 558752 samples\n",
            "0.9669048\n",
            "Training loss (for one batch) at step 17465: 0.0005\n",
            "Seen so far: 558912 samples\n",
            "0.96690893\n",
            "Training loss (for one batch) at step 17470: 0.0007\n",
            "Seen so far: 559072 samples\n",
            "0.96690947\n",
            "Training loss (for one batch) at step 17475: 0.1093\n",
            "Seen so far: 559232 samples\n",
            "0.96691537\n",
            "Training loss (for one batch) at step 17480: 0.0426\n",
            "Seen so far: 559392 samples\n",
            "0.966923\n",
            "Training loss (for one batch) at step 17485: 0.0034\n",
            "Seen so far: 559552 samples\n",
            "0.96692353\n",
            "Training loss (for one batch) at step 17490: 0.0165\n",
            "Seen so far: 559712 samples\n",
            "0.9669312\n",
            "Training loss (for one batch) at step 17495: 0.0013\n",
            "Seen so far: 559872 samples\n",
            "0.96693707\n",
            "Training loss (for one batch) at step 17500: 0.0017\n",
            "Seen so far: 560032 samples\n",
            "0.9669394\n",
            "Training loss (for one batch) at step 17505: 0.0051\n",
            "Seen so far: 560192 samples\n",
            "0.966947\n",
            "Training loss (for one batch) at step 17510: 0.1475\n",
            "Seen so far: 560352 samples\n",
            "0.966944\n",
            "Training loss (for one batch) at step 17515: 0.0246\n",
            "Seen so far: 560512 samples\n",
            "0.96695167\n",
            "Training loss (for one batch) at step 17520: 0.0675\n",
            "Seen so far: 560672 samples\n",
            "0.96695393\n",
            "Training loss (for one batch) at step 17525: 0.0042\n",
            "Seen so far: 560832 samples\n",
            "0.96695805\n",
            "Training loss (for one batch) at step 17530: 0.0017\n",
            "Seen so far: 560992 samples\n",
            "0.96695673\n",
            "Training loss (for one batch) at step 17535: 0.0059\n",
            "Seen so far: 561152 samples\n",
            "0.96696085\n",
            "Training loss (for one batch) at step 17540: 0.0234\n",
            "Seen so far: 561312 samples\n",
            "0.9669631\n",
            "Training loss (for one batch) at step 17545: 0.0024\n",
            "Seen so far: 561472 samples\n",
            "0.96697074\n",
            "Training loss (for one batch) at step 17550: 0.1256\n",
            "Seen so far: 561632 samples\n",
            "0.9669766\n",
            "Training loss (for one batch) at step 17555: 0.0110\n",
            "Seen so far: 561792 samples\n",
            "0.96698064\n",
            "Training loss (for one batch) at step 17560: 0.1861\n",
            "Seen so far: 561952 samples\n",
            "0.9669812\n",
            "Training loss (for one batch) at step 17565: 0.0030\n",
            "Seen so far: 562112 samples\n",
            "0.9669888\n",
            "Training loss (for one batch) at step 17570: 0.0066\n",
            "Seen so far: 562272 samples\n",
            "0.9669964\n",
            "Training loss (for one batch) at step 17575: 0.0679\n",
            "Seen so far: 562432 samples\n",
            "0.9669969\n",
            "Training loss (for one batch) at step 17580: 0.0003\n",
            "Seen so far: 562592 samples\n",
            "0.9670045\n",
            "Training loss (for one batch) at step 17585: 0.4192\n",
            "Seen so far: 562752 samples\n",
            "0.96699965\n",
            "Training loss (for one batch) at step 17590: 0.0450\n",
            "Seen so far: 562912 samples\n",
            "0.9670002\n",
            "Training loss (for one batch) at step 17595: 0.0193\n",
            "Seen so far: 563072 samples\n",
            "0.96700776\n",
            "Training loss (for one batch) at step 17600: 0.0603\n",
            "Seen so far: 563232 samples\n",
            "0.9670136\n",
            "Training loss (for one batch) at step 17605: 0.0016\n",
            "Seen so far: 563392 samples\n",
            "0.96701944\n",
            "Training loss (for one batch) at step 17610: 0.0111\n",
            "Seen so far: 563552 samples\n",
            "0.9670199\n",
            "Training loss (for one batch) at step 17615: 0.0832\n",
            "Seen so far: 563712 samples\n",
            "0.9670257\n",
            "Training loss (for one batch) at step 17620: 0.0440\n",
            "Seen so far: 563872 samples\n",
            "0.96702623\n",
            "Training loss (for one batch) at step 17625: 0.0012\n",
            "Seen so far: 564032 samples\n",
            "0.96703553\n",
            "Training loss (for one batch) at step 17630: 0.0027\n",
            "Seen so far: 564192 samples\n",
            "0.9670414\n",
            "Training loss (for one batch) at step 17635: 0.0237\n",
            "Seen so far: 564352 samples\n",
            "0.96704715\n",
            "Training loss (for one batch) at step 17640: 0.0105\n",
            "Seen so far: 564512 samples\n",
            "0.9670512\n",
            "Training loss (for one batch) at step 17645: 0.1337\n",
            "Seen so far: 564672 samples\n",
            "0.9670464\n",
            "Training loss (for one batch) at step 17650: 0.0042\n",
            "Seen so far: 564832 samples\n",
            "0.96705395\n",
            "Training loss (for one batch) at step 17655: 0.0040\n",
            "Seen so far: 564992 samples\n",
            "0.96706325\n",
            "Training loss (for one batch) at step 17660: 0.0541\n",
            "Seen so far: 565152 samples\n",
            "0.9670708\n",
            "Training loss (for one batch) at step 17665: 0.0222\n",
            "Seen so far: 565312 samples\n",
            "0.9670766\n",
            "Training loss (for one batch) at step 17670: 0.0002\n",
            "Seen so far: 565472 samples\n",
            "0.9670806\n",
            "Training loss (for one batch) at step 17675: 0.1156\n",
            "Seen so far: 565632 samples\n",
            "0.9670864\n",
            "Training loss (for one batch) at step 17680: 0.0046\n",
            "Seen so far: 565792 samples\n",
            "0.96709216\n",
            "Training loss (for one batch) at step 17685: 0.0009\n",
            "Seen so far: 565952 samples\n",
            "0.96709794\n",
            "Training loss (for one batch) at step 17690: 0.0039\n",
            "Seen so far: 566112 samples\n",
            "0.96710545\n",
            "Training loss (for one batch) at step 17695: 0.0106\n",
            "Seen so far: 566272 samples\n",
            "0.96711296\n",
            "Training loss (for one batch) at step 17700: 0.0473\n",
            "Seen so far: 566432 samples\n",
            "0.9671152\n",
            "Training loss (for one batch) at step 17705: 0.0246\n",
            "Seen so far: 566592 samples\n",
            "0.9671192\n",
            "Training loss (for one batch) at step 17710: 0.0037\n",
            "Seen so far: 566752 samples\n",
            "0.96712494\n",
            "Training loss (for one batch) at step 17715: 0.0023\n",
            "Seen so far: 566912 samples\n",
            "0.96712714\n",
            "Training loss (for one batch) at step 17720: 0.0092\n",
            "Seen so far: 567072 samples\n",
            "0.96713114\n",
            "Training loss (for one batch) at step 17725: 0.0003\n",
            "Seen so far: 567232 samples\n",
            "0.96713865\n",
            "Training loss (for one batch) at step 17730: 0.0042\n",
            "Seen so far: 567392 samples\n",
            "0.96714616\n",
            "Training loss (for one batch) at step 17735: 0.0475\n",
            "Seen so far: 567552 samples\n",
            "0.96715367\n",
            "Training loss (for one batch) at step 17740: 0.0025\n",
            "Seen so far: 567712 samples\n",
            "0.9671612\n",
            "Training loss (for one batch) at step 17745: 0.0019\n",
            "Seen so far: 567872 samples\n",
            "0.9671686\n",
            "Training loss (for one batch) at step 17750: 0.0154\n",
            "Seen so far: 568032 samples\n",
            "0.9671744\n",
            "Training loss (for one batch) at step 17755: 0.0026\n",
            "Seen so far: 568192 samples\n",
            "0.96718013\n",
            "Training loss (for one batch) at step 17760: 0.0119\n",
            "Seen so far: 568352 samples\n",
            "0.9671894\n",
            "Training loss (for one batch) at step 17765: 0.0769\n",
            "Seen so far: 568512 samples\n",
            "0.9671933\n",
            "Training loss (for one batch) at step 17770: 0.0023\n",
            "Seen so far: 568672 samples\n",
            "0.96720076\n",
            "Training loss (for one batch) at step 17775: 0.0066\n",
            "Seen so far: 568832 samples\n",
            "0.96721\n",
            "Training loss (for one batch) at step 17780: 0.0914\n",
            "Seen so far: 568992 samples\n",
            "0.96721745\n",
            "Training loss (for one batch) at step 17785: 0.0001\n",
            "Seen so far: 569152 samples\n",
            "0.96722317\n",
            "Training loss (for one batch) at step 17790: 0.0009\n",
            "Seen so far: 569312 samples\n",
            "0.9672289\n",
            "Training loss (for one batch) at step 17795: 0.0442\n",
            "Seen so far: 569472 samples\n",
            "0.96723634\n",
            "Training loss (for one batch) at step 17800: 0.0122\n",
            "Seen so far: 569632 samples\n",
            "0.9672438\n",
            "Training loss (for one batch) at step 17805: 0.0091\n",
            "Seen so far: 569792 samples\n",
            "0.9672512\n",
            "Training loss (for one batch) at step 17810: 0.0010\n",
            "Seen so far: 569952 samples\n",
            "0.9672569\n",
            "Training loss (for one batch) at step 17815: 0.0015\n",
            "Seen so far: 570112 samples\n",
            "0.9672661\n",
            "Training loss (for one batch) at step 17820: 0.0021\n",
            "Seen so far: 570272 samples\n",
            "0.96727353\n",
            "Training loss (for one batch) at step 17825: 0.0072\n",
            "Seen so far: 570432 samples\n",
            "0.9672792\n",
            "Training loss (for one batch) at step 17830: 0.0003\n",
            "Seen so far: 570592 samples\n",
            "0.9672866\n",
            "Training loss (for one batch) at step 17835: 0.0292\n",
            "Seen so far: 570752 samples\n",
            "0.96729577\n",
            "Training loss (for one batch) at step 17840: 0.0942\n",
            "Seen so far: 570912 samples\n",
            "0.9673014\n",
            "Training loss (for one batch) at step 17845: 0.0013\n",
            "Seen so far: 571072 samples\n",
            "0.9673089\n",
            "Training loss (for one batch) at step 17850: 0.0008\n",
            "Seen so far: 571232 samples\n",
            "0.96731275\n",
            "Training loss (for one batch) at step 17855: 0.0015\n",
            "Seen so far: 571392 samples\n",
            "0.96732014\n",
            "Training loss (for one batch) at step 17860: 0.0006\n",
            "Seen so far: 571552 samples\n",
            "0.96732754\n",
            "Training loss (for one batch) at step 17865: 0.0017\n",
            "Seen so far: 571712 samples\n",
            "0.9673367\n",
            "Training loss (for one batch) at step 17870: 0.0419\n",
            "Seen so far: 571872 samples\n",
            "0.9673406\n",
            "Training loss (for one batch) at step 17875: 0.0072\n",
            "Seen so far: 572032 samples\n",
            "0.96734273\n",
            "Training loss (for one batch) at step 17880: 0.0304\n",
            "Seen so far: 572192 samples\n",
            "0.9673449\n",
            "Training loss (for one batch) at step 17885: 0.1122\n",
            "Seen so far: 572352 samples\n",
            "0.9673418\n",
            "Training loss (for one batch) at step 17890: 0.0013\n",
            "Seen so far: 572512 samples\n",
            "0.9673492\n",
            "Training loss (for one batch) at step 17895: 0.1098\n",
            "Seen so far: 572672 samples\n",
            "0.96735305\n",
            "Training loss (for one batch) at step 17900: 0.0133\n",
            "Seen so far: 572832 samples\n",
            "0.96735865\n",
            "Training loss (for one batch) at step 17905: 0.0927\n",
            "Seen so far: 572992 samples\n",
            "0.96735907\n",
            "Training loss (for one batch) at step 17910: 0.1112\n",
            "Seen so far: 573152 samples\n",
            "0.96736294\n",
            "Training loss (for one batch) at step 17915: 0.0006\n",
            "Seen so far: 573312 samples\n",
            "0.9673633\n",
            "Training loss (for one batch) at step 17920: 0.0113\n",
            "Seen so far: 573472 samples\n",
            "0.96736896\n",
            "Training loss (for one batch) at step 17925: 0.0018\n",
            "Seen so far: 573632 samples\n",
            "0.96737283\n",
            "Training loss (for one batch) at step 17930: 0.0004\n",
            "Seen so far: 573792 samples\n",
            "0.96738017\n",
            "Training loss (for one batch) at step 17935: 0.0442\n",
            "Seen so far: 573952 samples\n",
            "0.96738404\n",
            "Training loss (for one batch) at step 17940: 0.0129\n",
            "Seen so far: 574112 samples\n",
            "0.9673931\n",
            "Training loss (for one batch) at step 17945: 0.0345\n",
            "Seen so far: 574272 samples\n",
            "0.9674005\n",
            "Training loss (for one batch) at step 17950: 0.0037\n",
            "Seen so far: 574432 samples\n",
            "0.9674043\n",
            "Training loss (for one batch) at step 17955: 0.1906\n",
            "Seen so far: 574592 samples\n",
            "0.9674099\n",
            "Training loss (for one batch) at step 17960: 0.0060\n",
            "Seen so far: 574752 samples\n",
            "0.96741897\n",
            "Training loss (for one batch) at step 17965: 0.0007\n",
            "Seen so far: 574912 samples\n",
            "0.96741414\n",
            "Training loss (for one batch) at step 17970: 0.0491\n",
            "Seen so far: 575072 samples\n",
            "0.96741974\n",
            "Training loss (for one batch) at step 17975: 0.0335\n",
            "Seen so far: 575232 samples\n",
            "0.96742356\n",
            "Training loss (for one batch) at step 17980: 0.0349\n",
            "Seen so far: 575392 samples\n",
            "0.9674309\n",
            "Training loss (for one batch) at step 17985: 0.0006\n",
            "Seen so far: 575552 samples\n",
            "0.9674365\n",
            "Training loss (for one batch) at step 17990: 0.0016\n",
            "Seen so far: 575712 samples\n",
            "0.96744204\n",
            "Training loss (for one batch) at step 17995: 0.0020\n",
            "Seen so far: 575872 samples\n",
            "0.96744764\n",
            "Training loss (for one batch) at step 18000: 0.0479\n",
            "Seen so far: 576032 samples\n",
            "0.96745145\n",
            "Training loss (for one batch) at step 18005: 0.0007\n",
            "Seen so far: 576192 samples\n",
            "0.9674588\n",
            "Training loss (for one batch) at step 18010: 0.0115\n",
            "Seen so far: 576352 samples\n",
            "0.9674678\n",
            "Training loss (for one batch) at step 18015: 0.0145\n",
            "Seen so far: 576512 samples\n",
            "0.9674716\n",
            "Training loss (for one batch) at step 18020: 0.0028\n",
            "Seen so far: 576672 samples\n",
            "0.96747893\n",
            "Training loss (for one batch) at step 18025: 0.0108\n",
            "Seen so far: 576832 samples\n",
            "0.9674862\n",
            "Training loss (for one batch) at step 18030: 0.0030\n",
            "Seen so far: 576992 samples\n",
            "0.9674935\n",
            "Training loss (for one batch) at step 18035: 0.2326\n",
            "Seen so far: 577152 samples\n",
            "0.967499\n",
            "Training loss (for one batch) at step 18040: 0.0032\n",
            "Seen so far: 577312 samples\n",
            "0.967508\n",
            "Training loss (for one batch) at step 18045: 0.0010\n",
            "Seen so far: 577472 samples\n",
            "0.967517\n",
            "Training loss (for one batch) at step 18050: 0.0341\n",
            "Seen so far: 577632 samples\n",
            "0.9675243\n",
            "Training loss (for one batch) at step 18055: 0.0003\n",
            "Seen so far: 577792 samples\n",
            "0.96753156\n",
            "Training loss (for one batch) at step 18060: 0.0002\n",
            "Seen so far: 577952 samples\n",
            "0.96754056\n",
            "Training loss (for one batch) at step 18065: 0.1456\n",
            "Seen so far: 578112 samples\n",
            "0.96754783\n",
            "Training loss (for one batch) at step 18070: 0.0115\n",
            "Seen so far: 578272 samples\n",
            "0.9675568\n",
            "Training loss (for one batch) at step 18075: 0.0015\n",
            "Seen so far: 578432 samples\n",
            "0.96756405\n",
            "Training loss (for one batch) at step 18080: 0.2847\n",
            "Seen so far: 578592 samples\n",
            "0.9675678\n",
            "Training loss (for one batch) at step 18085: 0.0073\n",
            "Seen so far: 578752 samples\n",
            "0.9675768\n",
            "Training loss (for one batch) at step 18090: 0.0000\n",
            "Seen so far: 578912 samples\n",
            "0.9675823\n",
            "Training loss (for one batch) at step 18095: 0.0010\n",
            "Seen so far: 579072 samples\n",
            "0.9675912\n",
            "Training loss (for one batch) at step 18100: 0.0002\n",
            "Seen so far: 579232 samples\n",
            "0.96759504\n",
            "Training loss (for one batch) at step 18105: 0.0263\n",
            "Seen so far: 579392 samples\n",
            "0.9675988\n",
            "Training loss (for one batch) at step 18110: 0.0006\n",
            "Seen so far: 579552 samples\n",
            "0.96760255\n",
            "Training loss (for one batch) at step 18115: 0.5307\n",
            "Seen so far: 579712 samples\n",
            "0.9676063\n",
            "Training loss (for one batch) at step 18120: 0.0009\n",
            "Seen so far: 579872 samples\n",
            "0.96761525\n",
            "Training loss (for one batch) at step 18125: 0.0015\n",
            "Seen so far: 580032 samples\n",
            "0.96762073\n",
            "Training loss (for one batch) at step 18130: 0.0005\n",
            "Seen so far: 580192 samples\n",
            "0.96761763\n",
            "Training loss (for one batch) at step 18135: 0.0818\n",
            "Seen so far: 580352 samples\n",
            "0.96762484\n",
            "Training loss (for one batch) at step 18140: 0.0002\n",
            "Seen so far: 580512 samples\n",
            "0.9676303\n",
            "Training loss (for one batch) at step 18145: 0.1821\n",
            "Seen so far: 580672 samples\n",
            "0.96763575\n",
            "Training loss (for one batch) at step 18150: 0.0023\n",
            "Seen so far: 580832 samples\n",
            "0.9676395\n",
            "Training loss (for one batch) at step 18155: 0.0002\n",
            "Seen so far: 580992 samples\n",
            "0.967645\n",
            "Training loss (for one batch) at step 18160: 0.0014\n",
            "Seen so far: 581152 samples\n",
            "0.96764874\n",
            "Training loss (for one batch) at step 18165: 0.0203\n",
            "Seen so far: 581312 samples\n",
            "0.9676559\n",
            "Training loss (for one batch) at step 18170: 0.0015\n",
            "Seen so far: 581472 samples\n",
            "0.9676614\n",
            "Training loss (for one batch) at step 18175: 0.0123\n",
            "Seen so far: 581632 samples\n",
            "0.96766514\n",
            "Training loss (for one batch) at step 18180: 0.0040\n",
            "Seen so far: 581792 samples\n",
            "0.9676723\n",
            "Training loss (for one batch) at step 18185: 0.0887\n",
            "Seen so far: 581952 samples\n",
            "0.9676726\n",
            "Training loss (for one batch) at step 18190: 0.0119\n",
            "Seen so far: 582112 samples\n",
            "0.96767974\n",
            "Training loss (for one batch) at step 18195: 0.0004\n",
            "Seen so far: 582272 samples\n",
            "0.9676886\n",
            "Training loss (for one batch) at step 18200: 0.0092\n",
            "Seen so far: 582432 samples\n",
            "0.9676958\n",
            "Training loss (for one batch) at step 18205: 0.0002\n",
            "Seen so far: 582592 samples\n",
            "0.96770126\n",
            "Training loss (for one batch) at step 18210: 0.0062\n",
            "Seen so far: 582752 samples\n",
            "0.9677101\n",
            "Training loss (for one batch) at step 18215: 0.0083\n",
            "Seen so far: 582912 samples\n",
            "0.96771556\n",
            "Training loss (for one batch) at step 18220: 0.0124\n",
            "Seen so far: 583072 samples\n",
            "0.967721\n",
            "Training loss (for one batch) at step 18225: 0.0004\n",
            "Seen so far: 583232 samples\n",
            "0.9677264\n",
            "Training loss (for one batch) at step 18230: 0.0032\n",
            "Seen so far: 583392 samples\n",
            "0.9677301\n",
            "Training loss (for one batch) at step 18235: 0.0007\n",
            "Seen so far: 583552 samples\n",
            "0.96773726\n",
            "Training loss (for one batch) at step 18240: 0.0019\n",
            "Seen so far: 583712 samples\n",
            "0.96774095\n",
            "Training loss (for one batch) at step 18245: 0.0117\n",
            "Seen so far: 583872 samples\n",
            "0.96774805\n",
            "Training loss (for one batch) at step 18250: 0.0047\n",
            "Seen so far: 584032 samples\n",
            "0.9677501\n",
            "Training loss (for one batch) at step 18255: 0.1598\n",
            "Seen so far: 584192 samples\n",
            "0.96775377\n",
            "Training loss (for one batch) at step 18260: 0.0034\n",
            "Seen so far: 584352 samples\n",
            "0.96776086\n",
            "Training loss (for one batch) at step 18265: 0.0005\n",
            "Seen so far: 584512 samples\n",
            "0.9677663\n",
            "Training loss (for one batch) at step 18270: 0.0803\n",
            "Seen so far: 584672 samples\n",
            "0.96776825\n",
            "Training loss (for one batch) at step 18275: 0.1052\n",
            "Seen so far: 584832 samples\n",
            "0.9677702\n",
            "Training loss (for one batch) at step 18280: 0.1362\n",
            "Seen so far: 584992 samples\n",
            "0.9677739\n",
            "Training loss (for one batch) at step 18285: 0.0447\n",
            "Seen so far: 585152 samples\n",
            "0.9677776\n",
            "Training loss (for one batch) at step 18290: 0.0049\n",
            "Seen so far: 585312 samples\n",
            "0.9677847\n",
            "Training loss (for one batch) at step 18295: 0.0105\n",
            "Seen so far: 585472 samples\n",
            "0.9677918\n",
            "Training loss (for one batch) at step 18300: 0.1276\n",
            "Seen so far: 585632 samples\n",
            "0.96779716\n",
            "Training loss (for one batch) at step 18305: 0.0029\n",
            "Seen so far: 585792 samples\n",
            "0.96780425\n",
            "Training loss (for one batch) at step 18310: 0.0025\n",
            "Seen so far: 585952 samples\n",
            "0.9678131\n",
            "Training loss (for one batch) at step 18315: 0.3954\n",
            "Seen so far: 586112 samples\n",
            "0.96781844\n",
            "Training loss (for one batch) at step 18320: 0.0277\n",
            "Seen so far: 586272 samples\n",
            "0.9678238\n",
            "Training loss (for one batch) at step 18325: 0.0694\n",
            "Seen so far: 586432 samples\n",
            "0.96782917\n",
            "Training loss (for one batch) at step 18330: 0.1401\n",
            "Seen so far: 586592 samples\n",
            "0.96783453\n",
            "Training loss (for one batch) at step 18335: 0.0319\n",
            "Seen so far: 586752 samples\n",
            "0.9678382\n",
            "Training loss (for one batch) at step 18340: 0.0117\n",
            "Seen so far: 586912 samples\n",
            "0.96784353\n",
            "Training loss (for one batch) at step 18345: 0.0388\n",
            "Seen so far: 587072 samples\n",
            "0.9678472\n",
            "Training loss (for one batch) at step 18350: 0.0004\n",
            "Seen so far: 587232 samples\n",
            "0.96785426\n",
            "Training loss (for one batch) at step 18355: 0.0392\n",
            "Seen so far: 587392 samples\n",
            "0.9678511\n",
            "Training loss (for one batch) at step 18360: 0.0024\n",
            "Seen so far: 587552 samples\n",
            "0.96785986\n",
            "Training loss (for one batch) at step 18365: 0.0061\n",
            "Seen so far: 587712 samples\n",
            "0.9678686\n",
            "Training loss (for one batch) at step 18370: 0.0378\n",
            "Seen so far: 587872 samples\n",
            "0.96787053\n",
            "Training loss (for one batch) at step 18375: 0.0364\n",
            "Seen so far: 588032 samples\n",
            "0.96787417\n",
            "Training loss (for one batch) at step 18380: 0.0550\n",
            "Seen so far: 588192 samples\n",
            "0.96788126\n",
            "Training loss (for one batch) at step 18385: 0.0016\n",
            "Seen so far: 588352 samples\n",
            "0.9678883\n",
            "Training loss (for one batch) at step 18390: 0.0242\n",
            "Seen so far: 588512 samples\n",
            "0.9678953\n",
            "Training loss (for one batch) at step 18395: 0.0032\n",
            "Seen so far: 588672 samples\n",
            "0.96790403\n",
            "Training loss (for one batch) at step 18400: 0.0740\n",
            "Seen so far: 588832 samples\n",
            "0.96791106\n",
            "Training loss (for one batch) at step 18405: 0.0006\n",
            "Seen so far: 588992 samples\n",
            "0.96791977\n",
            "Training loss (for one batch) at step 18410: 0.0834\n",
            "Seen so far: 589152 samples\n",
            "0.9679268\n",
            "Training loss (for one batch) at step 18415: 0.0003\n",
            "Seen so far: 589312 samples\n",
            "0.9679338\n",
            "Training loss (for one batch) at step 18420: 0.0218\n",
            "Seen so far: 589472 samples\n",
            "0.9679425\n",
            "Training loss (for one batch) at step 18425: 0.0003\n",
            "Seen so far: 589632 samples\n",
            "0.9679478\n",
            "Training loss (for one batch) at step 18430: 0.0964\n",
            "Seen so far: 589792 samples\n",
            "0.9679514\n",
            "Training loss (for one batch) at step 18435: 0.0008\n",
            "Seen so far: 589952 samples\n",
            "0.9679567\n",
            "Training loss (for one batch) at step 18440: 0.0062\n",
            "Seen so far: 590112 samples\n",
            "0.9679637\n",
            "Training loss (for one batch) at step 18445: 0.0071\n",
            "Seen so far: 590272 samples\n",
            "0.967969\n",
            "Training loss (for one batch) at step 18450: 0.0035\n",
            "Seen so far: 590432 samples\n",
            "0.967976\n",
            "Training loss (for one batch) at step 18455: 0.0014\n",
            "Seen so far: 590592 samples\n",
            "0.9679847\n",
            "Training loss (for one batch) at step 18460: 0.0005\n",
            "Seen so far: 590752 samples\n",
            "0.96799165\n",
            "Training loss (for one batch) at step 18465: 0.0018\n",
            "Seen so far: 590912 samples\n",
            "0.9679952\n",
            "Training loss (for one batch) at step 18470: 0.0250\n",
            "Seen so far: 591072 samples\n",
            "0.9680022\n",
            "Training loss (for one batch) at step 18475: 0.0376\n",
            "Seen so far: 591232 samples\n",
            "0.9680092\n",
            "Training loss (for one batch) at step 18480: 0.0017\n",
            "Seen so far: 591392 samples\n",
            "0.96801275\n",
            "Training loss (for one batch) at step 18485: 0.0004\n",
            "Seen so far: 591552 samples\n",
            "0.96801805\n",
            "Training loss (for one batch) at step 18490: 0.0523\n",
            "Seen so far: 591712 samples\n",
            "0.96802163\n",
            "Training loss (for one batch) at step 18495: 0.2398\n",
            "Seen so far: 591872 samples\n",
            "0.96802855\n",
            "Training loss (for one batch) at step 18500: 0.0183\n",
            "Seen so far: 592032 samples\n",
            "0.96803385\n",
            "Training loss (for one batch) at step 18505: 0.0051\n",
            "Seen so far: 592192 samples\n",
            "0.9680357\n",
            "Training loss (for one batch) at step 18510: 0.0329\n",
            "Seen so far: 592352 samples\n",
            "0.9680427\n",
            "Training loss (for one batch) at step 18515: 0.1827\n",
            "Seen so far: 592512 samples\n",
            "0.9680445\n",
            "Training loss (for one batch) at step 18520: 0.0002\n",
            "Seen so far: 592672 samples\n",
            "0.9680464\n",
            "Training loss (for one batch) at step 18525: 0.0175\n",
            "Seen so far: 592832 samples\n",
            "0.9680517\n",
            "Training loss (for one batch) at step 18530: 0.2922\n",
            "Seen so far: 592992 samples\n",
            "0.9680569\n",
            "Training loss (for one batch) at step 18535: 0.0047\n",
            "Seen so far: 593152 samples\n",
            "0.96806383\n",
            "Training loss (for one batch) at step 18540: 0.1046\n",
            "Seen so far: 593312 samples\n",
            "0.9680691\n",
            "Training loss (for one batch) at step 18545: 0.0006\n",
            "Seen so far: 593472 samples\n",
            "0.9680743\n",
            "Training loss (for one batch) at step 18550: 0.1437\n",
            "Seen so far: 593632 samples\n",
            "0.96807617\n",
            "Training loss (for one batch) at step 18555: 0.0001\n",
            "Seen so far: 593792 samples\n",
            "0.9680848\n",
            "Training loss (for one batch) at step 18560: 0.0746\n",
            "Seen so far: 593952 samples\n",
            "0.96809\n",
            "Training loss (for one batch) at step 18565: 0.1803\n",
            "Seen so far: 594112 samples\n",
            "0.96809524\n",
            "Training loss (for one batch) at step 18570: 0.0049\n",
            "Seen so far: 594272 samples\n",
            "0.9681005\n",
            "Training loss (for one batch) at step 18575: 0.0023\n",
            "Seen so far: 594432 samples\n",
            "0.96810234\n",
            "Training loss (for one batch) at step 18580: 0.0015\n",
            "Seen so far: 594592 samples\n",
            "0.9681042\n",
            "Training loss (for one batch) at step 18585: 0.0091\n",
            "Seen so far: 594752 samples\n",
            "0.9681111\n",
            "Training loss (for one batch) at step 18590: 0.0386\n",
            "Seen so far: 594912 samples\n",
            "0.96811795\n",
            "Training loss (for one batch) at step 18595: 0.0134\n",
            "Seen so far: 595072 samples\n",
            "0.96812487\n",
            "Training loss (for one batch) at step 18600: 0.0186\n",
            "Seen so far: 595232 samples\n",
            "0.96813345\n",
            "Training loss (for one batch) at step 18605: 0.0086\n",
            "Seen so far: 595392 samples\n",
            "0.96813697\n",
            "Training loss (for one batch) at step 18610: 0.0005\n",
            "Seen so far: 595552 samples\n",
            "0.9681405\n",
            "Training loss (for one batch) at step 18615: 0.0351\n",
            "Seen so far: 595712 samples\n",
            "0.96814233\n",
            "Training loss (for one batch) at step 18620: 0.0113\n",
            "Seen so far: 595872 samples\n",
            "0.96815085\n",
            "Training loss (for one batch) at step 18625: 0.0012\n",
            "Seen so far: 596032 samples\n",
            "0.9681544\n",
            "Training loss (for one batch) at step 18630: 0.4060\n",
            "Seen so far: 596192 samples\n",
            "0.9681479\n",
            "Training loss (for one batch) at step 18635: 0.0060\n",
            "Seen so far: 596352 samples\n",
            "0.9681547\n",
            "Training loss (for one batch) at step 18640: 0.0111\n",
            "Seen so far: 596512 samples\n",
            "0.96816325\n",
            "Training loss (for one batch) at step 18645: 0.0064\n",
            "Seen so far: 596672 samples\n",
            "0.96816844\n",
            "Training loss (for one batch) at step 18650: 0.0075\n",
            "Seen so far: 596832 samples\n",
            "0.9681753\n",
            "Training loss (for one batch) at step 18655: 0.0068\n",
            "Seen so far: 596992 samples\n",
            "0.96818215\n",
            "Training loss (for one batch) at step 18660: 0.0095\n",
            "Seen so far: 597152 samples\n",
            "0.96818566\n",
            "Training loss (for one batch) at step 18665: 0.0016\n",
            "Seen so far: 597312 samples\n",
            "0.96819085\n",
            "Training loss (for one batch) at step 18670: 0.0022\n",
            "Seen so far: 597472 samples\n",
            "0.96819764\n",
            "Training loss (for one batch) at step 18675: 0.0005\n",
            "Seen so far: 597632 samples\n",
            "0.96820116\n",
            "Training loss (for one batch) at step 18680: 0.0088\n",
            "Seen so far: 597792 samples\n",
            "0.96820635\n",
            "Training loss (for one batch) at step 18685: 0.0024\n",
            "Seen so far: 597952 samples\n",
            "0.9682098\n",
            "Training loss (for one batch) at step 18690: 0.1419\n",
            "Seen so far: 598112 samples\n",
            "0.9682133\n",
            "Training loss (for one batch) at step 18695: 0.0002\n",
            "Seen so far: 598272 samples\n",
            "0.9682201\n",
            "Training loss (for one batch) at step 18700: 0.0009\n",
            "Seen so far: 598432 samples\n",
            "0.96822864\n",
            "Training loss (for one batch) at step 18705: 0.0727\n",
            "Seen so far: 598592 samples\n",
            "0.96823376\n",
            "Training loss (for one batch) at step 18710: 0.0002\n",
            "Seen so far: 598752 samples\n",
            "0.9682373\n",
            "Training loss (for one batch) at step 18715: 0.0249\n",
            "Seen so far: 598912 samples\n",
            "0.9682424\n",
            "Training loss (for one batch) at step 18720: 0.2756\n",
            "Seen so far: 599072 samples\n",
            "0.9682442\n",
            "Training loss (for one batch) at step 18725: 0.1384\n",
            "Seen so far: 599232 samples\n",
            "0.9682477\n",
            "Training loss (for one batch) at step 18730: 0.0006\n",
            "Seen so far: 599392 samples\n",
            "0.9682545\n",
            "Training loss (for one batch) at step 18735: 0.0029\n",
            "Seen so far: 599552 samples\n",
            "0.96825963\n",
            "Training loss (for one batch) at step 18740: 0.0080\n",
            "Seen so far: 599712 samples\n",
            "0.96826476\n",
            "Training loss (for one batch) at step 18745: 0.0261\n",
            "Seen so far: 599872 samples\n",
            "0.96827155\n",
            "Training loss (for one batch) at step 18750: 0.0229\n",
            "Seen so far: 600032 samples\n",
            "0.968275\n",
            "Training loss (for one batch) at step 18755: 0.0001\n",
            "Seen so far: 600192 samples\n",
            "0.9682768\n",
            "Training loss (for one batch) at step 18760: 0.0033\n",
            "Seen so far: 600352 samples\n",
            "0.9682819\n",
            "Training loss (for one batch) at step 18765: 0.0011\n",
            "Seen so far: 600512 samples\n",
            "0.9682904\n",
            "Training loss (for one batch) at step 18770: 0.0413\n",
            "Seen so far: 600672 samples\n",
            "0.9682905\n",
            "Training loss (for one batch) at step 18775: 0.0299\n",
            "Seen so far: 600832 samples\n",
            "0.96829563\n",
            "Training loss (for one batch) at step 18780: 0.1774\n",
            "Seen so far: 600992 samples\n",
            "0.96830076\n",
            "Training loss (for one batch) at step 18785: 0.1914\n",
            "Seen so far: 601152 samples\n",
            "0.9683042\n",
            "Training loss (for one batch) at step 18790: 0.0019\n",
            "Seen so far: 601312 samples\n",
            "0.9683093\n",
            "Training loss (for one batch) at step 18795: 0.0004\n",
            "Seen so far: 601472 samples\n",
            "0.9683161\n",
            "Training loss (for one batch) at step 18800: 0.0252\n",
            "Seen so far: 601632 samples\n",
            "0.96832114\n",
            "Training loss (for one batch) at step 18805: 0.0250\n",
            "Seen so far: 601792 samples\n",
            "0.96832794\n",
            "Training loss (for one batch) at step 18810: 0.0004\n",
            "Seen so far: 601952 samples\n",
            "0.9683297\n",
            "Training loss (for one batch) at step 18815: 0.0293\n",
            "Seen so far: 602112 samples\n",
            "0.96833646\n",
            "Training loss (for one batch) at step 18820: 0.1399\n",
            "Seen so far: 602272 samples\n",
            "0.96833825\n",
            "Training loss (for one batch) at step 18825: 0.0025\n",
            "Seen so far: 602432 samples\n",
            "0.96834165\n",
            "Training loss (for one batch) at step 18830: 0.0048\n",
            "Seen so far: 602592 samples\n",
            "0.9683484\n",
            "Training loss (for one batch) at step 18835: 0.0137\n",
            "Seen so far: 602752 samples\n",
            "0.9683535\n",
            "Training loss (for one batch) at step 18840: 0.0009\n",
            "Seen so far: 602912 samples\n",
            "0.96835524\n",
            "Training loss (for one batch) at step 18845: 0.0171\n",
            "Seen so far: 603072 samples\n",
            "0.968362\n",
            "Training loss (for one batch) at step 18850: 0.2044\n",
            "Seen so far: 603232 samples\n",
            "0.96835715\n",
            "Training loss (for one batch) at step 18855: 0.0079\n",
            "Seen so far: 603392 samples\n",
            "0.96836054\n",
            "Training loss (for one batch) at step 18860: 0.3418\n",
            "Seen so far: 603552 samples\n",
            "0.96835566\n",
            "Training loss (for one batch) at step 18865: 0.3555\n",
            "Seen so far: 603712 samples\n",
            "0.96834916\n",
            "Training loss (for one batch) at step 18870: 0.3516\n",
            "Seen so far: 603872 samples\n",
            "0.968341\n",
            "Training loss (for one batch) at step 18875: 0.0271\n",
            "Seen so far: 604032 samples\n",
            "0.9683361\n",
            "Training loss (for one batch) at step 18880: 0.0646\n",
            "Seen so far: 604192 samples\n",
            "0.9683362\n",
            "Training loss (for one batch) at step 18885: 0.0102\n",
            "Seen so far: 604352 samples\n",
            "0.96833634\n",
            "Training loss (for one batch) at step 18890: 0.0042\n",
            "Seen so far: 604512 samples\n",
            "0.9683414\n",
            "Training loss (for one batch) at step 18895: 0.1255\n",
            "Seen so far: 604672 samples\n",
            "0.96834314\n",
            "Training loss (for one batch) at step 18900: 0.2155\n",
            "Seen so far: 604832 samples\n",
            "0.96833664\n",
            "Training loss (for one batch) at step 18905: 0.0093\n",
            "Seen so far: 604992 samples\n",
            "0.9683401\n",
            "Training loss (for one batch) at step 18910: 0.0430\n",
            "Seen so far: 605152 samples\n",
            "0.9683435\n",
            "Training loss (for one batch) at step 18915: 0.0016\n",
            "Seen so far: 605312 samples\n",
            "0.96834856\n",
            "Training loss (for one batch) at step 18920: 0.0059\n",
            "Seen so far: 605472 samples\n",
            "0.9683503\n",
            "Training loss (for one batch) at step 18925: 0.0627\n",
            "Seen so far: 605632 samples\n",
            "0.96835375\n",
            "Training loss (for one batch) at step 18930: 0.2165\n",
            "Seen so far: 605792 samples\n",
            "0.96834886\n",
            "Training loss (for one batch) at step 18935: 0.1541\n",
            "Seen so far: 605952 samples\n",
            "0.9683473\n",
            "Training loss (for one batch) at step 18940: 0.0337\n",
            "Seen so far: 606112 samples\n",
            "0.9683491\n",
            "Training loss (for one batch) at step 18945: 0.0926\n",
            "Seen so far: 606272 samples\n",
            "0.9683492\n",
            "Training loss (for one batch) at step 18950: 0.0064\n",
            "Seen so far: 606432 samples\n",
            "0.9683526\n",
            "Training loss (for one batch) at step 18955: 0.2353\n",
            "Seen so far: 606592 samples\n",
            "0.96835434\n",
            "Training loss (for one batch) at step 18960: 0.0834\n",
            "Seen so far: 606752 samples\n",
            "0.96835774\n",
            "Training loss (for one batch) at step 18965: 0.0225\n",
            "Seen so far: 606912 samples\n",
            "0.9683644\n",
            "Training loss (for one batch) at step 18970: 0.1842\n",
            "Seen so far: 607072 samples\n",
            "0.96836454\n",
            "Training loss (for one batch) at step 18975: 0.0627\n",
            "Seen so far: 607232 samples\n",
            "0.96836793\n",
            "Training loss (for one batch) at step 18980: 0.0230\n",
            "Seen so far: 607392 samples\n",
            "0.968373\n",
            "Training loss (for one batch) at step 18985: 0.1230\n",
            "Seen so far: 607552 samples\n",
            "0.968378\n",
            "Training loss (for one batch) at step 18990: 0.0034\n",
            "Seen so far: 607712 samples\n",
            "0.9683781\n",
            "Training loss (for one batch) at step 18995: 0.0343\n",
            "Seen so far: 607872 samples\n",
            "0.9683815\n",
            "Training loss (for one batch) at step 19000: 0.0001\n",
            "Seen so far: 608032 samples\n",
            "0.96838653\n",
            "Training loss (for one batch) at step 19005: 0.0009\n",
            "Seen so far: 608192 samples\n",
            "0.96838826\n",
            "Training loss (for one batch) at step 19010: 0.0696\n",
            "Seen so far: 608352 samples\n",
            "0.96839\n",
            "Training loss (for one batch) at step 19015: 0.2499\n",
            "Seen so far: 608512 samples\n",
            "0.96838844\n",
            "Training loss (for one batch) at step 19020: 0.0355\n",
            "Seen so far: 608672 samples\n",
            "0.96839184\n",
            "Training loss (for one batch) at step 19025: 0.0156\n",
            "Seen so far: 608832 samples\n",
            "0.96839684\n",
            "Training loss (for one batch) at step 19030: 0.0045\n",
            "Seen so far: 608992 samples\n",
            "0.96839696\n",
            "Training loss (for one batch) at step 19035: 0.0004\n",
            "Seen so far: 609152 samples\n",
            "0.96840364\n",
            "Training loss (for one batch) at step 19040: 0.0179\n",
            "Seen so far: 609312 samples\n",
            "0.96841025\n",
            "Training loss (for one batch) at step 19045: 0.0247\n",
            "Seen so far: 609472 samples\n",
            "0.968412\n",
            "Training loss (for one batch) at step 19050: 0.0005\n",
            "Seen so far: 609632 samples\n",
            "0.968417\n",
            "Training loss (for one batch) at step 19055: 0.0778\n",
            "Seen so far: 609792 samples\n",
            "0.9684187\n",
            "Training loss (for one batch) at step 19060: 0.0004\n",
            "Seen so far: 609952 samples\n",
            "0.9684221\n",
            "Training loss (for one batch) at step 19065: 0.0008\n",
            "Seen so far: 610112 samples\n",
            "0.96842545\n",
            "Training loss (for one batch) at step 19070: 0.0811\n",
            "Seen so far: 610272 samples\n",
            "0.9684256\n",
            "Training loss (for one batch) at step 19075: 0.1252\n",
            "Seen so far: 610432 samples\n",
            "0.9684273\n",
            "Training loss (for one batch) at step 19080: 0.1384\n",
            "Seen so far: 610592 samples\n",
            "0.96843064\n",
            "Training loss (for one batch) at step 19085: 0.9077\n",
            "Seen so far: 610752 samples\n",
            "0.96843237\n",
            "Training loss (for one batch) at step 19090: 0.0386\n",
            "Seen so far: 610912 samples\n",
            "0.9684341\n",
            "Training loss (for one batch) at step 19095: 0.8160\n",
            "Seen so far: 611072 samples\n",
            "0.96843255\n",
            "Training loss (for one batch) at step 19100: 0.1576\n",
            "Seen so far: 611232 samples\n",
            "0.9684293\n",
            "Training loss (for one batch) at step 19105: 0.2727\n",
            "Seen so far: 611392 samples\n",
            "0.96843266\n",
            "Training loss (for one batch) at step 19110: 0.0142\n",
            "Seen so far: 611552 samples\n",
            "0.9684279\n",
            "Training loss (for one batch) at step 19115: 0.7609\n",
            "Seen so far: 611712 samples\n",
            "0.9684165\n",
            "Training loss (for one batch) at step 19120: 0.0018\n",
            "Seen so far: 611872 samples\n",
            "0.9684215\n",
            "Training loss (for one batch) at step 19125: 0.0834\n",
            "Seen so far: 612032 samples\n",
            "0.9684183\n",
            "Training loss (for one batch) at step 19130: 0.2900\n",
            "Seen so far: 612192 samples\n",
            "0.96841514\n",
            "Training loss (for one batch) at step 19135: 0.0212\n",
            "Seen so far: 612352 samples\n",
            "0.96841687\n",
            "Training loss (for one batch) at step 19140: 0.3653\n",
            "Seen so far: 612512 samples\n",
            "0.96840876\n",
            "Training loss (for one batch) at step 19145: 0.1564\n",
            "Seen so far: 612672 samples\n",
            "0.9684023\n",
            "Training loss (for one batch) at step 19150: 0.0062\n",
            "Seen so far: 612832 samples\n",
            "0.96840894\n",
            "Training loss (for one batch) at step 19155: 0.0821\n",
            "Seen so far: 612992 samples\n",
            "0.9684058\n",
            "Training loss (for one batch) at step 19160: 0.1577\n",
            "Seen so far: 613152 samples\n",
            "0.9684075\n",
            "Training loss (for one batch) at step 19165: 0.0835\n",
            "Seen so far: 613312 samples\n",
            "0.9684011\n",
            "Training loss (for one batch) at step 19170: 1.0740\n",
            "Seen so far: 613472 samples\n",
            "0.96839136\n",
            "Training loss (for one batch) at step 19175: 0.6983\n",
            "Seen so far: 613632 samples\n",
            "0.9683801\n",
            "Training loss (for one batch) at step 19180: 0.0087\n",
            "Seen so far: 613792 samples\n",
            "0.96837366\n",
            "Training loss (for one batch) at step 19185: 0.2328\n",
            "Seen so far: 613952 samples\n",
            "0.9683656\n",
            "Training loss (for one batch) at step 19190: 0.3282\n",
            "Seen so far: 614112 samples\n",
            "0.96836406\n",
            "Training loss (for one batch) at step 19195: 0.0143\n",
            "Seen so far: 614272 samples\n",
            "0.9683658\n",
            "Training loss (for one batch) at step 19200: 0.2636\n",
            "Seen so far: 614432 samples\n",
            "0.9683643\n",
            "Training loss (for one batch) at step 19205: 0.0709\n",
            "Seen so far: 614592 samples\n",
            "0.96836925\n",
            "Training loss (for one batch) at step 19210: 0.0227\n",
            "Seen so far: 614752 samples\n",
            "0.96837586\n",
            "Training loss (for one batch) at step 19215: 0.0038\n",
            "Seen so far: 614912 samples\n",
            "0.96838087\n",
            "Training loss (for one batch) at step 19220: 0.0028\n",
            "Seen so far: 615072 samples\n",
            "0.9683809\n",
            "Training loss (for one batch) at step 19225: 0.0109\n",
            "Seen so far: 615232 samples\n",
            "0.96838266\n",
            "Training loss (for one batch) at step 19230: 0.1440\n",
            "Seen so far: 615392 samples\n",
            "0.9683811\n",
            "Training loss (for one batch) at step 19235: 0.6436\n",
            "Seen so far: 615552 samples\n",
            "0.96837795\n",
            "Training loss (for one batch) at step 19240: 0.1303\n",
            "Seen so far: 615712 samples\n",
            "0.9683797\n",
            "Training loss (for one batch) at step 19245: 0.0050\n",
            "Seen so far: 615872 samples\n",
            "0.968383\n",
            "Training loss (for one batch) at step 19250: 0.0101\n",
            "Seen so far: 616032 samples\n",
            "0.968388\n",
            "Training loss (for one batch) at step 19255: 0.0372\n",
            "Seen so far: 616192 samples\n",
            "0.96839136\n",
            "Training loss (for one batch) at step 19260: 0.0563\n",
            "Seen so far: 616352 samples\n",
            "0.9683979\n",
            "Training loss (for one batch) at step 19265: 0.0444\n",
            "Seen so far: 616512 samples\n",
            "0.96840453\n",
            "Training loss (for one batch) at step 19270: 0.1800\n",
            "Seen so far: 616672 samples\n",
            "0.9684062\n",
            "Training loss (for one batch) at step 19275: 0.3410\n",
            "Seen so far: 616832 samples\n",
            "0.96840304\n",
            "Training loss (for one batch) at step 19280: 0.0533\n",
            "Seen so far: 616992 samples\n",
            "0.96840477\n",
            "Training loss (for one batch) at step 19285: 0.2115\n",
            "Seen so far: 617152 samples\n",
            "0.9684065\n",
            "Training loss (for one batch) at step 19290: 0.0013\n",
            "Seen so far: 617312 samples\n",
            "0.96841305\n",
            "Training loss (for one batch) at step 19295: 0.0168\n",
            "Seen so far: 617472 samples\n",
            "0.9684148\n",
            "Training loss (for one batch) at step 19300: 0.2268\n",
            "Seen so far: 617632 samples\n",
            "0.96841973\n",
            "Training loss (for one batch) at step 19305: 0.0770\n",
            "Seen so far: 617792 samples\n",
            "0.9684166\n",
            "Training loss (for one batch) at step 19310: 0.1090\n",
            "Seen so far: 617952 samples\n",
            "0.96841985\n",
            "Training loss (for one batch) at step 19315: 0.1114\n",
            "Seen so far: 618112 samples\n",
            "0.9684248\n",
            "Training loss (for one batch) at step 19320: 0.0604\n",
            "Seen so far: 618272 samples\n",
            "0.9684249\n",
            "Training loss (for one batch) at step 19325: 0.0626\n",
            "Seen so far: 618432 samples\n",
            "0.96842337\n",
            "Training loss (for one batch) at step 19330: 0.0200\n",
            "Seen so far: 618592 samples\n",
            "0.9684202\n",
            "Training loss (for one batch) at step 19335: 0.1048\n",
            "Seen so far: 618752 samples\n",
            "0.96842194\n",
            "Training loss (for one batch) at step 19340: 0.0003\n",
            "Seen so far: 618912 samples\n",
            "0.9684268\n",
            "Training loss (for one batch) at step 19345: 0.0033\n",
            "Seen so far: 619072 samples\n",
            "0.96843016\n",
            "Training loss (for one batch) at step 19350: 0.0020\n",
            "Seen so far: 619232 samples\n",
            "0.9684302\n",
            "Training loss (for one batch) at step 19355: 0.0203\n",
            "Seen so far: 619392 samples\n",
            "0.9684255\n",
            "Training loss (for one batch) at step 19360: 0.0911\n",
            "Seen so far: 619552 samples\n",
            "0.968432\n",
            "Training loss (for one batch) at step 19365: 0.0475\n",
            "Seen so far: 619712 samples\n",
            "0.9684321\n",
            "Training loss (for one batch) at step 19370: 0.0046\n",
            "Seen so far: 619872 samples\n",
            "0.968437\n",
            "Training loss (for one batch) at step 19375: 0.0076\n",
            "Seen so far: 620032 samples\n",
            "0.96844196\n",
            "Training loss (for one batch) at step 19380: 0.3278\n",
            "Seen so far: 620192 samples\n",
            "0.96844363\n",
            "Training loss (for one batch) at step 19385: 0.0048\n",
            "Seen so far: 620352 samples\n",
            "0.96844536\n",
            "Training loss (for one batch) at step 19390: 0.0024\n",
            "Seen so far: 620512 samples\n",
            "0.96845186\n",
            "Training loss (for one batch) at step 19395: 0.4678\n",
            "Seen so far: 620672 samples\n",
            "0.9684519\n",
            "Training loss (for one batch) at step 19400: 0.0018\n",
            "Seen so far: 620832 samples\n",
            "0.96845686\n",
            "Training loss (for one batch) at step 19405: 0.0646\n",
            "Seen so far: 620992 samples\n",
            "0.96846014\n",
            "Training loss (for one batch) at step 19410: 0.0001\n",
            "Seen so far: 621152 samples\n",
            "0.96846503\n",
            "Training loss (for one batch) at step 19415: 0.0648\n",
            "Seen so far: 621312 samples\n",
            "0.9684651\n",
            "Training loss (for one batch) at step 19420: 0.0035\n",
            "Seen so far: 621472 samples\n",
            "0.96847004\n",
            "Training loss (for one batch) at step 19425: 0.0016\n",
            "Seen so far: 621632 samples\n",
            "0.9684733\n",
            "Training loss (for one batch) at step 19430: 0.0026\n",
            "Seen so far: 621792 samples\n",
            "0.9684798\n",
            "Training loss (for one batch) at step 19435: 0.0042\n",
            "Seen so far: 621952 samples\n",
            "0.9684863\n",
            "Training loss (for one batch) at step 19440: 0.1512\n",
            "Seen so far: 622112 samples\n",
            "0.968488\n",
            "Training loss (for one batch) at step 19445: 0.0286\n",
            "Seen so far: 622272 samples\n",
            "0.96848965\n",
            "Training loss (for one batch) at step 19450: 0.1598\n",
            "Seen so far: 622432 samples\n",
            "0.9684913\n",
            "Training loss (for one batch) at step 19455: 0.0820\n",
            "Seen so far: 622592 samples\n",
            "0.9684946\n",
            "Training loss (for one batch) at step 19460: 0.0454\n",
            "Seen so far: 622752 samples\n",
            "0.96849626\n",
            "Training loss (for one batch) at step 19465: 0.1370\n",
            "Seen so far: 622912 samples\n",
            "0.9684964\n",
            "Training loss (for one batch) at step 19470: 0.0059\n",
            "Seen so far: 623072 samples\n",
            "0.9685012\n",
            "Training loss (for one batch) at step 19475: 0.0157\n",
            "Seen so far: 623232 samples\n",
            "0.9685061\n",
            "Training loss (for one batch) at step 19480: 0.0046\n",
            "Seen so far: 623392 samples\n",
            "0.968511\n",
            "Training loss (for one batch) at step 19485: 0.0007\n",
            "Seen so far: 623552 samples\n",
            "0.9685175\n",
            "Training loss (for one batch) at step 19490: 0.0091\n",
            "Seen so far: 623712 samples\n",
            "0.9685223\n",
            "Training loss (for one batch) at step 19495: 0.1755\n",
            "Seen so far: 623872 samples\n",
            "0.9685256\n",
            "Training loss (for one batch) at step 19500: 0.0010\n",
            "Seen so far: 624032 samples\n",
            "0.96852726\n",
            "Training loss (for one batch) at step 19505: 0.0104\n",
            "Seen so far: 624192 samples\n",
            "0.96853215\n",
            "Training loss (for one batch) at step 19510: 0.0091\n",
            "Seen so far: 624352 samples\n",
            "0.96853536\n",
            "Training loss (for one batch) at step 19515: 0.0539\n",
            "Seen so far: 624512 samples\n",
            "0.96853703\n",
            "Training loss (for one batch) at step 19520: 0.0012\n",
            "Seen so far: 624672 samples\n",
            "0.96854347\n",
            "Training loss (for one batch) at step 19525: 0.2447\n",
            "Seen so far: 624832 samples\n",
            "0.9685435\n",
            "Training loss (for one batch) at step 19530: 0.0002\n",
            "Seen so far: 624992 samples\n",
            "0.9685484\n",
            "Training loss (for one batch) at step 19535: 0.1178\n",
            "Seen so far: 625152 samples\n",
            "0.96855\n",
            "Training loss (for one batch) at step 19540: 0.0074\n",
            "Seen so far: 625312 samples\n",
            "0.9685517\n",
            "Training loss (for one batch) at step 19545: 0.0019\n",
            "Seen so far: 625472 samples\n",
            "0.96855813\n",
            "Training loss (for one batch) at step 19550: 0.0030\n",
            "Seen so far: 625632 samples\n",
            "0.96856296\n",
            "Training loss (for one batch) at step 19555: 0.0004\n",
            "Seen so far: 625792 samples\n",
            "0.96856946\n",
            "Training loss (for one batch) at step 19560: 0.0031\n",
            "Seen so far: 625952 samples\n",
            "0.9685759\n",
            "Training loss (for one batch) at step 19565: 0.0853\n",
            "Seen so far: 626112 samples\n",
            "0.9685807\n",
            "Training loss (for one batch) at step 19570: 0.0141\n",
            "Seen so far: 626272 samples\n",
            "0.96858555\n",
            "Training loss (for one batch) at step 19575: 0.0002\n",
            "Seen so far: 626432 samples\n",
            "0.968592\n",
            "Training loss (for one batch) at step 19580: 0.0018\n",
            "Seen so far: 626592 samples\n",
            "0.9686\n",
            "Training loss (for one batch) at step 19585: 0.0000\n",
            "Seen so far: 626752 samples\n",
            "0.9686064\n",
            "Training loss (for one batch) at step 19590: 0.0024\n",
            "Seen so far: 626912 samples\n",
            "0.96861124\n",
            "Training loss (for one batch) at step 19595: 0.2685\n",
            "Seen so far: 627072 samples\n",
            "0.96861446\n",
            "Training loss (for one batch) at step 19600: 0.0051\n",
            "Seen so far: 627232 samples\n",
            "0.9686193\n",
            "Training loss (for one batch) at step 19605: 0.0035\n",
            "Seen so far: 627392 samples\n",
            "0.9686273\n",
            "Training loss (for one batch) at step 19610: 0.0017\n",
            "Seen so far: 627552 samples\n",
            "0.96863365\n",
            "Training loss (for one batch) at step 19615: 0.0678\n",
            "Seen so far: 627712 samples\n",
            "0.9686353\n",
            "Training loss (for one batch) at step 19620: 0.0274\n",
            "Seen so far: 627872 samples\n",
            "0.9686401\n",
            "Training loss (for one batch) at step 19625: 0.1093\n",
            "Seen so far: 628032 samples\n",
            "0.9686449\n",
            "Training loss (for one batch) at step 19630: 0.0049\n",
            "Seen so far: 628192 samples\n",
            "0.9686513\n",
            "Training loss (for one batch) at step 19635: 0.0017\n",
            "Seen so far: 628352 samples\n",
            "0.9686545\n",
            "Training loss (for one batch) at step 19640: 0.0005\n",
            "Seen so far: 628512 samples\n",
            "0.9686625\n",
            "Training loss (for one batch) at step 19645: 0.0026\n",
            "Seen so far: 628672 samples\n",
            "0.9686689\n",
            "Training loss (for one batch) at step 19650: 0.0140\n",
            "Seen so far: 628832 samples\n",
            "0.96867687\n",
            "Training loss (for one batch) at step 19655: 0.0000\n",
            "Seen so far: 628992 samples\n",
            "0.96868324\n",
            "Training loss (for one batch) at step 19660: 0.0004\n",
            "Seen so far: 629152 samples\n",
            "0.9686896\n",
            "Training loss (for one batch) at step 19665: 0.0169\n",
            "Seen so far: 629312 samples\n",
            "0.968696\n",
            "Training loss (for one batch) at step 19670: 0.0022\n",
            "Seen so far: 629472 samples\n",
            "0.9687023\n",
            "Training loss (for one batch) at step 19675: 0.2563\n",
            "Seen so far: 629632 samples\n",
            "0.96870553\n",
            "Training loss (for one batch) at step 19680: 0.0021\n",
            "Seen so far: 629792 samples\n",
            "0.96871346\n",
            "Training loss (for one batch) at step 19685: 0.0020\n",
            "Seen so far: 629952 samples\n",
            "0.96872145\n",
            "Training loss (for one batch) at step 19690: 0.0020\n",
            "Seen so far: 630112 samples\n",
            "0.968723\n",
            "Training loss (for one batch) at step 19695: 0.0011\n",
            "Seen so far: 630272 samples\n",
            "0.9687294\n",
            "Training loss (for one batch) at step 19700: 0.1544\n",
            "Seen so far: 630432 samples\n",
            "0.96873254\n",
            "Training loss (for one batch) at step 19705: 0.0055\n",
            "Seen so far: 630592 samples\n",
            "0.9687373\n",
            "Training loss (for one batch) at step 19710: 0.0037\n",
            "Seen so far: 630752 samples\n",
            "0.9687421\n",
            "Training loss (for one batch) at step 19715: 0.0085\n",
            "Seen so far: 630912 samples\n",
            "0.9687437\n",
            "Training loss (for one batch) at step 19720: 0.0019\n",
            "Seen so far: 631072 samples\n",
            "0.96874684\n",
            "Training loss (for one batch) at step 19725: 0.0336\n",
            "Seen so far: 631232 samples\n",
            "0.96875316\n",
            "Training loss (for one batch) at step 19730: 0.0090\n",
            "Seen so far: 631392 samples\n",
            "0.9687595\n",
            "Training loss (for one batch) at step 19735: 0.0003\n",
            "Seen so far: 631552 samples\n",
            "0.96876425\n",
            "Training loss (for one batch) at step 19740: 0.0104\n",
            "Seen so far: 631712 samples\n",
            "0.96877056\n",
            "Training loss (for one batch) at step 19745: 0.0002\n",
            "Seen so far: 631872 samples\n",
            "0.9687769\n",
            "Training loss (for one batch) at step 19750: 0.1013\n",
            "Seen so far: 632032 samples\n",
            "0.96878004\n",
            "Training loss (for one batch) at step 19755: 0.0289\n",
            "Seen so far: 632192 samples\n",
            "0.96878636\n",
            "Training loss (for one batch) at step 19760: 0.1700\n",
            "Seen so far: 632352 samples\n",
            "0.9687911\n",
            "Training loss (for one batch) at step 19765: 0.0929\n",
            "Seen so far: 632512 samples\n",
            "0.96879584\n",
            "Training loss (for one batch) at step 19770: 0.0040\n",
            "Seen so far: 632672 samples\n",
            "0.9688006\n",
            "Training loss (for one batch) at step 19775: 0.0020\n",
            "Seen so far: 632832 samples\n",
            "0.9688085\n",
            "Training loss (for one batch) at step 19780: 0.2011\n",
            "Seen so far: 632992 samples\n",
            "0.9688085\n",
            "Training loss (for one batch) at step 19785: 0.0033\n",
            "Seen so far: 633152 samples\n",
            "0.96881473\n",
            "Training loss (for one batch) at step 19790: 0.0173\n",
            "Seen so far: 633312 samples\n",
            "0.96882105\n",
            "Training loss (for one batch) at step 19795: 0.0002\n",
            "Seen so far: 633472 samples\n",
            "0.96882576\n",
            "Training loss (for one batch) at step 19800: 0.1208\n",
            "Seen so far: 633632 samples\n",
            "0.9688289\n",
            "Training loss (for one batch) at step 19805: 0.0605\n",
            "Seen so far: 633792 samples\n",
            "0.9688273\n",
            "Training loss (for one batch) at step 19810: 0.0250\n",
            "Seen so far: 633952 samples\n",
            "0.968832\n",
            "Training loss (for one batch) at step 19815: 0.0018\n",
            "Seen so far: 634112 samples\n",
            "0.9688352\n",
            "Training loss (for one batch) at step 19820: 0.0003\n",
            "Seen so far: 634272 samples\n",
            "0.96884143\n",
            "Training loss (for one batch) at step 19825: 0.0284\n",
            "Seen so far: 634432 samples\n",
            "0.96884775\n",
            "Training loss (for one batch) at step 19830: 0.0008\n",
            "Seen so far: 634592 samples\n",
            "0.9688524\n",
            "Training loss (for one batch) at step 19835: 0.1598\n",
            "Seen so far: 634752 samples\n",
            "0.9688571\n",
            "Training loss (for one batch) at step 19840: 0.0014\n",
            "Seen so far: 634912 samples\n",
            "0.968865\n",
            "Training loss (for one batch) at step 19845: 0.0882\n",
            "Seen so far: 635072 samples\n",
            "0.9688697\n",
            "Training loss (for one batch) at step 19850: 0.0154\n",
            "Seen so far: 635232 samples\n",
            "0.9688775\n",
            "Training loss (for one batch) at step 19855: 0.0075\n",
            "Seen so far: 635392 samples\n",
            "0.96888375\n",
            "Training loss (for one batch) at step 19860: 0.0003\n",
            "Seen so far: 635552 samples\n",
            "0.9688916\n",
            "Training loss (for one batch) at step 19865: 0.0109\n",
            "Seen so far: 635712 samples\n",
            "0.9688979\n",
            "Training loss (for one batch) at step 19870: 0.0001\n",
            "Seen so far: 635872 samples\n",
            "0.96890414\n",
            "Training loss (for one batch) at step 19875: 0.0011\n",
            "Seen so far: 636032 samples\n",
            "0.96891195\n",
            "Training loss (for one batch) at step 19880: 0.0006\n",
            "Seen so far: 636192 samples\n",
            "0.9689166\n",
            "Training loss (for one batch) at step 19885: 0.0000\n",
            "Seen so far: 636352 samples\n",
            "0.9689244\n",
            "Training loss (for one batch) at step 19890: 0.0349\n",
            "Seen so far: 636512 samples\n",
            "0.9689323\n",
            "Training loss (for one batch) at step 19895: 0.0017\n",
            "Seen so far: 636672 samples\n",
            "0.9689369\n",
            "Training loss (for one batch) at step 19900: 0.0105\n",
            "Seen so far: 636832 samples\n",
            "0.96894157\n",
            "Training loss (for one batch) at step 19905: 0.0009\n",
            "Seen so far: 636992 samples\n",
            "0.9689494\n",
            "Training loss (for one batch) at step 19910: 0.0108\n",
            "Seen so far: 637152 samples\n",
            "0.968954\n",
            "Training loss (for one batch) at step 19915: 0.0013\n",
            "Seen so far: 637312 samples\n",
            "0.9689587\n",
            "Training loss (for one batch) at step 19920: 0.0020\n",
            "Seen so far: 637472 samples\n",
            "0.9689665\n",
            "Training loss (for one batch) at step 19925: 0.0001\n",
            "Seen so far: 637632 samples\n",
            "0.9689743\n",
            "Training loss (for one batch) at step 19930: 0.0000\n",
            "Seen so far: 637792 samples\n",
            "0.96897894\n",
            "Training loss (for one batch) at step 19935: 0.0037\n",
            "Seen so far: 637952 samples\n",
            "0.96898353\n",
            "Training loss (for one batch) at step 19940: 0.0006\n",
            "Seen so far: 638112 samples\n",
            "0.9689898\n",
            "Training loss (for one batch) at step 19945: 0.0002\n",
            "Seen so far: 638272 samples\n",
            "0.96899754\n",
            "Training loss (for one batch) at step 19950: 0.0005\n",
            "Seen so far: 638432 samples\n",
            "0.96900374\n",
            "Training loss (for one batch) at step 19955: 0.0001\n",
            "Seen so far: 638592 samples\n",
            "0.9690115\n",
            "Training loss (for one batch) at step 19960: 0.0011\n",
            "Seen so far: 638752 samples\n",
            "0.96901613\n",
            "Training loss (for one batch) at step 19965: 0.3530\n",
            "Seen so far: 638912 samples\n",
            "0.96902233\n",
            "Training loss (for one batch) at step 19970: 0.0173\n",
            "Seen so far: 639072 samples\n",
            "0.96902853\n",
            "Training loss (for one batch) at step 19975: 0.0009\n",
            "Seen so far: 639232 samples\n",
            "0.9690363\n",
            "Training loss (for one batch) at step 19980: 0.0015\n",
            "Seen so far: 639392 samples\n",
            "0.9690425\n",
            "Training loss (for one batch) at step 19985: 0.0001\n",
            "Seen so far: 639552 samples\n",
            "0.96904397\n",
            "Training loss (for one batch) at step 19990: 0.0054\n",
            "Seen so far: 639712 samples\n",
            "0.9690501\n",
            "Training loss (for one batch) at step 19995: 0.0007\n",
            "Seen so far: 639872 samples\n",
            "0.96905476\n",
            "Training loss (for one batch) at step 20000: 0.0029\n",
            "Seen so far: 640032 samples\n",
            "0.9690625\n",
            "Training loss (for one batch) at step 20005: 0.0006\n",
            "Seen so far: 640192 samples\n",
            "0.9690671\n",
            "Training loss (for one batch) at step 20010: 0.0014\n",
            "Seen so far: 640352 samples\n",
            "0.9690717\n",
            "Training loss (for one batch) at step 20015: 0.0032\n",
            "Seen so far: 640512 samples\n",
            "0.96907943\n",
            "Training loss (for one batch) at step 20020: 0.0001\n",
            "Seen so far: 640672 samples\n",
            "0.9690871\n",
            "Training loss (for one batch) at step 20025: 0.0001\n",
            "Seen so far: 640832 samples\n",
            "0.9690949\n",
            "Training loss (for one batch) at step 20030: 0.0042\n",
            "Seen so far: 640992 samples\n",
            "0.969101\n",
            "Training loss (for one batch) at step 20035: 0.0000\n",
            "Seen so far: 641152 samples\n",
            "0.9691087\n",
            "Training loss (for one batch) at step 20040: 0.0011\n",
            "Seen so far: 641312 samples\n",
            "0.9691102\n",
            "Training loss (for one batch) at step 20045: 0.0871\n",
            "Seen so far: 641472 samples\n",
            "0.96911633\n",
            "Training loss (for one batch) at step 20050: 0.0048\n",
            "Seen so far: 641632 samples\n",
            "0.9691209\n",
            "Training loss (for one batch) at step 20055: 0.0122\n",
            "Seen so far: 641792 samples\n",
            "0.9691286\n",
            "Training loss (for one batch) at step 20060: 0.0008\n",
            "Seen so far: 641952 samples\n",
            "0.9691363\n",
            "Training loss (for one batch) at step 20065: 0.0694\n",
            "Seen so far: 642112 samples\n",
            "0.96914244\n",
            "Training loss (for one batch) at step 20070: 0.0012\n",
            "Seen so far: 642272 samples\n",
            "0.969147\n",
            "Training loss (for one batch) at step 20075: 0.0007\n",
            "Seen so far: 642432 samples\n",
            "0.9691547\n",
            "Training loss (for one batch) at step 20080: 0.0004\n",
            "Seen so far: 642592 samples\n",
            "0.9691624\n",
            "Training loss (for one batch) at step 20085: 0.0001\n",
            "Seen so far: 642752 samples\n",
            "0.9691701\n",
            "Training loss (for one batch) at step 20090: 0.0016\n",
            "Seen so far: 642912 samples\n",
            "0.9691777\n",
            "Training loss (for one batch) at step 20095: 0.0122\n",
            "Seen so far: 643072 samples\n",
            "0.96918076\n",
            "Training loss (for one batch) at step 20100: 0.0003\n",
            "Seen so far: 643232 samples\n",
            "0.96918684\n",
            "Training loss (for one batch) at step 20105: 0.0192\n",
            "Seen so far: 643392 samples\n",
            "0.96919143\n",
            "Training loss (for one batch) at step 20110: 0.0000\n",
            "Seen so far: 643552 samples\n",
            "0.96919906\n",
            "Training loss (for one batch) at step 20115: 0.0022\n",
            "Seen so far: 643712 samples\n",
            "0.96920204\n",
            "Training loss (for one batch) at step 20120: 0.0031\n",
            "Seen so far: 643872 samples\n",
            "0.96920973\n",
            "Training loss (for one batch) at step 20125: 0.0010\n",
            "Seen so far: 644032 samples\n",
            "0.9692158\n",
            "Training loss (for one batch) at step 20130: 0.1331\n",
            "Seen so far: 644192 samples\n",
            "0.96921724\n",
            "Training loss (for one batch) at step 20135: 0.0000\n",
            "Seen so far: 644352 samples\n",
            "0.9692249\n",
            "Training loss (for one batch) at step 20140: 0.0172\n",
            "Seen so far: 644512 samples\n",
            "0.96922946\n",
            "Training loss (for one batch) at step 20145: 0.0004\n",
            "Seen so far: 644672 samples\n",
            "0.96923554\n",
            "Training loss (for one batch) at step 20150: 0.0215\n",
            "Seen so far: 644832 samples\n",
            "0.96924007\n",
            "Training loss (for one batch) at step 20155: 0.0007\n",
            "Seen so far: 644992 samples\n",
            "0.96924305\n",
            "Training loss (for one batch) at step 20160: 0.0165\n",
            "Seen so far: 645152 samples\n",
            "0.9692476\n",
            "Training loss (for one batch) at step 20165: 0.0003\n",
            "Seen so far: 645312 samples\n",
            "0.9692552\n",
            "Training loss (for one batch) at step 20170: 0.0048\n",
            "Seen so far: 645472 samples\n",
            "0.9692628\n",
            "Training loss (for one batch) at step 20175: 0.0170\n",
            "Seen so far: 645632 samples\n",
            "0.96926886\n",
            "Training loss (for one batch) at step 20180: 0.0002\n",
            "Seen so far: 645792 samples\n",
            "0.9692765\n",
            "Training loss (for one batch) at step 20185: 0.0004\n",
            "Seen so far: 645952 samples\n",
            "0.969281\n",
            "Training loss (for one batch) at step 20190: 0.0055\n",
            "Seen so far: 646112 samples\n",
            "0.9692855\n",
            "Training loss (for one batch) at step 20195: 0.0002\n",
            "Seen so far: 646272 samples\n",
            "0.9692931\n",
            "Training loss (for one batch) at step 20200: 0.0015\n",
            "Seen so far: 646432 samples\n",
            "0.9692992\n",
            "Training loss (for one batch) at step 20205: 0.1036\n",
            "Seen so far: 646592 samples\n",
            "0.9693052\n",
            "Training loss (for one batch) at step 20210: 0.0020\n",
            "Seen so far: 646752 samples\n",
            "0.96930975\n",
            "Training loss (for one batch) at step 20215: 0.0005\n",
            "Seen so far: 646912 samples\n",
            "0.9693173\n",
            "Training loss (for one batch) at step 20220: 0.0085\n",
            "Seen so far: 647072 samples\n",
            "0.9693249\n",
            "Training loss (for one batch) at step 20225: 0.0095\n",
            "Seen so far: 647232 samples\n",
            "0.9693309\n",
            "Training loss (for one batch) at step 20230: 0.0143\n",
            "Seen so far: 647392 samples\n",
            "0.96933854\n",
            "Training loss (for one batch) at step 20235: 0.0212\n",
            "Seen so far: 647552 samples\n",
            "0.96934456\n",
            "Training loss (for one batch) at step 20240: 0.0020\n",
            "Seen so far: 647712 samples\n",
            "0.969349\n",
            "Training loss (for one batch) at step 20245: 0.0004\n",
            "Seen so far: 647872 samples\n",
            "0.96935505\n",
            "Training loss (for one batch) at step 20250: 0.0007\n",
            "Seen so far: 648032 samples\n",
            "0.9693626\n",
            "Training loss (for one batch) at step 20255: 0.0022\n",
            "Seen so far: 648192 samples\n",
            "0.96936864\n",
            "Training loss (for one batch) at step 20260: 0.0002\n",
            "Seen so far: 648352 samples\n",
            "0.96937466\n",
            "Training loss (for one batch) at step 20265: 0.0002\n",
            "Seen so far: 648512 samples\n",
            "0.9693822\n",
            "Training loss (for one batch) at step 20270: 0.0007\n",
            "Seen so far: 648672 samples\n",
            "0.96938825\n",
            "Training loss (for one batch) at step 20275: 0.0020\n",
            "Seen so far: 648832 samples\n",
            "0.96939576\n",
            "Training loss (for one batch) at step 20280: 0.0527\n",
            "Seen so far: 648992 samples\n",
            "0.9694018\n",
            "Training loss (for one batch) at step 20285: 0.1741\n",
            "Seen so far: 649152 samples\n",
            "0.9694078\n",
            "Training loss (for one batch) at step 20290: 0.0286\n",
            "Seen so far: 649312 samples\n",
            "0.96941376\n",
            "Training loss (for one batch) at step 20295: 0.0001\n",
            "Seen so far: 649472 samples\n",
            "0.9694213\n",
            "Training loss (for one batch) at step 20300: 0.2126\n",
            "Seen so far: 649632 samples\n",
            "0.9694273\n",
            "Training loss (for one batch) at step 20305: 0.0012\n",
            "Seen so far: 649792 samples\n",
            "0.96943486\n",
            "Training loss (for one batch) at step 20310: 0.0681\n",
            "Seen so far: 649952 samples\n",
            "0.9694408\n",
            "Training loss (for one batch) at step 20315: 0.0874\n",
            "Seen so far: 650112 samples\n",
            "0.9694422\n",
            "Training loss (for one batch) at step 20320: 0.0070\n",
            "Seen so far: 650272 samples\n",
            "0.96944666\n",
            "Training loss (for one batch) at step 20325: 0.0016\n",
            "Seen so far: 650432 samples\n",
            "0.9694526\n",
            "Training loss (for one batch) at step 20330: 0.0014\n",
            "Seen so far: 650592 samples\n",
            "0.9694601\n",
            "Training loss (for one batch) at step 20335: 0.0008\n",
            "Seen so far: 650752 samples\n",
            "0.96946454\n",
            "Training loss (for one batch) at step 20340: 0.0022\n",
            "Seen so far: 650912 samples\n",
            "0.96947205\n",
            "Training loss (for one batch) at step 20345: 0.0006\n",
            "Seen so far: 651072 samples\n",
            "0.969478\n",
            "Training loss (for one batch) at step 20350: 0.0005\n",
            "Seen so far: 651232 samples\n",
            "0.9694794\n",
            "Training loss (for one batch) at step 20355: 0.0010\n",
            "Seen so far: 651392 samples\n",
            "0.96948534\n",
            "Training loss (for one batch) at step 20360: 0.1131\n",
            "Seen so far: 651552 samples\n",
            "0.9694913\n",
            "Training loss (for one batch) at step 20365: 0.0016\n",
            "Seen so far: 651712 samples\n",
            "0.96949726\n",
            "Training loss (for one batch) at step 20370: 0.0001\n",
            "Seen so far: 651872 samples\n",
            "0.9695017\n",
            "Training loss (for one batch) at step 20375: 0.0037\n",
            "Seen so far: 652032 samples\n",
            "0.9695092\n",
            "Training loss (for one batch) at step 20380: 0.0006\n",
            "Seen so far: 652192 samples\n",
            "0.96951663\n",
            "Training loss (for one batch) at step 20385: 0.0004\n",
            "Seen so far: 652352 samples\n",
            "0.96952415\n",
            "Training loss (for one batch) at step 20390: 0.0035\n",
            "Seen so far: 652512 samples\n",
            "0.96953005\n",
            "Training loss (for one batch) at step 20395: 0.0091\n",
            "Seen so far: 652672 samples\n",
            "0.96953446\n",
            "Training loss (for one batch) at step 20400: 0.0581\n",
            "Seen so far: 652832 samples\n",
            "0.9695404\n",
            "Training loss (for one batch) at step 20405: 0.0262\n",
            "Seen so far: 652992 samples\n",
            "0.96954787\n",
            "Training loss (for one batch) at step 20410: 0.1646\n",
            "Seen so far: 653152 samples\n",
            "0.96955377\n",
            "Training loss (for one batch) at step 20415: 0.0002\n",
            "Seen so far: 653312 samples\n",
            "0.9695613\n",
            "Training loss (for one batch) at step 20420: 0.0003\n",
            "Seen so far: 653472 samples\n",
            "0.9695672\n",
            "Training loss (for one batch) at step 20425: 0.0100\n",
            "Seen so far: 653632 samples\n",
            "0.96957004\n",
            "Training loss (for one batch) at step 20430: 0.0002\n",
            "Seen so far: 653792 samples\n",
            "0.9695744\n",
            "Training loss (for one batch) at step 20435: 0.0045\n",
            "Seen so far: 653952 samples\n",
            "0.96958184\n",
            "Training loss (for one batch) at step 20440: 0.0098\n",
            "Seen so far: 654112 samples\n",
            "0.9695878\n",
            "Training loss (for one batch) at step 20445: 0.0002\n",
            "Seen so far: 654272 samples\n",
            "0.9695952\n",
            "Training loss (for one batch) at step 20450: 0.0623\n",
            "Seen so far: 654432 samples\n",
            "0.9696011\n",
            "Training loss (for one batch) at step 20455: 0.0004\n",
            "Seen so far: 654592 samples\n",
            "0.969607\n",
            "Training loss (for one batch) at step 20460: 0.0000\n",
            "Seen so far: 654752 samples\n",
            "0.9696129\n",
            "Training loss (for one batch) at step 20465: 0.0003\n",
            "Seen so far: 654912 samples\n",
            "0.9696188\n",
            "Training loss (for one batch) at step 20470: 0.0000\n",
            "Seen so far: 655072 samples\n",
            "0.9696247\n",
            "Training loss (for one batch) at step 20475: 0.0102\n",
            "Seen so far: 655232 samples\n",
            "0.96963215\n",
            "Training loss (for one batch) at step 20480: 0.0003\n",
            "Seen so far: 655392 samples\n",
            "0.9696365\n",
            "Training loss (for one batch) at step 20485: 0.0019\n",
            "Seen so far: 655552 samples\n",
            "0.9696439\n",
            "Training loss (for one batch) at step 20490: 0.0013\n",
            "Seen so far: 655712 samples\n",
            "0.9696513\n",
            "Training loss (for one batch) at step 20495: 0.0018\n",
            "Seen so far: 655872 samples\n",
            "0.9696572\n",
            "Training loss (for one batch) at step 20500: 0.0264\n",
            "Seen so far: 656032 samples\n",
            "0.9696646\n",
            "Training loss (for one batch) at step 20505: 0.0119\n",
            "Seen so far: 656192 samples\n",
            "0.96967196\n",
            "Training loss (for one batch) at step 20510: 0.0001\n",
            "Seen so far: 656352 samples\n",
            "0.9696748\n",
            "Training loss (for one batch) at step 20515: 0.0041\n",
            "Seen so far: 656512 samples\n",
            "0.9696822\n",
            "Training loss (for one batch) at step 20520: 0.0002\n",
            "Seen so far: 656672 samples\n",
            "0.96968657\n",
            "Training loss (for one batch) at step 20525: 0.0016\n",
            "Seen so far: 656832 samples\n",
            "0.96969086\n",
            "Training loss (for one batch) at step 20530: 0.0003\n",
            "Seen so far: 656992 samples\n",
            "0.96969825\n",
            "Training loss (for one batch) at step 20535: 0.0003\n",
            "Seen so far: 657152 samples\n",
            "0.96970105\n",
            "Training loss (for one batch) at step 20540: 0.0326\n",
            "Seen so far: 657312 samples\n",
            "0.96970695\n",
            "Training loss (for one batch) at step 20545: 0.1253\n",
            "Seen so far: 657472 samples\n",
            "0.9697128\n",
            "Training loss (for one batch) at step 20550: 0.0002\n",
            "Seen so far: 657632 samples\n",
            "0.9697201\n",
            "Training loss (for one batch) at step 20555: 0.0360\n",
            "Seen so far: 657792 samples\n",
            "0.9697199\n",
            "Training loss (for one batch) at step 20560: 0.0001\n",
            "Seen so far: 657952 samples\n",
            "0.9697273\n",
            "Training loss (for one batch) at step 20565: 0.1198\n",
            "Seen so far: 658112 samples\n",
            "0.9697301\n",
            "Training loss (for one batch) at step 20570: 0.0016\n",
            "Seen so far: 658272 samples\n",
            "0.9697374\n",
            "Training loss (for one batch) at step 20575: 0.0682\n",
            "Seen so far: 658432 samples\n",
            "0.96974176\n",
            "Training loss (for one batch) at step 20580: 0.0288\n",
            "Seen so far: 658592 samples\n",
            "0.9697476\n",
            "Training loss (for one batch) at step 20585: 0.0178\n",
            "Seen so far: 658752 samples\n",
            "0.9697534\n",
            "Training loss (for one batch) at step 20590: 0.0004\n",
            "Seen so far: 658912 samples\n",
            "0.9697592\n",
            "Training loss (for one batch) at step 20595: 0.0002\n",
            "Seen so far: 659072 samples\n",
            "0.96976656\n",
            "Training loss (for one batch) at step 20600: 0.0003\n",
            "Seen so far: 659232 samples\n",
            "0.96977395\n",
            "Training loss (for one batch) at step 20605: 0.0007\n",
            "Seen so far: 659392 samples\n",
            "0.96977973\n",
            "Training loss (for one batch) at step 20610: 0.0056\n",
            "Seen so far: 659552 samples\n",
            "0.96978706\n",
            "Training loss (for one batch) at step 20615: 0.0084\n",
            "Seen so far: 659712 samples\n",
            "0.9697944\n",
            "Training loss (for one batch) at step 20620: 0.0550\n",
            "Seen so far: 659872 samples\n",
            "0.9697987\n",
            "Training loss (for one batch) at step 20625: 0.0007\n",
            "Seen so far: 660032 samples\n",
            "0.96980447\n",
            "Training loss (for one batch) at step 20630: 0.0696\n",
            "Seen so far: 660192 samples\n",
            "0.9698042\n",
            "Training loss (for one batch) at step 20635: 0.0299\n",
            "Seen so far: 660352 samples\n",
            "0.9698085\n",
            "Training loss (for one batch) at step 20640: 0.0334\n",
            "Seen so far: 660512 samples\n",
            "0.9698113\n",
            "Training loss (for one batch) at step 20645: 0.0009\n",
            "Seen so far: 660672 samples\n",
            "0.96981406\n",
            "Training loss (for one batch) at step 20650: 0.0016\n",
            "Seen so far: 660832 samples\n",
            "0.96981835\n",
            "Training loss (for one batch) at step 20655: 0.0019\n",
            "Seen so far: 660992 samples\n",
            "0.96982414\n",
            "Training loss (for one batch) at step 20660: 0.0003\n",
            "Seen so far: 661152 samples\n",
            "0.9698299\n",
            "Training loss (for one batch) at step 20665: 0.0000\n",
            "Seen so far: 661312 samples\n",
            "0.9698357\n",
            "Training loss (for one batch) at step 20670: 0.0008\n",
            "Seen so far: 661472 samples\n",
            "0.96984303\n",
            "Training loss (for one batch) at step 20675: 0.0164\n",
            "Seen so far: 661632 samples\n",
            "0.9698503\n",
            "Training loss (for one batch) at step 20680: 0.1001\n",
            "Seen so far: 661792 samples\n",
            "0.9698561\n",
            "Training loss (for one batch) at step 20685: 0.0115\n",
            "Seen so far: 661952 samples\n",
            "0.9698604\n",
            "Training loss (for one batch) at step 20690: 0.0707\n",
            "Seen so far: 662112 samples\n",
            "0.9698661\n",
            "Training loss (for one batch) at step 20695: 0.0046\n",
            "Seen so far: 662272 samples\n",
            "0.9698719\n",
            "Training loss (for one batch) at step 20700: 0.0012\n",
            "Seen so far: 662432 samples\n",
            "0.96987915\n",
            "Training loss (for one batch) at step 20705: 0.0808\n",
            "Seen so far: 662592 samples\n",
            "0.96988493\n",
            "Training loss (for one batch) at step 20710: 0.0001\n",
            "Seen so far: 662752 samples\n",
            "0.9698922\n",
            "Training loss (for one batch) at step 20715: 0.0004\n",
            "Seen so far: 662912 samples\n",
            "0.969898\n",
            "Training loss (for one batch) at step 20720: 0.0002\n",
            "Seen so far: 663072 samples\n",
            "0.96990526\n",
            "Training loss (for one batch) at step 20725: 0.0079\n",
            "Seen so far: 663232 samples\n",
            "0.969911\n",
            "Training loss (for one batch) at step 20730: 0.1428\n",
            "Seen so far: 663392 samples\n",
            "0.9699167\n",
            "Training loss (for one batch) at step 20735: 0.1703\n",
            "Seen so far: 663552 samples\n",
            "0.9699225\n",
            "Training loss (for one batch) at step 20740: 0.0433\n",
            "Seen so far: 663712 samples\n",
            "0.9699267\n",
            "Training loss (for one batch) at step 20745: 0.0043\n",
            "Seen so far: 663872 samples\n",
            "0.96993095\n",
            "Training loss (for one batch) at step 20750: 0.0030\n",
            "Seen so far: 664032 samples\n",
            "0.96993667\n",
            "Training loss (for one batch) at step 20755: 0.0008\n",
            "Seen so far: 664192 samples\n",
            "0.9699409\n",
            "Training loss (for one batch) at step 20760: 0.0370\n",
            "Seen so far: 664352 samples\n",
            "0.96994513\n",
            "Training loss (for one batch) at step 20765: 0.0140\n",
            "Seen so far: 664512 samples\n",
            "0.96994936\n",
            "Training loss (for one batch) at step 20770: 0.1469\n",
            "Seen so far: 664672 samples\n",
            "0.9699551\n",
            "Training loss (for one batch) at step 20775: 0.0012\n",
            "Seen so far: 664832 samples\n",
            "0.96996236\n",
            "Training loss (for one batch) at step 20780: 0.0376\n",
            "Seen so far: 664992 samples\n",
            "0.96996504\n",
            "Training loss (for one batch) at step 20785: 0.0002\n",
            "Seen so far: 665152 samples\n",
            "0.96997225\n",
            "Training loss (for one batch) at step 20790: 0.0024\n",
            "Seen so far: 665312 samples\n",
            "0.969978\n",
            "Training loss (for one batch) at step 20795: 0.0057\n",
            "Seen so far: 665472 samples\n",
            "0.9699852\n",
            "Training loss (for one batch) at step 20800: 0.0020\n",
            "Seen so far: 665632 samples\n",
            "0.9699924\n",
            "Training loss (for one batch) at step 20805: 0.0022\n",
            "Seen so far: 665792 samples\n",
            "0.9699996\n",
            "Training loss (for one batch) at step 20810: 0.0017\n",
            "Seen so far: 665952 samples\n",
            "0.97000533\n",
            "Training loss (for one batch) at step 20815: 0.0008\n",
            "Seen so far: 666112 samples\n",
            "0.97001106\n",
            "Training loss (for one batch) at step 20820: 0.0170\n",
            "Seen so far: 666272 samples\n",
            "0.97001374\n",
            "Training loss (for one batch) at step 20825: 0.0098\n",
            "Seen so far: 666432 samples\n",
            "0.97001946\n",
            "Training loss (for one batch) at step 20830: 0.0024\n",
            "Seen so far: 666592 samples\n",
            "0.9700267\n",
            "Training loss (for one batch) at step 20835: 0.0001\n",
            "Seen so far: 666752 samples\n",
            "0.9700338\n",
            "Training loss (for one batch) at step 20840: 0.0002\n",
            "Seen so far: 666912 samples\n",
            "0.97003955\n",
            "Training loss (for one batch) at step 20845: 0.0002\n",
            "Seen so far: 667072 samples\n",
            "0.9700467\n",
            "Training loss (for one batch) at step 20850: 0.0000\n",
            "Seen so far: 667232 samples\n",
            "0.9700524\n",
            "Training loss (for one batch) at step 20855: 0.0018\n",
            "Seen so far: 667392 samples\n",
            "0.9700596\n",
            "Training loss (for one batch) at step 20860: 0.0003\n",
            "Seen so far: 667552 samples\n",
            "0.9700667\n",
            "Training loss (for one batch) at step 20865: 0.0038\n",
            "Seen so far: 667712 samples\n",
            "0.97007245\n",
            "Training loss (for one batch) at step 20870: 0.0003\n",
            "Seen so far: 667872 samples\n",
            "0.9700781\n",
            "Training loss (for one batch) at step 20875: 0.0000\n",
            "Seen so far: 668032 samples\n",
            "0.97008526\n",
            "Training loss (for one batch) at step 20880: 0.0025\n",
            "Seen so far: 668192 samples\n",
            "0.9700924\n",
            "Training loss (for one batch) at step 20885: 0.0051\n",
            "Seen so far: 668352 samples\n",
            "0.9700966\n",
            "Training loss (for one batch) at step 20890: 0.0817\n",
            "Seen so far: 668512 samples\n",
            "0.97010076\n",
            "Training loss (for one batch) at step 20895: 0.0010\n",
            "Seen so far: 668672 samples\n",
            "0.9701064\n",
            "Training loss (for one batch) at step 20900: 0.0041\n",
            "Seen so far: 668832 samples\n",
            "0.9701136\n",
            "Training loss (for one batch) at step 20905: 0.0011\n",
            "Seen so far: 668992 samples\n",
            "0.9701207\n",
            "Training loss (for one batch) at step 20910: 0.0001\n",
            "Seen so far: 669152 samples\n",
            "0.97012335\n",
            "Training loss (for one batch) at step 20915: 0.0008\n",
            "Seen so far: 669312 samples\n",
            "0.9701305\n",
            "Training loss (for one batch) at step 20920: 0.0013\n",
            "Seen so far: 669472 samples\n",
            "0.97013766\n",
            "Training loss (for one batch) at step 20925: 0.0143\n",
            "Seen so far: 669632 samples\n",
            "0.9701433\n",
            "Training loss (for one batch) at step 20930: 0.0001\n",
            "Seen so far: 669792 samples\n",
            "0.97014743\n",
            "Training loss (for one batch) at step 20935: 0.0006\n",
            "Seen so far: 669952 samples\n",
            "0.9701546\n",
            "Training loss (for one batch) at step 20940: 0.0004\n",
            "Seen so far: 670112 samples\n",
            "0.9701602\n",
            "Training loss (for one batch) at step 20945: 0.0001\n",
            "Seen so far: 670272 samples\n",
            "0.97016585\n",
            "Training loss (for one batch) at step 20950: 0.0013\n",
            "Seen so far: 670432 samples\n",
            "0.97017294\n",
            "Training loss (for one batch) at step 20955: 0.0003\n",
            "Seen so far: 670592 samples\n",
            "0.9701756\n",
            "Training loss (for one batch) at step 20960: 0.0010\n",
            "Seen so far: 670752 samples\n",
            "0.9701738\n",
            "Training loss (for one batch) at step 20965: 0.0082\n",
            "Seen so far: 670912 samples\n",
            "0.97018087\n",
            "Training loss (for one batch) at step 20970: 0.1265\n",
            "Seen so far: 671072 samples\n",
            "0.97018504\n",
            "Training loss (for one batch) at step 20975: 0.0047\n",
            "Seen so far: 671232 samples\n",
            "0.97019064\n",
            "Training loss (for one batch) at step 20980: 0.0173\n",
            "Seen so far: 671392 samples\n",
            "0.97019774\n",
            "Training loss (for one batch) at step 20985: 0.0628\n",
            "Seen so far: 671552 samples\n",
            "0.97020036\n",
            "Training loss (for one batch) at step 20990: 0.0015\n",
            "Seen so far: 671712 samples\n",
            "0.9702045\n",
            "Training loss (for one batch) at step 20995: 0.0005\n",
            "Seen so far: 671872 samples\n",
            "0.97021157\n",
            "Training loss (for one batch) at step 21000: 0.0025\n",
            "Seen so far: 672032 samples\n",
            "0.9702157\n",
            "Training loss (for one batch) at step 21005: 0.0001\n",
            "Seen so far: 672192 samples\n",
            "0.9702228\n",
            "Training loss (for one batch) at step 21010: 0.0089\n",
            "Seen so far: 672352 samples\n",
            "0.9702284\n",
            "Training loss (for one batch) at step 21015: 0.0023\n",
            "Seen so far: 672512 samples\n",
            "0.9702325\n",
            "Training loss (for one batch) at step 21020: 0.0062\n",
            "Seen so far: 672672 samples\n",
            "0.9702396\n",
            "Training loss (for one batch) at step 21025: 0.0963\n",
            "Seen so far: 672832 samples\n",
            "0.9702437\n",
            "Training loss (for one batch) at step 21030: 0.0018\n",
            "Seen so far: 672992 samples\n",
            "0.9702478\n",
            "Training loss (for one batch) at step 21035: 0.0018\n",
            "Seen so far: 673152 samples\n",
            "0.97025335\n",
            "Training loss (for one batch) at step 21040: 0.1231\n",
            "Seen so far: 673312 samples\n",
            "0.97025746\n",
            "Training loss (for one batch) at step 21045: 0.0002\n",
            "Seen so far: 673472 samples\n",
            "0.97026455\n",
            "Training loss (for one batch) at step 21050: 0.0108\n",
            "Seen so far: 673632 samples\n",
            "0.9702716\n",
            "Training loss (for one batch) at step 21055: 0.0054\n",
            "Seen so far: 673792 samples\n",
            "0.9702742\n",
            "Training loss (for one batch) at step 21060: 0.0005\n",
            "Seen so far: 673952 samples\n",
            "0.9702783\n",
            "Training loss (for one batch) at step 21065: 0.0001\n",
            "Seen so far: 674112 samples\n",
            "0.9702809\n",
            "Training loss (for one batch) at step 21070: 0.0005\n",
            "Seen so far: 674272 samples\n",
            "0.970288\n",
            "Training loss (for one batch) at step 21075: 0.0009\n",
            "Seen so far: 674432 samples\n",
            "0.9702935\n",
            "Training loss (for one batch) at step 21080: 0.0006\n",
            "Seen so far: 674592 samples\n",
            "0.97030056\n",
            "Training loss (for one batch) at step 21085: 0.0104\n",
            "Seen so far: 674752 samples\n",
            "0.97030467\n",
            "Training loss (for one batch) at step 21090: 0.0007\n",
            "Seen so far: 674912 samples\n",
            "0.9703102\n",
            "Training loss (for one batch) at step 21095: 0.0052\n",
            "Seen so far: 675072 samples\n",
            "0.97030836\n",
            "Training loss (for one batch) at step 21100: 0.2835\n",
            "Seen so far: 675232 samples\n",
            "0.97030944\n",
            "Training loss (for one batch) at step 21105: 0.0001\n",
            "Seen so far: 675392 samples\n",
            "0.97031504\n",
            "Training loss (for one batch) at step 21110: 0.0726\n",
            "Seen so far: 675552 samples\n",
            "0.9703206\n",
            "Training loss (for one batch) at step 21115: 0.0045\n",
            "Seen so far: 675712 samples\n",
            "0.97032464\n",
            "Training loss (for one batch) at step 21120: 0.0023\n",
            "Seen so far: 675872 samples\n",
            "0.9703287\n",
            "Training loss (for one batch) at step 21125: 0.0032\n",
            "Seen so far: 676032 samples\n",
            "0.97033274\n",
            "Training loss (for one batch) at step 21130: 0.0012\n",
            "Seen so far: 676192 samples\n",
            "0.97033536\n",
            "Training loss (for one batch) at step 21135: 0.0001\n",
            "Seen so far: 676352 samples\n",
            "0.9703394\n",
            "Training loss (for one batch) at step 21140: 0.1196\n",
            "Seen so far: 676512 samples\n",
            "0.970342\n",
            "Training loss (for one batch) at step 21145: 0.0337\n",
            "Seen so far: 676672 samples\n",
            "0.97034603\n",
            "Training loss (for one batch) at step 21150: 0.0000\n",
            "Seen so far: 676832 samples\n",
            "0.97035307\n",
            "Training loss (for one batch) at step 21155: 0.0072\n",
            "Seen so far: 676992 samples\n",
            "0.9703586\n",
            "Training loss (for one batch) at step 21160: 0.0032\n",
            "Seen so far: 677152 samples\n",
            "0.9703567\n",
            "Training loss (for one batch) at step 21165: 0.0077\n",
            "Seen so far: 677312 samples\n",
            "0.97036374\n",
            "Training loss (for one batch) at step 21170: 0.0001\n",
            "Seen so far: 677472 samples\n",
            "0.9703693\n",
            "Training loss (for one batch) at step 21175: 0.0018\n",
            "Seen so far: 677632 samples\n",
            "0.97037476\n",
            "Training loss (for one batch) at step 21180: 0.0113\n",
            "Seen so far: 677792 samples\n",
            "0.9703818\n",
            "Training loss (for one batch) at step 21185: 0.0192\n",
            "Seen so far: 677952 samples\n",
            "0.97038436\n",
            "Training loss (for one batch) at step 21190: 0.0291\n",
            "Seen so far: 678112 samples\n",
            "0.97039133\n",
            "Training loss (for one batch) at step 21195: 0.1887\n",
            "Seen so far: 678272 samples\n",
            "0.9703924\n",
            "Training loss (for one batch) at step 21200: 0.0022\n",
            "Seen so far: 678432 samples\n",
            "0.9703979\n",
            "Training loss (for one batch) at step 21205: 0.0004\n",
            "Seen so far: 678592 samples\n",
            "0.97040343\n",
            "Training loss (for one batch) at step 21210: 0.0110\n",
            "Seen so far: 678752 samples\n",
            "0.9704104\n",
            "Training loss (for one batch) at step 21215: 0.0037\n",
            "Seen so far: 678912 samples\n",
            "0.9704144\n",
            "Training loss (for one batch) at step 21220: 0.0049\n",
            "Seen so far: 679072 samples\n",
            "0.9704214\n",
            "Training loss (for one batch) at step 21225: 0.0001\n",
            "Seen so far: 679232 samples\n",
            "0.970421\n",
            "Training loss (for one batch) at step 21230: 0.1174\n",
            "Seen so far: 679392 samples\n",
            "0.9704221\n",
            "Training loss (for one batch) at step 21235: 0.0115\n",
            "Seen so far: 679552 samples\n",
            "0.97042465\n",
            "Training loss (for one batch) at step 21240: 0.0107\n",
            "Seen so far: 679712 samples\n",
            "0.97042716\n",
            "Training loss (for one batch) at step 21245: 0.0080\n",
            "Seen so far: 679872 samples\n",
            "0.9704312\n",
            "Training loss (for one batch) at step 21250: 0.1999\n",
            "Seen so far: 680032 samples\n",
            "0.9704352\n",
            "Training loss (for one batch) at step 21255: 0.0152\n",
            "Seen so far: 680192 samples\n",
            "0.97043926\n",
            "Training loss (for one batch) at step 21260: 0.0023\n",
            "Seen so far: 680352 samples\n",
            "0.97044474\n",
            "Training loss (for one batch) at step 21265: 0.0948\n",
            "Seen so far: 680512 samples\n",
            "0.97045016\n",
            "Training loss (for one batch) at step 21270: 0.0100\n",
            "Seen so far: 680672 samples\n",
            "0.97045714\n",
            "Training loss (for one batch) at step 21275: 0.0069\n",
            "Seen so far: 680832 samples\n",
            "0.97046113\n",
            "Training loss (for one batch) at step 21280: 0.0313\n",
            "Seen so far: 680992 samples\n",
            "0.9704651\n",
            "Training loss (for one batch) at step 21285: 0.0031\n",
            "Seen so far: 681152 samples\n",
            "0.9704677\n",
            "Training loss (for one batch) at step 21290: 0.0068\n",
            "Seen so far: 681312 samples\n",
            "0.9704746\n",
            "Training loss (for one batch) at step 21295: 0.0050\n",
            "Seen so far: 681472 samples\n",
            "0.9704801\n",
            "Training loss (for one batch) at step 21300: 0.0104\n",
            "Seen so far: 681632 samples\n",
            "0.970487\n",
            "Training loss (for one batch) at step 21305: 0.0002\n",
            "Seen so far: 681792 samples\n",
            "0.9704939\n",
            "Training loss (for one batch) at step 21310: 0.0069\n",
            "Seen so far: 681952 samples\n",
            "0.9705008\n",
            "Training loss (for one batch) at step 21315: 0.0133\n",
            "Seen so far: 682112 samples\n",
            "0.9705048\n",
            "Training loss (for one batch) at step 21320: 0.0006\n",
            "Seen so far: 682272 samples\n",
            "0.97051173\n",
            "Training loss (for one batch) at step 21325: 0.1669\n",
            "Seen so far: 682432 samples\n",
            "0.9705143\n",
            "Training loss (for one batch) at step 21330: 0.0101\n",
            "Seen so far: 682592 samples\n",
            "0.9705197\n",
            "Training loss (for one batch) at step 21335: 0.0001\n",
            "Seen so far: 682752 samples\n",
            "0.9705237\n",
            "Training loss (for one batch) at step 21340: 0.0032\n",
            "Seen so far: 682912 samples\n",
            "0.97052914\n",
            "Training loss (for one batch) at step 21345: 0.0015\n",
            "Seen so far: 683072 samples\n",
            "0.97053456\n",
            "Training loss (for one batch) at step 21350: 0.0090\n",
            "Seen so far: 683232 samples\n",
            "0.97053856\n",
            "Training loss (for one batch) at step 21355: 0.0022\n",
            "Seen so far: 683392 samples\n",
            "0.970544\n",
            "Training loss (for one batch) at step 21360: 0.0001\n",
            "Seen so far: 683552 samples\n",
            "0.970548\n",
            "Training loss (for one batch) at step 21365: 0.0002\n",
            "Seen so far: 683712 samples\n",
            "0.9705519\n",
            "Training loss (for one batch) at step 21370: 0.0922\n",
            "Seen so far: 683872 samples\n",
            "0.97055006\n",
            "Training loss (for one batch) at step 21375: 0.0012\n",
            "Seen so far: 684032 samples\n",
            "0.9705569\n",
            "Training loss (for one batch) at step 21380: 0.0005\n",
            "Seen so far: 684192 samples\n",
            "0.97056234\n",
            "Training loss (for one batch) at step 21385: 0.0001\n",
            "Seen so far: 684352 samples\n",
            "0.97056484\n",
            "Training loss (for one batch) at step 21390: 0.0062\n",
            "Seen so far: 684512 samples\n",
            "0.97057176\n",
            "Training loss (for one batch) at step 21395: 0.0004\n",
            "Seen so far: 684672 samples\n",
            "0.9705772\n",
            "Training loss (for one batch) at step 21400: 0.0000\n",
            "Seen so far: 684832 samples\n",
            "0.97058403\n",
            "Training loss (for one batch) at step 21405: 0.0085\n",
            "Seen so far: 684992 samples\n",
            "0.97058505\n",
            "Training loss (for one batch) at step 21410: 0.0089\n",
            "Seen so far: 685152 samples\n",
            "0.9705919\n",
            "Training loss (for one batch) at step 21415: 0.0080\n",
            "Seen so far: 685312 samples\n",
            "0.9705988\n",
            "Training loss (for one batch) at step 21420: 0.0030\n",
            "Seen so far: 685472 samples\n",
            "0.9706057\n",
            "Training loss (for one batch) at step 21425: 0.0001\n",
            "Seen so far: 685632 samples\n",
            "0.97061104\n",
            "Training loss (for one batch) at step 21430: 0.0014\n",
            "Seen so far: 685792 samples\n",
            "0.97061354\n",
            "Training loss (for one batch) at step 21435: 0.1790\n",
            "Seen so far: 685952 samples\n",
            "0.97061896\n",
            "Training loss (for one batch) at step 21440: 0.0169\n",
            "Seen so far: 686112 samples\n",
            "0.9706243\n",
            "Training loss (for one batch) at step 21445: 0.0044\n",
            "Seen so far: 686272 samples\n",
            "0.9706312\n",
            "Training loss (for one batch) at step 21450: 0.1279\n",
            "Seen so far: 686432 samples\n",
            "0.9706351\n",
            "Training loss (for one batch) at step 21455: 0.0049\n",
            "Seen so far: 686592 samples\n",
            "0.9706405\n",
            "Training loss (for one batch) at step 21460: 0.0007\n",
            "Seen so far: 686752 samples\n",
            "0.9706459\n",
            "Training loss (for one batch) at step 21465: 0.1534\n",
            "Seen so far: 686912 samples\n",
            "0.97064835\n",
            "Training loss (for one batch) at step 21470: 0.1016\n",
            "Seen so far: 687072 samples\n",
            "0.97064936\n",
            "Training loss (for one batch) at step 21475: 0.0032\n",
            "Seen so far: 687232 samples\n",
            "0.9706547\n",
            "Training loss (for one batch) at step 21480: 0.0287\n",
            "Seen so far: 687392 samples\n",
            "0.9706601\n",
            "Training loss (for one batch) at step 21485: 0.0201\n",
            "Seen so far: 687552 samples\n",
            "0.9706611\n",
            "Training loss (for one batch) at step 21490: 0.0401\n",
            "Seen so far: 687712 samples\n",
            "0.9706607\n",
            "Training loss (for one batch) at step 21495: 0.0010\n",
            "Seen so far: 687872 samples\n",
            "0.9706617\n",
            "Training loss (for one batch) at step 21500: 0.7556\n",
            "Seen so far: 688032 samples\n",
            "0.97066414\n",
            "Training loss (for one batch) at step 21505: 0.0010\n",
            "Seen so far: 688192 samples\n",
            "0.9706695\n",
            "Training loss (for one batch) at step 21510: 0.6130\n",
            "Seen so far: 688352 samples\n",
            "0.9706749\n",
            "Training loss (for one batch) at step 21515: 0.0180\n",
            "Seen so far: 688512 samples\n",
            "0.97068024\n",
            "Training loss (for one batch) at step 21520: 0.0138\n",
            "Seen so far: 688672 samples\n",
            "0.97068125\n",
            "Training loss (for one batch) at step 21525: 0.0801\n",
            "Seen so far: 688832 samples\n",
            "0.9706852\n",
            "Training loss (for one batch) at step 21530: 0.0010\n",
            "Seen so far: 688992 samples\n",
            "0.9706905\n",
            "Training loss (for one batch) at step 21535: 0.0056\n",
            "Seen so far: 689152 samples\n",
            "0.9706944\n",
            "Training loss (for one batch) at step 21540: 0.1443\n",
            "Seen so far: 689312 samples\n",
            "0.97069395\n",
            "Training loss (for one batch) at step 21545: 0.0527\n",
            "Seen so far: 689472 samples\n",
            "0.9706964\n",
            "Training loss (for one batch) at step 21550: 0.0023\n",
            "Seen so far: 689632 samples\n",
            "0.9707003\n",
            "Training loss (for one batch) at step 21555: 0.0019\n",
            "Seen so far: 689792 samples\n",
            "0.9707057\n",
            "Training loss (for one batch) at step 21560: 0.0634\n",
            "Seen so far: 689952 samples\n",
            "0.9707052\n",
            "Training loss (for one batch) at step 21565: 0.1725\n",
            "Seen so far: 690112 samples\n",
            "0.9707019\n",
            "Training loss (for one batch) at step 21570: 0.2554\n",
            "Seen so far: 690272 samples\n",
            "0.9707028\n",
            "Training loss (for one batch) at step 21575: 0.0013\n",
            "Seen so far: 690432 samples\n",
            "0.9707096\n",
            "Training loss (for one batch) at step 21580: 0.0029\n",
            "Seen so far: 690592 samples\n",
            "0.97071064\n",
            "Training loss (for one batch) at step 21585: 0.3067\n",
            "Seen so far: 690752 samples\n",
            "0.97071016\n",
            "Training loss (for one batch) at step 21590: 0.0190\n",
            "Seen so far: 690912 samples\n",
            "0.9707126\n",
            "Training loss (for one batch) at step 21595: 0.0026\n",
            "Seen so far: 691072 samples\n",
            "0.97071654\n",
            "Training loss (for one batch) at step 21600: 0.0029\n",
            "Seen so far: 691232 samples\n",
            "0.9707189\n",
            "Training loss (for one batch) at step 21605: 0.0096\n",
            "Seen so far: 691392 samples\n",
            "0.9707257\n",
            "Training loss (for one batch) at step 21610: 0.0013\n",
            "Seen so far: 691552 samples\n",
            "0.97072816\n",
            "Training loss (for one batch) at step 21615: 0.0009\n",
            "Seen so far: 691712 samples\n",
            "0.97073203\n",
            "Training loss (for one batch) at step 21620: 0.0858\n",
            "Seen so far: 691872 samples\n",
            "0.9707301\n",
            "Training loss (for one batch) at step 21625: 0.0191\n",
            "Seen so far: 692032 samples\n",
            "0.9707268\n",
            "Training loss (for one batch) at step 21630: 0.0094\n",
            "Seen so far: 692192 samples\n",
            "0.9707321\n",
            "Training loss (for one batch) at step 21635: 0.0135\n",
            "Seen so far: 692352 samples\n",
            "0.97073454\n",
            "Training loss (for one batch) at step 21640: 0.0990\n",
            "Seen so far: 692512 samples\n",
            "0.9707384\n",
            "Training loss (for one batch) at step 21645: 0.1784\n",
            "Seen so far: 692672 samples\n",
            "0.97073364\n",
            "Training loss (for one batch) at step 21650: 0.0131\n",
            "Seen so far: 692832 samples\n",
            "0.97073174\n",
            "Training loss (for one batch) at step 21655: 0.1853\n",
            "Seen so far: 692992 samples\n",
            "0.97073126\n",
            "Training loss (for one batch) at step 21660: 0.0060\n",
            "Seen so far: 693152 samples\n",
            "0.97073656\n",
            "Training loss (for one batch) at step 21665: 0.0560\n",
            "Seen so far: 693312 samples\n",
            "0.97074044\n",
            "Training loss (for one batch) at step 21670: 0.0081\n",
            "Seen so far: 693472 samples\n",
            "0.97074574\n",
            "Training loss (for one batch) at step 21675: 0.2927\n",
            "Seen so far: 693632 samples\n",
            "0.97074527\n",
            "Training loss (for one batch) at step 21680: 0.1159\n",
            "Seen so far: 693792 samples\n",
            "0.9707463\n",
            "Training loss (for one batch) at step 21685: 0.0879\n",
            "Seen so far: 693952 samples\n",
            "0.9707487\n",
            "Training loss (for one batch) at step 21690: 0.0958\n",
            "Seen so far: 694112 samples\n",
            "0.9707511\n",
            "Training loss (for one batch) at step 21695: 0.1298\n",
            "Seen so far: 694272 samples\n",
            "0.9707521\n",
            "Training loss (for one batch) at step 21700: 0.0702\n",
            "Seen so far: 694432 samples\n",
            "0.97075593\n",
            "Training loss (for one batch) at step 21705: 0.1051\n",
            "Seen so far: 694592 samples\n",
            "0.9707584\n",
            "Training loss (for one batch) at step 21710: 0.1649\n",
            "Seen so far: 694752 samples\n",
            "0.97076225\n",
            "Training loss (for one batch) at step 21715: 0.0004\n",
            "Seen so far: 694912 samples\n",
            "0.97076607\n",
            "Training loss (for one batch) at step 21720: 0.0960\n",
            "Seen so far: 695072 samples\n",
            "0.9707685\n",
            "Training loss (for one batch) at step 21725: 0.0375\n",
            "Seen so far: 695232 samples\n",
            "0.9707723\n",
            "Training loss (for one batch) at step 21730: 0.0447\n",
            "Seen so far: 695392 samples\n",
            "0.970769\n",
            "Training loss (for one batch) at step 21735: 0.0988\n",
            "Seen so far: 695552 samples\n",
            "0.97077143\n",
            "Training loss (for one batch) at step 21740: 0.0258\n",
            "Seen so far: 695712 samples\n",
            "0.9707767\n",
            "Training loss (for one batch) at step 21745: 0.1022\n",
            "Seen so far: 695872 samples\n",
            "0.9707777\n",
            "Training loss (for one batch) at step 21750: 0.1531\n",
            "Seen so far: 696032 samples\n",
            "0.9707801\n",
            "Training loss (for one batch) at step 21755: 0.0053\n",
            "Seen so far: 696192 samples\n",
            "0.970781\n",
            "Training loss (for one batch) at step 21760: 0.0069\n",
            "Seen so far: 696352 samples\n",
            "0.9707849\n",
            "Training loss (for one batch) at step 21765: 0.0111\n",
            "Seen so far: 696512 samples\n",
            "0.9707873\n",
            "Training loss (for one batch) at step 21770: 0.0064\n",
            "Seen so far: 696672 samples\n",
            "0.970794\n",
            "Training loss (for one batch) at step 21775: 0.0367\n",
            "Seen so far: 696832 samples\n",
            "0.9707964\n",
            "Training loss (for one batch) at step 21780: 0.0414\n",
            "Seen so far: 696992 samples\n",
            "0.97079736\n",
            "Training loss (for one batch) at step 21785: 0.0027\n",
            "Seen so far: 697152 samples\n",
            "0.9708012\n",
            "Training loss (for one batch) at step 21790: 0.0149\n",
            "Seen so far: 697312 samples\n",
            "0.9708079\n",
            "Training loss (for one batch) at step 21795: 0.0799\n",
            "Seen so far: 697472 samples\n",
            "0.9708117\n",
            "Training loss (for one batch) at step 21800: 0.0036\n",
            "Seen so far: 697632 samples\n",
            "0.9708141\n",
            "Training loss (for one batch) at step 21805: 0.0664\n",
            "Seen so far: 697792 samples\n",
            "0.9708194\n",
            "Training loss (for one batch) at step 21810: 0.0008\n",
            "Seen so far: 697952 samples\n",
            "0.9708232\n",
            "Training loss (for one batch) at step 21815: 0.0008\n",
            "Seen so far: 698112 samples\n",
            "0.9708285\n",
            "Training loss (for one batch) at step 21820: 0.0316\n",
            "Seen so far: 698272 samples\n",
            "0.97083086\n",
            "Training loss (for one batch) at step 21825: 0.0006\n",
            "Seen so far: 698432 samples\n",
            "0.9708318\n",
            "Training loss (for one batch) at step 21830: 0.0037\n",
            "Seen so far: 698592 samples\n",
            "0.9708342\n",
            "Training loss (for one batch) at step 21835: 0.1202\n",
            "Seen so far: 698752 samples\n",
            "0.97083944\n",
            "Training loss (for one batch) at step 21840: 0.0019\n",
            "Seen so far: 698912 samples\n",
            "0.9708447\n",
            "Training loss (for one batch) at step 21845: 0.0216\n",
            "Seen so far: 699072 samples\n",
            "0.97084993\n",
            "Training loss (for one batch) at step 21850: 0.0832\n",
            "Seen so far: 699232 samples\n",
            "0.97085375\n",
            "Training loss (for one batch) at step 21855: 0.1040\n",
            "Seen so far: 699392 samples\n",
            "0.97085756\n",
            "Training loss (for one batch) at step 21860: 0.0303\n",
            "Seen so far: 699552 samples\n",
            "0.9708571\n",
            "Training loss (for one batch) at step 21865: 0.0776\n",
            "Seen so far: 699712 samples\n",
            "0.97086084\n",
            "Training loss (for one batch) at step 21870: 0.2320\n",
            "Seen so far: 699872 samples\n",
            "0.97086465\n",
            "Training loss (for one batch) at step 21875: 0.0272\n",
            "Seen so far: 700032 samples\n",
            "0.97086847\n",
            "Training loss (for one batch) at step 21880: 0.0043\n",
            "Seen so far: 700192 samples\n",
            "0.9708723\n",
            "Training loss (for one batch) at step 21885: 0.1072\n",
            "Seen so far: 700352 samples\n",
            "0.97087467\n",
            "Training loss (for one batch) at step 21890: 0.1501\n",
            "Seen so far: 700512 samples\n",
            "0.97087276\n",
            "Training loss (for one batch) at step 21895: 0.0002\n",
            "Seen so far: 700672 samples\n",
            "0.9708765\n",
            "Training loss (for one batch) at step 21900: 0.0100\n",
            "Seen so far: 700832 samples\n",
            "0.97087604\n",
            "Training loss (for one batch) at step 21905: 0.0062\n",
            "Seen so far: 700992 samples\n",
            "0.9708827\n",
            "Training loss (for one batch) at step 21910: 0.0038\n",
            "Seen so far: 701152 samples\n",
            "0.97088647\n",
            "Training loss (for one batch) at step 21915: 0.1035\n",
            "Seen so far: 701312 samples\n",
            "0.97088885\n",
            "Training loss (for one batch) at step 21920: 0.0001\n",
            "Seen so far: 701472 samples\n",
            "0.97089404\n",
            "Training loss (for one batch) at step 21925: 0.1569\n",
            "Seen so far: 701632 samples\n",
            "0.970895\n",
            "Training loss (for one batch) at step 21930: 0.0341\n",
            "Seen so far: 701792 samples\n",
            "0.9709016\n",
            "Training loss (for one batch) at step 21935: 0.0356\n",
            "Seen so far: 701952 samples\n",
            "0.97090685\n",
            "Training loss (for one batch) at step 21940: 0.0003\n",
            "Seen so far: 702112 samples\n",
            "0.97091204\n",
            "Training loss (for one batch) at step 21945: 0.0000\n",
            "Seen so far: 702272 samples\n",
            "0.97091585\n",
            "Training loss (for one batch) at step 21950: 0.0298\n",
            "Seen so far: 702432 samples\n",
            "0.97092104\n",
            "Training loss (for one batch) at step 21955: 0.0028\n",
            "Seen so far: 702592 samples\n",
            "0.97092766\n",
            "Training loss (for one batch) at step 21960: 0.0072\n",
            "Seen so far: 702752 samples\n",
            "0.97093\n",
            "Training loss (for one batch) at step 21965: 0.2146\n",
            "Seen so far: 702912 samples\n",
            "0.97093236\n",
            "Training loss (for one batch) at step 21970: 0.0036\n",
            "Seen so far: 703072 samples\n",
            "0.97093755\n",
            "Training loss (for one batch) at step 21975: 0.1260\n",
            "Seen so far: 703232 samples\n",
            "0.97094274\n",
            "Training loss (for one batch) at step 21980: 0.0008\n",
            "Seen so far: 703392 samples\n",
            "0.97094506\n",
            "Training loss (for one batch) at step 21985: 0.0006\n",
            "Seen so far: 703552 samples\n",
            "0.970946\n",
            "Training loss (for one batch) at step 21990: 0.0041\n",
            "Seen so far: 703712 samples\n",
            "0.9709512\n",
            "Training loss (for one batch) at step 21995: 0.0430\n",
            "Seen so far: 703872 samples\n",
            "0.9709535\n",
            "Training loss (for one batch) at step 22000: 0.1585\n",
            "Seen so far: 704032 samples\n",
            "0.9709544\n",
            "Training loss (for one batch) at step 22005: 0.0113\n",
            "Seen so far: 704192 samples\n",
            "0.9709596\n",
            "Training loss (for one batch) at step 22010: 0.0031\n",
            "Seen so far: 704352 samples\n",
            "0.97096056\n",
            "Training loss (for one batch) at step 22015: 0.0494\n",
            "Seen so far: 704512 samples\n",
            "0.97096574\n",
            "Training loss (for one batch) at step 22020: 0.0059\n",
            "Seen so far: 704672 samples\n",
            "0.97097087\n",
            "Training loss (for one batch) at step 22025: 0.0093\n",
            "Seen so far: 704832 samples\n",
            "0.97097605\n",
            "Training loss (for one batch) at step 22030: 0.5703\n",
            "Seen so far: 704992 samples\n",
            "0.9709798\n",
            "Training loss (for one batch) at step 22035: 0.0042\n",
            "Seen so far: 705152 samples\n",
            "0.97098356\n",
            "Training loss (for one batch) at step 22040: 0.0003\n",
            "Seen so far: 705312 samples\n",
            "0.97098875\n",
            "Training loss (for one batch) at step 22045: 0.0316\n",
            "Seen so far: 705472 samples\n",
            "0.9709939\n",
            "Training loss (for one batch) at step 22050: 0.0074\n",
            "Seen so far: 705632 samples\n",
            "0.97099763\n",
            "Training loss (for one batch) at step 22055: 0.0007\n",
            "Seen so far: 705792 samples\n",
            "0.9710028\n",
            "Training loss (for one batch) at step 22060: 0.0447\n",
            "Seen so far: 705952 samples\n",
            "0.97100794\n",
            "Training loss (for one batch) at step 22065: 0.0004\n",
            "Seen so far: 706112 samples\n",
            "0.97101307\n",
            "Training loss (for one batch) at step 22070: 0.0135\n",
            "Seen so far: 706272 samples\n",
            "0.97101825\n",
            "Training loss (for one batch) at step 22075: 0.0411\n",
            "Seen so far: 706432 samples\n",
            "0.9710206\n",
            "Training loss (for one batch) at step 22080: 0.0164\n",
            "Seen so far: 706592 samples\n",
            "0.9710257\n",
            "Training loss (for one batch) at step 22085: 0.0023\n",
            "Seen so far: 706752 samples\n",
            "0.97103083\n",
            "Training loss (for one batch) at step 22090: 0.0025\n",
            "Seen so far: 706912 samples\n",
            "0.9710346\n",
            "Training loss (for one batch) at step 22095: 0.1244\n",
            "Seen so far: 707072 samples\n",
            "0.9710397\n",
            "Training loss (for one batch) at step 22100: 0.0011\n",
            "Seen so far: 707232 samples\n",
            "0.97104627\n",
            "Training loss (for one batch) at step 22105: 0.0303\n",
            "Seen so far: 707392 samples\n",
            "0.9710514\n",
            "Training loss (for one batch) at step 22110: 0.0011\n",
            "Seen so far: 707552 samples\n",
            "0.97105515\n",
            "Training loss (for one batch) at step 22115: 0.0006\n",
            "Seen so far: 707712 samples\n",
            "0.9710603\n",
            "Training loss (for one batch) at step 22120: 0.0586\n",
            "Seen so far: 707872 samples\n",
            "0.971064\n",
            "Training loss (for one batch) at step 22125: 0.0017\n",
            "Seen so far: 708032 samples\n",
            "0.9710705\n",
            "Training loss (for one batch) at step 22130: 0.0688\n",
            "Seen so far: 708192 samples\n",
            "0.9710728\n",
            "Training loss (for one batch) at step 22135: 0.0002\n",
            "Seen so far: 708352 samples\n",
            "0.9710779\n",
            "Training loss (for one batch) at step 22140: 0.0448\n",
            "Seen so far: 708512 samples\n",
            "0.97107744\n",
            "Training loss (for one batch) at step 22145: 0.1161\n",
            "Seen so far: 708672 samples\n",
            "0.9710797\n",
            "Training loss (for one batch) at step 22150: 0.1383\n",
            "Seen so far: 708832 samples\n",
            "0.9710834\n",
            "Training loss (for one batch) at step 22155: 0.0056\n",
            "Seen so far: 708992 samples\n",
            "0.97108996\n",
            "Training loss (for one batch) at step 22160: 0.1182\n",
            "Seen so far: 709152 samples\n",
            "0.971095\n",
            "Training loss (for one batch) at step 22165: 0.0024\n",
            "Seen so far: 709312 samples\n",
            "0.9710988\n",
            "Training loss (for one batch) at step 22170: 0.0015\n",
            "Seen so far: 709472 samples\n",
            "0.97110385\n",
            "Training loss (for one batch) at step 22175: 0.0967\n",
            "Seen so far: 709632 samples\n",
            "0.971109\n",
            "Training loss (for one batch) at step 22180: 0.0103\n",
            "Seen so far: 709792 samples\n",
            "0.97111267\n",
            "Training loss (for one batch) at step 22185: 0.0498\n",
            "Seen so far: 709952 samples\n",
            "0.97111636\n",
            "Training loss (for one batch) at step 22190: 0.0145\n",
            "Seen so far: 710112 samples\n",
            "0.97112143\n",
            "Training loss (for one batch) at step 22195: 0.0062\n",
            "Seen so far: 710272 samples\n",
            "0.97112656\n",
            "Training loss (for one batch) at step 22200: 0.0149\n",
            "Seen so far: 710432 samples\n",
            "0.97113025\n",
            "Training loss (for one batch) at step 22205: 0.0243\n",
            "Seen so far: 710592 samples\n",
            "0.97113395\n",
            "Training loss (for one batch) at step 22210: 0.0136\n",
            "Seen so far: 710752 samples\n",
            "0.97114044\n",
            "Training loss (for one batch) at step 22215: 0.0218\n",
            "Seen so far: 710912 samples\n",
            "0.9711455\n",
            "Training loss (for one batch) at step 22220: 0.0026\n",
            "Seen so far: 711072 samples\n",
            "0.9711464\n",
            "Training loss (for one batch) at step 22225: 0.0013\n",
            "Seen so far: 711232 samples\n",
            "0.9711529\n",
            "Training loss (for one batch) at step 22230: 0.0208\n",
            "Seen so far: 711392 samples\n",
            "0.97115797\n",
            "Training loss (for one batch) at step 22235: 0.0028\n",
            "Seen so far: 711552 samples\n",
            "0.97116446\n",
            "Training loss (for one batch) at step 22240: 0.0110\n",
            "Seen so far: 711712 samples\n",
            "0.9711625\n",
            "Training loss (for one batch) at step 22245: 0.0003\n",
            "Seen so far: 711872 samples\n",
            "0.9711662\n",
            "Training loss (for one batch) at step 22250: 0.0035\n",
            "Seen so far: 712032 samples\n",
            "0.97117126\n",
            "Training loss (for one batch) at step 22255: 0.0590\n",
            "Seen so far: 712192 samples\n",
            "0.9711749\n",
            "Training loss (for one batch) at step 22260: 0.0014\n",
            "Seen so far: 712352 samples\n",
            "0.9711814\n",
            "Training loss (for one batch) at step 22265: 0.0007\n",
            "Seen so far: 712512 samples\n",
            "0.97118646\n",
            "Training loss (for one batch) at step 22270: 0.1667\n",
            "Seen so far: 712672 samples\n",
            "0.9711873\n",
            "Training loss (for one batch) at step 22275: 0.0021\n",
            "Seen so far: 712832 samples\n",
            "0.9711938\n",
            "Training loss (for one batch) at step 22280: 0.0322\n",
            "Seen so far: 712992 samples\n",
            "0.97119886\n",
            "Training loss (for one batch) at step 22285: 0.0184\n",
            "Seen so far: 713152 samples\n",
            "0.9712025\n",
            "Training loss (for one batch) at step 22290: 0.0463\n",
            "Seen so far: 713312 samples\n",
            "0.9712061\n",
            "Training loss (for one batch) at step 22295: 0.0767\n",
            "Seen so far: 713472 samples\n",
            "0.971207\n",
            "Training loss (for one batch) at step 22300: 0.0042\n",
            "Seen so far: 713632 samples\n",
            "0.9712092\n",
            "Training loss (for one batch) at step 22305: 0.0543\n",
            "Seen so far: 713792 samples\n",
            "0.9712115\n",
            "Training loss (for one batch) at step 22310: 0.0012\n",
            "Seen so far: 713952 samples\n",
            "0.9712151\n",
            "Training loss (for one batch) at step 22315: 0.0024\n",
            "Seen so far: 714112 samples\n",
            "0.9712202\n",
            "Training loss (for one batch) at step 22320: 0.0006\n",
            "Seen so far: 714272 samples\n",
            "0.97122663\n",
            "Training loss (for one batch) at step 22325: 0.0001\n",
            "Seen so far: 714432 samples\n",
            "0.97123307\n",
            "Training loss (for one batch) at step 22330: 0.0166\n",
            "Seen so far: 714592 samples\n",
            "0.9712395\n",
            "Training loss (for one batch) at step 22335: 0.0030\n",
            "Seen so far: 714752 samples\n",
            "0.9712446\n",
            "Training loss (for one batch) at step 22340: 0.0007\n",
            "Seen so far: 714912 samples\n",
            "0.9712482\n",
            "Training loss (for one batch) at step 22345: 0.0046\n",
            "Seen so far: 715072 samples\n",
            "0.97125185\n",
            "Training loss (for one batch) at step 22350: 0.0606\n",
            "Seen so far: 715232 samples\n",
            "0.9712555\n",
            "Training loss (for one batch) at step 22355: 0.1018\n",
            "Seen so far: 715392 samples\n",
            "0.9712605\n",
            "Training loss (for one batch) at step 22360: 0.0001\n",
            "Seen so far: 715552 samples\n",
            "0.9712641\n",
            "Training loss (for one batch) at step 22365: 0.0069\n",
            "Seen so far: 715712 samples\n",
            "0.9712692\n",
            "Training loss (for one batch) at step 22370: 0.0300\n",
            "Seen so far: 715872 samples\n",
            "0.9712742\n",
            "Training loss (for one batch) at step 22375: 0.0007\n",
            "Seen so far: 716032 samples\n",
            "0.9712792\n",
            "Training loss (for one batch) at step 22380: 0.0011\n",
            "Seen so far: 716192 samples\n",
            "0.9712842\n",
            "Training loss (for one batch) at step 22385: 0.1483\n",
            "Seen so far: 716352 samples\n",
            "0.97128505\n",
            "Training loss (for one batch) at step 22390: 0.0001\n",
            "Seen so far: 716512 samples\n",
            "0.9712915\n",
            "Training loss (for one batch) at step 22395: 0.0000\n",
            "Seen so far: 716672 samples\n",
            "0.97129786\n",
            "Training loss (for one batch) at step 22400: 0.0417\n",
            "Seen so far: 716832 samples\n",
            "0.9713015\n",
            "Training loss (for one batch) at step 22405: 0.0727\n",
            "Seen so far: 716992 samples\n",
            "0.97130513\n",
            "Training loss (for one batch) at step 22410: 0.0023\n",
            "Seen so far: 717152 samples\n",
            "0.97131014\n",
            "Training loss (for one batch) at step 22415: 0.0316\n",
            "Seen so far: 717312 samples\n",
            "0.971311\n",
            "Training loss (for one batch) at step 22420: 0.0113\n",
            "Seen so far: 717472 samples\n",
            "0.97131455\n",
            "Training loss (for one batch) at step 22425: 0.0021\n",
            "Seen so far: 717632 samples\n",
            "0.97131675\n",
            "Training loss (for one batch) at step 22430: 0.0059\n",
            "Seen so far: 717792 samples\n",
            "0.9713176\n",
            "Training loss (for one batch) at step 22435: 0.3307\n",
            "Seen so far: 717952 samples\n",
            "0.9713156\n",
            "Training loss (for one batch) at step 22440: 0.0350\n",
            "Seen so far: 718112 samples\n",
            "0.9713206\n",
            "Training loss (for one batch) at step 22445: 0.0492\n",
            "Seen so far: 718272 samples\n",
            "0.971327\n",
            "Training loss (for one batch) at step 22450: 0.0383\n",
            "Seen so far: 718432 samples\n",
            "0.97133064\n",
            "Training loss (for one batch) at step 22455: 0.0145\n",
            "Seen so far: 718592 samples\n",
            "0.9713356\n",
            "Training loss (for one batch) at step 22460: 0.2431\n",
            "Seen so far: 718752 samples\n",
            "0.9713392\n",
            "Training loss (for one batch) at step 22465: 0.2321\n",
            "Seen so far: 718912 samples\n",
            "0.9713428\n",
            "Training loss (for one batch) at step 22470: 0.0019\n",
            "Seen so far: 719072 samples\n",
            "0.9713478\n",
            "Training loss (for one batch) at step 22475: 0.0414\n",
            "Seen so far: 719232 samples\n",
            "0.9713514\n",
            "Training loss (for one batch) at step 22480: 0.0800\n",
            "Seen so far: 719392 samples\n",
            "0.9713522\n",
            "Training loss (for one batch) at step 22485: 0.0599\n",
            "Seen so far: 719552 samples\n",
            "0.97135717\n",
            "Training loss (for one batch) at step 22490: 0.0741\n",
            "Seen so far: 719712 samples\n",
            "0.97136074\n",
            "Training loss (for one batch) at step 22495: 0.0005\n",
            "Seen so far: 719872 samples\n",
            "0.97136575\n",
            "Training loss (for one batch) at step 22500: 0.0002\n",
            "Seen so far: 720032 samples\n",
            "0.9713665\n",
            "Training loss (for one batch) at step 22505: 0.1305\n",
            "Seen so far: 720192 samples\n",
            "0.97136736\n",
            "Training loss (for one batch) at step 22510: 0.0043\n",
            "Seen so far: 720352 samples\n",
            "0.9713723\n",
            "Training loss (for one batch) at step 22515: 0.0020\n",
            "Seen so far: 720512 samples\n",
            "0.97137034\n",
            "Training loss (for one batch) at step 22520: 0.1642\n",
            "Seen so far: 720672 samples\n",
            "0.9713684\n",
            "Training loss (for one batch) at step 22525: 0.0048\n",
            "Seen so far: 720832 samples\n",
            "0.9713734\n",
            "Training loss (for one batch) at step 22530: 0.0096\n",
            "Seen so far: 720992 samples\n",
            "0.97137696\n",
            "Training loss (for one batch) at step 22535: 0.0337\n",
            "Seen so far: 721152 samples\n",
            "0.9713833\n",
            "Training loss (for one batch) at step 22540: 0.0033\n",
            "Seen so far: 721312 samples\n",
            "0.97138965\n",
            "Training loss (for one batch) at step 22545: 0.0491\n",
            "Seen so far: 721472 samples\n",
            "0.9713904\n",
            "Training loss (for one batch) at step 22550: 0.0678\n",
            "Seen so far: 721632 samples\n",
            "0.97138983\n",
            "Training loss (for one batch) at step 22555: 0.1237\n",
            "Seen so far: 721792 samples\n",
            "0.9713948\n",
            "Training loss (for one batch) at step 22560: 0.0098\n",
            "Seen so far: 721952 samples\n",
            "0.971397\n",
            "Training loss (for one batch) at step 22565: 0.0008\n",
            "Seen so far: 722112 samples\n",
            "0.9713978\n",
            "Training loss (for one batch) at step 22570: 0.0006\n",
            "Seen so far: 722272 samples\n",
            "0.97140414\n",
            "Training loss (for one batch) at step 22575: 0.0291\n",
            "Seen so far: 722432 samples\n",
            "0.9714077\n",
            "Training loss (for one batch) at step 22580: 0.0432\n",
            "Seen so far: 722592 samples\n",
            "0.97140574\n",
            "Training loss (for one batch) at step 22585: 0.0010\n",
            "Seen so far: 722752 samples\n",
            "0.97141206\n",
            "Training loss (for one batch) at step 22590: 0.0000\n",
            "Seen so far: 722912 samples\n",
            "0.9714156\n",
            "Training loss (for one batch) at step 22595: 0.0130\n",
            "Seen so far: 723072 samples\n",
            "0.97141916\n",
            "Training loss (for one batch) at step 22600: 0.0021\n",
            "Seen so far: 723232 samples\n",
            "0.9714255\n",
            "Training loss (for one batch) at step 22605: 0.0064\n",
            "Seen so far: 723392 samples\n",
            "0.9714304\n",
            "Training loss (for one batch) at step 22610: 0.0175\n",
            "Seen so far: 723552 samples\n",
            "0.97143674\n",
            "Training loss (for one batch) at step 22615: 0.0419\n",
            "Seen so far: 723712 samples\n",
            "0.9714403\n",
            "Training loss (for one batch) at step 22620: 0.0038\n",
            "Seen so far: 723872 samples\n",
            "0.9714452\n",
            "Training loss (for one batch) at step 22625: 0.0010\n",
            "Seen so far: 724032 samples\n",
            "0.9714515\n",
            "Training loss (for one batch) at step 22630: 0.0022\n",
            "Seen so far: 724192 samples\n",
            "0.97145784\n",
            "Training loss (for one batch) at step 22635: 0.0204\n",
            "Seen so far: 724352 samples\n",
            "0.9714628\n",
            "Training loss (for one batch) at step 22640: 0.0005\n",
            "Seen so far: 724512 samples\n",
            "0.9714677\n",
            "Training loss (for one batch) at step 22645: 0.0078\n",
            "Seen so far: 724672 samples\n",
            "0.9714726\n",
            "Training loss (for one batch) at step 22650: 0.0012\n",
            "Seen so far: 724832 samples\n",
            "0.9714789\n",
            "Training loss (for one batch) at step 22655: 0.0141\n",
            "Seen so far: 724992 samples\n",
            "0.9714852\n",
            "Training loss (for one batch) at step 22660: 0.0023\n",
            "Seen so far: 725152 samples\n",
            "0.9714915\n",
            "Training loss (for one batch) at step 22665: 0.0122\n",
            "Seen so far: 725312 samples\n",
            "0.9714964\n",
            "Training loss (for one batch) at step 22670: 0.0130\n",
            "Seen so far: 725472 samples\n",
            "0.97150266\n",
            "Training loss (for one batch) at step 22675: 0.0857\n",
            "Seen so far: 725632 samples\n",
            "0.9715076\n",
            "Training loss (for one batch) at step 22680: 0.0003\n",
            "Seen so far: 725792 samples\n",
            "0.9715111\n",
            "Training loss (for one batch) at step 22685: 0.1298\n",
            "Seen so far: 725952 samples\n",
            "0.971516\n",
            "Training loss (for one batch) at step 22690: 0.0025\n",
            "Seen so far: 726112 samples\n",
            "0.9715223\n",
            "Training loss (for one batch) at step 22695: 0.0008\n",
            "Seen so far: 726272 samples\n",
            "0.9715272\n",
            "Training loss (for one batch) at step 22700: 0.0003\n",
            "Seen so far: 726432 samples\n",
            "0.9715321\n",
            "Training loss (for one batch) at step 22705: 0.1156\n",
            "Seen so far: 726592 samples\n",
            "0.9715356\n",
            "Training loss (for one batch) at step 22710: 0.0007\n",
            "Seen so far: 726752 samples\n",
            "0.9715405\n",
            "Training loss (for one batch) at step 22715: 0.0035\n",
            "Seen so far: 726912 samples\n",
            "0.9715454\n",
            "Training loss (for one batch) at step 22720: 0.0044\n",
            "Seen so far: 727072 samples\n",
            "0.9715503\n",
            "Training loss (for one batch) at step 22725: 0.0060\n",
            "Seen so far: 727232 samples\n",
            "0.9715538\n",
            "Training loss (for one batch) at step 22730: 0.0267\n",
            "Seen so far: 727392 samples\n",
            "0.9715559\n",
            "Training loss (for one batch) at step 22735: 0.0412\n",
            "Seen so far: 727552 samples\n",
            "0.9715608\n",
            "Training loss (for one batch) at step 22740: 0.0674\n",
            "Seen so far: 727712 samples\n",
            "0.97156155\n",
            "Training loss (for one batch) at step 22745: 0.0433\n",
            "Seen so far: 727872 samples\n",
            "0.9715623\n",
            "Training loss (for one batch) at step 22750: 0.1601\n",
            "Seen so far: 728032 samples\n",
            "0.9715672\n",
            "Training loss (for one batch) at step 22755: 0.0020\n",
            "Seen so far: 728192 samples\n",
            "0.9715734\n",
            "Training loss (for one batch) at step 22760: 0.0106\n",
            "Seen so far: 728352 samples\n",
            "0.9715783\n",
            "Training loss (for one batch) at step 22765: 0.0052\n",
            "Seen so far: 728512 samples\n",
            "0.9715818\n",
            "Training loss (for one batch) at step 22770: 0.0023\n",
            "Seen so far: 728672 samples\n",
            "0.97158664\n",
            "Training loss (for one batch) at step 22775: 0.2618\n",
            "Seen so far: 728832 samples\n",
            "0.97159016\n",
            "Training loss (for one batch) at step 22780: 0.0005\n",
            "Seen so far: 728992 samples\n",
            "0.97159505\n",
            "Training loss (for one batch) at step 22785: 0.0049\n",
            "Seen so far: 729152 samples\n",
            "0.97160125\n",
            "Training loss (for one batch) at step 22790: 0.0451\n",
            "Seen so far: 729312 samples\n",
            "0.97160614\n",
            "Training loss (for one batch) at step 22795: 0.0038\n",
            "Seen so far: 729472 samples\n",
            "0.9716096\n",
            "Training loss (for one batch) at step 22800: 0.0098\n",
            "Seen so far: 729632 samples\n",
            "0.97161585\n",
            "Training loss (for one batch) at step 22805: 0.0976\n",
            "Seen so far: 729792 samples\n",
            "0.9716193\n",
            "Training loss (for one batch) at step 22810: 0.0002\n",
            "Seen so far: 729952 samples\n",
            "0.97162414\n",
            "Training loss (for one batch) at step 22815: 0.0286\n",
            "Seen so far: 730112 samples\n",
            "0.97162765\n",
            "Training loss (for one batch) at step 22820: 0.2440\n",
            "Seen so far: 730272 samples\n",
            "0.97162974\n",
            "Training loss (for one batch) at step 22825: 0.1182\n",
            "Seen so far: 730432 samples\n",
            "0.9716319\n",
            "Training loss (for one batch) at step 22830: 0.0009\n",
            "Seen so far: 730592 samples\n",
            "0.97163534\n",
            "Training loss (for one batch) at step 22835: 0.0037\n",
            "Seen so far: 730752 samples\n",
            "0.97164017\n",
            "Training loss (for one batch) at step 22840: 0.0261\n",
            "Seen so far: 730912 samples\n",
            "0.9716436\n",
            "Training loss (for one batch) at step 22845: 0.0973\n",
            "Seen so far: 731072 samples\n",
            "0.97164303\n",
            "Training loss (for one batch) at step 22850: 0.0093\n",
            "Seen so far: 731232 samples\n",
            "0.9716465\n",
            "Training loss (for one batch) at step 22855: 0.0026\n",
            "Seen so far: 731392 samples\n",
            "0.9716486\n",
            "Training loss (for one batch) at step 22860: 0.0112\n",
            "Seen so far: 731552 samples\n",
            "0.97165066\n",
            "Training loss (for one batch) at step 22865: 0.0651\n",
            "Seen so far: 731712 samples\n",
            "0.97165686\n",
            "Training loss (for one batch) at step 22870: 0.1114\n",
            "Seen so far: 731872 samples\n",
            "0.971659\n",
            "Training loss (for one batch) at step 22875: 0.0119\n",
            "Seen so far: 732032 samples\n",
            "0.97166383\n",
            "Training loss (for one batch) at step 22880: 0.0074\n",
            "Seen so far: 732192 samples\n",
            "0.97166866\n",
            "Training loss (for one batch) at step 22885: 0.0067\n",
            "Seen so far: 732352 samples\n",
            "0.9716748\n",
            "Training loss (for one batch) at step 22890: 0.0033\n",
            "Seen so far: 732512 samples\n",
            "0.9716796\n",
            "Training loss (for one batch) at step 22895: 0.0030\n",
            "Seen so far: 732672 samples\n",
            "0.97168446\n",
            "Training loss (for one batch) at step 22900: 0.0309\n",
            "Seen so far: 732832 samples\n",
            "0.9716879\n",
            "Training loss (for one batch) at step 22905: 0.0135\n",
            "Seen so far: 732992 samples\n",
            "0.9716941\n",
            "Training loss (for one batch) at step 22910: 0.0031\n",
            "Seen so far: 733152 samples\n",
            "0.97169894\n",
            "Training loss (for one batch) at step 22915: 0.0028\n",
            "Seen so far: 733312 samples\n",
            "0.9717051\n",
            "Training loss (for one batch) at step 22920: 0.0001\n",
            "Seen so far: 733472 samples\n",
            "0.9717113\n",
            "Training loss (for one batch) at step 22925: 0.0016\n",
            "Seen so far: 733632 samples\n",
            "0.9717174\n",
            "Training loss (for one batch) at step 22930: 0.0848\n",
            "Seen so far: 733792 samples\n",
            "0.97172225\n",
            "Training loss (for one batch) at step 22935: 0.0725\n",
            "Seen so far: 733952 samples\n",
            "0.971727\n",
            "Training loss (for one batch) at step 22940: 0.0000\n",
            "Seen so far: 734112 samples\n",
            "0.9717332\n",
            "Training loss (for one batch) at step 22945: 0.0008\n",
            "Seen so far: 734272 samples\n",
            "0.97173935\n",
            "Training loss (for one batch) at step 22950: 0.0022\n",
            "Seen so far: 734432 samples\n",
            "0.9717455\n",
            "Training loss (for one batch) at step 22955: 0.0038\n",
            "Seen so far: 734592 samples\n",
            "0.9717517\n",
            "Training loss (for one batch) at step 22960: 0.0042\n",
            "Seen so far: 734752 samples\n",
            "0.9717578\n",
            "Training loss (for one batch) at step 22965: 0.0764\n",
            "Seen so far: 734912 samples\n",
            "0.9717612\n",
            "Training loss (for one batch) at step 22970: 0.0009\n",
            "Seen so far: 735072 samples\n",
            "0.97176737\n",
            "Training loss (for one batch) at step 22975: 0.0074\n",
            "Seen so far: 735232 samples\n",
            "0.97177356\n",
            "Training loss (for one batch) at step 22980: 0.0022\n",
            "Seen so far: 735392 samples\n",
            "0.97177833\n",
            "Training loss (for one batch) at step 22985: 0.0015\n",
            "Seen so far: 735552 samples\n",
            "0.97178173\n",
            "Training loss (for one batch) at step 22990: 0.0021\n",
            "Seen so far: 735712 samples\n",
            "0.97178787\n",
            "Training loss (for one batch) at step 22995: 0.0009\n",
            "Seen so far: 735872 samples\n",
            "0.971794\n",
            "Training loss (for one batch) at step 23000: 0.0646\n",
            "Seen so far: 736032 samples\n",
            "0.9717988\n",
            "Training loss (for one batch) at step 23005: 0.0049\n",
            "Seen so far: 736192 samples\n",
            "0.97180355\n",
            "Training loss (for one batch) at step 23010: 0.0205\n",
            "Seen so far: 736352 samples\n",
            "0.9718097\n",
            "Training loss (for one batch) at step 23015: 0.0012\n",
            "Seen so far: 736512 samples\n",
            "0.9718158\n",
            "Training loss (for one batch) at step 23020: 0.0026\n",
            "Seen so far: 736672 samples\n",
            "0.9718192\n",
            "Training loss (for one batch) at step 23025: 0.0052\n",
            "Seen so far: 736832 samples\n",
            "0.9718226\n",
            "Training loss (for one batch) at step 23030: 0.0035\n",
            "Seen so far: 736992 samples\n",
            "0.97182465\n",
            "Training loss (for one batch) at step 23035: 0.0000\n",
            "Seen so far: 737152 samples\n",
            "0.9718294\n",
            "Training loss (for one batch) at step 23040: 0.0005\n",
            "Seen so far: 737312 samples\n",
            "0.9718328\n",
            "Training loss (for one batch) at step 23045: 0.0009\n",
            "Seen so far: 737472 samples\n",
            "0.97183895\n",
            "Training loss (for one batch) at step 23050: 0.0710\n",
            "Seen so far: 737632 samples\n",
            "0.97184366\n",
            "Training loss (for one batch) at step 23055: 0.0000\n",
            "Seen so far: 737792 samples\n",
            "0.97184706\n",
            "Training loss (for one batch) at step 23060: 0.0002\n",
            "Seen so far: 737952 samples\n",
            "0.9718518\n",
            "Training loss (for one batch) at step 23065: 0.0002\n",
            "Seen so far: 738112 samples\n",
            "0.9718566\n",
            "Training loss (for one batch) at step 23070: 0.0001\n",
            "Seen so far: 738272 samples\n",
            "0.9718613\n",
            "Training loss (for one batch) at step 23075: 0.0019\n",
            "Seen so far: 738432 samples\n",
            "0.9718647\n",
            "Training loss (for one batch) at step 23080: 0.0001\n",
            "Seen so far: 738592 samples\n",
            "0.97186947\n",
            "Training loss (for one batch) at step 23085: 0.0003\n",
            "Seen so far: 738752 samples\n",
            "0.9718728\n",
            "Training loss (for one batch) at step 23090: 0.0002\n",
            "Seen so far: 738912 samples\n",
            "0.97187895\n",
            "Training loss (for one batch) at step 23095: 0.0006\n",
            "Seen so far: 739072 samples\n",
            "0.9718823\n",
            "Training loss (for one batch) at step 23100: 0.0003\n",
            "Seen so far: 739232 samples\n",
            "0.97188705\n",
            "Training loss (for one batch) at step 23105: 0.0001\n",
            "Seen so far: 739392 samples\n",
            "0.97189176\n",
            "Training loss (for one batch) at step 23110: 0.0323\n",
            "Seen so far: 739552 samples\n",
            "0.9718938\n",
            "Training loss (for one batch) at step 23115: 0.0410\n",
            "Seen so far: 739712 samples\n",
            "0.9718958\n",
            "Training loss (for one batch) at step 23120: 0.0003\n",
            "Seen so far: 739872 samples\n",
            "0.97189784\n",
            "Training loss (for one batch) at step 23125: 0.0075\n",
            "Seen so far: 740032 samples\n",
            "0.9719039\n",
            "Training loss (for one batch) at step 23130: 0.0272\n",
            "Seen so far: 740192 samples\n",
            "0.97191\n",
            "Training loss (for one batch) at step 23135: 0.0086\n",
            "Seen so far: 740352 samples\n",
            "0.9719161\n",
            "Training loss (for one batch) at step 23140: 0.0022\n",
            "Seen so far: 740512 samples\n",
            "0.9719194\n",
            "Training loss (for one batch) at step 23145: 0.0017\n",
            "Seen so far: 740672 samples\n",
            "0.9719255\n",
            "Training loss (for one batch) at step 23150: 0.1931\n",
            "Seen so far: 740832 samples\n",
            "0.9719275\n",
            "Training loss (for one batch) at step 23155: 0.1225\n",
            "Seen so far: 740992 samples\n",
            "0.9719282\n",
            "Training loss (for one batch) at step 23160: 0.0000\n",
            "Seen so far: 741152 samples\n",
            "0.9719329\n",
            "Training loss (for one batch) at step 23165: 0.0341\n",
            "Seen so far: 741312 samples\n",
            "0.9719362\n",
            "Training loss (for one batch) at step 23170: 0.0004\n",
            "Seen so far: 741472 samples\n",
            "0.97194093\n",
            "Training loss (for one batch) at step 23175: 0.0123\n",
            "Seen so far: 741632 samples\n",
            "0.97194433\n",
            "Training loss (for one batch) at step 23180: 0.0011\n",
            "Seen so far: 741792 samples\n",
            "0.9719463\n",
            "Training loss (for one batch) at step 23185: 0.0045\n",
            "Seen so far: 741952 samples\n",
            "0.971951\n",
            "Training loss (for one batch) at step 23190: 0.0092\n",
            "Seen so far: 742112 samples\n",
            "0.9719476\n",
            "Training loss (for one batch) at step 23195: 0.0126\n",
            "Seen so far: 742272 samples\n",
            "0.9719523\n",
            "Training loss (for one batch) at step 23200: 0.0030\n",
            "Seen so far: 742432 samples\n",
            "0.97195566\n",
            "Training loss (for one batch) at step 23205: 0.0556\n",
            "Seen so far: 742592 samples\n",
            "0.97195363\n",
            "Training loss (for one batch) at step 23210: 0.0025\n",
            "Seen so far: 742752 samples\n",
            "0.97195697\n",
            "Training loss (for one batch) at step 23215: 0.0151\n",
            "Seen so far: 742912 samples\n",
            "0.9719563\n",
            "Training loss (for one batch) at step 23220: 0.0013\n",
            "Seen so far: 743072 samples\n",
            "0.97195697\n",
            "Training loss (for one batch) at step 23225: 0.0064\n",
            "Seen so far: 743232 samples\n",
            "0.9719617\n",
            "Training loss (for one batch) at step 23230: 0.0036\n",
            "Seen so far: 743392 samples\n",
            "0.971965\n",
            "Training loss (for one batch) at step 23235: 0.0065\n",
            "Seen so far: 743552 samples\n",
            "0.97196966\n",
            "Training loss (for one batch) at step 23240: 0.0170\n",
            "Seen so far: 743712 samples\n",
            "0.9719757\n",
            "Training loss (for one batch) at step 23245: 0.0017\n",
            "Seen so far: 743872 samples\n",
            "0.971979\n",
            "Training loss (for one batch) at step 23250: 0.0127\n",
            "Seen so far: 744032 samples\n",
            "0.97198105\n",
            "Training loss (for one batch) at step 23255: 0.0932\n",
            "Seen so far: 744192 samples\n",
            "0.9719857\n",
            "Training loss (for one batch) at step 23260: 0.0012\n",
            "Seen so far: 744352 samples\n",
            "0.97198504\n",
            "Training loss (for one batch) at step 23265: 0.0321\n",
            "Seen so far: 744512 samples\n",
            "0.9719843\n",
            "Training loss (for one batch) at step 23270: 0.0022\n",
            "Seen so far: 744672 samples\n",
            "0.97198904\n",
            "Training loss (for one batch) at step 23275: 0.0000\n",
            "Seen so far: 744832 samples\n",
            "0.97199506\n",
            "Training loss (for one batch) at step 23280: 0.0257\n",
            "Seen so far: 744992 samples\n",
            "0.9719997\n",
            "Training loss (for one batch) at step 23285: 0.0116\n",
            "Seen so far: 745152 samples\n",
            "0.97200304\n",
            "Training loss (for one batch) at step 23290: 0.0003\n",
            "Seen so far: 745312 samples\n",
            "0.9720064\n",
            "Training loss (for one batch) at step 23295: 0.1613\n",
            "Seen so far: 745472 samples\n",
            "0.97200835\n",
            "Training loss (for one batch) at step 23300: 0.0448\n",
            "Seen so far: 745632 samples\n",
            "0.972013\n",
            "Training loss (for one batch) at step 23305: 0.0002\n",
            "Seen so far: 745792 samples\n",
            "0.97201496\n",
            "Training loss (for one batch) at step 23310: 0.0289\n",
            "Seen so far: 745952 samples\n",
            "0.9720197\n",
            "Training loss (for one batch) at step 23315: 0.1559\n",
            "Seen so far: 746112 samples\n",
            "0.97202295\n",
            "Training loss (for one batch) at step 23320: 0.0159\n",
            "Seen so far: 746272 samples\n",
            "0.9720263\n",
            "Training loss (for one batch) at step 23325: 0.0030\n",
            "Seen so far: 746432 samples\n",
            "0.9720323\n",
            "Training loss (for one batch) at step 23330: 0.0022\n",
            "Seen so far: 746592 samples\n",
            "0.9720356\n",
            "Training loss (for one batch) at step 23335: 0.0153\n",
            "Seen so far: 746752 samples\n",
            "0.97203755\n",
            "Training loss (for one batch) at step 23340: 0.0204\n",
            "Seen so far: 746912 samples\n",
            "0.9720422\n",
            "Training loss (for one batch) at step 23345: 0.0085\n",
            "Seen so far: 747072 samples\n",
            "0.97204685\n",
            "Training loss (for one batch) at step 23350: 0.0000\n",
            "Seen so far: 747232 samples\n",
            "0.9720502\n",
            "Training loss (for one batch) at step 23355: 0.2935\n",
            "Seen so far: 747392 samples\n",
            "0.9720508\n",
            "Training loss (for one batch) at step 23360: 0.1094\n",
            "Seen so far: 747552 samples\n",
            "0.97205275\n",
            "Training loss (for one batch) at step 23365: 0.0204\n",
            "Seen so far: 747712 samples\n",
            "0.9720574\n",
            "Training loss (for one batch) at step 23370: 0.0015\n",
            "Seen so far: 747872 samples\n",
            "0.97205937\n",
            "Training loss (for one batch) at step 23375: 0.0010\n",
            "Seen so far: 748032 samples\n",
            "0.9720627\n",
            "Training loss (for one batch) at step 23380: 0.0007\n",
            "Seen so far: 748192 samples\n",
            "0.9720647\n",
            "Training loss (for one batch) at step 23385: 0.0019\n",
            "Seen so far: 748352 samples\n",
            "0.97206795\n",
            "Training loss (for one batch) at step 23390: 0.0939\n",
            "Seen so far: 748512 samples\n",
            "0.9720686\n",
            "Training loss (for one batch) at step 23395: 0.0009\n",
            "Seen so far: 748672 samples\n",
            "0.9720706\n",
            "Training loss (for one batch) at step 23400: 0.0117\n",
            "Seen so far: 748832 samples\n",
            "0.9720725\n",
            "Training loss (for one batch) at step 23405: 0.0057\n",
            "Seen so far: 748992 samples\n",
            "0.97207445\n",
            "Training loss (for one batch) at step 23410: 0.0043\n",
            "Seen so far: 749152 samples\n",
            "0.9720764\n",
            "Training loss (for one batch) at step 23415: 0.0057\n",
            "Seen so far: 749312 samples\n",
            "0.97208107\n",
            "Training loss (for one batch) at step 23420: 0.0834\n",
            "Seen so far: 749472 samples\n",
            "0.97208035\n",
            "Training loss (for one batch) at step 23425: 0.0022\n",
            "Seen so far: 749632 samples\n",
            "0.972085\n",
            "Training loss (for one batch) at step 23430: 0.0060\n",
            "Seen so far: 749792 samples\n",
            "0.9720883\n",
            "Training loss (for one batch) at step 23435: 0.0016\n",
            "Seen so far: 749952 samples\n",
            "0.97209424\n",
            "Training loss (for one batch) at step 23440: 0.1864\n",
            "Seen so far: 750112 samples\n",
            "0.9720935\n",
            "Training loss (for one batch) at step 23445: 0.1423\n",
            "Seen so far: 750272 samples\n",
            "0.9720968\n",
            "Training loss (for one batch) at step 23450: 0.0015\n",
            "Seen so far: 750432 samples\n",
            "0.97210276\n",
            "Training loss (for one batch) at step 23455: 0.0023\n",
            "Seen so far: 750592 samples\n",
            "0.97210604\n",
            "Training loss (for one batch) at step 23460: 0.0019\n",
            "Seen so far: 750752 samples\n",
            "0.97210795\n",
            "Training loss (for one batch) at step 23465: 0.0003\n",
            "Seen so far: 750912 samples\n",
            "0.9721112\n",
            "Training loss (for one batch) at step 23470: 0.0132\n",
            "Seen so far: 751072 samples\n",
            "0.9721145\n",
            "Training loss (for one batch) at step 23475: 0.0066\n",
            "Seen so far: 751232 samples\n",
            "0.97211915\n",
            "Training loss (for one batch) at step 23480: 0.0012\n",
            "Seen so far: 751392 samples\n",
            "0.97212374\n",
            "Training loss (for one batch) at step 23485: 0.0011\n",
            "Seen so far: 751552 samples\n",
            "0.97212833\n",
            "Training loss (for one batch) at step 23490: 0.0024\n",
            "Seen so far: 751712 samples\n",
            "0.9721316\n",
            "Training loss (for one batch) at step 23495: 0.1065\n",
            "Seen so far: 751872 samples\n",
            "0.9721336\n",
            "Training loss (for one batch) at step 23500: 0.0378\n",
            "Seen so far: 752032 samples\n",
            "0.9721342\n",
            "Training loss (for one batch) at step 23505: 0.0303\n",
            "Seen so far: 752192 samples\n",
            "0.97213745\n",
            "Training loss (for one batch) at step 23510: 0.0083\n",
            "Seen so far: 752352 samples\n",
            "0.97214204\n",
            "Training loss (for one batch) at step 23515: 0.1977\n",
            "Seen so far: 752512 samples\n",
            "0.97214264\n",
            "Training loss (for one batch) at step 23520: 0.0038\n",
            "Seen so far: 752672 samples\n",
            "0.9721472\n",
            "Training loss (for one batch) at step 23525: 0.0162\n",
            "Seen so far: 752832 samples\n",
            "0.9721518\n",
            "Training loss (for one batch) at step 23530: 0.0106\n",
            "Seen so far: 752992 samples\n",
            "0.9721538\n",
            "Training loss (for one batch) at step 23535: 0.0087\n",
            "Seen so far: 753152 samples\n",
            "0.9721583\n",
            "Training loss (for one batch) at step 23540: 0.0001\n",
            "Seen so far: 753312 samples\n",
            "0.97215897\n",
            "Training loss (for one batch) at step 23545: 0.0024\n",
            "Seen so far: 753472 samples\n",
            "0.97216356\n",
            "Training loss (for one batch) at step 23550: 0.0001\n",
            "Seen so far: 753632 samples\n",
            "0.9721681\n",
            "Training loss (for one batch) at step 23555: 0.0005\n",
            "Seen so far: 753792 samples\n",
            "0.9721727\n",
            "Training loss (for one batch) at step 23560: 0.0029\n",
            "Seen so far: 753952 samples\n",
            "0.9721786\n",
            "Training loss (for one batch) at step 23565: 0.0002\n",
            "Seen so far: 754112 samples\n",
            "0.97218317\n",
            "Training loss (for one batch) at step 23570: 0.0446\n",
            "Seen so far: 754272 samples\n",
            "0.97218776\n",
            "Training loss (for one batch) at step 23575: 0.0159\n",
            "Seen so far: 754432 samples\n",
            "0.97219235\n",
            "Training loss (for one batch) at step 23580: 0.0027\n",
            "Seen so far: 754592 samples\n",
            "0.97219557\n",
            "Training loss (for one batch) at step 23585: 0.0236\n",
            "Seen so far: 754752 samples\n",
            "0.97220016\n",
            "Training loss (for one batch) at step 23590: 0.0387\n",
            "Seen so far: 754912 samples\n",
            "0.9722047\n",
            "Training loss (for one batch) at step 23595: 0.0295\n",
            "Seen so far: 755072 samples\n",
            "0.9722093\n",
            "Training loss (for one batch) at step 23600: 0.1464\n",
            "Seen so far: 755232 samples\n",
            "0.9722099\n",
            "Training loss (for one batch) at step 23605: 0.0311\n",
            "Seen so far: 755392 samples\n",
            "0.9722118\n",
            "Training loss (for one batch) at step 23610: 0.0207\n",
            "Seen so far: 755552 samples\n",
            "0.9722177\n",
            "Training loss (for one batch) at step 23615: 0.0753\n",
            "Seen so far: 755712 samples\n",
            "0.9722183\n",
            "Training loss (for one batch) at step 23620: 0.0030\n",
            "Seen so far: 755872 samples\n",
            "0.9722215\n",
            "Training loss (for one batch) at step 23625: 0.0014\n",
            "Seen so far: 756032 samples\n",
            "0.9722274\n",
            "Training loss (for one batch) at step 23630: 0.0007\n",
            "Seen so far: 756192 samples\n",
            "0.9722306\n",
            "Training loss (for one batch) at step 23635: 0.0034\n",
            "Seen so far: 756352 samples\n",
            "0.9722312\n",
            "Training loss (for one batch) at step 23640: 0.0087\n",
            "Seen so far: 756512 samples\n",
            "0.9722331\n",
            "Training loss (for one batch) at step 23645: 0.0473\n",
            "Seen so far: 756672 samples\n",
            "0.97223634\n",
            "Training loss (for one batch) at step 23650: 0.0255\n",
            "Seen so far: 756832 samples\n",
            "0.97223824\n",
            "Training loss (for one batch) at step 23655: 0.0003\n",
            "Seen so far: 756992 samples\n",
            "0.97224146\n",
            "Training loss (for one batch) at step 23660: 0.0007\n",
            "Seen so far: 757152 samples\n",
            "0.9722447\n",
            "Training loss (for one batch) at step 23665: 0.0006\n",
            "Seen so far: 757312 samples\n",
            "0.9722505\n",
            "Training loss (for one batch) at step 23670: 0.0502\n",
            "Seen so far: 757472 samples\n",
            "0.9722511\n",
            "Training loss (for one batch) at step 23675: 0.0014\n",
            "Seen so far: 757632 samples\n",
            "0.97225565\n",
            "Training loss (for one batch) at step 23680: 0.0048\n",
            "Seen so far: 757792 samples\n",
            "0.9722602\n",
            "Training loss (for one batch) at step 23685: 0.0032\n",
            "Seen so far: 757952 samples\n",
            "0.97225946\n",
            "Training loss (for one batch) at step 23690: 0.0429\n",
            "Seen so far: 758112 samples\n",
            "0.97226137\n",
            "Training loss (for one batch) at step 23695: 0.0017\n",
            "Seen so far: 758272 samples\n",
            "0.9722659\n",
            "Training loss (for one batch) at step 23700: 0.0284\n",
            "Seen so far: 758432 samples\n",
            "0.9722704\n",
            "Training loss (for one batch) at step 23705: 0.0022\n",
            "Seen so far: 758592 samples\n",
            "0.9722763\n",
            "Training loss (for one batch) at step 23710: 0.0260\n",
            "Seen so far: 758752 samples\n",
            "0.9722808\n",
            "Training loss (for one batch) at step 23715: 0.0006\n",
            "Seen so far: 758912 samples\n",
            "0.97228533\n",
            "Training loss (for one batch) at step 23720: 0.1714\n",
            "Seen so far: 759072 samples\n",
            "0.97228724\n",
            "Training loss (for one batch) at step 23725: 0.0533\n",
            "Seen so far: 759232 samples\n",
            "0.97228646\n",
            "Training loss (for one batch) at step 23730: 0.0709\n",
            "Seen so far: 759392 samples\n",
            "0.97228837\n",
            "Training loss (for one batch) at step 23735: 0.0072\n",
            "Seen so far: 759552 samples\n",
            "0.9722929\n",
            "Training loss (for one batch) at step 23740: 0.1019\n",
            "Seen so far: 759712 samples\n",
            "0.97229475\n",
            "Training loss (for one batch) at step 23745: 0.0090\n",
            "Seen so far: 759872 samples\n",
            "0.97229666\n",
            "Training loss (for one batch) at step 23750: 0.0001\n",
            "Seen so far: 760032 samples\n",
            "0.97229856\n",
            "Training loss (for one batch) at step 23755: 0.0581\n",
            "Seen so far: 760192 samples\n",
            "0.9723017\n",
            "Training loss (for one batch) at step 23760: 0.0016\n",
            "Seen so far: 760352 samples\n",
            "0.97230756\n",
            "Training loss (for one batch) at step 23765: 0.0004\n",
            "Seen so far: 760512 samples\n",
            "0.97230816\n",
            "Training loss (for one batch) at step 23770: 0.0091\n",
            "Seen so far: 760672 samples\n",
            "0.9723113\n",
            "Training loss (for one batch) at step 23775: 0.1367\n",
            "Seen so far: 760832 samples\n",
            "0.9723132\n",
            "Training loss (for one batch) at step 23780: 0.0040\n",
            "Seen so far: 760992 samples\n",
            "0.9723177\n",
            "Training loss (for one batch) at step 23785: 0.0052\n",
            "Seen so far: 761152 samples\n",
            "0.97232354\n",
            "Training loss (for one batch) at step 23790: 0.0092\n",
            "Seen so far: 761312 samples\n",
            "0.972328\n",
            "Training loss (for one batch) at step 23795: 0.2865\n",
            "Seen so far: 761472 samples\n",
            "0.97233254\n",
            "Training loss (for one batch) at step 23800: 0.0291\n",
            "Seen so far: 761632 samples\n",
            "0.9723357\n",
            "Training loss (for one batch) at step 23805: 0.0061\n",
            "Seen so far: 761792 samples\n",
            "0.9723389\n",
            "Training loss (for one batch) at step 23810: 0.0032\n",
            "Seen so far: 761952 samples\n",
            "0.9723447\n",
            "Training loss (for one batch) at step 23815: 0.0826\n",
            "Seen so far: 762112 samples\n",
            "0.9723492\n",
            "Training loss (for one batch) at step 23820: 0.1144\n",
            "Seen so far: 762272 samples\n",
            "0.9723524\n",
            "Training loss (for one batch) at step 23825: 0.0019\n",
            "Seen so far: 762432 samples\n",
            "0.97235686\n",
            "Training loss (for one batch) at step 23830: 0.0226\n",
            "Seen so far: 762592 samples\n",
            "0.9723614\n",
            "Training loss (for one batch) at step 23835: 0.0010\n",
            "Seen so far: 762752 samples\n",
            "0.97236717\n",
            "Training loss (for one batch) at step 23840: 0.0055\n",
            "Seen so far: 762912 samples\n",
            "0.97237295\n",
            "Training loss (for one batch) at step 23845: 0.0097\n",
            "Seen so far: 763072 samples\n",
            "0.97237873\n",
            "Training loss (for one batch) at step 23850: 0.0397\n",
            "Seen so far: 763232 samples\n",
            "0.97238326\n",
            "Training loss (for one batch) at step 23855: 0.0004\n",
            "Seen so far: 763392 samples\n",
            "0.97238773\n",
            "Training loss (for one batch) at step 23860: 0.0006\n",
            "Seen so far: 763552 samples\n",
            "0.9723922\n",
            "Training loss (for one batch) at step 23865: 0.0070\n",
            "Seen so far: 763712 samples\n",
            "0.97239536\n",
            "Training loss (for one batch) at step 23870: 0.0008\n",
            "Seen so far: 763872 samples\n",
            "0.97239983\n",
            "Training loss (for one batch) at step 23875: 0.0038\n",
            "Seen so far: 764032 samples\n",
            "0.9724056\n",
            "Training loss (for one batch) at step 23880: 0.0040\n",
            "Seen so far: 764192 samples\n",
            "0.9724101\n",
            "Training loss (for one batch) at step 23885: 0.0001\n",
            "Seen so far: 764352 samples\n",
            "0.97241324\n",
            "Training loss (for one batch) at step 23890: 0.0081\n",
            "Seen so far: 764512 samples\n",
            "0.9724177\n",
            "Training loss (for one batch) at step 23895: 0.1807\n",
            "Seen so far: 764672 samples\n",
            "0.9724222\n",
            "Training loss (for one batch) at step 23900: 0.0030\n",
            "Seen so far: 764832 samples\n",
            "0.97242665\n",
            "Training loss (for one batch) at step 23905: 0.0148\n",
            "Seen so far: 764992 samples\n",
            "0.97242975\n",
            "Training loss (for one batch) at step 23910: 0.0002\n",
            "Seen so far: 765152 samples\n",
            "0.9724342\n",
            "Training loss (for one batch) at step 23915: 0.0050\n",
            "Seen so far: 765312 samples\n",
            "0.9724361\n",
            "Training loss (for one batch) at step 23920: 0.0012\n",
            "Seen so far: 765472 samples\n",
            "0.97244185\n",
            "Training loss (for one batch) at step 23925: 0.2692\n",
            "Seen so far: 765632 samples\n",
            "0.972445\n",
            "Training loss (for one batch) at step 23930: 0.0029\n",
            "Seen so far: 765792 samples\n",
            "0.9724481\n",
            "Training loss (for one batch) at step 23935: 0.0003\n",
            "Seen so far: 765952 samples\n",
            "0.9724539\n",
            "Training loss (for one batch) at step 23940: 0.0131\n",
            "Seen so far: 766112 samples\n",
            "0.9724596\n",
            "Training loss (for one batch) at step 23945: 0.0022\n",
            "Seen so far: 766272 samples\n",
            "0.9724641\n",
            "Training loss (for one batch) at step 23950: 0.0227\n",
            "Seen so far: 766432 samples\n",
            "0.97246855\n",
            "Training loss (for one batch) at step 23955: 0.0241\n",
            "Seen so far: 766592 samples\n",
            "0.97247034\n",
            "Training loss (for one batch) at step 23960: 0.0014\n",
            "Seen so far: 766752 samples\n",
            "0.9724748\n",
            "Training loss (for one batch) at step 23965: 0.1187\n",
            "Seen so far: 766912 samples\n",
            "0.9724779\n",
            "Training loss (for one batch) at step 23970: 0.0148\n",
            "Seen so far: 767072 samples\n",
            "0.9724824\n",
            "Training loss (for one batch) at step 23975: 0.1313\n",
            "Seen so far: 767232 samples\n",
            "0.9724868\n",
            "Training loss (for one batch) at step 23980: 0.0018\n",
            "Seen so far: 767392 samples\n",
            "0.97248864\n",
            "Training loss (for one batch) at step 23985: 0.0754\n",
            "Seen so far: 767552 samples\n",
            "0.97249174\n",
            "Training loss (for one batch) at step 23990: 0.0369\n",
            "Seen so far: 767712 samples\n",
            "0.9724923\n",
            "Training loss (for one batch) at step 23995: 0.0584\n",
            "Seen so far: 767872 samples\n",
            "0.97249675\n",
            "Training loss (for one batch) at step 24000: 0.0290\n",
            "Seen so far: 768032 samples\n",
            "0.97249985\n",
            "Training loss (for one batch) at step 24005: 0.1031\n",
            "Seen so far: 768192 samples\n",
            "0.9725017\n",
            "Training loss (for one batch) at step 24010: 0.0041\n",
            "Seen so far: 768352 samples\n",
            "0.9725061\n",
            "Training loss (for one batch) at step 24015: 0.0001\n",
            "Seen so far: 768512 samples\n",
            "0.9725105\n",
            "Training loss (for one batch) at step 24020: 0.0373\n",
            "Seen so far: 768672 samples\n",
            "0.9725123\n",
            "Training loss (for one batch) at step 24025: 0.0010\n",
            "Seen so far: 768832 samples\n",
            "0.97251415\n",
            "Training loss (for one batch) at step 24030: 0.0016\n",
            "Seen so far: 768992 samples\n",
            "0.97251725\n",
            "Training loss (for one batch) at step 24035: 0.0633\n",
            "Seen so far: 769152 samples\n",
            "0.9725204\n",
            "Training loss (for one batch) at step 24040: 0.0025\n",
            "Seen so far: 769312 samples\n",
            "0.9725248\n",
            "Training loss (for one batch) at step 24045: 0.0357\n",
            "Seen so far: 769472 samples\n",
            "0.9725253\n",
            "Training loss (for one batch) at step 24050: 0.0069\n",
            "Seen so far: 769632 samples\n",
            "0.972531\n",
            "Training loss (for one batch) at step 24055: 0.0077\n",
            "Seen so far: 769792 samples\n",
            "0.97253287\n",
            "Training loss (for one batch) at step 24060: 0.0423\n",
            "Seen so far: 769952 samples\n",
            "0.97253466\n",
            "Training loss (for one batch) at step 24065: 0.0234\n",
            "Seen so far: 770112 samples\n",
            "0.97253644\n",
            "Training loss (for one batch) at step 24070: 0.1463\n",
            "Seen so far: 770272 samples\n",
            "0.97253954\n",
            "Training loss (for one batch) at step 24075: 0.0072\n",
            "Seen so far: 770432 samples\n",
            "0.9725427\n",
            "Training loss (for one batch) at step 24080: 0.0068\n",
            "Seen so far: 770592 samples\n",
            "0.97254837\n",
            "Training loss (for one batch) at step 24085: 0.0005\n",
            "Seen so far: 770752 samples\n",
            "0.97255147\n",
            "Training loss (for one batch) at step 24090: 0.0203\n",
            "Seen so far: 770912 samples\n",
            "0.9725572\n",
            "Training loss (for one batch) at step 24095: 0.0055\n",
            "Seen so far: 771072 samples\n",
            "0.97256285\n",
            "Training loss (for one batch) at step 24100: 0.0003\n",
            "Seen so far: 771232 samples\n",
            "0.97256726\n",
            "Training loss (for one batch) at step 24105: 0.0086\n",
            "Seen so far: 771392 samples\n",
            "0.97256905\n",
            "Training loss (for one batch) at step 24110: 0.0349\n",
            "Seen so far: 771552 samples\n",
            "0.9725696\n",
            "Training loss (for one batch) at step 24115: 0.0114\n",
            "Seen so far: 771712 samples\n",
            "0.9725727\n",
            "Training loss (for one batch) at step 24120: 0.0048\n",
            "Seen so far: 771872 samples\n",
            "0.97257704\n",
            "Training loss (for one batch) at step 24125: 0.0183\n",
            "Seen so far: 772032 samples\n",
            "0.97258276\n",
            "Training loss (for one batch) at step 24130: 0.0306\n",
            "Seen so far: 772192 samples\n",
            "0.97258586\n",
            "Training loss (for one batch) at step 24135: 0.2301\n",
            "Seen so far: 772352 samples\n",
            "0.97258765\n",
            "Training loss (for one batch) at step 24140: 0.0004\n",
            "Seen so far: 772512 samples\n",
            "0.9725881\n",
            "Training loss (for one batch) at step 24145: 0.0101\n",
            "Seen so far: 772672 samples\n",
            "0.97259253\n",
            "Training loss (for one batch) at step 24150: 0.0004\n",
            "Seen so far: 772832 samples\n",
            "0.9725982\n",
            "Training loss (for one batch) at step 24155: 0.0191\n",
            "Seen so far: 772992 samples\n",
            "0.97260386\n",
            "Training loss (for one batch) at step 24160: 0.0002\n",
            "Seen so far: 773152 samples\n",
            "0.97260696\n",
            "Training loss (for one batch) at step 24165: 0.0003\n",
            "Seen so far: 773312 samples\n",
            "0.97261\n",
            "Training loss (for one batch) at step 24170: 0.0512\n",
            "Seen so far: 773472 samples\n",
            "0.9726118\n",
            "Training loss (for one batch) at step 24175: 0.0067\n",
            "Seen so far: 773632 samples\n",
            "0.9726149\n",
            "Training loss (for one batch) at step 24180: 0.0030\n",
            "Seen so far: 773792 samples\n",
            "0.972618\n",
            "Training loss (for one batch) at step 24185: 0.0168\n",
            "Seen so far: 773952 samples\n",
            "0.97262233\n",
            "Training loss (for one batch) at step 24190: 0.0240\n",
            "Seen so far: 774112 samples\n",
            "0.97262543\n",
            "Training loss (for one batch) at step 24195: 0.0030\n",
            "Seen so far: 774272 samples\n",
            "0.97263104\n",
            "Training loss (for one batch) at step 24200: 0.0010\n",
            "Seen so far: 774432 samples\n",
            "0.97263414\n",
            "Training loss (for one batch) at step 24205: 0.0001\n",
            "Seen so far: 774592 samples\n",
            "0.97263724\n",
            "Training loss (for one batch) at step 24210: 0.0029\n",
            "Seen so far: 774752 samples\n",
            "0.9726403\n",
            "Training loss (for one batch) at step 24215: 0.0511\n",
            "Seen so far: 774912 samples\n",
            "0.97264206\n",
            "Training loss (for one batch) at step 24220: 0.0008\n",
            "Seen so far: 775072 samples\n",
            "0.9726477\n",
            "Training loss (for one batch) at step 24225: 0.0241\n",
            "Seen so far: 775232 samples\n",
            "0.9726521\n",
            "Training loss (for one batch) at step 24230: 0.0126\n",
            "Seen so far: 775392 samples\n",
            "0.9726577\n",
            "Training loss (for one batch) at step 24235: 0.0055\n",
            "Seen so far: 775552 samples\n",
            "0.9726608\n",
            "Training loss (for one batch) at step 24240: 0.0001\n",
            "Seen so far: 775712 samples\n",
            "0.9726664\n",
            "Training loss (for one batch) at step 24245: 0.0019\n",
            "Seen so far: 775872 samples\n",
            "0.97267073\n",
            "Training loss (for one batch) at step 24250: 0.0143\n",
            "Seen so far: 776032 samples\n",
            "0.9726764\n",
            "Training loss (for one batch) at step 24255: 0.0009\n",
            "Seen so far: 776192 samples\n",
            "0.97268075\n",
            "Training loss (for one batch) at step 24260: 0.0020\n",
            "Seen so far: 776352 samples\n",
            "0.97268635\n",
            "Training loss (for one batch) at step 24265: 0.0012\n",
            "Seen so far: 776512 samples\n",
            "0.9726907\n",
            "Training loss (for one batch) at step 24270: 0.0076\n",
            "Seen so far: 776672 samples\n",
            "0.9726963\n",
            "Training loss (for one batch) at step 24275: 0.0202\n",
            "Seen so far: 776832 samples\n",
            "0.97270197\n",
            "Training loss (for one batch) at step 24280: 0.0341\n",
            "Seen so far: 776992 samples\n",
            "0.97270626\n",
            "Training loss (for one batch) at step 24285: 0.0001\n",
            "Seen so far: 777152 samples\n",
            "0.9727119\n",
            "Training loss (for one batch) at step 24290: 0.0000\n",
            "Seen so far: 777312 samples\n",
            "0.97271496\n",
            "Training loss (for one batch) at step 24295: 0.0001\n",
            "Seen so far: 777472 samples\n",
            "0.97271925\n",
            "Training loss (for one batch) at step 24300: 0.0006\n",
            "Seen so far: 777632 samples\n",
            "0.9727249\n",
            "Training loss (for one batch) at step 24305: 0.0004\n",
            "Seen so far: 777792 samples\n",
            "0.9727292\n",
            "Training loss (for one batch) at step 24310: 0.0095\n",
            "Seen so far: 777952 samples\n",
            "0.97273225\n",
            "Training loss (for one batch) at step 24315: 0.0090\n",
            "Seen so far: 778112 samples\n",
            "0.97273785\n",
            "Training loss (for one batch) at step 24320: 0.0002\n",
            "Seen so far: 778272 samples\n",
            "0.9727422\n",
            "Training loss (for one batch) at step 24325: 0.0629\n",
            "Seen so far: 778432 samples\n",
            "0.9727439\n",
            "Training loss (for one batch) at step 24330: 0.0159\n",
            "Seen so far: 778592 samples\n",
            "0.9727482\n",
            "Training loss (for one batch) at step 24335: 0.0036\n",
            "Seen so far: 778752 samples\n",
            "0.97274745\n",
            "Training loss (for one batch) at step 24340: 0.0004\n",
            "Seen so far: 778912 samples\n",
            "0.9727466\n",
            "Training loss (for one batch) at step 24345: 0.0025\n",
            "Seen so far: 779072 samples\n",
            "0.9727509\n",
            "Training loss (for one batch) at step 24350: 0.0015\n",
            "Seen so far: 779232 samples\n",
            "0.9727565\n",
            "Training loss (for one batch) at step 24355: 0.0023\n",
            "Seen so far: 779392 samples\n",
            "0.972757\n",
            "Training loss (for one batch) at step 24360: 0.0023\n",
            "Seen so far: 779552 samples\n",
            "0.97275746\n",
            "Training loss (for one batch) at step 24365: 0.0023\n",
            "Seen so far: 779712 samples\n",
            "0.9727579\n",
            "Training loss (for one batch) at step 24370: 0.2790\n",
            "Seen so far: 779872 samples\n",
            "0.9727519\n",
            "Training loss (for one batch) at step 24375: 0.0414\n",
            "Seen so far: 780032 samples\n",
            "0.9727524\n",
            "Training loss (for one batch) at step 24380: 0.2488\n",
            "Seen so far: 780192 samples\n",
            "0.97275287\n",
            "Training loss (for one batch) at step 24385: 0.0001\n",
            "Seen so far: 780352 samples\n",
            "0.97275335\n",
            "Training loss (for one batch) at step 24390: 0.0778\n",
            "Seen so far: 780512 samples\n",
            "0.97275376\n",
            "Training loss (for one batch) at step 24395: 0.0601\n",
            "Seen so far: 780672 samples\n",
            "0.9727504\n",
            "Training loss (for one batch) at step 24400: 0.0159\n",
            "Seen so far: 780832 samples\n",
            "0.97275084\n",
            "Training loss (for one batch) at step 24405: 0.0665\n",
            "Seen so far: 780992 samples\n",
            "0.97275007\n",
            "Training loss (for one batch) at step 24410: 0.1231\n",
            "Seen so far: 781152 samples\n",
            "0.9727505\n",
            "Training loss (for one batch) at step 24415: 0.2808\n",
            "Seen so far: 781312 samples\n",
            "0.9727484\n",
            "Training loss (for one batch) at step 24420: 0.0013\n",
            "Seen so far: 781472 samples\n",
            "0.972754\n",
            "Training loss (for one batch) at step 24425: 0.2224\n",
            "Seen so far: 781632 samples\n",
            "0.9727544\n",
            "Training loss (for one batch) at step 24430: 0.3409\n",
            "Seen so far: 781792 samples\n",
            "0.97274977\n",
            "Training loss (for one batch) at step 24435: 0.2698\n",
            "Seen so far: 781952 samples\n",
            "0.97274643\n",
            "Training loss (for one batch) at step 24440: 0.0739\n",
            "Seen so far: 782112 samples\n",
            "0.97274816\n",
            "Training loss (for one batch) at step 24445: 0.0005\n",
            "Seen so far: 782272 samples\n",
            "0.97275114\n",
            "Training loss (for one batch) at step 24450: 0.2578\n",
            "Seen so far: 782432 samples\n",
            "0.97274905\n",
            "Training loss (for one batch) at step 24455: 0.0023\n",
            "Seen so far: 782592 samples\n",
            "0.9727508\n",
            "Training loss (for one batch) at step 24460: 0.0006\n",
            "Seen so far: 782752 samples\n",
            "0.97275\n",
            "Training loss (for one batch) at step 24465: 0.0162\n",
            "Seen so far: 782912 samples\n",
            "0.97275174\n",
            "Training loss (for one batch) at step 24470: 0.0007\n",
            "Seen so far: 783072 samples\n",
            "0.972756\n",
            "Training loss (for one batch) at step 24475: 0.0028\n",
            "Seen so far: 783232 samples\n",
            "0.9727565\n",
            "Training loss (for one batch) at step 24480: 0.0232\n",
            "Seen so far: 783392 samples\n",
            "0.97275823\n",
            "Training loss (for one batch) at step 24485: 0.0145\n",
            "Seen so far: 783552 samples\n",
            "0.9727625\n",
            "Training loss (for one batch) at step 24490: 0.0014\n",
            "Seen so far: 783712 samples\n",
            "0.9727655\n",
            "Training loss (for one batch) at step 24495: 0.0028\n",
            "Seen so far: 783872 samples\n",
            "0.97276723\n",
            "Training loss (for one batch) at step 24500: 0.0029\n",
            "Seen so far: 784032 samples\n",
            "0.9727677\n",
            "Training loss (for one batch) at step 24505: 0.0020\n",
            "Seen so far: 784192 samples\n",
            "0.9727707\n",
            "Training loss (for one batch) at step 24510: 0.1749\n",
            "Seen so far: 784352 samples\n",
            "0.97277117\n",
            "Training loss (for one batch) at step 24515: 0.0011\n",
            "Seen so far: 784512 samples\n",
            "0.9727767\n",
            "Training loss (for one batch) at step 24520: 0.0225\n",
            "Seen so far: 784672 samples\n",
            "0.972781\n",
            "Training loss (for one batch) at step 24525: 0.0035\n",
            "Seen so far: 784832 samples\n",
            "0.972784\n",
            "Training loss (for one batch) at step 24530: 0.0013\n",
            "Seen so far: 784992 samples\n",
            "0.9727883\n",
            "Training loss (for one batch) at step 24535: 0.0025\n",
            "Seen so far: 785152 samples\n",
            "0.9727938\n",
            "Training loss (for one batch) at step 24540: 0.0022\n",
            "Seen so far: 785312 samples\n",
            "0.9727968\n",
            "Training loss (for one batch) at step 24545: 0.0016\n",
            "Seen so far: 785472 samples\n",
            "0.9728011\n",
            "Training loss (for one batch) at step 24550: 0.0006\n",
            "Seen so far: 785632 samples\n",
            "0.9728028\n",
            "Training loss (for one batch) at step 24555: 0.0060\n",
            "Seen so far: 785792 samples\n",
            "0.97280705\n",
            "Training loss (for one batch) at step 24560: 0.2122\n",
            "Seen so far: 785952 samples\n",
            "0.9728088\n",
            "Training loss (for one batch) at step 24565: 0.0224\n",
            "Seen so far: 786112 samples\n",
            "0.97281176\n",
            "Training loss (for one batch) at step 24570: 0.1687\n",
            "Seen so far: 786272 samples\n",
            "0.97281474\n",
            "Training loss (for one batch) at step 24575: 0.0082\n",
            "Seen so far: 786432 samples\n",
            "0.9728152\n",
            "Training loss (for one batch) at step 24580: 0.0052\n",
            "Seen so far: 786592 samples\n",
            "0.9728207\n",
            "Training loss (for one batch) at step 24585: 0.0039\n",
            "Seen so far: 786752 samples\n",
            "0.97282624\n",
            "Training loss (for one batch) at step 24590: 0.0010\n",
            "Seen so far: 786912 samples\n",
            "0.97283053\n",
            "Training loss (for one batch) at step 24595: 0.0191\n",
            "Seen so far: 787072 samples\n",
            "0.9728335\n",
            "Training loss (for one batch) at step 24600: 0.0233\n",
            "Seen so far: 787232 samples\n",
            "0.972839\n",
            "Training loss (for one batch) at step 24605: 0.0134\n",
            "Seen so far: 787392 samples\n",
            "0.97284454\n",
            "Training loss (for one batch) at step 24610: 0.0977\n",
            "Seen so far: 787552 samples\n",
            "0.9728462\n",
            "Training loss (for one batch) at step 24615: 0.0352\n",
            "Seen so far: 787712 samples\n",
            "0.9728492\n",
            "Training loss (for one batch) at step 24620: 0.0004\n",
            "Seen so far: 787872 samples\n",
            "0.9728535\n",
            "Training loss (for one batch) at step 24625: 0.0055\n",
            "Seen so far: 788032 samples\n",
            "0.9728577\n",
            "Training loss (for one batch) at step 24630: 0.1737\n",
            "Seen so far: 788192 samples\n",
            "0.97286195\n",
            "Training loss (for one batch) at step 24635: 0.0018\n",
            "Seen so far: 788352 samples\n",
            "0.9728674\n",
            "Training loss (for one batch) at step 24640: 0.0119\n",
            "Seen so far: 788512 samples\n",
            "0.97286916\n",
            "Training loss (for one batch) at step 24645: 0.0260\n",
            "Seen so far: 788672 samples\n",
            "0.97287214\n",
            "Training loss (for one batch) at step 24650: 0.0027\n",
            "Seen so far: 788832 samples\n",
            "0.97287637\n",
            "Training loss (for one batch) at step 24655: 0.1785\n",
            "Seen so far: 788992 samples\n",
            "0.9728806\n",
            "Training loss (for one batch) at step 24660: 0.0026\n",
            "Seen so far: 789152 samples\n",
            "0.9728835\n",
            "Training loss (for one batch) at step 24665: 0.0016\n",
            "Seen so far: 789312 samples\n",
            "0.97288907\n",
            "Training loss (for one batch) at step 24670: 0.0049\n",
            "Seen so far: 789472 samples\n",
            "0.97289455\n",
            "Training loss (for one batch) at step 24675: 0.0255\n",
            "Seen so far: 789632 samples\n",
            "0.97289497\n",
            "Training loss (for one batch) at step 24680: 0.0122\n",
            "Seen so far: 789792 samples\n",
            "0.9728992\n",
            "Training loss (for one batch) at step 24685: 0.0388\n",
            "Seen so far: 789952 samples\n",
            "0.9729022\n",
            "Training loss (for one batch) at step 24690: 0.0003\n",
            "Seen so far: 790112 samples\n",
            "0.97290766\n",
            "Training loss (for one batch) at step 24695: 0.0023\n",
            "Seen so far: 790272 samples\n",
            "0.97290426\n",
            "Training loss (for one batch) at step 24700: 0.0072\n",
            "Seen so far: 790432 samples\n",
            "0.9729085\n",
            "Training loss (for one batch) at step 24705: 0.1055\n",
            "Seen so far: 790592 samples\n",
            "0.9729114\n",
            "Training loss (for one batch) at step 24710: 0.2699\n",
            "Seen so far: 790752 samples\n",
            "0.97291565\n",
            "Training loss (for one batch) at step 24715: 0.0012\n",
            "Seen so far: 790912 samples\n",
            "0.97292113\n",
            "Training loss (for one batch) at step 24720: 0.0018\n",
            "Seen so far: 791072 samples\n",
            "0.9729266\n",
            "Training loss (for one batch) at step 24725: 0.0174\n",
            "Seen so far: 791232 samples\n",
            "0.9729321\n",
            "Training loss (for one batch) at step 24730: 0.0064\n",
            "Seen so far: 791392 samples\n",
            "0.9729363\n",
            "Training loss (for one batch) at step 24735: 0.1325\n",
            "Seen so far: 791552 samples\n",
            "0.972938\n",
            "Training loss (for one batch) at step 24740: 0.0116\n",
            "Seen so far: 791712 samples\n",
            "0.9729409\n",
            "Training loss (for one batch) at step 24745: 0.0001\n",
            "Seen so far: 791872 samples\n",
            "0.9729464\n",
            "Training loss (for one batch) at step 24750: 0.1104\n",
            "Seen so far: 792032 samples\n",
            "0.9729468\n",
            "Training loss (for one batch) at step 24755: 0.1914\n",
            "Seen so far: 792192 samples\n",
            "0.9729485\n",
            "Training loss (for one batch) at step 24760: 0.0175\n",
            "Seen so far: 792352 samples\n",
            "0.9729514\n",
            "Training loss (for one batch) at step 24765: 0.0208\n",
            "Seen so far: 792512 samples\n",
            "0.97295564\n",
            "Training loss (for one batch) at step 24770: 0.0048\n",
            "Seen so far: 792672 samples\n",
            "0.9729598\n",
            "Training loss (for one batch) at step 24775: 0.0416\n",
            "Seen so far: 792832 samples\n",
            "0.97296023\n",
            "Training loss (for one batch) at step 24780: 0.0103\n",
            "Seen so far: 792992 samples\n",
            "0.97296315\n",
            "Training loss (for one batch) at step 24785: 0.0007\n",
            "Seen so far: 793152 samples\n",
            "0.9729661\n",
            "Training loss (for one batch) at step 24790: 0.0150\n",
            "Seen so far: 793312 samples\n",
            "0.97296774\n",
            "Training loss (for one batch) at step 24795: 0.0125\n",
            "Seen so far: 793472 samples\n",
            "0.9729694\n",
            "Training loss (for one batch) at step 24800: 0.7113\n",
            "Seen so far: 793632 samples\n",
            "0.9729686\n",
            "Training loss (for one batch) at step 24805: 0.0066\n",
            "Seen so far: 793792 samples\n",
            "0.97297025\n",
            "Training loss (for one batch) at step 24810: 0.2177\n",
            "Seen so far: 793952 samples\n",
            "0.97296816\n",
            "Training loss (for one batch) at step 24815: 0.0020\n",
            "Seen so far: 794112 samples\n",
            "0.9729711\n",
            "Training loss (for one batch) at step 24820: 0.0618\n",
            "Seen so far: 794272 samples\n",
            "0.972974\n",
            "Training loss (for one batch) at step 24825: 0.0623\n",
            "Seen so far: 794432 samples\n",
            "0.9729757\n",
            "Training loss (for one batch) at step 24830: 0.0111\n",
            "Seen so far: 794592 samples\n",
            "0.9729761\n",
            "Training loss (for one batch) at step 24835: 0.0041\n",
            "Seen so far: 794752 samples\n",
            "0.972979\n",
            "Training loss (for one batch) at step 24840: 0.0005\n",
            "Seen so far: 794912 samples\n",
            "0.9729832\n",
            "Training loss (for one batch) at step 24845: 0.0094\n",
            "Seen so far: 795072 samples\n",
            "0.9729836\n",
            "Training loss (for one batch) at step 24850: 0.0014\n",
            "Seen so far: 795232 samples\n",
            "0.97298527\n",
            "Training loss (for one batch) at step 24855: 0.1495\n",
            "Seen so far: 795392 samples\n",
            "0.9729844\n",
            "Training loss (for one batch) at step 24860: 0.0259\n",
            "Seen so far: 795552 samples\n",
            "0.9729873\n",
            "Training loss (for one batch) at step 24865: 0.0106\n",
            "Seen so far: 795712 samples\n",
            "0.9729902\n",
            "Training loss (for one batch) at step 24870: 0.0109\n",
            "Seen so far: 795872 samples\n",
            "0.97299564\n",
            "Training loss (for one batch) at step 24875: 0.1091\n",
            "Seen so far: 796032 samples\n",
            "0.9729973\n",
            "Training loss (for one batch) at step 24880: 0.0000\n",
            "Seen so far: 796192 samples\n",
            "0.9730002\n",
            "Training loss (for one batch) at step 24885: 0.0003\n",
            "Seen so far: 796352 samples\n",
            "0.97300565\n",
            "Training loss (for one batch) at step 24890: 0.0209\n",
            "Seen so far: 796512 samples\n",
            "0.9730098\n",
            "Training loss (for one batch) at step 24895: 0.0498\n",
            "Seen so far: 796672 samples\n",
            "0.9730115\n",
            "Training loss (for one batch) at step 24900: 0.0746\n",
            "Seen so far: 796832 samples\n",
            "0.97301567\n",
            "Training loss (for one batch) at step 24905: 0.0413\n",
            "Seen so far: 796992 samples\n",
            "0.9730185\n",
            "Training loss (for one batch) at step 24910: 0.0194\n",
            "Seen so far: 797152 samples\n",
            "0.9730202\n",
            "Training loss (for one batch) at step 24915: 0.0019\n",
            "Seen so far: 797312 samples\n",
            "0.97302186\n",
            "Training loss (for one batch) at step 24920: 0.2537\n",
            "Seen so far: 797472 samples\n",
            "0.97302604\n",
            "Training loss (for one batch) at step 24925: 0.1440\n",
            "Seen so far: 797632 samples\n",
            "0.97302765\n",
            "Training loss (for one batch) at step 24930: 0.0022\n",
            "Seen so far: 797792 samples\n",
            "0.9730331\n",
            "Training loss (for one batch) at step 24935: 0.0316\n",
            "Seen so far: 797952 samples\n",
            "0.973036\n",
            "Training loss (for one batch) at step 24940: 0.0989\n",
            "Seen so far: 798112 samples\n",
            "0.9730401\n",
            "Training loss (for one batch) at step 24945: 0.0455\n",
            "Seen so far: 798272 samples\n",
            "0.9730443\n",
            "Training loss (for one batch) at step 24950: 0.0673\n",
            "Seen so far: 798432 samples\n",
            "0.9730472\n",
            "Training loss (for one batch) at step 24955: 0.1267\n",
            "Seen so far: 798592 samples\n",
            "0.9730488\n",
            "Training loss (for one batch) at step 24960: 0.0216\n",
            "Seen so far: 798752 samples\n",
            "0.973053\n",
            "Training loss (for one batch) at step 24965: 0.0080\n",
            "Seen so far: 798912 samples\n",
            "0.9730571\n",
            "Training loss (for one batch) at step 24970: 0.0014\n",
            "Seen so far: 799072 samples\n",
            "0.97306\n",
            "Training loss (for one batch) at step 24975: 0.0010\n",
            "Seen so far: 799232 samples\n",
            "0.9730616\n",
            "Training loss (for one batch) at step 24980: 0.0023\n",
            "Seen so far: 799392 samples\n",
            "0.9730658\n",
            "Training loss (for one batch) at step 24985: 0.1384\n",
            "Seen so far: 799552 samples\n",
            "0.9730674\n",
            "Training loss (for one batch) at step 24990: 0.0115\n",
            "Seen so far: 799712 samples\n",
            "0.9730703\n",
            "Training loss (for one batch) at step 24995: 0.1302\n",
            "Seen so far: 799872 samples\n",
            "0.9730694\n",
            "Training loss (for one batch) at step 25000: 0.0018\n",
            "Seen so far: 800032 samples\n",
            "0.9730736\n",
            "Training loss (for one batch) at step 25005: 0.1423\n",
            "Seen so far: 800192 samples\n",
            "0.9730752\n",
            "Training loss (for one batch) at step 25010: 0.0130\n",
            "Seen so far: 800352 samples\n",
            "0.9730806\n",
            "Training loss (for one batch) at step 25015: 0.0007\n",
            "Seen so far: 800512 samples\n",
            "0.973081\n",
            "Training loss (for one batch) at step 25020: 0.0692\n",
            "Seen so far: 800672 samples\n",
            "0.97308385\n",
            "Training loss (for one batch) at step 25025: 0.0585\n",
            "Seen so far: 800832 samples\n",
            "0.97308546\n",
            "Training loss (for one batch) at step 25030: 0.0001\n",
            "Seen so far: 800992 samples\n",
            "0.9730846\n",
            "Training loss (for one batch) at step 25035: 0.2537\n",
            "Seen so far: 801152 samples\n",
            "0.97308874\n",
            "Training loss (for one batch) at step 25040: 0.0389\n",
            "Seen so far: 801312 samples\n",
            "0.97309285\n",
            "Training loss (for one batch) at step 25045: 0.0120\n",
            "Seen so far: 801472 samples\n",
            "0.9730945\n",
            "Training loss (for one batch) at step 25050: 0.0242\n",
            "Seen so far: 801632 samples\n",
            "0.97309864\n",
            "Training loss (for one batch) at step 25055: 0.0068\n",
            "Seen so far: 801792 samples\n",
            "0.973104\n",
            "Training loss (for one batch) at step 25060: 0.0067\n",
            "Seen so far: 801952 samples\n",
            "0.9731056\n",
            "Training loss (for one batch) at step 25065: 0.0280\n",
            "Seen so far: 802112 samples\n",
            "0.9731085\n",
            "Training loss (for one batch) at step 25070: 0.0029\n",
            "Seen so far: 802272 samples\n",
            "0.97311014\n",
            "Training loss (for one batch) at step 25075: 0.0072\n",
            "Seen so far: 802432 samples\n",
            "0.973113\n",
            "Training loss (for one batch) at step 25080: 0.0140\n",
            "Seen so far: 802592 samples\n",
            "0.9731171\n",
            "Training loss (for one batch) at step 25085: 0.0679\n",
            "Seen so far: 802752 samples\n",
            "0.9731212\n",
            "Training loss (for one batch) at step 25090: 0.1174\n",
            "Seen so far: 802912 samples\n",
            "0.9731216\n",
            "Training loss (for one batch) at step 25095: 0.0112\n",
            "Seen so far: 803072 samples\n",
            "0.9731257\n",
            "Training loss (for one batch) at step 25100: 0.0932\n",
            "Seen so far: 803232 samples\n",
            "0.9731236\n",
            "Training loss (for one batch) at step 25105: 0.0082\n",
            "Seen so far: 803392 samples\n",
            "0.9731252\n",
            "Training loss (for one batch) at step 25110: 0.1084\n",
            "Seen so far: 803552 samples\n",
            "0.9731256\n",
            "Training loss (for one batch) at step 25115: 0.0143\n",
            "Seen so far: 803712 samples\n",
            "0.97313094\n",
            "Training loss (for one batch) at step 25120: 0.0617\n",
            "Seen so far: 803872 samples\n",
            "0.97313505\n",
            "Training loss (for one batch) at step 25125: 0.1263\n",
            "Seen so far: 804032 samples\n",
            "0.97313416\n",
            "Training loss (for one batch) at step 25130: 0.0083\n",
            "Seen so far: 804192 samples\n",
            "0.9731296\n",
            "Training loss (for one batch) at step 25135: 0.0001\n",
            "Seen so far: 804352 samples\n",
            "0.9731349\n",
            "Training loss (for one batch) at step 25140: 0.0002\n",
            "Seen so far: 804512 samples\n",
            "0.9731353\n",
            "Training loss (for one batch) at step 25145: 0.0877\n",
            "Seen so far: 804672 samples\n",
            "0.9731319\n",
            "Training loss (for one batch) at step 25150: 0.0007\n",
            "Seen so far: 804832 samples\n",
            "0.97313476\n",
            "Training loss (for one batch) at step 25155: 0.0009\n",
            "Seen so far: 804992 samples\n",
            "0.97313637\n",
            "Training loss (for one batch) at step 25160: 0.0309\n",
            "Seen so far: 805152 samples\n",
            "0.973138\n",
            "Training loss (for one batch) at step 25165: 0.0761\n",
            "Seen so far: 805312 samples\n",
            "0.9731421\n",
            "Training loss (for one batch) at step 25170: 0.0009\n",
            "Seen so far: 805472 samples\n",
            "0.97314495\n",
            "Training loss (for one batch) at step 25175: 0.0016\n",
            "Seen so far: 805632 samples\n",
            "0.973149\n",
            "Training loss (for one batch) at step 25180: 0.0008\n",
            "Seen so far: 805792 samples\n",
            "0.97315186\n",
            "Training loss (for one batch) at step 25185: 0.0058\n",
            "Seen so far: 805952 samples\n",
            "0.9731547\n",
            "Training loss (for one batch) at step 25190: 0.0682\n",
            "Seen so far: 806112 samples\n",
            "0.9731538\n",
            "Training loss (for one batch) at step 25195: 0.0323\n",
            "Seen so far: 806272 samples\n",
            "0.9731567\n",
            "Training loss (for one batch) at step 25200: 0.0233\n",
            "Seen so far: 806432 samples\n",
            "0.97315955\n",
            "Training loss (for one batch) at step 25205: 0.0392\n",
            "Seen so far: 806592 samples\n",
            "0.9731636\n",
            "Training loss (for one batch) at step 25210: 0.0120\n",
            "Seen so far: 806752 samples\n",
            "0.9731677\n",
            "Training loss (for one batch) at step 25215: 0.0260\n",
            "Seen so far: 806912 samples\n",
            "0.9731718\n",
            "Training loss (for one batch) at step 25220: 0.0615\n",
            "Seen so far: 807072 samples\n",
            "0.9731759\n",
            "Training loss (for one batch) at step 25225: 0.0009\n",
            "Seen so far: 807232 samples\n",
            "0.97317994\n",
            "Training loss (for one batch) at step 25230: 0.0018\n",
            "Seen so far: 807392 samples\n",
            "0.9731828\n",
            "Training loss (for one batch) at step 25235: 0.0010\n",
            "Seen so far: 807552 samples\n",
            "0.9731856\n",
            "Training loss (for one batch) at step 25240: 0.1679\n",
            "Seen so far: 807712 samples\n",
            "0.9731897\n",
            "Training loss (for one batch) at step 25245: 0.0116\n",
            "Seen so far: 807872 samples\n",
            "0.97319376\n",
            "Training loss (for one batch) at step 25250: 0.0175\n",
            "Seen so far: 808032 samples\n",
            "0.9731966\n",
            "Training loss (for one batch) at step 25255: 0.0012\n",
            "Seen so far: 808192 samples\n",
            "0.9732007\n",
            "Training loss (for one batch) at step 25260: 0.0488\n",
            "Seen so far: 808352 samples\n",
            "0.97320473\n",
            "Training loss (for one batch) at step 25265: 0.0004\n",
            "Seen so far: 808512 samples\n",
            "0.97321004\n",
            "Training loss (for one batch) at step 25270: 0.0003\n",
            "Seen so far: 808672 samples\n",
            "0.9732129\n",
            "Training loss (for one batch) at step 25275: 0.0004\n",
            "Seen so far: 808832 samples\n",
            "0.97321814\n",
            "Training loss (for one batch) at step 25280: 0.0056\n",
            "Seen so far: 808992 samples\n",
            "0.973221\n",
            "Training loss (for one batch) at step 25285: 0.0185\n",
            "Seen so far: 809152 samples\n",
            "0.9732263\n",
            "Training loss (for one batch) at step 25290: 0.0583\n",
            "Seen so far: 809312 samples\n",
            "0.97323036\n",
            "Training loss (for one batch) at step 25295: 0.1061\n",
            "Seen so far: 809472 samples\n",
            "0.9732319\n",
            "Training loss (for one batch) at step 25300: 0.0034\n",
            "Seen so far: 809632 samples\n",
            "0.9732348\n",
            "Training loss (for one batch) at step 25305: 0.0114\n",
            "Seen so far: 809792 samples\n",
            "0.9732376\n",
            "Training loss (for one batch) at step 25310: 0.0001\n",
            "Seen so far: 809952 samples\n",
            "0.9732416\n",
            "Training loss (for one batch) at step 25315: 0.0080\n",
            "Seen so far: 810112 samples\n",
            "0.9732444\n",
            "Training loss (for one batch) at step 25320: 0.0095\n",
            "Seen so far: 810272 samples\n",
            "0.97324723\n",
            "Training loss (for one batch) at step 25325: 0.0160\n",
            "Seen so far: 810432 samples\n",
            "0.97324884\n",
            "Training loss (for one batch) at step 25330: 0.0087\n",
            "Seen so far: 810592 samples\n",
            "0.97325164\n",
            "Training loss (for one batch) at step 25335: 0.3707\n",
            "Seen so far: 810752 samples\n",
            "0.973252\n",
            "Training loss (for one batch) at step 25340: 0.1687\n",
            "Seen so far: 810912 samples\n",
            "0.97325355\n",
            "Training loss (for one batch) at step 25345: 0.0858\n",
            "Seen so far: 811072 samples\n",
            "0.9732539\n",
            "Training loss (for one batch) at step 25350: 0.0189\n",
            "Seen so far: 811232 samples\n",
            "0.97325796\n",
            "Training loss (for one batch) at step 25355: 0.0039\n",
            "Seen so far: 811392 samples\n",
            "0.973262\n",
            "Training loss (for one batch) at step 25360: 0.0067\n",
            "Seen so far: 811552 samples\n",
            "0.9732648\n",
            "Training loss (for one batch) at step 25365: 0.0186\n",
            "Seen so far: 811712 samples\n",
            "0.97326887\n",
            "Training loss (for one batch) at step 25370: 0.0296\n",
            "Seen so far: 811872 samples\n",
            "0.9732704\n",
            "Training loss (for one batch) at step 25375: 0.0025\n",
            "Seen so far: 812032 samples\n",
            "0.97327566\n",
            "Training loss (for one batch) at step 25380: 0.0774\n",
            "Seen so far: 812192 samples\n",
            "0.973276\n",
            "Training loss (for one batch) at step 25385: 0.0125\n",
            "Seen so far: 812352 samples\n",
            "0.9732801\n",
            "Training loss (for one batch) at step 25390: 0.0007\n",
            "Seen so far: 812512 samples\n",
            "0.9732853\n",
            "Training loss (for one batch) at step 25395: 0.0053\n",
            "Seen so far: 812672 samples\n",
            "0.97328687\n",
            "Training loss (for one batch) at step 25400: 0.0236\n",
            "Seen so far: 812832 samples\n",
            "0.9732909\n",
            "Training loss (for one batch) at step 25405: 0.1457\n",
            "Seen so far: 812992 samples\n",
            "0.9732949\n",
            "Training loss (for one batch) at step 25410: 0.0038\n",
            "Seen so far: 813152 samples\n",
            "0.9733002\n",
            "Training loss (for one batch) at step 25415: 0.0000\n",
            "Seen so far: 813312 samples\n",
            "0.97330546\n",
            "Training loss (for one batch) at step 25420: 0.0074\n",
            "Seen so far: 813472 samples\n",
            "0.97330946\n",
            "Training loss (for one batch) at step 25425: 0.0000\n",
            "Seen so far: 813632 samples\n",
            "0.9733147\n",
            "Training loss (for one batch) at step 25430: 0.0011\n",
            "Seen so far: 813792 samples\n",
            "0.97331876\n",
            "Training loss (for one batch) at step 25435: 0.1858\n",
            "Seen so far: 813952 samples\n",
            "0.97332275\n",
            "Training loss (for one batch) at step 25440: 0.0043\n",
            "Seen so far: 814112 samples\n",
            "0.97332674\n",
            "Training loss (for one batch) at step 25445: 0.0909\n",
            "Seen so far: 814272 samples\n",
            "0.9733308\n",
            "Training loss (for one batch) at step 25450: 0.0018\n",
            "Seen so far: 814432 samples\n",
            "0.9733348\n",
            "Training loss (for one batch) at step 25455: 0.0077\n",
            "Seen so far: 814592 samples\n",
            "0.9733376\n",
            "Training loss (for one batch) at step 25460: 0.0006\n",
            "Seen so far: 814752 samples\n",
            "0.97334033\n",
            "Training loss (for one batch) at step 25465: 0.0274\n",
            "Seen so far: 814912 samples\n",
            "0.97333944\n",
            "Training loss (for one batch) at step 25470: 0.0004\n",
            "Seen so far: 815072 samples\n",
            "0.9733447\n",
            "Training loss (for one batch) at step 25475: 0.0058\n",
            "Seen so far: 815232 samples\n",
            "0.97334623\n",
            "Training loss (for one batch) at step 25480: 0.0006\n",
            "Seen so far: 815392 samples\n",
            "0.9733515\n",
            "Training loss (for one batch) at step 25485: 0.0017\n",
            "Seen so far: 815552 samples\n",
            "0.973353\n",
            "Training loss (for one batch) at step 25490: 0.0014\n",
            "Seen so far: 815712 samples\n",
            "0.973357\n",
            "Training loss (for one batch) at step 25495: 0.0599\n",
            "Seen so far: 815872 samples\n",
            "0.97335976\n",
            "Training loss (for one batch) at step 25500: 0.1339\n",
            "Seen so far: 816032 samples\n",
            "0.97336257\n",
            "Training loss (for one batch) at step 25505: 0.0021\n",
            "Seen so far: 816192 samples\n",
            "0.9733678\n",
            "Training loss (for one batch) at step 25510: 0.0532\n",
            "Seen so far: 816352 samples\n",
            "0.97336936\n",
            "Training loss (for one batch) at step 25515: 0.0009\n",
            "Seen so far: 816512 samples\n",
            "0.97337455\n",
            "Training loss (for one batch) at step 25520: 0.0011\n",
            "Seen so far: 816672 samples\n",
            "0.9733798\n",
            "Training loss (for one batch) at step 25525: 0.0028\n",
            "Seen so far: 816832 samples\n",
            "0.973385\n",
            "Training loss (for one batch) at step 25530: 0.0007\n",
            "Seen so far: 816992 samples\n",
            "0.9733877\n",
            "Training loss (for one batch) at step 25535: 0.0047\n",
            "Seen so far: 817152 samples\n",
            "0.97339296\n",
            "Training loss (for one batch) at step 25540: 0.0001\n",
            "Seen so far: 817312 samples\n",
            "0.97339326\n",
            "Training loss (for one batch) at step 25545: 0.0006\n",
            "Seen so far: 817472 samples\n",
            "0.97339725\n",
            "Training loss (for one batch) at step 25550: 0.0182\n",
            "Seen so far: 817632 samples\n",
            "0.9734\n",
            "Training loss (for one batch) at step 25555: 0.0036\n",
            "Seen so far: 817792 samples\n",
            "0.9734028\n",
            "Training loss (for one batch) at step 25560: 0.0810\n",
            "Seen so far: 817952 samples\n",
            "0.97340673\n",
            "Training loss (for one batch) at step 25565: 0.1441\n",
            "Seen so far: 818112 samples\n",
            "0.97340953\n",
            "Training loss (for one batch) at step 25570: 0.0085\n",
            "Seen so far: 818272 samples\n",
            "0.9734123\n",
            "Training loss (for one batch) at step 25575: 0.0015\n",
            "Seen so far: 818432 samples\n",
            "0.97341746\n",
            "Training loss (for one batch) at step 25580: 0.0314\n",
            "Seen so far: 818592 samples\n",
            "0.973419\n",
            "Training loss (for one batch) at step 25585: 0.1592\n",
            "Seen so far: 818752 samples\n",
            "0.97342175\n",
            "Training loss (for one batch) at step 25590: 0.0027\n",
            "Seen so far: 818912 samples\n",
            "0.97342694\n",
            "Training loss (for one batch) at step 25595: 0.0008\n",
            "Seen so far: 819072 samples\n",
            "0.9734285\n",
            "Training loss (for one batch) at step 25600: 0.5961\n",
            "Seen so far: 819232 samples\n",
            "0.9734288\n",
            "Training loss (for one batch) at step 25605: 0.0028\n",
            "Seen so far: 819392 samples\n",
            "0.973434\n",
            "Training loss (for one batch) at step 25610: 0.0212\n",
            "Seen so far: 819552 samples\n",
            "0.97343916\n",
            "Training loss (for one batch) at step 25615: 0.0001\n",
            "Seen so far: 819712 samples\n",
            "0.9734419\n",
            "Training loss (for one batch) at step 25620: 0.0010\n",
            "Seen so far: 819872 samples\n",
            "0.9734471\n",
            "Training loss (for one batch) at step 25625: 0.0039\n",
            "Seen so far: 820032 samples\n",
            "0.973451\n",
            "Training loss (for one batch) at step 25630: 0.0009\n",
            "Seen so far: 820192 samples\n",
            "0.97345257\n",
            "Training loss (for one batch) at step 25635: 0.0010\n",
            "Seen so far: 820352 samples\n",
            "0.9734553\n",
            "Training loss (for one batch) at step 25640: 0.0007\n",
            "Seen so far: 820512 samples\n",
            "0.9734605\n",
            "Training loss (for one batch) at step 25645: 0.0025\n",
            "Seen so far: 820672 samples\n",
            "0.9734656\n",
            "Training loss (for one batch) at step 25650: 0.0606\n",
            "Seen so far: 820832 samples\n",
            "0.97346836\n",
            "Training loss (for one batch) at step 25655: 0.0082\n",
            "Seen so far: 820992 samples\n",
            "0.97347355\n",
            "Training loss (for one batch) at step 25660: 0.0025\n",
            "Seen so far: 821152 samples\n",
            "0.9734751\n",
            "Training loss (for one batch) at step 25665: 0.3649\n",
            "Seen so far: 821312 samples\n",
            "0.97347295\n",
            "Training loss (for one batch) at step 25670: 0.0047\n",
            "Seen so far: 821472 samples\n",
            "0.97347564\n",
            "Training loss (for one batch) at step 25675: 0.0006\n",
            "Seen so far: 821632 samples\n",
            "0.9734772\n",
            "Training loss (for one batch) at step 25680: 0.0009\n",
            "Seen so far: 821792 samples\n",
            "0.9734811\n",
            "Training loss (for one batch) at step 25685: 0.0501\n",
            "Seen so far: 821952 samples\n",
            "0.9734826\n",
            "Training loss (for one batch) at step 25690: 0.2053\n",
            "Seen so far: 822112 samples\n",
            "0.97348535\n",
            "Training loss (for one batch) at step 25695: 0.0035\n",
            "Seen so far: 822272 samples\n",
            "0.97349054\n",
            "Training loss (for one batch) at step 25700: 0.2816\n",
            "Seen so far: 822432 samples\n",
            "0.9734896\n",
            "Training loss (for one batch) at step 25705: 0.0006\n",
            "Seen so far: 822592 samples\n",
            "0.97349113\n",
            "Training loss (for one batch) at step 25710: 0.0309\n",
            "Seen so far: 822752 samples\n",
            "0.9734926\n",
            "Training loss (for one batch) at step 25715: 0.0001\n",
            "Seen so far: 822912 samples\n",
            "0.97349775\n",
            "Training loss (for one batch) at step 25720: 0.0352\n",
            "Seen so far: 823072 samples\n",
            "0.9735017\n",
            "Training loss (for one batch) at step 25725: 0.1538\n",
            "Seen so far: 823232 samples\n",
            "0.9735044\n",
            "Training loss (for one batch) at step 25730: 0.0136\n",
            "Seen so far: 823392 samples\n",
            "0.97350717\n",
            "Training loss (for one batch) at step 25735: 0.0001\n",
            "Seen so far: 823552 samples\n",
            "0.97350985\n",
            "Training loss (for one batch) at step 25740: 0.0009\n",
            "Seen so far: 823712 samples\n",
            "0.9735138\n",
            "Training loss (for one batch) at step 25745: 0.0081\n",
            "Seen so far: 823872 samples\n",
            "0.9735165\n",
            "Training loss (for one batch) at step 25750: 0.0031\n",
            "Seen so far: 824032 samples\n",
            "0.97352046\n",
            "Training loss (for one batch) at step 25755: 0.0178\n",
            "Seen so far: 824192 samples\n",
            "0.9735244\n",
            "Training loss (for one batch) at step 25760: 0.0006\n",
            "Seen so far: 824352 samples\n",
            "0.9735295\n",
            "Training loss (for one batch) at step 25765: 0.0001\n",
            "Seen so far: 824512 samples\n",
            "0.97353345\n",
            "Training loss (for one batch) at step 25770: 0.0080\n",
            "Seen so far: 824672 samples\n",
            "0.9735374\n",
            "Training loss (for one batch) at step 25775: 0.0383\n",
            "Seen so far: 824832 samples\n",
            "0.9735389\n",
            "Training loss (for one batch) at step 25780: 0.0012\n",
            "Seen so far: 824992 samples\n",
            "0.97354275\n",
            "Training loss (for one batch) at step 25785: 0.1097\n",
            "Seen so far: 825152 samples\n",
            "0.97354424\n",
            "Training loss (for one batch) at step 25790: 0.0061\n",
            "Seen so far: 825312 samples\n",
            "0.973547\n",
            "Training loss (for one batch) at step 25795: 0.0035\n",
            "Seen so far: 825472 samples\n",
            "0.9735509\n",
            "Training loss (for one batch) at step 25800: 0.0012\n",
            "Seen so far: 825632 samples\n",
            "0.9735548\n",
            "Training loss (for one batch) at step 25805: 0.0340\n",
            "Seen so far: 825792 samples\n",
            "0.9735587\n",
            "Training loss (for one batch) at step 25810: 0.0040\n",
            "Seen so far: 825952 samples\n",
            "0.9735614\n",
            "Training loss (for one batch) at step 25815: 0.1989\n",
            "Seen so far: 826112 samples\n",
            "0.97356534\n",
            "Training loss (for one batch) at step 25820: 0.0002\n",
            "Seen so far: 826272 samples\n",
            "0.9735692\n",
            "Training loss (for one batch) at step 25825: 0.0016\n",
            "Seen so far: 826432 samples\n",
            "0.97357434\n",
            "Training loss (for one batch) at step 25830: 0.0065\n",
            "Seen so far: 826592 samples\n",
            "0.97357947\n",
            "Training loss (for one batch) at step 25835: 0.0003\n",
            "Seen so far: 826752 samples\n",
            "0.9735834\n",
            "Training loss (for one batch) at step 25840: 0.0769\n",
            "Seen so far: 826912 samples\n",
            "0.9735861\n",
            "Training loss (for one batch) at step 25845: 0.2678\n",
            "Seen so far: 827072 samples\n",
            "0.9735851\n",
            "Training loss (for one batch) at step 25850: 0.0018\n",
            "Seen so far: 827232 samples\n",
            "0.97359025\n",
            "Training loss (for one batch) at step 25855: 0.0001\n",
            "Seen so far: 827392 samples\n",
            "0.9735953\n",
            "Training loss (for one batch) at step 25860: 0.0049\n",
            "Seen so far: 827552 samples\n",
            "0.9735968\n",
            "Training loss (for one batch) at step 25865: 0.0095\n",
            "Seen so far: 827712 samples\n",
            "0.9735995\n",
            "Training loss (for one batch) at step 25870: 0.0049\n",
            "Seen so far: 827872 samples\n",
            "0.9736022\n",
            "Training loss (for one batch) at step 25875: 0.0000\n",
            "Seen so far: 828032 samples\n",
            "0.9736061\n",
            "Training loss (for one batch) at step 25880: 0.0010\n",
            "Seen so far: 828192 samples\n",
            "0.9736112\n",
            "Training loss (for one batch) at step 25885: 0.0277\n",
            "Seen so far: 828352 samples\n",
            "0.9736151\n",
            "Training loss (for one batch) at step 25890: 0.0056\n",
            "Seen so far: 828512 samples\n",
            "0.9736202\n",
            "Training loss (for one batch) at step 25895: 0.0013\n",
            "Seen so far: 828672 samples\n",
            "0.97362286\n",
            "Training loss (for one batch) at step 25900: 0.0015\n",
            "Seen so far: 828832 samples\n",
            "0.9736279\n",
            "Training loss (for one batch) at step 25905: 0.0013\n",
            "Seen so far: 828992 samples\n",
            "0.97363186\n",
            "Training loss (for one batch) at step 25910: 0.1432\n",
            "Seen so far: 829152 samples\n",
            "0.9736345\n",
            "Training loss (for one batch) at step 25915: 0.0003\n",
            "Seen so far: 829312 samples\n",
            "0.9736396\n",
            "Training loss (for one batch) at step 25920: 0.0001\n",
            "Seen so far: 829472 samples\n",
            "0.9736423\n",
            "Training loss (for one batch) at step 25925: 0.0415\n",
            "Seen so far: 829632 samples\n",
            "0.9736437\n",
            "Training loss (for one batch) at step 25930: 0.0001\n",
            "Seen so far: 829792 samples\n",
            "0.97364885\n",
            "Training loss (for one batch) at step 25935: 0.0044\n",
            "Seen so far: 829952 samples\n",
            "0.97365147\n",
            "Training loss (for one batch) at step 25940: 0.0025\n",
            "Seen so far: 830112 samples\n",
            "0.9736566\n",
            "Training loss (for one batch) at step 25945: 0.0001\n",
            "Seen so far: 830272 samples\n",
            "0.9736604\n",
            "Training loss (for one batch) at step 25950: 0.0029\n",
            "Seen so far: 830432 samples\n",
            "0.9736643\n",
            "Training loss (for one batch) at step 25955: 0.0008\n",
            "Seen so far: 830592 samples\n",
            "0.9736694\n",
            "Training loss (for one batch) at step 25960: 0.0002\n",
            "Seen so far: 830752 samples\n",
            "0.97367084\n",
            "Training loss (for one batch) at step 25965: 0.0484\n",
            "Seen so far: 830912 samples\n",
            "0.9736735\n",
            "Training loss (for one batch) at step 25970: 0.0005\n",
            "Seen so far: 831072 samples\n",
            "0.97367615\n",
            "Training loss (for one batch) at step 25975: 0.0081\n",
            "Seen so far: 831232 samples\n",
            "0.97368\n",
            "Training loss (for one batch) at step 25980: 0.0018\n",
            "Seen so far: 831392 samples\n",
            "0.9736839\n",
            "Training loss (for one batch) at step 25985: 0.0043\n",
            "Seen so far: 831552 samples\n",
            "0.97368896\n",
            "Training loss (for one batch) at step 25990: 0.0062\n",
            "Seen so far: 831712 samples\n",
            "0.97369164\n",
            "Training loss (for one batch) at step 25995: 0.0029\n",
            "Seen so far: 831872 samples\n",
            "0.97369426\n",
            "Training loss (for one batch) at step 26000: 0.0004\n",
            "Seen so far: 832032 samples\n",
            "0.97369933\n",
            "Training loss (for one batch) at step 26005: 0.0006\n",
            "Seen so far: 832192 samples\n",
            "0.97370195\n",
            "Training loss (for one batch) at step 26010: 0.0002\n",
            "Seen so far: 832352 samples\n",
            "0.973707\n",
            "Training loss (for one batch) at step 26015: 0.0002\n",
            "Seen so far: 832512 samples\n",
            "0.9737109\n",
            "Training loss (for one batch) at step 26020: 0.0025\n",
            "Seen so far: 832672 samples\n",
            "0.97371596\n",
            "Training loss (for one batch) at step 26025: 0.0045\n",
            "Seen so far: 832832 samples\n",
            "0.97372097\n",
            "Training loss (for one batch) at step 26030: 0.0003\n",
            "Seen so far: 832992 samples\n",
            "0.97372603\n",
            "Training loss (for one batch) at step 26035: 0.0219\n",
            "Seen so far: 833152 samples\n",
            "0.9737311\n",
            "Training loss (for one batch) at step 26040: 0.0806\n",
            "Seen so far: 833312 samples\n",
            "0.9737349\n",
            "Training loss (for one batch) at step 26045: 0.0034\n",
            "Seen so far: 833472 samples\n",
            "0.9737388\n",
            "Training loss (for one batch) at step 26050: 0.0007\n",
            "Seen so far: 833632 samples\n",
            "0.9737426\n",
            "Training loss (for one batch) at step 26055: 0.0002\n",
            "Seen so far: 833792 samples\n",
            "0.9737477\n",
            "Training loss (for one batch) at step 26060: 0.0078\n",
            "Seen so far: 833952 samples\n",
            "0.9737515\n",
            "Training loss (for one batch) at step 26065: 0.0065\n",
            "Seen so far: 834112 samples\n",
            "0.9737565\n",
            "Training loss (for one batch) at step 26070: 0.0019\n",
            "Seen so far: 834272 samples\n",
            "0.97376037\n",
            "Training loss (for one batch) at step 26075: 0.0035\n",
            "Seen so far: 834432 samples\n",
            "0.9737642\n",
            "Training loss (for one batch) at step 26080: 0.0005\n",
            "Seen so far: 834592 samples\n",
            "0.97376925\n",
            "Training loss (for one batch) at step 26085: 0.0002\n",
            "Seen so far: 834752 samples\n",
            "0.97377306\n",
            "Training loss (for one batch) at step 26090: 0.0001\n",
            "Seen so far: 834912 samples\n",
            "0.9737769\n",
            "Training loss (for one batch) at step 26095: 0.0697\n",
            "Seen so far: 835072 samples\n",
            "0.9737795\n",
            "Training loss (for one batch) at step 26100: 0.0000\n",
            "Seen so far: 835232 samples\n",
            "0.97378093\n",
            "Training loss (for one batch) at step 26105: 0.0589\n",
            "Seen so far: 835392 samples\n",
            "0.97378355\n",
            "Training loss (for one batch) at step 26110: 0.0008\n",
            "Seen so far: 835552 samples\n",
            "0.973785\n",
            "Training loss (for one batch) at step 26115: 0.0027\n",
            "Seen so far: 835712 samples\n",
            "0.97379\n",
            "Training loss (for one batch) at step 26120: 0.0389\n",
            "Seen so far: 835872 samples\n",
            "0.97379386\n",
            "Training loss (for one batch) at step 26125: 0.0108\n",
            "Seen so far: 836032 samples\n",
            "0.9737989\n",
            "Training loss (for one batch) at step 26130: 0.0006\n",
            "Seen so far: 836192 samples\n",
            "0.9738015\n",
            "Training loss (for one batch) at step 26135: 0.0311\n",
            "Seen so far: 836352 samples\n",
            "0.9738053\n",
            "Training loss (for one batch) at step 26140: 0.0044\n",
            "Seen so far: 836512 samples\n",
            "0.9738103\n",
            "Training loss (for one batch) at step 26145: 0.0018\n",
            "Seen so far: 836672 samples\n",
            "0.9738153\n",
            "Training loss (for one batch) at step 26150: 0.0002\n",
            "Seen so far: 836832 samples\n",
            "0.9738203\n",
            "Training loss (for one batch) at step 26155: 0.2088\n",
            "Seen so far: 836992 samples\n",
            "0.97382295\n",
            "Training loss (for one batch) at step 26160: 0.0009\n",
            "Seen so far: 837152 samples\n",
            "0.97382796\n",
            "Training loss (for one batch) at step 26165: 0.0086\n",
            "Seen so far: 837312 samples\n",
            "0.9738317\n",
            "Training loss (for one batch) at step 26170: 0.0040\n",
            "Seen so far: 837472 samples\n",
            "0.9738367\n",
            "Training loss (for one batch) at step 26175: 0.0002\n",
            "Seen so far: 837632 samples\n",
            "0.9738417\n",
            "Training loss (for one batch) at step 26180: 0.0004\n",
            "Seen so far: 837792 samples\n",
            "0.97384554\n",
            "Training loss (for one batch) at step 26185: 0.0003\n",
            "Seen so far: 837952 samples\n",
            "0.97385055\n",
            "Training loss (for one batch) at step 26190: 0.0012\n",
            "Seen so far: 838112 samples\n",
            "0.9738543\n",
            "Training loss (for one batch) at step 26195: 0.0039\n",
            "Seen so far: 838272 samples\n",
            "0.9738581\n",
            "Training loss (for one batch) at step 26200: 0.0283\n",
            "Seen so far: 838432 samples\n",
            "0.97386193\n",
            "Training loss (for one batch) at step 26205: 0.0658\n",
            "Seen so far: 838592 samples\n",
            "0.97386575\n",
            "Training loss (for one batch) at step 26210: 0.0002\n",
            "Seen so far: 838752 samples\n",
            "0.9738695\n",
            "Training loss (for one batch) at step 26215: 0.0226\n",
            "Seen so far: 838912 samples\n",
            "0.9738733\n",
            "Training loss (for one batch) at step 26220: 0.0111\n",
            "Seen so far: 839072 samples\n",
            "0.9738759\n",
            "Training loss (for one batch) at step 26225: 0.0001\n",
            "Seen so far: 839232 samples\n",
            "0.9738785\n",
            "Training loss (for one batch) at step 26230: 0.2395\n",
            "Seen so far: 839392 samples\n",
            "0.9738799\n",
            "Training loss (for one batch) at step 26235: 0.0189\n",
            "Seen so far: 839552 samples\n",
            "0.9738837\n",
            "Training loss (for one batch) at step 26240: 0.0012\n",
            "Seen so far: 839712 samples\n",
            "0.9738875\n",
            "Training loss (for one batch) at step 26245: 0.0004\n",
            "Seen so far: 839872 samples\n",
            "0.9738877\n",
            "Training loss (for one batch) at step 26250: 0.0001\n",
            "Seen so far: 840032 samples\n",
            "0.9738903\n",
            "Training loss (for one batch) at step 26255: 0.0068\n",
            "Seen so far: 840192 samples\n",
            "0.97389525\n",
            "Training loss (for one batch) at step 26260: 0.1722\n",
            "Seen so far: 840352 samples\n",
            "0.9738943\n",
            "Training loss (for one batch) at step 26265: 0.0119\n",
            "Seen so far: 840512 samples\n",
            "0.97389925\n",
            "Training loss (for one batch) at step 26270: 0.0002\n",
            "Seen so far: 840672 samples\n",
            "0.973903\n",
            "Training loss (for one batch) at step 26275: 0.0159\n",
            "Seen so far: 840832 samples\n",
            "0.9739068\n",
            "Training loss (for one batch) at step 26280: 0.1152\n",
            "Seen so far: 840992 samples\n",
            "0.9739094\n",
            "Training loss (for one batch) at step 26285: 0.0246\n",
            "Seen so far: 841152 samples\n",
            "0.9739143\n",
            "Training loss (for one batch) at step 26290: 0.0009\n",
            "Seen so far: 841312 samples\n",
            "0.97391814\n",
            "Training loss (for one batch) at step 26295: 0.0003\n",
            "Seen so far: 841472 samples\n",
            "0.9739231\n",
            "Training loss (for one batch) at step 26300: 0.0002\n",
            "Seen so far: 841632 samples\n",
            "0.97392803\n",
            "Training loss (for one batch) at step 26305: 0.0002\n",
            "Seen so far: 841792 samples\n",
            "0.973933\n",
            "Training loss (for one batch) at step 26310: 0.0105\n",
            "Seen so far: 841952 samples\n",
            "0.9739379\n",
            "Training loss (for one batch) at step 26315: 0.0018\n",
            "Seen so far: 842112 samples\n",
            "0.9739405\n",
            "Training loss (for one batch) at step 26320: 0.0007\n",
            "Seen so far: 842272 samples\n",
            "0.9739455\n",
            "Training loss (for one batch) at step 26325: 0.0017\n",
            "Seen so far: 842432 samples\n",
            "0.97395045\n",
            "Training loss (for one batch) at step 26330: 0.0224\n",
            "Seen so far: 842592 samples\n",
            "0.9739518\n",
            "Training loss (for one batch) at step 26335: 0.0059\n",
            "Seen so far: 842752 samples\n",
            "0.9739556\n",
            "Training loss (for one batch) at step 26340: 0.0025\n",
            "Seen so far: 842912 samples\n",
            "0.9739593\n",
            "Training loss (for one batch) at step 26345: 0.0006\n",
            "Seen so far: 843072 samples\n",
            "0.9739631\n",
            "Training loss (for one batch) at step 26350: 0.0019\n",
            "Seen so far: 843232 samples\n",
            "0.97396564\n",
            "Training loss (for one batch) at step 26355: 0.0002\n",
            "Seen so far: 843392 samples\n",
            "0.9739694\n",
            "Training loss (for one batch) at step 26360: 0.0007\n",
            "Seen so far: 843552 samples\n",
            "0.97397316\n",
            "Training loss (for one batch) at step 26365: 0.0001\n",
            "Seen so far: 843712 samples\n",
            "0.9739769\n",
            "Training loss (for one batch) at step 26370: 0.0025\n",
            "Seen so far: 843872 samples\n",
            "0.97398186\n",
            "Training loss (for one batch) at step 26375: 0.0038\n",
            "Seen so far: 844032 samples\n",
            "0.97398204\n",
            "Training loss (for one batch) at step 26380: 0.0005\n",
            "Seen so far: 844192 samples\n",
            "0.9739822\n",
            "Training loss (for one batch) at step 26385: 0.0009\n",
            "Seen so far: 844352 samples\n",
            "0.9739836\n",
            "Training loss (for one batch) at step 26390: 0.0038\n",
            "Seen so far: 844512 samples\n",
            "0.97398734\n",
            "Training loss (for one batch) at step 26395: 0.0007\n",
            "Seen so far: 844672 samples\n",
            "0.9739923\n",
            "Training loss (for one batch) at step 26400: 0.0061\n",
            "Seen so far: 844832 samples\n",
            "0.97399604\n",
            "Training loss (for one batch) at step 26405: 0.0020\n",
            "Seen so far: 844992 samples\n",
            "0.97399855\n",
            "Training loss (for one batch) at step 26410: 0.0004\n",
            "Seen so far: 845152 samples\n",
            "0.9740035\n",
            "Training loss (for one batch) at step 26415: 0.0369\n",
            "Seen so far: 845312 samples\n",
            "0.97400486\n",
            "Training loss (for one batch) at step 26420: 0.0679\n",
            "Seen so far: 845472 samples\n",
            "0.9740086\n",
            "Training loss (for one batch) at step 26425: 0.0761\n",
            "Seen so far: 845632 samples\n",
            "0.97401\n",
            "Training loss (for one batch) at step 26430: 0.0608\n",
            "Seen so far: 845792 samples\n",
            "0.9740125\n",
            "Training loss (for one batch) at step 26435: 0.0010\n",
            "Seen so far: 845952 samples\n",
            "0.97401625\n",
            "Training loss (for one batch) at step 26440: 0.0533\n",
            "Seen so far: 846112 samples\n",
            "0.97402\n",
            "Training loss (for one batch) at step 26445: 0.0030\n",
            "Seen so far: 846272 samples\n",
            "0.9740202\n",
            "Training loss (for one batch) at step 26450: 0.0036\n",
            "Seen so far: 846432 samples\n",
            "0.97402275\n",
            "Training loss (for one batch) at step 26455: 0.0050\n",
            "Seen so far: 846592 samples\n",
            "0.97402173\n",
            "Training loss (for one batch) at step 26460: 0.0261\n",
            "Seen so far: 846752 samples\n",
            "0.9740231\n",
            "Training loss (for one batch) at step 26465: 0.0359\n",
            "Seen so far: 846912 samples\n",
            "0.9740268\n",
            "Training loss (for one batch) at step 26470: 0.0206\n",
            "Seen so far: 847072 samples\n",
            "0.97402936\n",
            "Training loss (for one batch) at step 26475: 0.2753\n",
            "Seen so far: 847232 samples\n",
            "0.97403073\n",
            "Training loss (for one batch) at step 26480: 0.1925\n",
            "Seen so far: 847392 samples\n",
            "0.9740344\n",
            "Training loss (for one batch) at step 26485: 0.0414\n",
            "Seen so far: 847552 samples\n",
            "0.9740394\n",
            "Training loss (for one batch) at step 26490: 0.0118\n",
            "Seen so far: 847712 samples\n",
            "0.9740407\n",
            "Training loss (for one batch) at step 26495: 0.0008\n",
            "Seen so far: 847872 samples\n",
            "0.97404563\n",
            "Training loss (for one batch) at step 26500: 0.0198\n",
            "Seen so far: 848032 samples\n",
            "0.97404695\n",
            "Training loss (for one batch) at step 26505: 0.0000\n",
            "Seen so far: 848192 samples\n",
            "0.9740495\n",
            "Training loss (for one batch) at step 26510: 0.0357\n",
            "Seen so far: 848352 samples\n",
            "0.9740521\n",
            "Training loss (for one batch) at step 26515: 0.0029\n",
            "Seen so far: 848512 samples\n",
            "0.97405696\n",
            "Training loss (for one batch) at step 26520: 0.0053\n",
            "Seen so far: 848672 samples\n",
            "0.97405946\n",
            "Training loss (for one batch) at step 26525: 0.0010\n",
            "Seen so far: 848832 samples\n",
            "0.97406435\n",
            "Training loss (for one batch) at step 26530: 0.0723\n",
            "Seen so far: 848992 samples\n",
            "0.9740645\n",
            "Training loss (for one batch) at step 26535: 0.0167\n",
            "Seen so far: 849152 samples\n",
            "0.9740659\n",
            "Training loss (for one batch) at step 26540: 0.0112\n",
            "Seen so far: 849312 samples\n",
            "0.9740708\n",
            "Training loss (for one batch) at step 26545: 0.0023\n",
            "Seen so far: 849472 samples\n",
            "0.97407097\n",
            "Training loss (for one batch) at step 26550: 0.0589\n",
            "Seen so far: 849632 samples\n",
            "0.97407466\n",
            "Training loss (for one batch) at step 26555: 0.0213\n",
            "Seen so far: 849792 samples\n",
            "0.97407955\n",
            "Training loss (for one batch) at step 26560: 0.0582\n",
            "Seen so far: 849952 samples\n",
            "0.97408086\n",
            "Training loss (for one batch) at step 26565: 0.0666\n",
            "Seen so far: 850112 samples\n",
            "0.9740834\n",
            "Training loss (for one batch) at step 26570: 0.0003\n",
            "Seen so far: 850272 samples\n",
            "0.9740859\n",
            "Training loss (for one batch) at step 26575: 0.0030\n",
            "Seen so far: 850432 samples\n",
            "0.9740873\n",
            "Training loss (for one batch) at step 26580: 0.1025\n",
            "Seen so far: 850592 samples\n",
            "0.9740886\n",
            "Training loss (for one batch) at step 26585: 0.0029\n",
            "Seen so far: 850752 samples\n",
            "0.9740935\n",
            "Training loss (for one batch) at step 26590: 0.0726\n",
            "Seen so far: 850912 samples\n",
            "0.974096\n",
            "Training loss (for one batch) at step 26595: 0.0036\n",
            "Seen so far: 851072 samples\n",
            "0.9740997\n",
            "Training loss (for one batch) at step 26600: 0.0071\n",
            "Seen so far: 851232 samples\n",
            "0.9741034\n",
            "Training loss (for one batch) at step 26605: 0.0365\n",
            "Seen so far: 851392 samples\n",
            "0.97410476\n",
            "Training loss (for one batch) at step 26610: 0.0182\n",
            "Seen so far: 851552 samples\n",
            "0.97410965\n",
            "Training loss (for one batch) at step 26615: 0.0014\n",
            "Seen so far: 851712 samples\n",
            "0.9741145\n",
            "Training loss (for one batch) at step 26620: 0.1788\n",
            "Seen so far: 851872 samples\n",
            "0.9741182\n",
            "Training loss (for one batch) at step 26625: 0.0080\n",
            "Seen so far: 852032 samples\n",
            "0.9741207\n",
            "Training loss (for one batch) at step 26630: 0.0020\n",
            "Seen so far: 852192 samples\n",
            "0.9741244\n",
            "Training loss (for one batch) at step 26635: 0.0021\n",
            "Seen so far: 852352 samples\n",
            "0.9741269\n",
            "Training loss (for one batch) at step 26640: 0.0708\n",
            "Seen so far: 852512 samples\n",
            "0.97412825\n",
            "Training loss (for one batch) at step 26645: 0.0087\n",
            "Seen so far: 852672 samples\n",
            "0.9741319\n",
            "Training loss (for one batch) at step 26650: 0.0006\n",
            "Seen so far: 852832 samples\n",
            "0.9741344\n",
            "Training loss (for one batch) at step 26655: 0.5018\n",
            "Seen so far: 852992 samples\n",
            "0.97413695\n",
            "Training loss (for one batch) at step 26660: 0.0009\n",
            "Seen so far: 853152 samples\n",
            "0.9741418\n",
            "Training loss (for one batch) at step 26665: 0.0013\n",
            "Seen so far: 853312 samples\n",
            "0.9741466\n",
            "Training loss (for one batch) at step 26670: 0.0409\n",
            "Seen so far: 853472 samples\n",
            "0.9741491\n",
            "Training loss (for one batch) at step 26675: 0.1392\n",
            "Seen so far: 853632 samples\n",
            "0.9741516\n",
            "Training loss (for one batch) at step 26680: 0.0016\n",
            "Seen so far: 853792 samples\n",
            "0.9741553\n",
            "Training loss (for one batch) at step 26685: 0.0041\n",
            "Seen so far: 853952 samples\n",
            "0.97415894\n",
            "Training loss (for one batch) at step 26690: 0.0165\n",
            "Seen so far: 854112 samples\n",
            "0.9741603\n",
            "Training loss (for one batch) at step 26695: 0.0019\n",
            "Seen so far: 854272 samples\n",
            "0.97416395\n",
            "Training loss (for one batch) at step 26700: 0.0192\n",
            "Seen so far: 854432 samples\n",
            "0.97416645\n",
            "Training loss (for one batch) at step 26705: 0.0403\n",
            "Seen so far: 854592 samples\n",
            "0.97417015\n",
            "Training loss (for one batch) at step 26710: 0.0154\n",
            "Seen so far: 854752 samples\n",
            "0.9741738\n",
            "Training loss (for one batch) at step 26715: 0.0018\n",
            "Seen so far: 854912 samples\n",
            "0.9741763\n",
            "Training loss (for one batch) at step 26720: 0.1684\n",
            "Seen so far: 855072 samples\n",
            "0.9741799\n",
            "Training loss (for one batch) at step 26725: 0.0008\n",
            "Seen so far: 855232 samples\n",
            "0.9741813\n",
            "Training loss (for one batch) at step 26730: 0.0002\n",
            "Seen so far: 855392 samples\n",
            "0.9741826\n",
            "Training loss (for one batch) at step 26735: 0.0118\n",
            "Seen so far: 855552 samples\n",
            "0.97418624\n",
            "Training loss (for one batch) at step 26740: 0.0002\n",
            "Seen so far: 855712 samples\n",
            "0.97418755\n",
            "Training loss (for one batch) at step 26745: 0.0182\n",
            "Seen so far: 855872 samples\n",
            "0.97419125\n",
            "Training loss (for one batch) at step 26750: 0.0002\n",
            "Seen so far: 856032 samples\n",
            "0.9741949\n",
            "Training loss (for one batch) at step 26755: 0.0001\n",
            "Seen so far: 856192 samples\n",
            "0.9741974\n",
            "Training loss (for one batch) at step 26760: 0.0014\n",
            "Seen so far: 856352 samples\n",
            "0.9742022\n",
            "Training loss (for one batch) at step 26765: 0.0003\n",
            "Seen so far: 856512 samples\n",
            "0.9742035\n",
            "Training loss (for one batch) at step 26770: 0.0016\n",
            "Seen so far: 856672 samples\n",
            "0.974206\n",
            "Training loss (for one batch) at step 26775: 0.1261\n",
            "Seen so far: 856832 samples\n",
            "0.97420615\n",
            "Training loss (for one batch) at step 26780: 0.0007\n",
            "Seen so far: 856992 samples\n",
            "0.97420746\n",
            "Training loss (for one batch) at step 26785: 0.0724\n",
            "Seen so far: 857152 samples\n",
            "0.97420996\n",
            "Training loss (for one batch) at step 26790: 0.0344\n",
            "Seen so far: 857312 samples\n",
            "0.9742124\n",
            "Training loss (for one batch) at step 26795: 0.1586\n",
            "Seen so far: 857472 samples\n",
            "0.97421604\n",
            "Training loss (for one batch) at step 26800: 0.0260\n",
            "Seen so far: 857632 samples\n",
            "0.9742209\n",
            "Training loss (for one batch) at step 26805: 0.0233\n",
            "Seen so far: 857792 samples\n",
            "0.97422105\n",
            "Training loss (for one batch) at step 26810: 0.0282\n",
            "Seen so far: 857952 samples\n",
            "0.9742235\n",
            "Training loss (for one batch) at step 26815: 0.0000\n",
            "Seen so far: 858112 samples\n",
            "0.97422713\n",
            "Training loss (for one batch) at step 26820: 0.0206\n",
            "Seen so far: 858272 samples\n",
            "0.97423077\n",
            "Training loss (for one batch) at step 26825: 0.0141\n",
            "Seen so far: 858432 samples\n",
            "0.9742344\n",
            "Training loss (for one batch) at step 26830: 0.0236\n",
            "Seen so far: 858592 samples\n",
            "0.9742357\n",
            "Training loss (for one batch) at step 26835: 0.0481\n",
            "Seen so far: 858752 samples\n",
            "0.974237\n",
            "Training loss (for one batch) at step 26840: 0.0043\n",
            "Seen so far: 858912 samples\n",
            "0.97424066\n",
            "Training loss (for one batch) at step 26845: 0.0312\n",
            "Seen so far: 859072 samples\n",
            "0.9742443\n",
            "Training loss (for one batch) at step 26850: 0.0099\n",
            "Seen so far: 859232 samples\n",
            "0.97424674\n",
            "Training loss (for one batch) at step 26855: 0.0005\n",
            "Seen so far: 859392 samples\n",
            "0.9742504\n",
            "Training loss (for one batch) at step 26860: 0.0224\n",
            "Seen so far: 859552 samples\n",
            "0.9742552\n",
            "Training loss (for one batch) at step 26865: 0.0013\n",
            "Seen so far: 859712 samples\n",
            "0.97426\n",
            "Training loss (for one batch) at step 26870: 0.0022\n",
            "Seen so far: 859872 samples\n",
            "0.9742625\n",
            "Training loss (for one batch) at step 26875: 0.0009\n",
            "Seen so far: 860032 samples\n",
            "0.97426724\n",
            "Training loss (for one batch) at step 26880: 0.0060\n",
            "Seen so far: 860192 samples\n",
            "0.9742697\n",
            "Training loss (for one batch) at step 26885: 0.0096\n",
            "Seen so far: 860352 samples\n",
            "0.9742675\n",
            "Training loss (for one batch) at step 26890: 0.0001\n",
            "Seen so far: 860512 samples\n",
            "0.97427\n",
            "Training loss (for one batch) at step 26895: 0.0787\n",
            "Seen so far: 860672 samples\n",
            "0.97427124\n",
            "Training loss (for one batch) at step 26900: 0.2987\n",
            "Seen so far: 860832 samples\n",
            "0.9742702\n",
            "Training loss (for one batch) at step 26905: 0.3221\n",
            "Seen so far: 860992 samples\n",
            "0.9742692\n",
            "Training loss (for one batch) at step 26910: 0.0020\n",
            "Seen so far: 861152 samples\n",
            "0.9742705\n",
            "Training loss (for one batch) at step 26915: 0.0002\n",
            "Seen so far: 861312 samples\n",
            "0.9742753\n",
            "Training loss (for one batch) at step 26920: 0.0055\n",
            "Seen so far: 861472 samples\n",
            "0.97427773\n",
            "Training loss (for one batch) at step 26925: 0.0002\n",
            "Seen so far: 861632 samples\n",
            "0.97427905\n",
            "Training loss (for one batch) at step 26930: 0.0007\n",
            "Seen so far: 861792 samples\n",
            "0.97428036\n",
            "Training loss (for one batch) at step 26935: 0.1436\n",
            "Seen so far: 861952 samples\n",
            "0.9742805\n",
            "Training loss (for one batch) at step 26940: 0.0777\n",
            "Seen so far: 862112 samples\n",
            "0.9742818\n",
            "Training loss (for one batch) at step 26945: 0.0553\n",
            "Seen so far: 862272 samples\n",
            "0.97428536\n",
            "Training loss (for one batch) at step 26950: 0.0019\n",
            "Seen so far: 862432 samples\n",
            "0.97429013\n",
            "Training loss (for one batch) at step 26955: 0.0416\n",
            "Seen so far: 862592 samples\n",
            "0.97429377\n",
            "Training loss (for one batch) at step 26960: 0.1033\n",
            "Seen so far: 862752 samples\n",
            "0.97429734\n",
            "Training loss (for one batch) at step 26965: 0.0008\n",
            "Seen so far: 862912 samples\n",
            "0.974301\n",
            "Training loss (for one batch) at step 26970: 0.0558\n",
            "Seen so far: 863072 samples\n",
            "0.9743034\n",
            "Training loss (for one batch) at step 26975: 0.0016\n",
            "Seen so far: 863232 samples\n",
            "0.97430587\n",
            "Training loss (for one batch) at step 26980: 0.0011\n",
            "Seen so far: 863392 samples\n",
            "0.97431064\n",
            "Training loss (for one batch) at step 26985: 0.0143\n",
            "Seen so far: 863552 samples\n",
            "0.97431076\n",
            "Training loss (for one batch) at step 26990: 0.0001\n",
            "Seen so far: 863712 samples\n",
            "0.97430974\n",
            "Training loss (for one batch) at step 26995: 0.0005\n",
            "Seen so far: 863872 samples\n",
            "0.9743133\n",
            "Training loss (for one batch) at step 27000: 0.0123\n",
            "Seen so far: 864032 samples\n",
            "0.97431576\n",
            "Training loss (for one batch) at step 27005: 0.0015\n",
            "Seen so far: 864192 samples\n",
            "0.97432053\n",
            "Training loss (for one batch) at step 27010: 0.0167\n",
            "Seen so far: 864352 samples\n",
            "0.9743218\n",
            "Training loss (for one batch) at step 27015: 0.0020\n",
            "Seen so far: 864512 samples\n",
            "0.9743242\n",
            "Training loss (for one batch) at step 27020: 0.1468\n",
            "Seen so far: 864672 samples\n",
            "0.97432435\n",
            "Training loss (for one batch) at step 27025: 0.0025\n",
            "Seen so far: 864832 samples\n",
            "0.974328\n",
            "Training loss (for one batch) at step 27030: 0.0053\n",
            "Seen so far: 864992 samples\n",
            "0.9743327\n",
            "Training loss (for one batch) at step 27035: 0.0712\n",
            "Seen so far: 865152 samples\n",
            "0.97433513\n",
            "Training loss (for one batch) at step 27040: 0.0094\n",
            "Seen so far: 865312 samples\n",
            "0.9743376\n",
            "Training loss (for one batch) at step 27045: 0.0276\n",
            "Seen so far: 865472 samples\n",
            "0.97433656\n",
            "Training loss (for one batch) at step 27050: 0.0005\n",
            "Seen so far: 865632 samples\n",
            "0.97434014\n",
            "Training loss (for one batch) at step 27055: 0.1598\n",
            "Seen so far: 865792 samples\n",
            "0.9743414\n",
            "Training loss (for one batch) at step 27060: 0.0002\n",
            "Seen so far: 865952 samples\n",
            "0.97434616\n",
            "Training loss (for one batch) at step 27065: 0.0017\n",
            "Seen so far: 866112 samples\n",
            "0.9743486\n",
            "Training loss (for one batch) at step 27070: 0.1417\n",
            "Seen so far: 866272 samples\n",
            "0.9743522\n",
            "Training loss (for one batch) at step 27075: 0.0039\n",
            "Seen so far: 866432 samples\n",
            "0.97435343\n",
            "Training loss (for one batch) at step 27080: 0.0022\n",
            "Seen so far: 866592 samples\n",
            "0.974357\n",
            "Training loss (for one batch) at step 27085: 0.0110\n",
            "Seen so far: 866752 samples\n",
            "0.9743606\n",
            "Training loss (for one batch) at step 27090: 0.0021\n",
            "Seen so far: 866912 samples\n",
            "0.97436535\n",
            "Training loss (for one batch) at step 27095: 0.0003\n",
            "Seen so far: 867072 samples\n",
            "0.97436774\n",
            "Training loss (for one batch) at step 27100: 0.0782\n",
            "Seen so far: 867232 samples\n",
            "0.9743713\n",
            "Training loss (for one batch) at step 27105: 0.0006\n",
            "Seen so far: 867392 samples\n",
            "0.9743761\n",
            "Training loss (for one batch) at step 27110: 0.0040\n",
            "Seen so far: 867552 samples\n",
            "0.9743808\n",
            "Training loss (for one batch) at step 27115: 0.0105\n",
            "Seen so far: 867712 samples\n",
            "0.9743855\n",
            "Training loss (for one batch) at step 27120: 0.0016\n",
            "Seen so far: 867872 samples\n",
            "0.9743891\n",
            "Training loss (for one batch) at step 27125: 0.0171\n",
            "Seen so far: 868032 samples\n",
            "0.9743903\n",
            "Training loss (for one batch) at step 27130: 0.0117\n",
            "Seen so far: 868192 samples\n",
            "0.9743916\n",
            "Training loss (for one batch) at step 27135: 0.0038\n",
            "Seen so far: 868352 samples\n",
            "0.97439635\n",
            "Training loss (for one batch) at step 27140: 0.1030\n",
            "Seen so far: 868512 samples\n",
            "0.97439873\n",
            "Training loss (for one batch) at step 27145: 0.0020\n",
            "Seen so far: 868672 samples\n",
            "0.9743977\n",
            "Training loss (for one batch) at step 27150: 0.1932\n",
            "Seen so far: 868832 samples\n",
            "0.97439784\n",
            "Training loss (for one batch) at step 27155: 0.0001\n",
            "Seen so far: 868992 samples\n",
            "0.9743991\n",
            "Training loss (for one batch) at step 27160: 0.0003\n",
            "Seen so far: 869152 samples\n",
            "0.9744026\n",
            "Training loss (for one batch) at step 27165: 0.0012\n",
            "Seen so far: 869312 samples\n",
            "0.9744062\n",
            "Training loss (for one batch) at step 27170: 0.3273\n",
            "Seen so far: 869472 samples\n",
            "0.97440517\n",
            "Training loss (for one batch) at step 27175: 0.0415\n",
            "Seen so far: 869632 samples\n",
            "0.9744053\n",
            "Training loss (for one batch) at step 27180: 0.0000\n",
            "Seen so far: 869792 samples\n",
            "0.9744088\n",
            "Training loss (for one batch) at step 27185: 0.0110\n",
            "Seen so far: 869952 samples\n",
            "0.97441006\n",
            "Training loss (for one batch) at step 27190: 0.0021\n",
            "Seen so far: 870112 samples\n",
            "0.9744125\n",
            "Training loss (for one batch) at step 27195: 0.0000\n",
            "Seen so far: 870272 samples\n",
            "0.97441375\n",
            "Training loss (for one batch) at step 27200: 0.0669\n",
            "Seen so far: 870432 samples\n",
            "0.97441614\n",
            "Training loss (for one batch) at step 27205: 0.0045\n",
            "Seen so far: 870592 samples\n",
            "0.97442085\n",
            "Training loss (for one batch) at step 27210: 0.0033\n",
            "Seen so far: 870752 samples\n",
            "0.9744232\n",
            "Training loss (for one batch) at step 27215: 0.0103\n",
            "Seen so far: 870912 samples\n",
            "0.9744268\n",
            "Training loss (for one batch) at step 27220: 0.0009\n",
            "Seen so far: 871072 samples\n",
            "0.9744315\n",
            "Training loss (for one batch) at step 27225: 0.0261\n",
            "Seen so far: 871232 samples\n",
            "0.9744339\n",
            "Training loss (for one batch) at step 27230: 0.0001\n",
            "Seen so far: 871392 samples\n",
            "0.9744375\n",
            "Training loss (for one batch) at step 27235: 0.0001\n",
            "Seen so far: 871552 samples\n",
            "0.97443986\n",
            "Training loss (for one batch) at step 27240: 0.0016\n",
            "Seen so far: 871712 samples\n",
            "0.97444224\n",
            "Training loss (for one batch) at step 27245: 0.0000\n",
            "Seen so far: 871872 samples\n",
            "0.97444695\n",
            "Training loss (for one batch) at step 27250: 0.1652\n",
            "Seen so far: 872032 samples\n",
            "0.97444934\n",
            "Training loss (for one batch) at step 27255: 0.0040\n",
            "Seen so far: 872192 samples\n",
            "0.97445405\n",
            "Training loss (for one batch) at step 27260: 0.0001\n",
            "Seen so far: 872352 samples\n",
            "0.9744587\n",
            "Training loss (for one batch) at step 27265: 0.0038\n",
            "Seen so far: 872512 samples\n",
            "0.9744634\n",
            "Training loss (for one batch) at step 27270: 0.2950\n",
            "Seen so far: 872672 samples\n",
            "0.97446346\n",
            "Training loss (for one batch) at step 27275: 0.0007\n",
            "Seen so far: 872832 samples\n",
            "0.97446704\n",
            "Training loss (for one batch) at step 27280: 0.0002\n",
            "Seen so far: 872992 samples\n",
            "0.9744683\n",
            "Training loss (for one batch) at step 27285: 0.0003\n",
            "Seen so far: 873152 samples\n",
            "0.9744695\n",
            "Training loss (for one batch) at step 27290: 0.0058\n",
            "Seen so far: 873312 samples\n",
            "0.97447073\n",
            "Training loss (for one batch) at step 27295: 0.0004\n",
            "Seen so far: 873472 samples\n",
            "0.97447544\n",
            "Training loss (for one batch) at step 27300: 0.0091\n",
            "Seen so far: 873632 samples\n",
            "0.9744801\n",
            "Training loss (for one batch) at step 27305: 0.0000\n",
            "Seen so far: 873792 samples\n",
            "0.9744836\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_296/3719640463.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m trainer.train(train_dataset=dataset,\n\u001b[0m\u001b[1;32m     25\u001b[0m               \u001b[0mtrain_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_acc_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m               callbacks=[early_stopping])\n",
            "\u001b[0;32m/tmp/ipykernel_296/1583776888.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, train_metric, callbacks)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                     \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_296/1974525113.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[0;32m--> 414\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    415\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m               outputs, _apply_fn, inner_rank=self.rank + 1)\n\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m           outputs = tf.nn.bias_add(\n\u001b[0m\u001b[1;32m    268\u001b[0m               outputs, self.bias, data_format=self._tf_data_format)\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m   3494\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3495\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3496\u001b[0;31m       return gen_nn_ops.bias_add(\n\u001b[0m\u001b[1;32m   3497\u001b[0m           value, bias, data_format=data_format, name=name)\n\u001b[1;32m   3498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m    672\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    675\u001b[0m         _ctx, \"BiasAdd\", name, value, bias, \"data_format\", data_format)\n\u001b[1;32m    676\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 모델 학습 코드\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "train_path = \"/aiffel/aiffel/model-fit/data/30vnfoods/Train\"\n",
        "epoch = 5\n",
        "batch = 32\n",
        "\n",
        "model = Model(num_classes=10)\n",
        "dataset = load_data(data_path=train_path, batch_size=batch)\n",
        "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "trainer = Trainer(model=model,\n",
        "                  epochs=epoch,\n",
        "                  batch=batch,\n",
        "                  ds_length=train_length,\n",
        "                  loss_fn=loss_function,\n",
        "                  optimizer=optimizer)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "trainer.train(train_dataset=dataset,\n",
        "              train_metric=train_acc_metric,\n",
        "              callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e70e5485",
      "metadata": {
        "id": "e70e5485"
      },
      "source": [
        "### Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0ea7b54",
      "metadata": {
        "id": "e0ea7b54",
        "outputId": "67a77be5-0b8e-42bd-fbc1-4b20d80bfa6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Bun rieu', 'Banh mi', 'Banh xeo', 'Chao long', 'Pho', 'Banh khot', 'Bun bo Hue', 'Banh cuon', 'Com tam', 'Bun dau mam tom']\n",
            "28/32\n",
            "29/32\n",
            "27/32\n",
            "30/32\n",
            "31/32\n",
            "25/32\n",
            "29/32\n",
            "27/32\n",
            "32/32\n",
            "27/32\n"
          ]
        }
      ],
      "source": [
        "# 모델 테스트 코드\n",
        "\n",
        "test_ds = load_data(data_path=test_path)\n",
        "\n",
        "for step_train, (x_batch_train, y_batch_train) in enumerate(test_ds.take(10)):\n",
        "    prediction = model(x_batch_train)\n",
        "    print(\"{}/{}\".format(np.array(tf.equal(tf.argmax(y_batch_train, axis=1), tf.argmax(prediction, axis=1))).sum(), tf.argmax(y_batch_train, axis=1).shape[0]))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}