{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CAVASOL/aiffel_quest/blob/main/Reference/30vnfoods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f3eafd9",
      "metadata": {
        "id": "4f3eafd9"
      },
      "source": [
        "## 3-1. 프로젝트: 베트남 음식 분류하기\n",
        "\n",
        "**Index**\n",
        "\n",
        "Set up  \n",
        "Remove broken files  \n",
        "Check data for training  \n",
        "Dataloader  \n",
        "Create a model  \n",
        "Custom Trainer  \n",
        "Training  \n",
        "Test model  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84a71e7c",
      "metadata": {
        "id": "84a71e7c"
      },
      "source": [
        "### Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d2907bf",
      "metadata": {
        "id": "6d2907bf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d15a1d0",
      "metadata": {
        "id": "9d15a1d0"
      },
      "source": [
        "### Remove broken files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f098b47",
      "metadata": {
        "id": "3f098b47"
      },
      "outputs": [],
      "source": [
        "# training set과 test set의 모든 이미지 파일에 대해서,\n",
        "# jpg image header가 포함되지 않은 (jpg의 파일 구조에 어긋나는) 파일들을 삭제해줍니다.\n",
        "\n",
        "data_path = '/aiffel/aiffel/model-fit/data/30vnfoods/'\n",
        "train_path = data_path + 'Train/'\n",
        "test_path = data_path + 'Test/'\n",
        "\n",
        "for path in [train_path, test_path]:\n",
        "    classes = os.listdir(path)\n",
        "\n",
        "    for food in classes:\n",
        "        food_path = os.path.join(path, food)\n",
        "        images = os.listdir(food_path)\n",
        "\n",
        "        for image in images:\n",
        "            with open(os.path.join(food_path, image), 'rb') as f:\n",
        "                bytes = f.read()\n",
        "            if bytes[:3] != b'\\xff\\xd8\\xff':\n",
        "                print(os.path.join(food_path, image))\n",
        "                os.remove(os.path.join(food_path, image))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "783bee33",
      "metadata": {
        "id": "783bee33"
      },
      "source": [
        "### Check data for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49b517cc",
      "metadata": {
        "id": "49b517cc",
        "outputId": "06398e79-5b41-4237-e77e-54fc6bcf2163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training data의 개수: 9775\n"
          ]
        }
      ],
      "source": [
        "classes = os.listdir(train_path)\n",
        "train_length = 0\n",
        "\n",
        "for food in classes:\n",
        "    food_path = os.path.join(train_path, food)\n",
        "    images = os.listdir(food_path)\n",
        "\n",
        "    train_length += len(images)\n",
        "\n",
        "print('training data의 개수: '+str(train_length))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b1876f7",
      "metadata": {
        "id": "0b1876f7"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fef12564",
      "metadata": {
        "id": "fef12564"
      },
      "outputs": [],
      "source": [
        "# 문제 1: dataloader 구현하기\n",
        "\n",
        "def process_path(file_path, class_names, img_shape=(224, 224)):\n",
        "    '''\n",
        "    file_path로 부터 class label을 만들고, 이미지를 읽는 함수\n",
        "    이미지 크기를 (224, 224)로 맞춰주세요.\n",
        "    '''\n",
        "    label = tf.strings.split(file_path, os.path.sep)\n",
        "    label = label[-2] == class_names\n",
        "\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, img_shape)\n",
        "\n",
        "    return img, label\n",
        "\n",
        "def prepare_for_training(ds, batch_size=32, cache=True, shuffle_buffer_size=1000):\n",
        "    '''\n",
        "    TensorFlow Data API를 이용해 data batch를 만드는 함수\n",
        "    '''\n",
        "    if cache:\n",
        "        if isinstance(cache, str):\n",
        "            ds = ds.cache(cache)\n",
        "        else:\n",
        "            ds = ds.cache()\n",
        "\n",
        "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "    ds = ds.repeat()\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return ds\n",
        "\n",
        "def load_data(data_path, batch_size=32):\n",
        "    '''\n",
        "    데이터를 만들기 위해 필요한 함수들을 호출하고 데이터를 리턴해주는 함수\n",
        "    TensorFlow Dataset 객체를 생성하고 process_path 함수로 이미지와 라벨을 묶은 다음,\n",
        "    prepare_for_training 함수로 batch가 적용된 Dataset 객체를 만들어주세요.\n",
        "    '''\n",
        "    class_names = [cls for cls in os.listdir(data_path) if cls != '.DS_Store']\n",
        "    print(class_names)\n",
        "    data_path = pathlib.Path(data_path)\n",
        "\n",
        "    list_ds = tf.data.Dataset.list_files(str(data_path/'*/*'))\n",
        "    labeled_ds = list_ds.map(lambda x: process_path(x, class_names, img_shape=(224, 224)))\n",
        "    ds = prepare_for_training(labeled_ds, batch_size=batch_size)\n",
        "\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "704bf675",
      "metadata": {
        "id": "704bf675"
      },
      "source": [
        "### Create a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a086679f",
      "metadata": {
        "id": "a086679f",
        "outputId": "4de9b8cf-7dbd-4ba4-9be3-44bb3480094e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "efficientnetb0 (Functional)  (None, None, None, 1280)  4049571   \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 1280)              5120      \n",
            "_________________________________________________________________\n",
            "pred (Dense)                 multiple                  6405      \n",
            "=================================================================\n",
            "Total params: 4,061,096\n",
            "Trainable params: 8,965\n",
            "Non-trainable params: 4,052,131\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# 문제 2: 모델 구현하기\n",
        "\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "class Model(tf.keras.Model):\n",
        "    '''\n",
        "    EfficientNetB0을 백본으로 사용하는 모델을 구성합니다.\n",
        "    Classification 문제로 접근할 것이기 때문에 맨 마지막 Dense 레이어에\n",
        "    우리가 원하는 클래스 개수만큼을 지정해주어야 합니다.\n",
        "    '''\n",
        "    def __init__(self, num_classes=10, freeze=False):\n",
        "        super(Model, self).__init__()\n",
        "        self.base_model = EfficientNetB0(include_top=False, weights='imagenet')\n",
        "        if freeze:\n",
        "            self.base_model.trainable = False\n",
        "        self.top = tf.keras.Sequential([tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\"),\n",
        "                                       tf.keras.layers.BatchNormalization(),\n",
        "                                       tf.keras.layers.Dropout(0.5, name=\"top_dropout\")])\n",
        "        self.classifier = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")\n",
        "    def call(self, inputs, training=True):\n",
        "        x = self.base_model(inputs)\n",
        "        x = self.top(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = Model(num_classes=5, freeze=True)\n",
        "    model.build(input_shape=(None, 224, 224, 3))\n",
        "    print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e6d9559",
      "metadata": {
        "id": "8e6d9559"
      },
      "source": [
        "### Custom Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e07e0a3",
      "metadata": {
        "id": "2e07e0a3"
      },
      "outputs": [],
      "source": [
        "# 문제 3: custom trainer 구현하기\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, epochs, batch, ds_length, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.epochs = epochs\n",
        "        self.batch = batch\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "    def train(self, train_dataset, train_metric):\n",
        "        for epoch in range(self.epochs):\n",
        "            print(\"\\nStart of epoch %d\" % (epoch+1,))\n",
        "            for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "                with tf.GradientTape() as tape:\n",
        "                    logits = model(x_batch_train, training=True)\n",
        "                    loss_value = self.loss_fn(y_batch_train, logits)\n",
        "                grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "                self.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "                # train metric 업데이트\n",
        "                train_metric.update_state(y_batch_train, logits)\n",
        "                # 5 배치마다 로깅\n",
        "                if step % 5 == 0:\n",
        "                    print(\n",
        "                        \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                        % (step, float(loss_value))\n",
        "                    )\n",
        "                    print(\"Seen so far: %d samples\" % ((step + 1) * self.batch))\n",
        "                    print(train_metric.result().numpy())\n",
        "            # 마지막 epoch 학습이 끝나면 train 결과를 보여줌\n",
        "            train_acc = train_acc_metric.result()\n",
        "            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caed4915",
      "metadata": {
        "id": "caed4915"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29aa8f2b",
      "metadata": {
        "id": "29aa8f2b",
        "outputId": "167b769a-1ffb-4171-9f6d-8df883a3aa24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Bun rieu', 'Banh mi', 'Banh xeo', 'Chao long', 'Pho', 'Banh khot', 'Bun bo Hue', 'Banh cuon', 'Com tam', 'Bun dau mam tom']\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 3.5719\n",
            "Seen so far: 32 samples\n",
            "0.125\n",
            "Training loss (for one batch) at step 5: 2.8947\n",
            "Seen so far: 192 samples\n",
            "0.17708333\n",
            "Training loss (for one batch) at step 10: 2.6582\n",
            "Seen so far: 352 samples\n",
            "0.21306819\n",
            "Training loss (for one batch) at step 15: 2.4352\n",
            "Seen so far: 512 samples\n",
            "0.26171875\n",
            "Training loss (for one batch) at step 20: 1.0362\n",
            "Seen so far: 672 samples\n",
            "0.32291666\n",
            "Training loss (for one batch) at step 25: 1.2399\n",
            "Seen so far: 832 samples\n",
            "0.36177886\n",
            "Training loss (for one batch) at step 30: 1.1131\n",
            "Seen so far: 992 samples\n",
            "0.40221775\n",
            "Training loss (for one batch) at step 35: 1.4706\n",
            "Seen so far: 1152 samples\n",
            "0.43489584\n",
            "Training loss (for one batch) at step 40: 1.0896\n",
            "Seen so far: 1312 samples\n",
            "0.46417683\n",
            "Training loss (for one batch) at step 45: 1.0042\n",
            "Seen so far: 1472 samples\n",
            "0.4816576\n",
            "Training loss (for one batch) at step 50: 0.5993\n",
            "Seen so far: 1632 samples\n",
            "0.5055147\n",
            "Training loss (for one batch) at step 55: 1.0799\n",
            "Seen so far: 1792 samples\n",
            "0.52008927\n",
            "Training loss (for one batch) at step 60: 0.7649\n",
            "Seen so far: 1952 samples\n",
            "0.5302254\n",
            "Training loss (for one batch) at step 65: 0.8443\n",
            "Seen so far: 2112 samples\n",
            "0.5378788\n",
            "Training loss (for one batch) at step 70: 0.9617\n",
            "Seen so far: 2272 samples\n",
            "0.5497359\n",
            "Training loss (for one batch) at step 75: 0.7210\n",
            "Seen so far: 2432 samples\n",
            "0.5587993\n",
            "Training loss (for one batch) at step 80: 0.8736\n",
            "Seen so far: 2592 samples\n",
            "0.568287\n",
            "Training loss (for one batch) at step 85: 0.8292\n",
            "Seen so far: 2752 samples\n",
            "0.5755814\n",
            "Training loss (for one batch) at step 90: 1.5194\n",
            "Seen so far: 2912 samples\n",
            "0.5831044\n",
            "Training loss (for one batch) at step 95: 0.7178\n",
            "Seen so far: 3072 samples\n",
            "0.5914714\n",
            "Training loss (for one batch) at step 100: 0.6604\n",
            "Seen so far: 3232 samples\n",
            "0.6011757\n",
            "Training loss (for one batch) at step 105: 0.8702\n",
            "Seen so far: 3392 samples\n",
            "0.6049528\n",
            "Training loss (for one batch) at step 110: 0.8617\n",
            "Seen so far: 3552 samples\n",
            "0.6120495\n",
            "Training loss (for one batch) at step 115: 0.3769\n",
            "Seen so far: 3712 samples\n",
            "0.61772627\n",
            "Training loss (for one batch) at step 120: 0.8095\n",
            "Seen so far: 3872 samples\n",
            "0.62396693\n",
            "Training loss (for one batch) at step 125: 0.6584\n",
            "Seen so far: 4032 samples\n",
            "0.6314484\n",
            "Training loss (for one batch) at step 130: 0.4525\n",
            "Seen so far: 4192 samples\n",
            "0.6378817\n",
            "Training loss (for one batch) at step 135: 0.3516\n",
            "Seen so far: 4352 samples\n",
            "0.6424632\n",
            "Training loss (for one batch) at step 140: 0.8186\n",
            "Seen so far: 4512 samples\n",
            "0.64937943\n",
            "Training loss (for one batch) at step 145: 1.2627\n",
            "Seen so far: 4672 samples\n",
            "0.65282536\n",
            "Training loss (for one batch) at step 150: 0.7176\n",
            "Seen so far: 4832 samples\n",
            "0.6589404\n",
            "Training loss (for one batch) at step 155: 0.8093\n",
            "Seen so far: 4992 samples\n",
            "0.6620593\n",
            "Training loss (for one batch) at step 160: 0.9994\n",
            "Seen so far: 5152 samples\n",
            "0.66595495\n",
            "Training loss (for one batch) at step 165: 0.5890\n",
            "Seen so far: 5312 samples\n",
            "0.66773343\n",
            "Training loss (for one batch) at step 170: 1.0612\n",
            "Seen so far: 5472 samples\n",
            "0.67032164\n",
            "Training loss (for one batch) at step 175: 1.0757\n",
            "Seen so far: 5632 samples\n",
            "0.6713423\n",
            "Training loss (for one batch) at step 180: 0.5655\n",
            "Seen so far: 5792 samples\n",
            "0.6748964\n",
            "Training loss (for one batch) at step 185: 0.5286\n",
            "Seen so far: 5952 samples\n",
            "0.67876345\n",
            "Training loss (for one batch) at step 190: 0.4886\n",
            "Seen so far: 6112 samples\n",
            "0.68177354\n",
            "Training loss (for one batch) at step 195: 0.5040\n",
            "Seen so far: 6272 samples\n",
            "0.68478954\n",
            "Training loss (for one batch) at step 200: 0.5558\n",
            "Seen so far: 6432 samples\n",
            "0.6881219\n",
            "Training loss (for one batch) at step 205: 0.4198\n",
            "Seen so far: 6592 samples\n",
            "0.6906857\n",
            "Training loss (for one batch) at step 210: 0.3753\n",
            "Seen so far: 6752 samples\n",
            "0.6941647\n",
            "Training loss (for one batch) at step 215: 0.7805\n",
            "Seen so far: 6912 samples\n",
            "0.6958912\n",
            "Training loss (for one batch) at step 220: 0.5015\n",
            "Seen so far: 7072 samples\n",
            "0.6985294\n",
            "Training loss (for one batch) at step 225: 0.7625\n",
            "Seen so far: 7232 samples\n",
            "0.69966817\n",
            "Training loss (for one batch) at step 230: 0.5472\n",
            "Seen so far: 7392 samples\n",
            "0.70170456\n",
            "Training loss (for one batch) at step 235: 0.3423\n",
            "Seen so far: 7552 samples\n",
            "0.7039195\n",
            "Training loss (for one batch) at step 240: 0.6868\n",
            "Seen so far: 7712 samples\n",
            "0.7057832\n",
            "Training loss (for one batch) at step 245: 0.6216\n",
            "Seen so far: 7872 samples\n",
            "0.7084604\n",
            "Training loss (for one batch) at step 250: 0.5242\n",
            "Seen so far: 8032 samples\n",
            "0.7104084\n",
            "Training loss (for one batch) at step 255: 0.6022\n",
            "Seen so far: 8192 samples\n",
            "0.7114258\n",
            "Training loss (for one batch) at step 260: 0.6279\n",
            "Seen so far: 8352 samples\n",
            "0.71324235\n",
            "Training loss (for one batch) at step 265: 0.5859\n",
            "Seen so far: 8512 samples\n",
            "0.7152256\n",
            "Training loss (for one batch) at step 270: 0.6197\n",
            "Seen so far: 8672 samples\n",
            "0.7173662\n",
            "Training loss (for one batch) at step 275: 0.3756\n",
            "Seen so far: 8832 samples\n",
            "0.71886325\n",
            "Training loss (for one batch) at step 280: 0.4515\n",
            "Seen so far: 8992 samples\n",
            "0.7213078\n",
            "Training loss (for one batch) at step 285: 0.4420\n",
            "Seen so far: 9152 samples\n",
            "0.72344846\n",
            "Training loss (for one batch) at step 290: 0.5658\n",
            "Seen so far: 9312 samples\n",
            "0.7251933\n",
            "Training loss (for one batch) at step 295: 0.3848\n",
            "Seen so far: 9472 samples\n",
            "0.7274071\n",
            "Training loss (for one batch) at step 300: 0.5273\n",
            "Seen so far: 9632 samples\n",
            "0.72944355\n",
            "Training loss (for one batch) at step 305: 0.5674\n",
            "Seen so far: 9792 samples\n",
            "0.7317198\n",
            "Training loss (for one batch) at step 310: 0.4029\n",
            "Seen so far: 9952 samples\n",
            "0.73372185\n",
            "Training loss (for one batch) at step 315: 0.4900\n",
            "Seen so far: 10112 samples\n",
            "0.73506725\n",
            "Training loss (for one batch) at step 320: 0.4504\n",
            "Seen so far: 10272 samples\n",
            "0.7369548\n",
            "Training loss (for one batch) at step 325: 0.8008\n",
            "Seen so far: 10432 samples\n",
            "0.7383052\n",
            "Training loss (for one batch) at step 330: 0.2469\n",
            "Seen so far: 10592 samples\n",
            "0.74008685\n",
            "Training loss (for one batch) at step 335: 0.0990\n",
            "Seen so far: 10752 samples\n",
            "0.7430245\n",
            "Training loss (for one batch) at step 340: 0.3356\n",
            "Seen so far: 10912 samples\n",
            "0.7450513\n",
            "Training loss (for one batch) at step 345: 0.6600\n",
            "Seen so far: 11072 samples\n",
            "0.74665827\n",
            "Training loss (for one batch) at step 350: 0.6096\n",
            "Seen so far: 11232 samples\n",
            "0.7475071\n",
            "Training loss (for one batch) at step 355: 0.7935\n",
            "Seen so far: 11392 samples\n",
            "0.7489466\n",
            "Training loss (for one batch) at step 360: 0.6948\n",
            "Seen so far: 11552 samples\n",
            "0.7505194\n",
            "Training loss (for one batch) at step 365: 0.4558\n",
            "Seen so far: 11712 samples\n",
            "0.7520492\n",
            "Training loss (for one batch) at step 370: 0.6522\n",
            "Seen so far: 11872 samples\n",
            "0.75269544\n",
            "Training loss (for one batch) at step 375: 0.3014\n",
            "Seen so far: 12032 samples\n",
            "0.7542387\n",
            "Training loss (for one batch) at step 380: 1.1432\n",
            "Seen so far: 12192 samples\n",
            "0.75533134\n",
            "Training loss (for one batch) at step 385: 0.1470\n",
            "Seen so far: 12352 samples\n",
            "0.7570434\n",
            "Training loss (for one batch) at step 390: 0.6870\n",
            "Seen so far: 12512 samples\n",
            "0.7586317\n",
            "Training loss (for one batch) at step 395: 0.4604\n",
            "Seen so far: 12672 samples\n",
            "0.75970644\n",
            "Training loss (for one batch) at step 400: 0.3785\n",
            "Seen so far: 12832 samples\n",
            "0.7615337\n",
            "Training loss (for one batch) at step 405: 0.4317\n",
            "Seen so far: 12992 samples\n",
            "0.7625462\n",
            "Training loss (for one batch) at step 410: 0.2279\n",
            "Seen so far: 13152 samples\n",
            "0.763382\n",
            "Training loss (for one batch) at step 415: 0.1444\n",
            "Seen so far: 13312 samples\n",
            "0.7648738\n",
            "Training loss (for one batch) at step 420: 0.2040\n",
            "Seen so far: 13472 samples\n",
            "0.7664044\n",
            "Training loss (for one batch) at step 425: 0.5040\n",
            "Seen so far: 13632 samples\n",
            "0.7680458\n",
            "Training loss (for one batch) at step 430: 0.3555\n",
            "Seen so far: 13792 samples\n",
            "0.76957655\n",
            "Training loss (for one batch) at step 435: 0.4409\n",
            "Seen so far: 13952 samples\n",
            "0.77078557\n",
            "Training loss (for one batch) at step 440: 0.1594\n",
            "Seen so far: 14112 samples\n",
            "0.7723214\n",
            "Training loss (for one batch) at step 445: 0.4929\n",
            "Seen so far: 14272 samples\n",
            "0.7731923\n",
            "Training loss (for one batch) at step 450: 0.3829\n",
            "Seen so far: 14432 samples\n",
            "0.7739745\n",
            "Training loss (for one batch) at step 455: 0.7134\n",
            "Seen so far: 14592 samples\n",
            "0.77508223\n",
            "Training loss (for one batch) at step 460: 0.4198\n",
            "Seen so far: 14752 samples\n",
            "0.77609813\n",
            "Training loss (for one batch) at step 465: 0.3612\n",
            "Seen so far: 14912 samples\n",
            "0.7770923\n",
            "Training loss (for one batch) at step 470: 0.2971\n",
            "Seen so far: 15072 samples\n",
            "0.778198\n",
            "Training loss (for one batch) at step 475: 0.4072\n",
            "Seen so far: 15232 samples\n",
            "0.77901787\n",
            "Training loss (for one batch) at step 480: 0.1479\n",
            "Seen so far: 15392 samples\n",
            "0.7801455\n",
            "Training loss (for one batch) at step 485: 0.1387\n",
            "Seen so far: 15552 samples\n",
            "0.78125\n",
            "Training loss (for one batch) at step 490: 0.2366\n",
            "Seen so far: 15712 samples\n",
            "0.7823956\n",
            "Training loss (for one batch) at step 495: 0.1904\n",
            "Seen so far: 15872 samples\n",
            "0.7832661\n",
            "Training loss (for one batch) at step 500: 0.1949\n",
            "Seen so far: 16032 samples\n",
            "0.78443116\n",
            "Training loss (for one batch) at step 505: 0.3295\n",
            "Seen so far: 16192 samples\n",
            "0.7853879\n",
            "Training loss (for one batch) at step 510: 0.5060\n",
            "Seen so far: 16352 samples\n",
            "0.7855308\n",
            "Training loss (for one batch) at step 515: 0.1351\n",
            "Seen so far: 16512 samples\n",
            "0.7867006\n",
            "Training loss (for one batch) at step 520: 1.0224\n",
            "Seen so far: 16672 samples\n",
            "0.78760797\n",
            "Training loss (for one batch) at step 525: 0.6750\n",
            "Seen so far: 16832 samples\n",
            "0.7883199\n",
            "Training loss (for one batch) at step 530: 0.1445\n",
            "Seen so far: 16992 samples\n",
            "0.7888418\n",
            "Training loss (for one batch) at step 535: 0.2697\n",
            "Seen so far: 17152 samples\n",
            "0.7898787\n",
            "Training loss (for one batch) at step 540: 0.2668\n",
            "Seen so far: 17312 samples\n",
            "0.7902611\n",
            "Training loss (for one batch) at step 545: 0.2443\n",
            "Seen so far: 17472 samples\n",
            "0.7905792\n",
            "Training loss (for one batch) at step 550: 0.2313\n",
            "Seen so far: 17632 samples\n",
            "0.791402\n",
            "Training loss (for one batch) at step 555: 0.2942\n",
            "Seen so far: 17792 samples\n",
            "0.7923786\n",
            "Training loss (for one batch) at step 560: 0.2579\n",
            "Seen so far: 17952 samples\n",
            "0.7930593\n",
            "Training loss (for one batch) at step 565: 0.3048\n",
            "Seen so far: 18112 samples\n",
            "0.7940592\n",
            "Training loss (for one batch) at step 570: 0.5727\n",
            "Seen so far: 18272 samples\n",
            "0.7948774\n",
            "Training loss (for one batch) at step 575: 0.0436\n",
            "Seen so far: 18432 samples\n",
            "0.7960069\n",
            "Training loss (for one batch) at step 580: 0.2199\n",
            "Seen so far: 18592 samples\n",
            "0.79700947\n",
            "Training loss (for one batch) at step 585: 0.2909\n",
            "Seen so far: 18752 samples\n",
            "0.7978349\n",
            "Training loss (for one batch) at step 590: 0.1389\n",
            "Seen so far: 18912 samples\n",
            "0.79885787\n",
            "Training loss (for one batch) at step 595: 0.0710\n",
            "Seen so far: 19072 samples\n",
            "0.7998637\n",
            "Training loss (for one batch) at step 600: 0.9421\n",
            "Seen so far: 19232 samples\n",
            "0.80064476\n",
            "Training loss (for one batch) at step 605: 0.2234\n",
            "Seen so far: 19392 samples\n",
            "0.80125827\n",
            "Training loss (for one batch) at step 610: 0.6250\n",
            "Seen so far: 19552 samples\n",
            "0.801964\n",
            "Training loss (for one batch) at step 615: 0.5368\n",
            "Seen so far: 19712 samples\n",
            "0.8025568\n",
            "Training loss (for one batch) at step 620: 0.6912\n",
            "Seen so far: 19872 samples\n",
            "0.80303943\n",
            "Training loss (for one batch) at step 625: 0.2016\n",
            "Seen so far: 20032 samples\n",
            "0.80396366\n",
            "Training loss (for one batch) at step 630: 0.7548\n",
            "Seen so far: 20192 samples\n",
            "0.8042789\n",
            "Training loss (for one batch) at step 635: 0.2023\n",
            "Seen so far: 20352 samples\n",
            "0.8048349\n",
            "Training loss (for one batch) at step 640: 0.2195\n",
            "Seen so far: 20512 samples\n",
            "0.80567473\n",
            "Training loss (for one batch) at step 645: 0.6076\n",
            "Seen so far: 20672 samples\n",
            "0.80645317\n",
            "Training loss (for one batch) at step 650: 0.3977\n",
            "Seen so far: 20832 samples\n",
            "0.8072197\n",
            "Training loss (for one batch) at step 655: 0.1912\n",
            "Seen so far: 20992 samples\n",
            "0.80826026\n",
            "Training loss (for one batch) at step 660: 0.4528\n",
            "Seen so far: 21152 samples\n",
            "0.8088124\n",
            "Training loss (for one batch) at step 665: 0.2188\n",
            "Seen so far: 21312 samples\n",
            "0.8093562\n",
            "Training loss (for one batch) at step 670: 0.2353\n",
            "Seen so far: 21472 samples\n",
            "0.8099851\n",
            "Training loss (for one batch) at step 675: 0.3111\n",
            "Seen so far: 21632 samples\n",
            "0.810466\n",
            "Training loss (for one batch) at step 680: 0.2748\n",
            "Seen so far: 21792 samples\n",
            "0.8110316\n",
            "Training loss (for one batch) at step 685: 0.2720\n",
            "Seen so far: 21952 samples\n",
            "0.81172556\n",
            "Training loss (for one batch) at step 690: 0.1383\n",
            "Seen so far: 22112 samples\n",
            "0.81254524\n",
            "Training loss (for one batch) at step 695: 0.1533\n",
            "Seen so far: 22272 samples\n",
            "0.8131735\n",
            "Training loss (for one batch) at step 700: 0.3960\n",
            "Seen so far: 22432 samples\n",
            "0.8137928\n",
            "Training loss (for one batch) at step 705: 0.1494\n",
            "Seen so far: 22592 samples\n",
            "0.8146689\n",
            "Training loss (for one batch) at step 710: 0.4103\n",
            "Seen so far: 22752 samples\n",
            "0.8153569\n",
            "Training loss (for one batch) at step 715: 0.1080\n",
            "Seen so far: 22912 samples\n",
            "0.81594795\n",
            "Training loss (for one batch) at step 720: 0.1995\n",
            "Seen so far: 23072 samples\n",
            "0.8165742\n",
            "Training loss (for one batch) at step 725: 0.4530\n",
            "Seen so far: 23232 samples\n",
            "0.8169335\n",
            "Training loss (for one batch) at step 730: 0.1941\n",
            "Seen so far: 23392 samples\n",
            "0.81762993\n",
            "Training loss (for one batch) at step 735: 0.1574\n",
            "Seen so far: 23552 samples\n",
            "0.81827444\n",
            "Training loss (for one batch) at step 740: 0.2993\n",
            "Seen so far: 23712 samples\n",
            "0.8186572\n",
            "Training loss (for one batch) at step 745: 0.4166\n",
            "Seen so far: 23872 samples\n",
            "0.8191186\n",
            "Training loss (for one batch) at step 750: 0.1465\n",
            "Seen so far: 24032 samples\n",
            "0.81974036\n",
            "Training loss (for one batch) at step 755: 0.1303\n",
            "Seen so far: 24192 samples\n",
            "0.82047784\n",
            "Training loss (for one batch) at step 760: 0.3449\n",
            "Seen so far: 24352 samples\n",
            "0.8211646\n",
            "Training loss (for one batch) at step 765: 0.1405\n",
            "Seen so far: 24512 samples\n",
            "0.82180154\n",
            "Training loss (for one batch) at step 770: 0.3598\n",
            "Seen so far: 24672 samples\n",
            "0.82234925\n",
            "Training loss (for one batch) at step 775: 0.3140\n",
            "Seen so far: 24832 samples\n",
            "0.82268846\n",
            "Training loss (for one batch) at step 780: 0.4504\n",
            "Seen so far: 24992 samples\n",
            "0.8233835\n",
            "Training loss (for one batch) at step 785: 0.1943\n",
            "Seen so far: 25152 samples\n",
            "0.82410944\n",
            "Training loss (for one batch) at step 790: 0.3447\n",
            "Seen so far: 25312 samples\n",
            "0.8245101\n",
            "Training loss (for one batch) at step 795: 0.2338\n",
            "Seen so far: 25472 samples\n",
            "0.8251806\n",
            "Training loss (for one batch) at step 800: 0.1818\n",
            "Seen so far: 25632 samples\n",
            "0.82595974\n",
            "Training loss (for one batch) at step 805: 0.1284\n",
            "Seen so far: 25792 samples\n",
            "0.82657415\n",
            "Training loss (for one batch) at step 810: 0.1405\n",
            "Seen so far: 25952 samples\n",
            "0.82729656\n",
            "Training loss (for one batch) at step 815: 0.4707\n",
            "Seen so far: 26112 samples\n",
            "0.8277803\n",
            "Training loss (for one batch) at step 820: 0.1379\n",
            "Seen so far: 26272 samples\n",
            "0.8284866\n",
            "Training loss (for one batch) at step 825: 0.5230\n",
            "Seen so far: 26432 samples\n",
            "0.8289573\n",
            "Training loss (for one batch) at step 830: 0.2120\n",
            "Seen so far: 26592 samples\n",
            "0.82942235\n",
            "Training loss (for one batch) at step 835: 0.6681\n",
            "Seen so far: 26752 samples\n",
            "0.82995665\n",
            "Training loss (for one batch) at step 840: 0.1851\n",
            "Seen so far: 26912 samples\n",
            "0.830596\n",
            "Training loss (for one batch) at step 845: 0.1968\n",
            "Seen so far: 27072 samples\n",
            "0.8310801\n",
            "Training loss (for one batch) at step 850: 0.1417\n",
            "Seen so far: 27232 samples\n",
            "0.8313748\n",
            "Training loss (for one batch) at step 855: 0.6557\n",
            "Seen so far: 27392 samples\n",
            "0.8317392\n",
            "Training loss (for one batch) at step 860: 0.2173\n",
            "Seen so far: 27552 samples\n",
            "0.8322082\n",
            "Training loss (for one batch) at step 865: 0.0936\n",
            "Seen so far: 27712 samples\n",
            "0.83249134\n",
            "Training loss (for one batch) at step 870: 0.1046\n",
            "Seen so far: 27872 samples\n",
            "0.83313\n",
            "Training loss (for one batch) at step 875: 0.4685\n",
            "Seen so far: 28032 samples\n",
            "0.83358306\n",
            "Training loss (for one batch) at step 880: 0.2672\n",
            "Seen so far: 28192 samples\n",
            "0.83388907\n",
            "Training loss (for one batch) at step 885: 0.4563\n",
            "Seen so far: 28352 samples\n",
            "0.83426213\n",
            "Training loss (for one batch) at step 890: 0.2313\n",
            "Seen so far: 28512 samples\n",
            "0.8347012\n",
            "Training loss (for one batch) at step 895: 0.2782\n",
            "Seen so far: 28672 samples\n",
            "0.8351005\n",
            "Training loss (for one batch) at step 900: 0.3081\n",
            "Seen so far: 28832 samples\n",
            "0.8355647\n",
            "Training loss (for one batch) at step 905: 0.3530\n",
            "Seen so far: 28992 samples\n",
            "0.83598924\n",
            "Training loss (for one batch) at step 910: 0.2052\n",
            "Seen so far: 29152 samples\n",
            "0.83640915\n",
            "Training loss (for one batch) at step 915: 0.3746\n",
            "Seen so far: 29312 samples\n",
            "0.83685863\n",
            "Training loss (for one batch) at step 920: 0.1311\n",
            "Seen so far: 29472 samples\n",
            "0.83733714\n",
            "Training loss (for one batch) at step 925: 0.2075\n",
            "Seen so far: 29632 samples\n",
            "0.83781046\n",
            "Training loss (for one batch) at step 930: 0.2634\n",
            "Seen so far: 29792 samples\n",
            "0.8382787\n",
            "Training loss (for one batch) at step 935: 0.1337\n",
            "Seen so far: 29952 samples\n",
            "0.8386752\n",
            "Training loss (for one batch) at step 940: 0.5394\n",
            "Seen so far: 30112 samples\n",
            "0.8388682\n",
            "Training loss (for one batch) at step 945: 0.2432\n",
            "Seen so far: 30272 samples\n",
            "0.83929044\n",
            "Training loss (for one batch) at step 950: 0.0649\n",
            "Seen so far: 30432 samples\n",
            "0.8397739\n",
            "Training loss (for one batch) at step 955: 0.6022\n",
            "Seen so far: 30592 samples\n",
            "0.84005624\n",
            "Training loss (for one batch) at step 960: 0.1349\n",
            "Seen so far: 30752 samples\n",
            "0.84046566\n",
            "Training loss (for one batch) at step 965: 0.3624\n",
            "Seen so far: 30912 samples\n",
            "0.8407738\n",
            "Training loss (for one batch) at step 970: 0.0361\n",
            "Seen so far: 31072 samples\n",
            "0.8412397\n",
            "Training loss (for one batch) at step 975: 0.1131\n",
            "Seen so far: 31232 samples\n",
            "0.8416688\n",
            "Training loss (for one batch) at step 980: 0.0998\n",
            "Seen so far: 31392 samples\n",
            "0.84215724\n",
            "Training loss (for one batch) at step 985: 0.2148\n",
            "Seen so far: 31552 samples\n",
            "0.8423238\n",
            "Training loss (for one batch) at step 990: 0.2200\n",
            "Seen so far: 31712 samples\n",
            "0.84270936\n",
            "Training loss (for one batch) at step 995: 0.4962\n",
            "Seen so far: 31872 samples\n",
            "0.8431539\n",
            "Training loss (for one batch) at step 1000: 0.1110\n",
            "Seen so far: 32032 samples\n",
            "0.8435939\n",
            "Training loss (for one batch) at step 1005: 0.3063\n",
            "Seen so far: 32192 samples\n",
            "0.8438121\n",
            "Training loss (for one batch) at step 1010: 0.3380\n",
            "Seen so far: 32352 samples\n",
            "0.84421366\n",
            "Training loss (for one batch) at step 1015: 0.1292\n",
            "Seen so far: 32512 samples\n",
            "0.84467274\n",
            "Training loss (for one batch) at step 1020: 0.5733\n",
            "Seen so far: 32672 samples\n",
            "0.84512734\n",
            "Training loss (for one batch) at step 1025: 0.1396\n",
            "Seen so far: 32832 samples\n",
            "0.8453338\n",
            "Training loss (for one batch) at step 1030: 0.2154\n",
            "Seen so far: 32992 samples\n",
            "0.845902\n",
            "Training loss (for one batch) at step 1035: 0.2674\n",
            "Seen so far: 33152 samples\n",
            "0.8463441\n",
            "Training loss (for one batch) at step 1040: 0.1129\n",
            "Seen so far: 33312 samples\n",
            "0.84678197\n",
            "Training loss (for one batch) at step 1045: 0.3313\n",
            "Seen so far: 33472 samples\n",
            "0.84691685\n",
            "Training loss (for one batch) at step 1050: 0.0913\n",
            "Seen so far: 33632 samples\n",
            "0.8472883\n",
            "Training loss (for one batch) at step 1055: 1.1484\n",
            "Seen so far: 33792 samples\n",
            "0.84771544\n",
            "Training loss (for one batch) at step 1060: 0.2687\n",
            "Seen so far: 33952 samples\n",
            "0.8481386\n",
            "Training loss (for one batch) at step 1065: 0.3628\n",
            "Seen so far: 34112 samples\n",
            "0.84849906\n",
            "Training loss (for one batch) at step 1070: 0.0996\n",
            "Seen so far: 34272 samples\n",
            "0.84894377\n",
            "Training loss (for one batch) at step 1075: 0.6550\n",
            "Seen so far: 34432 samples\n",
            "0.84926814\n",
            "Training loss (for one batch) at step 1080: 0.1767\n",
            "Seen so far: 34592 samples\n",
            "0.84964734\n",
            "Training loss (for one batch) at step 1085: 0.1509\n",
            "Seen so far: 34752 samples\n",
            "0.84999424\n",
            "Training loss (for one batch) at step 1090: 0.1050\n",
            "Seen so far: 34912 samples\n",
            "0.85036665\n",
            "Training loss (for one batch) at step 1095: 0.3363\n",
            "Seen so far: 35072 samples\n",
            "0.8505931\n",
            "Training loss (for one batch) at step 1100: 0.4089\n",
            "Seen so far: 35232 samples\n",
            "0.85098773\n",
            "Training loss (for one batch) at step 1105: 0.1941\n",
            "Seen so far: 35392 samples\n",
            "0.85120934\n",
            "Training loss (for one batch) at step 1110: 0.0843\n",
            "Seen so far: 35552 samples\n",
            "0.85148513\n",
            "Training loss (for one batch) at step 1115: 0.3743\n",
            "Seen so far: 35712 samples\n",
            "0.8517305\n",
            "Training loss (for one batch) at step 1120: 0.6184\n",
            "Seen so far: 35872 samples\n",
            "0.8518064\n",
            "Training loss (for one batch) at step 1125: 0.1225\n",
            "Seen so far: 36032 samples\n",
            "0.8522147\n",
            "Training loss (for one batch) at step 1130: 0.2334\n",
            "Seen so far: 36192 samples\n",
            "0.8523431\n",
            "Training loss (for one batch) at step 1135: 0.3573\n",
            "Seen so far: 36352 samples\n",
            "0.8525803\n",
            "Training loss (for one batch) at step 1140: 0.3493\n",
            "Seen so far: 36512 samples\n",
            "0.85276073\n",
            "Training loss (for one batch) at step 1145: 0.4494\n",
            "Seen so far: 36672 samples\n",
            "0.85296685\n",
            "Training loss (for one batch) at step 1150: 0.3386\n",
            "Seen so far: 36832 samples\n",
            "0.85317117\n",
            "Training loss (for one batch) at step 1155: 0.3217\n",
            "Seen so far: 36992 samples\n",
            "0.8534007\n",
            "Training loss (for one batch) at step 1160: 0.1586\n",
            "Seen so far: 37152 samples\n",
            "0.8537091\n",
            "Training loss (for one batch) at step 1165: 0.2680\n",
            "Seen so far: 37312 samples\n",
            "0.8539344\n",
            "Training loss (for one batch) at step 1170: 0.2717\n",
            "Seen so far: 37472 samples\n",
            "0.8542645\n",
            "Training loss (for one batch) at step 1175: 0.3154\n",
            "Seen so far: 37632 samples\n",
            "0.8545387\n",
            "Training loss (for one batch) at step 1180: 0.1673\n",
            "Seen so far: 37792 samples\n",
            "0.85486346\n",
            "Training loss (for one batch) at step 1185: 0.3020\n",
            "Seen so far: 37952 samples\n",
            "0.8550274\n",
            "Training loss (for one batch) at step 1190: 0.3887\n",
            "Seen so far: 38112 samples\n",
            "0.85524243\n",
            "Training loss (for one batch) at step 1195: 0.1006\n",
            "Seen so far: 38272 samples\n",
            "0.85558635\n",
            "Training loss (for one batch) at step 1200: 0.0387\n",
            "Seen so far: 38432 samples\n",
            "0.85590136\n",
            "Training loss (for one batch) at step 1205: 0.1791\n",
            "Seen so far: 38592 samples\n",
            "0.85613596\n",
            "Training loss (for one batch) at step 1210: 0.2732\n",
            "Seen so far: 38752 samples\n",
            "0.85644615\n",
            "Training loss (for one batch) at step 1215: 0.0644\n",
            "Seen so far: 38912 samples\n",
            "0.8568308\n",
            "Training loss (for one batch) at step 1220: 0.0362\n",
            "Seen so far: 39072 samples\n",
            "0.85716116\n",
            "Training loss (for one batch) at step 1225: 0.0828\n",
            "Seen so far: 39232 samples\n",
            "0.8573868\n",
            "Training loss (for one batch) at step 1230: 0.5758\n",
            "Seen so far: 39392 samples\n",
            "0.8576107\n",
            "Training loss (for one batch) at step 1235: 0.3011\n",
            "Seen so far: 39552 samples\n",
            "0.8579339\n",
            "Training loss (for one batch) at step 1240: 0.1053\n",
            "Seen so far: 39712 samples\n",
            "0.8582293\n",
            "Training loss (for one batch) at step 1245: 0.1383\n",
            "Seen so far: 39872 samples\n",
            "0.8584972\n",
            "Training loss (for one batch) at step 1250: 0.0792\n",
            "Seen so far: 40032 samples\n",
            "0.85871303\n",
            "Training loss (for one batch) at step 1255: 0.3973\n",
            "Seen so far: 40192 samples\n",
            "0.85892713\n",
            "Training loss (for one batch) at step 1260: 0.0386\n",
            "Seen so far: 40352 samples\n",
            "0.8593378\n",
            "Training loss (for one batch) at step 1265: 0.2461\n",
            "Seen so far: 40512 samples\n",
            "0.85967124\n",
            "Training loss (for one batch) at step 1270: 0.3298\n",
            "Seen so far: 40672 samples\n",
            "0.859879\n",
            "Training loss (for one batch) at step 1275: 0.0095\n",
            "Seen so far: 40832 samples\n",
            "0.86030567\n",
            "Training loss (for one batch) at step 1280: 0.1954\n",
            "Seen so far: 40992 samples\n",
            "0.86055815\n",
            "Training loss (for one batch) at step 1285: 0.2048\n",
            "Seen so far: 41152 samples\n",
            "0.8609302\n",
            "Training loss (for one batch) at step 1290: 0.1829\n",
            "Seen so far: 41312 samples\n",
            "0.8612752\n",
            "Training loss (for one batch) at step 1295: 0.3706\n",
            "Seen so far: 41472 samples\n",
            "0.8614487\n",
            "Training loss (for one batch) at step 1300: 0.0564\n",
            "Seen so far: 41632 samples\n",
            "0.8619331\n",
            "Training loss (for one batch) at step 1305: 0.0821\n",
            "Seen so far: 41792 samples\n",
            "0.8621267\n",
            "Training loss (for one batch) at step 1310: 0.1652\n",
            "Seen so far: 41952 samples\n",
            "0.8623188\n",
            "Training loss (for one batch) at step 1315: 0.2368\n",
            "Seen so far: 42112 samples\n",
            "0.8625807\n",
            "Training loss (for one batch) at step 1320: 0.1739\n",
            "Seen so far: 42272 samples\n",
            "0.862817\n",
            "Training loss (for one batch) at step 1325: 0.0953\n",
            "Seen so far: 42432 samples\n",
            "0.8630986\n",
            "Training loss (for one batch) at step 1330: 0.1395\n",
            "Seen so far: 42592 samples\n",
            "0.86330765\n",
            "Training loss (for one batch) at step 1335: 0.3376\n",
            "Seen so far: 42752 samples\n",
            "0.8635619\n",
            "Training loss (for one batch) at step 1340: 0.2560\n",
            "Seen so far: 42912 samples\n",
            "0.8638143\n",
            "Training loss (for one batch) at step 1345: 0.0853\n",
            "Seen so far: 43072 samples\n",
            "0.8641577\n",
            "Training loss (for one batch) at step 1350: 0.1179\n",
            "Seen so far: 43232 samples\n",
            "0.86447537\n",
            "Training loss (for one batch) at step 1355: 0.0375\n",
            "Seen so far: 43392 samples\n",
            "0.8648599\n",
            "Training loss (for one batch) at step 1360: 0.0868\n",
            "Seen so far: 43552 samples\n",
            "0.86501193\n",
            "Training loss (for one batch) at step 1365: 0.0707\n",
            "Seen so far: 43712 samples\n",
            "0.8653688\n",
            "Training loss (for one batch) at step 1370: 0.1142\n",
            "Seen so far: 43872 samples\n",
            "0.86565465\n",
            "Training loss (for one batch) at step 1375: 0.3115\n",
            "Seen so far: 44032 samples\n",
            "0.8658703\n",
            "Training loss (for one batch) at step 1380: 0.2019\n",
            "Seen so far: 44192 samples\n",
            "0.86606175\n",
            "Training loss (for one batch) at step 1385: 0.5279\n",
            "Seen so far: 44352 samples\n",
            "0.8662067\n",
            "Training loss (for one batch) at step 1390: 0.0204\n",
            "Seen so far: 44512 samples\n",
            "0.8665528\n",
            "Training loss (for one batch) at step 1395: 0.2679\n",
            "Seen so far: 44672 samples\n",
            "0.8668741\n",
            "Training loss (for one batch) at step 1400: 0.1874\n",
            "Seen so far: 44832 samples\n",
            "0.8669477\n",
            "Training loss (for one batch) at step 1405: 0.0467\n",
            "Seen so far: 44992 samples\n",
            "0.8671986\n",
            "Training loss (for one batch) at step 1410: 0.2860\n",
            "Seen so far: 45152 samples\n",
            "0.8673813\n",
            "Training loss (for one batch) at step 1415: 0.1645\n",
            "Seen so far: 45312 samples\n",
            "0.86767304\n",
            "Training loss (for one batch) at step 1420: 0.1989\n",
            "Seen so far: 45472 samples\n",
            "0.8679187\n",
            "Training loss (for one batch) at step 1425: 0.0823\n",
            "Seen so far: 45632 samples\n",
            "0.8680312\n",
            "Training loss (for one batch) at step 1430: 0.0953\n",
            "Seen so far: 45792 samples\n",
            "0.8682084\n",
            "Training loss (for one batch) at step 1435: 0.1707\n",
            "Seen so far: 45952 samples\n",
            "0.8684062\n",
            "Training loss (for one batch) at step 1440: 0.2111\n",
            "Seen so far: 46112 samples\n",
            "0.8685808\n",
            "Training loss (for one batch) at step 1445: 0.2074\n",
            "Seen so far: 46272 samples\n",
            "0.8686679\n",
            "Training loss (for one batch) at step 1450: 0.0487\n",
            "Seen so far: 46432 samples\n",
            "0.8689266\n",
            "Training loss (for one batch) at step 1455: 0.1066\n",
            "Seen so far: 46592 samples\n",
            "0.8690548\n",
            "Training loss (for one batch) at step 1460: 0.1365\n",
            "Seen so far: 46752 samples\n",
            "0.8693532\n",
            "Training loss (for one batch) at step 1465: 0.2923\n",
            "Seen so far: 46912 samples\n",
            "0.86950034\n",
            "Training loss (for one batch) at step 1470: 0.2564\n",
            "Seen so far: 47072 samples\n",
            "0.869604\n",
            "Training loss (for one batch) at step 1475: 0.1947\n",
            "Seen so far: 47232 samples\n",
            "0.869707\n",
            "Training loss (for one batch) at step 1480: 0.0974\n",
            "Seen so far: 47392 samples\n",
            "0.8699992\n",
            "Training loss (for one batch) at step 1485: 0.0674\n",
            "Seen so far: 47552 samples\n",
            "0.8700791\n",
            "Training loss (for one batch) at step 1490: 0.0592\n",
            "Seen so far: 47712 samples\n",
            "0.8703471\n",
            "Training loss (for one batch) at step 1495: 0.2694\n",
            "Seen so far: 47872 samples\n",
            "0.87057155\n",
            "Training loss (for one batch) at step 1500: 0.2003\n",
            "Seen so far: 48032 samples\n",
            "0.8707737\n",
            "Training loss (for one batch) at step 1505: 0.3769\n",
            "Seen so far: 48192 samples\n",
            "0.8708707\n",
            "Training loss (for one batch) at step 1510: 0.2121\n",
            "Seen so far: 48352 samples\n",
            "0.8710912\n",
            "Training loss (for one batch) at step 1515: 0.0767\n",
            "Seen so far: 48512 samples\n",
            "0.871269\n",
            "Training loss (for one batch) at step 1520: 0.2696\n",
            "Seen so far: 48672 samples\n",
            "0.87134284\n",
            "Training loss (for one batch) at step 1525: 0.0720\n",
            "Seen so far: 48832 samples\n",
            "0.8714982\n",
            "Training loss (for one batch) at step 1530: 0.1946\n",
            "Seen so far: 48992 samples\n",
            "0.87165254\n",
            "Training loss (for one batch) at step 1535: 0.0812\n",
            "Seen so far: 49152 samples\n",
            "0.8719279\n",
            "Training loss (for one batch) at step 1540: 0.3073\n",
            "Seen so far: 49312 samples\n",
            "0.87214065\n",
            "Training loss (for one batch) at step 1545: 0.0911\n",
            "Seen so far: 49472 samples\n",
            "0.8723116\n",
            "Training loss (for one batch) at step 1550: 0.1062\n",
            "Seen so far: 49632 samples\n",
            "0.87252176\n",
            "Training loss (for one batch) at step 1555: 0.4833\n",
            "Seen so far: 49792 samples\n",
            "0.8726301\n",
            "Training loss (for one batch) at step 1560: 0.2465\n",
            "Seen so far: 49952 samples\n",
            "0.8728579\n",
            "Training loss (for one batch) at step 1565: 0.1777\n",
            "Seen so far: 50112 samples\n",
            "0.8730843\n",
            "Training loss (for one batch) at step 1570: 0.2060\n",
            "Seen so far: 50272 samples\n",
            "0.8733092\n",
            "Training loss (for one batch) at step 1575: 0.0629\n",
            "Seen so far: 50432 samples\n",
            "0.873612\n",
            "Training loss (for one batch) at step 1580: 0.0525\n",
            "Seen so far: 50592 samples\n",
            "0.87375474\n",
            "Training loss (for one batch) at step 1585: 0.1518\n",
            "Seen so far: 50752 samples\n",
            "0.8739951\n",
            "Training loss (for one batch) at step 1590: 0.2440\n",
            "Seen so far: 50912 samples\n",
            "0.87423396\n",
            "Training loss (for one batch) at step 1595: 0.1699\n",
            "Seen so far: 51072 samples\n",
            "0.8743343\n",
            "Training loss (for one batch) at step 1600: 0.0772\n",
            "Seen so far: 51232 samples\n",
            "0.8746096\n",
            "Training loss (for one batch) at step 1605: 0.4993\n",
            "Seen so far: 51392 samples\n",
            "0.8748443\n",
            "Training loss (for one batch) at step 1610: 0.1736\n",
            "Seen so far: 51552 samples\n",
            "0.8750776\n",
            "Training loss (for one batch) at step 1615: 0.0231\n",
            "Seen so far: 51712 samples\n",
            "0.8752514\n",
            "Training loss (for one batch) at step 1620: 0.1689\n",
            "Seen so far: 51872 samples\n",
            "0.87546265\n",
            "Training loss (for one batch) at step 1625: 0.2157\n",
            "Seen so far: 52032 samples\n",
            "0.8755189\n",
            "Training loss (for one batch) at step 1630: 0.0384\n",
            "Seen so far: 52192 samples\n",
            "0.87574726\n",
            "Training loss (for one batch) at step 1635: 0.1954\n",
            "Seen so far: 52352 samples\n",
            "0.8759742\n",
            "Training loss (for one batch) at step 1640: 0.1209\n",
            "Seen so far: 52512 samples\n",
            "0.8762188\n",
            "Training loss (for one batch) at step 1645: 0.3398\n",
            "Seen so far: 52672 samples\n",
            "0.87634796\n",
            "Training loss (for one batch) at step 1650: 0.3610\n",
            "Seen so far: 52832 samples\n",
            "0.87658995\n",
            "Training loss (for one batch) at step 1655: 0.0663\n",
            "Seen so far: 52992 samples\n",
            "0.8768116\n",
            "Training loss (for one batch) at step 1660: 0.2631\n",
            "Seen so far: 53152 samples\n",
            "0.8770131\n",
            "Training loss (for one batch) at step 1665: 0.1092\n",
            "Seen so far: 53312 samples\n",
            "0.8773072\n",
            "Training loss (for one batch) at step 1670: 0.1238\n",
            "Seen so far: 53472 samples\n",
            "0.8775247\n",
            "Training loss (for one batch) at step 1675: 0.3633\n",
            "Seen so far: 53632 samples\n",
            "0.8777596\n",
            "Training loss (for one batch) at step 1680: 0.1403\n",
            "Seen so far: 53792 samples\n",
            "0.8780116\n",
            "Training loss (for one batch) at step 1685: 0.1352\n",
            "Seen so far: 53952 samples\n",
            "0.87826216\n",
            "Training loss (for one batch) at step 1690: 0.1681\n",
            "Seen so far: 54112 samples\n",
            "0.8784003\n",
            "Training loss (for one batch) at step 1695: 0.0721\n",
            "Seen so far: 54272 samples\n",
            "0.87862986\n",
            "Training loss (for one batch) at step 1700: 0.3182\n",
            "Seen so far: 54432 samples\n",
            "0.87871104\n",
            "Training loss (for one batch) at step 1705: 0.1764\n",
            "Seen so far: 54592 samples\n",
            "0.87891996\n",
            "Training loss (for one batch) at step 1710: 0.3294\n",
            "Seen so far: 54752 samples\n",
            "0.8791277\n",
            "Training loss (for one batch) at step 1715: 0.3885\n",
            "Seen so far: 54912 samples\n",
            "0.8793342\n",
            "Training loss (for one batch) at step 1720: 0.1982\n",
            "Seen so far: 55072 samples\n",
            "0.87952137\n",
            "Training loss (for one batch) at step 1725: 0.4975\n",
            "Seen so far: 55232 samples\n",
            "0.8796712\n",
            "Training loss (for one batch) at step 1730: 0.2249\n",
            "Seen so far: 55392 samples\n",
            "0.8798563\n",
            "Training loss (for one batch) at step 1735: 0.2216\n",
            "Seen so far: 55552 samples\n",
            "0.88005835\n",
            "Training loss (for one batch) at step 1740: 0.0998\n",
            "Seen so far: 55712 samples\n",
            "0.8802412\n",
            "Training loss (for one batch) at step 1745: 0.0703\n",
            "Seen so far: 55872 samples\n",
            "0.8804589\n",
            "Training loss (for one batch) at step 1750: 0.2005\n",
            "Seen so far: 56032 samples\n",
            "0.88060397\n",
            "Training loss (for one batch) at step 1755: 0.0339\n",
            "Seen so far: 56192 samples\n",
            "0.88080156\n",
            "Training loss (for one batch) at step 1760: 0.2468\n",
            "Seen so far: 56352 samples\n",
            "0.88098025\n",
            "Training loss (for one batch) at step 1765: 0.1793\n",
            "Seen so far: 56512 samples\n",
            "0.8811226\n",
            "Training loss (for one batch) at step 1770: 0.0450\n",
            "Seen so far: 56672 samples\n",
            "0.8813347\n",
            "Training loss (for one batch) at step 1775: 0.0427\n",
            "Seen so far: 56832 samples\n",
            "0.88142246\n",
            "Training loss (for one batch) at step 1780: 0.0401\n",
            "Seen so far: 56992 samples\n",
            "0.881615\n",
            "Training loss (for one batch) at step 1785: 0.1104\n",
            "Seen so far: 57152 samples\n",
            "0.88177145\n",
            "Training loss (for one batch) at step 1790: 0.0681\n",
            "Seen so far: 57312 samples\n",
            "0.88197935\n",
            "Training loss (for one batch) at step 1795: 0.1789\n",
            "Seen so far: 57472 samples\n",
            "0.8820817\n",
            "Training loss (for one batch) at step 1800: 0.0704\n",
            "Seen so far: 57632 samples\n",
            "0.8822703\n",
            "Training loss (for one batch) at step 1805: 0.1430\n",
            "Seen so far: 57792 samples\n",
            "0.88242316\n",
            "Training loss (for one batch) at step 1810: 0.0710\n",
            "Seen so far: 57952 samples\n",
            "0.88269603\n",
            "Training loss (for one batch) at step 1815: 0.1000\n",
            "Seen so far: 58112 samples\n",
            "0.8828125\n",
            "Training loss (for one batch) at step 1820: 0.1647\n",
            "Seen so far: 58272 samples\n",
            "0.88301414\n",
            "Training loss (for one batch) at step 1825: 0.3960\n",
            "Seen so far: 58432 samples\n",
            "0.88316333\n",
            "Training loss (for one batch) at step 1830: 0.0984\n",
            "Seen so far: 58592 samples\n",
            "0.88338\n",
            "Training loss (for one batch) at step 1835: 0.1863\n",
            "Seen so far: 58752 samples\n",
            "0.88359547\n",
            "Training loss (for one batch) at step 1840: 0.1500\n",
            "Seen so far: 58912 samples\n",
            "0.88369095\n",
            "Training loss (for one batch) at step 1845: 0.0031\n",
            "Seen so far: 59072 samples\n",
            "0.88387054\n",
            "Training loss (for one batch) at step 1850: 0.0393\n",
            "Seen so far: 59232 samples\n",
            "0.8840829\n",
            "Training loss (for one batch) at step 1855: 0.1421\n",
            "Seen so far: 59392 samples\n",
            "0.88429415\n",
            "Training loss (for one batch) at step 1860: 0.5499\n",
            "Seen so far: 59552 samples\n",
            "0.8844035\n",
            "Training loss (for one batch) at step 1865: 0.2180\n",
            "Seen so far: 59712 samples\n",
            "0.88449556\n",
            "Training loss (for one batch) at step 1870: 0.0469\n",
            "Seen so far: 59872 samples\n",
            "0.8846706\n",
            "Training loss (for one batch) at step 1875: 0.0481\n",
            "Seen so far: 60032 samples\n",
            "0.88477814\n",
            "Training loss (for one batch) at step 1880: 0.0499\n",
            "Seen so far: 60192 samples\n",
            "0.88501793\n",
            "Training loss (for one batch) at step 1885: 0.2090\n",
            "Seen so far: 60352 samples\n",
            "0.8852399\n",
            "Training loss (for one batch) at step 1890: 0.0965\n",
            "Seen so far: 60512 samples\n",
            "0.88536155\n",
            "Training loss (for one batch) at step 1895: 0.4093\n",
            "Seen so far: 60672 samples\n",
            "0.885565\n",
            "Training loss (for one batch) at step 1900: 0.0994\n",
            "Seen so far: 60832 samples\n",
            "0.8857016\n",
            "Training loss (for one batch) at step 1905: 0.1238\n",
            "Seen so far: 60992 samples\n",
            "0.8858211\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "OOM when allocating tensor with shape[1280] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:FusedBatchNormV3]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_235/183399485.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 optimizer=optimizer)\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m trainer.train(train_dataset=dataset,\n\u001b[0m\u001b[1;32m     21\u001b[0m             train_metric=train_acc_metric)\n",
            "\u001b[0;32m/tmp/ipykernel_235/1636777303.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, train_metric)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                     \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_235/1974525113.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[0;32m--> 414\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    415\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;31m# Currently never reaches here since fused_batch_norm does not support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# pylint: enable=g-long-lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     output, mean, variance = control_flow_util.smart_cond(\n\u001b[0m\u001b[1;32m    612\u001b[0m         training, train_op, _fused_batch_norm_inference)\n\u001b[1;32m    613\u001b[0m     \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_add_or_remove_bessels_correction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/control_flow_util.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    103\u001b[0m     return tf.cond(\n\u001b[1;32m    104\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0;32m--> 105\u001b[0;31m   return tf.__internal__.smart_cond.smart_cond(\n\u001b[0m\u001b[1;32m    106\u001b[0m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fused_batch_norm_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m       return tf.compat.v1.nn.fused_batch_norm(\n\u001b[0m\u001b[1;32m    578\u001b[0m           \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m           \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36mfused_batch_norm\u001b[0;34m(x, scale, offset, mean, variance, epsilon, data_format, is_training, name, exponential_avg_factor)\u001b[0m\n\u001b[1;32m   1666\u001b[0m   \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_epsilon\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmin_epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1668\u001b[0;31m   y, running_mean, running_var, _, _, _ = gen_nn_ops.fused_batch_norm_v3(\n\u001b[0m\u001b[1;32m   1669\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1670\u001b[0m       \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mfused_batch_norm_v3\u001b[0;34m(x, scale, offset, mean, variance, epsilon, exponential_avg_factor, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   4268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4269\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4270\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4271\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4272\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1280] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:FusedBatchNormV3]"
          ]
        }
      ],
      "source": [
        "# 모델 학습 코드\n",
        "\n",
        "train_path = \"/aiffel/aiffel/model-fit/data/30vnfoods/Train\"\n",
        "\n",
        "epoch = 5\n",
        "batch = 32\n",
        "\n",
        "model = Model(num_classes=10)\n",
        "dataset = load_data(data_path=train_path, batch_size=batch)\n",
        "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "trainer = Trainer(model=model,\n",
        "                epochs=epoch,\n",
        "                batch=batch,\n",
        "                ds_length=train_length,\n",
        "                loss_fn=loss_function,\n",
        "                optimizer=optimizer)\n",
        "\n",
        "trainer.train(train_dataset=dataset,\n",
        "            train_metric=train_acc_metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3e2d502",
      "metadata": {
        "id": "a3e2d502"
      },
      "source": [
        "### Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ac5e7ed",
      "metadata": {
        "id": "2ac5e7ed",
        "outputId": "3526a5b2-e41c-4b87-9a2d-45cc5688af21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Bun rieu', 'Banh mi', 'Banh xeo', 'Chao long', 'Pho', 'Banh khot', 'Bun bo Hue', 'Banh cuon', 'Com tam', 'Bun dau mam tom']\n"
          ]
        },
        {
          "ename": "InternalError",
          "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run Mul: Dst tensor is not initialized. [Op:Mul]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_235/3606825763.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_235/1974525113.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[0;32m--> 414\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    415\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/layers/preprocessing/image_preprocessing.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1708\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    528\u001b[0m   \"\"\"\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6234\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6235\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6236\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6237\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6238\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run Mul: Dst tensor is not initialized. [Op:Mul]"
          ]
        }
      ],
      "source": [
        "# 모델 테스트 코드\n",
        "\n",
        "test_ds = load_data(data_path=test_path)\n",
        "\n",
        "for step_train, (x_batch_train, y_batch_train) in enumerate(test_ds.take(10)):\n",
        "    prediction = model(x_batch_train)\n",
        "    print(\"{}/{}\".format(np.array(tf.equal(tf.argmax(y_batch_train, axis=1), tf.argmax(prediction, axis=1))).sum(), tf.argmax(y_batch_train, axis=1).shape[0]))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}