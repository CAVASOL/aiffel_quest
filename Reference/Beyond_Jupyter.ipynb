{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CAVASOL/aiffel_quest/blob/main/Reference/Beyond_Jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f503deaa",
      "metadata": {
        "id": "f503deaa"
      },
      "source": [
        "### 학습 목표"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d3aa81c",
      "metadata": {
        "id": "5d3aa81c"
      },
      "source": [
        "* 혼자서도 딥러닝 프로젝트 개발 환경을 세팅할 수 있습니다.\n",
        "* Jupyter를 탈출하고 터미널 상에서 하이퍼파라미터를 바꿔가며 실험하는 방법을 익힙니다.\n",
        "* 딥러닝 프로젝트를 모듈화하여 관리할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cc10853",
      "metadata": {
        "id": "0cc10853"
      },
      "source": [
        "### Jupyter를 탈출하면 좋은 이유"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e97ae6a0",
      "metadata": {
        "id": "e97ae6a0"
      },
      "source": [
        "**1. 버전 관리가 어렵습니다.**  \n",
        "Jupyter Notebook(ipynb 파일)은 사실상 json 파일 형태로 만들어져있습니다. 따라서 수정된 코드와 이전 코드를 한 번에 비교하기 어렵고,  \n",
        "특히 일반적인 방법으로 서로 다른 버전의 파일을 github에서 Merge하는 것이 불가능합니다.  \n",
        "  \n",
        "**2. 코드의 모듈화와 파일 분리를 하지 않는 습관을 만듭니다(+남이 짜놓은 모듈화된 코드의 해석이 어렵습니다.)**  \n",
        "필자 본인 또한 데이터 사이언스를 공부하며 Jupyter Notebook으로 코딩을 처음 접하였습니다. 처음에는 문제가 없다고 생각했으나  \n",
        "추후 남들의 코드를 참고하거나 협업을 해야할 때 그 코드가 모듈화된 코드면 그 방식이 익숙하지 않아 알아보기가 힘들더라구요.  \n",
        "즉 모듈화된 코드가 따라야 하는 개발자들이 애용하는 정석적인 방법이라는 것을 뒤늦게 알게 되었습니다.  \n",
        "  \n",
        "코드가 길어지고 개발의 규모도 커진다면 소스 코드를 여러 개의 파일로 분리하여 관리하는 것은 필수입니다.  \n",
        "모듈화를 통한 코드 관리 방식은 협업하기 편하고 디버깅과 유지보수도 훨씬 용이하니 이 방식을 익히시기를 추천드립니다.  \n",
        "  \n",
        "**3. 상대적으로 생태계가 좁습니다.**  \n",
        "개발 전체의 큰 생태계에 비하면 Jupyter Notebook의 생태계는 아주 작습니다. 특히 요즘은 대부분의 개발자분들이 VSCode를 기본 IDE로 쓰고 있고, VSCode를 비롯한 다른 유명한 IDE에도 코딩을 편하게 해주는 다양한 extension이 있습니다.  \n",
        "이에 비해 Jupyter Notebook은 기능 개발도 더딘 편이고 extension의 종류도 한정적이어서 상대적으로 개발 생산성이 떨어질 수 있습니다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3127000d",
      "metadata": {
        "id": "3127000d"
      },
      "source": [
        "### 1-2. 필요한 것들을 설치해보자"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "820e487b",
      "metadata": {
        "id": "820e487b"
      },
      "source": [
        "본 콘텐츠는 학습하시는 분들께서 Local 컴퓨터에 딥러닝 프로젝트를 위한 개발환경을 직접 만드실 수 있게끔 도와드리는 걸 목표로 삼고 있습니다.\n",
        "\n",
        "물론 지금 갖고 계신 컴퓨터가 딥러닝 프로젝트를 하기에 적절하지 않을 수 있습니다. (사실 딥러닝 프로젝트에 적절한 컴퓨터를 사용하고 계신 분이 오히려 적을 겁니다.🙂 고사양 gpu가 탑재된 운영체제가 리눅스인..?!) 하지만 사양이 낮은 컴퓨터라도 AWS, GCP 등의 서버에 원격으로 접속하여 딥러닝 프로젝트를 진행할 수도 있고(이 경우에도 결국 서버에 직접 환경을 세팅해주어야 합니다.), 언젠가는 직접 환경 세팅을 하셔야할 날이 올 겁니다.\n",
        "\n",
        "개발 환경 세팅 역량을 익히는 가장 좋은 방법은 직접 찾아보고 시도하며 시행착오를 겪는 것이라고 (필자는) 생각합니다. 왜냐하면 프로그램을 설치하고 지우고 뭔가 이상하여 컴퓨터도 다시 포맷해보고 하는 과정에서만 얻을 수 있는 것이 있기 때문입니다.\n",
        "\n",
        "하지만 빠르게 한 번 따라해보실 수 있도록, 제가 겪은 시행착오를 바탕으로 가이드를 하나 드리는 것도 유의미할 수 있겠다고 생각하여 아래의 설명을 덧붙입니다. 물론 시간은 흐르고 있고 기술은 늘 발전하기에 아래의 가이드는 언제든 구식이 될 수 있습니다. 좀더 효율적인 방법이 없을지 여러분께서 직접 찾아보고 고민해주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb04939b",
      "metadata": {
        "id": "fb04939b"
      },
      "source": [
        "### 개발 환경 세팅"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "603e374d",
      "metadata": {
        "id": "603e374d"
      },
      "source": [
        "제가 드리는 가이드의 개발 환경을 간단히 설명드리면 다음과 같습니다.  \n",
        "\n",
        "IDE로는 VSCode를 씁니다.  \n",
        "도커(Docker)를 통해 가상화된 환경을 활용합니다.  \n",
        "도커를 쓰면 각종 라이브러리 버전 관리에 용이하고, 협업자들이 각자 모두 동일한 환경에서 실험해보기 편리합니다.  \n",
        "개발환경을 위해 설치가 필요한 프로그램은 다음과 같습니다. 갖고 계신 컴퓨터의 운영체제에 맞게 설치하시면 됩니다.  \n",
        "\n",
        "윈도우 : VSCode, WSL2, Docker  \n",
        "맥 : Homebrew, VSCode, Docker  \n",
        "우분투(리눅스) : VSCode, Docker  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6a5f9b4",
      "metadata": {
        "id": "e6a5f9b4"
      },
      "source": [
        "### 1-3. 나도 한 번 써보자 도커 그놈"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccedd361",
      "metadata": {
        "id": "ccedd361"
      },
      "source": [
        "여기서는 추상적인 개념 설명은 최소화하고 실전적인 가이드를 드리겠습니다.  \n",
        "\n",
        "**도커의 장점**  \n",
        "\n",
        "요즘은 도커를 모르는 개발자를 찾기 힘들 정도인데요, 그만큼 도커를 통해 프로젝트를 관리하면 장점이 많습니다. 주요 장점을 몇 가지만 꼽아 보겠습니다.  \n",
        "\n",
        "**1. 여러 라이브러리나 패키지의 의존성 충돌로 인한 문제를 피할 수 있습니다.**  \n",
        "\n",
        "보통 하나의 딥러닝 프로젝트에는 NumPy, pandas, TensorFlow부터 시작해서 여러 라이브러리를 설치해야 합니다. 한 컴퓨터에서 처음 프로젝트를 할 때에는 문제가 안됩니다. 그러나 두 개 이상의 프로젝트를 진행한다면 이전에 설치해두었던 라이브러리 버전이 지금 진행하는 프로젝트에서 설치한 다른 어떤 라이브러리와의 의존성에 충돌이 일어날 수 있습니다. 이러한 문제는 꽤나 빈번하게 발생하며, 그 원인을 파악하기 쉽지 않습니다. 하지만 도커를 통해 프로젝트를 각각의 독립된 환경에서 관리한다면 이 문제를 피할 수 있습니다.  \n",
        "\n",
        "**2. 협업자들도 각자가 모두 동일한 환경에서 실험할 수 있습니다.**  \n",
        "\n",
        "여럿이 함께 개발을 해야하는 상황에서는 모두가 동일한 개발 환경을 갖추어야 합니다.  \n",
        "이때 도커를 활용한다면 모두가 동일한 컴퓨터를 구매하지 않아도 이를 가능하게 합니다.  \n",
        "\n",
        "**3. 프로젝트의 재현성 검증과 배포가 쉬워집니다.**  \n",
        "\n",
        "프로젝트를 완료 후 이를 남에게 공유하거나 학술 논문 출판 등으로 재현성을 검증해야하는 상황이 생길 수 있습니다.  \n",
        "이때 도커를 활용하면 손쉽게 프로젝트를 검증할 수 있고, 배포 또한 용이해집니다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad6f8f34",
      "metadata": {
        "id": "ad6f8f34"
      },
      "source": [
        "### 도커 사용법"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e83e43ee",
      "metadata": {
        "id": "e83e43ee"
      },
      "source": [
        "Required to install VS Code extension\n",
        "\n",
        "`Remote Development`\n",
        "\n",
        "**1. 컨테이너 출력**\n",
        "\n",
        "```\n",
        "# 현재 실행중인 컨테이너 출력  \n",
        "docker ps\n",
        "(or) sudo docker ps\n",
        "\n",
        "# 모든 컨테이너 출력  \n",
        "docker ps -a\n",
        "\n",
        "# 이미지 검색하기\n",
        "docker images\n",
        "```\n",
        "\n",
        "**2. 검색한 도커 이미지 pull & 출력**\n",
        "\n",
        "* [tensorflow:2.10.0 이미지](https://hub.docker.com/layers/tensorflow/tensorflow/2.10.0/images/sha256-7f9f23ce2473eb52d17fe1b465c79c3a3604047343e23acc036296f512071bc9?context=explore)\n",
        "* [tensorflow:2.10.0-gpu 이미지](https://hub.docker.com/layers/tensorflow/tensorflow/2.10.0-gpu/images/sha256-3aeb6a5489ad8221d79ab50ec09e0b09afc483dfdb4b868ea38cfb9335269049?context=explore)\n",
        "* [(맥 m1, m2 위한) tensorflow 이미지](https://hub.docker.com/layers/armswdev/tensorflow-arm-neoverse/r22.04-tf-2.8.0-eigen/images/sha256-85f0515a53d4a502d6f8e0155ab19c73eff2a13a1c237d51b96a0d42cdc55a6c?context=explore)\n",
        "* [아이펠 lms 이미지](https://hub.docker.com/layers/ainblockchain/workspace/base-cuda114-tf2.6-aiffel/images/sha256-eabd2c7fa4c72efad5fa2d059ffd26e1eef9cb7b1474139bf1597d7cd20c41ec?context=explore)\n",
        "\n",
        "```\n",
        "# 이미지 pull 하기  \n",
        "# tensorflow:2.10.0 이미지\n",
        "docker pull tensorflow/tensorflow:2.10.0  \n",
        "\n",
        "# tensorflow:2.10.0-gpu 이미지\n",
        "docker pull tensorflow/tensorflow:2.10.0-gpu  \n",
        "\n",
        "# (맥 m1, m2 위한) tensorflow 이미지\n",
        "docker pull armswdev/tensorflow-arm-neoverse:r22.04-tf-2.8.0-eigen  \n",
        "\n",
        "# 아이펠 lms 이미지\n",
        "docker pull ainblockchain/workspace:base-cuda114-tf2.6-aiffel  \n",
        "\n",
        "# 이미지 출력  \n",
        "docker images\n",
        "```\n",
        "\n",
        "**3. 컨테이너 생성, 접속, 종료**\n",
        "\n",
        "```\n",
        "# 컨테이너 생성  \n",
        "# i: interactive, -t: tty , -d: detached\n",
        "# (옵션을 주지 않으면 컨테이너 안에서의 터미널을 볼 수 없어요.)\n",
        "docker run -itd <이미지 ID>\n",
        "\n",
        "# 컨테이너 접속  \n",
        "docker exec -it <컨테이너 ID> /bin/bash\n",
        "\n",
        "# 컨테이너에서 나오기  \n",
        "exit\n",
        "\n",
        "# 컨테이너 종료  \n",
        "docker stop <컨테이너 ID>\n",
        "```\n",
        "\n",
        ">volume 옵션 사용해서 컨테이너 생성하기\n",
        "\n",
        "```\n",
        "docker run -itd -v <로컬 디렉토리>:<컨테이너의 volume 디렉토리> <이미지 ID> /bin/bash\n",
        "```\n",
        "\n",
        ">Docker 컨테이너(container)에 쓰여진 데이터는 기본적으로 컨테이너가 삭제될 때 함께 사라지게 됩니다. 이를 방지하기 위해 volume(-v) 옵션을 이용합니다. volume 옵션을 사용하면 설정한 로컬 디렉토리를 컨테이너의 디렉토리로 사용할 수 있습니다. 즉 로컬 디렉토리에 저장된 데이터를 컨테이너에 마운트할 수 있고, 반대로 컨테이너에서 생성한 파일을 로컬의 디렉토리에 저장할 수 있습니다.\n",
        "\n",
        "**4. 컨테이너 및 이미지 삭제**\n",
        "\n",
        "```\n",
        "# 컨테이너 삭제  \n",
        "docker rm <컨테이너>\n",
        "\n",
        "# 이미지 삭제  \n",
        "docker rmi <이미지>\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40f3341e",
      "metadata": {
        "id": "40f3341e"
      },
      "source": [
        "### 1-4. 터미널에서 딥러닝 프로젝트 돌리기(feat 모듈화)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4677805",
      "metadata": {
        "id": "d4677805"
      },
      "source": [
        "파일 구성과 코드 모듈화에 정답은 없습니다.\n",
        "다만 아래의 딥러닝 프로젝트 예시 코드들을 모듈화되기 전의 코드와 비교해보고, '이런 식으로 프로젝트를 모듈화할 수 있구나'하고 느껴보시길 바라요.\n",
        "\n",
        "코드 모듈화가 익숙해지면 추후에 다른 사람들의 코드를 참고하실 때도 도움이 되실겁니다.\n",
        "\n",
        "\n",
        "**ipynb 파일로 작성된 모듈화되기 전의 코드**\n",
        "\n",
        "[링크](https://colab.research.google.com/drive/1ojwZHI-RHUrCo3rh5duaJD4WuSaBRWJe?usp=sharing)를 열어 모듈화되기 전의 코드를 확인해 보세요.\n",
        "\n",
        "\n",
        "**딥러닝 프로젝트 예시의 모듈화된 코드**\n",
        "\n",
        "[딥러닝 프로젝트](https://github.com/kwanghoum/beyond_jupyter) 예시입니다.\n",
        "딥러닝 프로젝트 예시는 아래 설명을 따라 간편하게 따라해보실 수 있습니다.  \n",
        "\n",
        "```\n",
        "# 프로젝트 클론하고 생성된 폴더로 이동하기\n",
        "git clone https://github.com/kwanghoum/beyond_jupyter.git\n",
        "cd beyond_jupyter\n",
        "\n",
        "# scipy 설치하기 (tf 2.10 이미지의 경우)\n",
        "pip install scipy==1.7.3\n",
        "\n",
        "# 데이터셋 구성하기\n",
        "python datasets.py\n",
        "\n",
        "# 모델 돌리기\n",
        "python main.py\n",
        "```\n",
        "\n",
        "모듈화된 코드를 살펴보면서 어떤 식으로 코드를 모듈화시켰는지 익혀 보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "595e5bb2",
      "metadata": {
        "id": "595e5bb2"
      },
      "source": [
        "**datasets.py**\n",
        "\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "import pickle\n",
        "import wget\n",
        "import tarfile\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 이 파일(datasets.py)을 직접 터미널에서 실행할 경우 실행되는 코드\n",
        "if __name__ == \"__main__\":\n",
        "    # cifar-10 데이터 다운로드\n",
        "    current_path = os.getcwd()\n",
        "    url = \"http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "    wget.download(url, out = current_path)\n",
        "\n",
        "    # 압축 풀기\n",
        "    tar = tarfile.open(current_path + \"/cifar-10-python.tar.gz\")\n",
        "    tar.extractall(path = current_path)\n",
        "    tar.close()\n",
        "\n",
        "    # 압축 파일 삭제\n",
        "    os.remove(current_path+\"/cifar-10-python.tar.gz\")\n",
        "\n",
        "    # 폴더명 '/data'로 변경\n",
        "    os.rename(current_path+\"/cifar-10-batches-py\", current_path+\"/data\")\n",
        "\n",
        "def unpickle(file):\n",
        "    with open(file, \"rb\") as fo:\n",
        "        dict = pickle.load(fo, encoding = \"bytes\")\n",
        "    return dict\n",
        "\n",
        "def pickle_to_images_and_labels(root):\n",
        "    data = unpickle(root)\n",
        "    data_images = data[b'data'] / 255\n",
        "    data_images = data_images.reshape(-1, 32, 32, 3).astype(\"float32\")\n",
        "    data_labels = data[b'labels']\n",
        "    return data_images, data_labels\n",
        "\n",
        "def data_loader(batch_size):\n",
        "    current_path = os.getcwd()\n",
        "    images1, label1 = pickle_to_images_and_labels(current_path + \"/data/data_batch_1\")\n",
        "    images2, label2 = pickle_to_images_and_labels(current_path + \"/data/data_batch_2\")\n",
        "    images3, label3 = pickle_to_images_and_labels(current_path + \"/data/data_batch_3\")\n",
        "    images4, label4 = pickle_to_images_and_labels(current_path + \"/data/data_batch_4\")\n",
        "    images5, label5 = pickle_to_images_and_labels(current_path + \"/data/data_batch_5\")\n",
        "\n",
        "    test_images, test_labels = pickle_to_images_and_labels(current_path + \"/data/test_batch\")\n",
        "\n",
        "    train_images = np.concatenate([images1, images2, images3, images4, images5], axis = 0)\n",
        "    train_labels = np.concatenate([label1, label2, label3, label4, label5], axis = 0)\n",
        "    test_images = np.concatenate([test_images], axis = 0)\n",
        "    test_labels = np.concatenate([test_labels], axis = 0)\n",
        "\n",
        "    idg = ImageDataGenerator(horizontal_flip=True) # data augmentation\n",
        "    train_generator = idg.flow(train_images, y = train_labels, batch_size = batch_size)\n",
        "    test_generator = idg.flow(test_images, y = test_labels, batch_size = batch_size,\n",
        "                                            shuffle = False)\n",
        "\n",
        "    return train_generator, test_generator\n",
        "    \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "727efce3",
      "metadata": {
        "id": "727efce3"
      },
      "source": [
        "**main.py**\n",
        "\n",
        "```\n",
        "import argparse\n",
        "import training\n",
        "import datasets\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description='CIFAR10 image classification')\n",
        "    parser.add_argument('--batch_size', default=128, type=int, help='batch size')\n",
        "    parser.add_argument('--epoch', default=5, type=int, help='training epoch')\n",
        "    parser.add_argument('--train', default='train', type=str, help='train and eval')\n",
        "    args = parser.parse_args()\n",
        "    print(args)\n",
        "\n",
        "    # 데이터 불러오기\n",
        "    train_generator, test_generator = datasets.data_loader(args.batch_size)\n",
        "    print(\"데이터를 잘 준비했습니다.\")\n",
        "\n",
        "    # 모델 불러오기 및 학습하기\n",
        "    if args.train == 'train':\n",
        "        learning = training.train_model(train_generator, test_generator, args.epoch)\n",
        "    else:\n",
        "        train_acc = learning.eval_model(trainloader)\n",
        "        test_acc = learning.eval_model(testloader)\n",
        "        print(f' Train Accuracy: {train_acc}, Test Accuracy: {test_acc}')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0325924a",
      "metadata": {
        "id": "0325924a"
      },
      "source": [
        "**models.py**\n",
        "\n",
        "```\n",
        "from keras import Sequential\n",
        "from keras.layers import *\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(kernel_size=3, filters=32, padding='same', input_shape=(32,32,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(kernel_size=3, filters=32, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2, padding = 'same'))\n",
        "\n",
        "model.add(Conv2D(kernel_size=3, filters=64, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(kernel_size=3, filters=64, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2, padding = 'same'))\n",
        "\n",
        "model.add(Conv2D(kernel_size=3, filters=128, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(kernel_size=3, filters=128, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2, padding = 'same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "model.add(Dense(256, Activation('relu')))\n",
        "model.add(Dense(10, Activation('softmax')))\n",
        "\n",
        "model.compile(metrics = [\"acc\"],\n",
        "              loss = \"sparse_categorical_crossentropy\",\n",
        "              optimizer = \"adam\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4f109db",
      "metadata": {
        "id": "f4f109db"
      },
      "source": [
        "**training.py**\n",
        "\n",
        "```\n",
        "\n",
        "from models import model\n",
        "\n",
        "def train_model(train_generator, valid_generator, epoch):\n",
        "    model.fit(train_generator,\n",
        "            validation_data=valid_generator,\n",
        "            epochs=epoch)\n",
        "\n",
        "def eval_model(test_generator):\n",
        "    _, acc = model.evaluate(test_generator)\n",
        "\n",
        "    return acc\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b71ec6de",
      "metadata": {
        "id": "b71ec6de"
      },
      "source": [
        "**Tips and tricks**\n",
        "\n",
        "파이썬에는 Command Line Interface(터미널)를 이용한 실행을 돕기 위한 라이브러리로 argparse 말고도 fire라는 라이브러리가 있습니다.  \n",
        "보편적으로 argparse를 많이 쓰기 때문에 argparse를 소개드렸는데요. 구글에서 만든 fire 라이브러리를 활용하면 더욱 간편한 코드 작성이 가능해집니다.  관심있으신 분은 한 번 찾아보시고 활용해보시길 권합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beef5003",
      "metadata": {
        "id": "beef5003"
      },
      "source": [
        "### 1-5. Git으로 협업하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f59429cb",
      "metadata": {
        "id": "f59429cb"
      },
      "source": [
        "**리더가 해야할 일**\n",
        "\n",
        "1. Github 계정 만들기\n",
        "Github 사이트에 접속해 Sign Up을 눌러 계정을 생성합니다.\n",
        "\n",
        "2. Repository 생성하기\n",
        "Github 사이트에서 팀프로젝트를 위한 Repository를 생성합니다. 처음이시라면 [공식 가이드](https://docs.github.com/en/repositories/creating-and-managing-repositories/quickstart-for-repositories)를 참고하셔도 좋습니다.\n",
        "\n",
        "3. 로컬 환경에서 git 시작하기\n",
        "터미널을 켜고 다음 명령어를 입력합니다.\n",
        "\n",
        "```\n",
        "# git 설치\n",
        "sudo apt update\n",
        "sudo apt install git\n",
        "\n",
        "# 로컬에 프로젝트를 진행할 폴더 생성.\n",
        "# (원하시는 위치에 원하는 이름으로 진행하셔도 좋습니다.)\n",
        "cd ~\n",
        "mkdir aiffelproject\n",
        "cd aiffelproject\n",
        "\n",
        "# git으로 관리 시작\n",
        "git init\n",
        "\n",
        "# 로컬의 git에 github 계정 정보 등록\n",
        "# my-email@gmail.com 과 my-username 부분은 자신의 email 주소와 username으로 변경해서 입력하면 됩니다.\n",
        "git config --global user.email \"my-email@gmail.com\"\n",
        "git config --global user.name \"my-username\"\n",
        "\n",
        "# git에 등록한 config의 정보를 모두 확인\n",
        "git config -l\n",
        "\n",
        "# 내 로컬 저장소와 원격 저장소(Repository) 연결\n",
        "# 뒤의 주소 부분은 여러분의 github repository의 주소를 적으면 됩니다.( 끝에 .git 포함!)\n",
        "git remote add origin https://github.com/xxx/first-repository.git\n",
        "```\n",
        "\n",
        "4. github에서 토큰 생성하기\n",
        "[Github Token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens) 사이트로 접속하여 토큰을 만들어줍니다.  \n",
        "토큰은 시간 제한이 있는 비밀번호라고 생각하면 됩니다. 후에 터미널로 로그인할 때 비밀번호로 사용할 겁니다.\n",
        "\n",
        "5. 로컬에서 파일 하나 만들고, 원격으로 git add, commit, push\n",
        "\n",
        "```\n",
        "cd aiffelproject\n",
        "\n",
        "# 첫 파일 생성\n",
        "echo \"# 작고 소중한 나의 첫 레포\" >> README.md\n",
        "\n",
        "# add\n",
        "git add .\n",
        "\n",
        "# commit: 어떤 작업을 하였는지 설명합니다. 협업하는 사람들이 내가 한 작업을 이해할 수 있도록 적어줍니다.\n",
        "git commit -m \"new readme file\"\n",
        "\n",
        "# 인증 절차 저장: 앞으로 해당 git directory에서 인증 절차(ID, pw 입력 절차)를 생략할 수 있습니다.\n",
        "git config credential.helper store\n",
        "\n",
        "# push: github에 내가 한 작업이 올라갑니다.\n",
        "git push origin main\n",
        "\n",
        "# 인증\n",
        "Username for 'https://github.com': [계정에 사용된 이메일을 입력하세요]\n",
        "Password for 'https://[위에 입력한 이메일]@github.com': [비밀번호(토큰)를 입력하세요]\n",
        "```\n",
        "\n",
        "6. github repository의 collaborators 설정하기\n",
        "해당 github repository에서 Settings > Collaborators > add people 버튼을 눌러줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dde41b61",
      "metadata": {
        "id": "dde41b61"
      },
      "source": [
        "**멤버가 할 일**\n",
        "  \n",
        "1. 작업 폴더를 생성하고, 원격의 repository clone하기  \n",
        "  \n",
        "```\n",
        "# 작업 공간 폴더 생성\n",
        "cd ~\n",
        "mkdir workplace\n",
        "cd workplace\n",
        "\n",
        "# 원격의 repository를 clone\n",
        "# 뒤의 주소 부분은 여러분의 github repository의 주소를 적으면 됩니다. (끝에 .git 포함!)\n",
        "git clone https://github.com/xxx/first-repository.git\n",
        "```\n",
        "\n",
        "2. 2. branch 생성하기  \n",
        "main branch(혹은 master branch)는 최종 버전이 올라가는 곳입니다.\n",
        "팀원 개인을 위한 branch를 따로 생성하여 관리해주는 것이 바람직합니다.\n",
        "  \n",
        "```\n",
        "git checkout -b 브랜치이름\n",
        "```\n",
        "\n",
        "3. 맡은 개발 진행하기  \n",
        "\n",
        "```\n",
        "# clone 해온 폴더로 이동\n",
        "cd first-repository\n",
        "\n",
        "# 맡은 개발 진행 (파일 생성)\n",
        "echo \"print('cool code')\" >> addcoolcode.py\n",
        "\n",
        "# add, commit, push\n",
        "git add .\n",
        "git commit -m \"cool code 추가\"\n",
        "git push origin 생성한브랜치이름\n",
        "```\n",
        "\n",
        "4. Compare & pull request\n",
        "push 후 github 사이트의 repository 페이지를 '새로고침'해보면 push했다는 알림 메시지와 함께 Compare & pull request 버튼이 생깁니다. 이 버튼을 클릭해서 pull request를 진행합니다. pull request는 내 작업을 main branch에 올리기 전에 팀리더에게 확인 요청하는 과정이라고 보시면 됩니다. pull request를 진행할 때는 어떤 작업을 하였는지 자세하게 적어 리더가 해당 작업을 확인할 수 있도록 합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "158ef914",
      "metadata": {
        "id": "158ef914"
      },
      "source": [
        "**리더가 할 일**\n",
        "\n",
        "1. pull request 확인하기\n",
        "github 사이트의 repository 페이지 상단에 pull request 메뉴를 클릭하여 팀원이 작성한 pull request를 확인합니다. pull request를 확인하면 자세한 내용을 알 수 있습니다.\n",
        "\n",
        "* 수정할 사항이 있다면, Review changes를 클릭합니다.\n",
        "* 아무 문제가 없다면, Merge pull request ➔ Confirm merge를 클릭합니다.\n",
        "\n",
        "2. pull\n",
        "팀원이 작성하여 merge된 코드를 내 로컬에 동기화해줍니다.\n",
        "\n",
        "```\n",
        "# 내가 작성 중이던 코드가 있다면 이를 먼저 저장\n",
        "git add .\n",
        "git commit -m \"메시지\"\n",
        "\n",
        "# merge된 코드를 내 로컬에 동기화\n",
        "git pull origin main\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}