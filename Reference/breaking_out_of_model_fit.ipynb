{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CAVASOL/aiffel_quest/blob/main/Reference/breaking_out_of_model_fit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5d7601e",
      "metadata": {
        "id": "a5d7601e"
      },
      "source": [
        "## Breaking out of **model.fit()**\n",
        "\n",
        "**Index**\n",
        "\n",
        "Prep Data  \n",
        "Load Data  \n",
        "Create a model  \n",
        "Create a custom trainer  \n",
        "Add Progbar and Validation Data  \n",
        "Create a custom dataloader with coarse labels  \n",
        "Test Model  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f40f8912",
      "metadata": {
        "id": "f40f8912"
      },
      "source": [
        "### Prep Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8e45847",
      "metadata": {
        "id": "f8e45847"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "data_path = '/aiffel/aiffel/model-fit/data/DATASET/TRAIN'\n",
        "cls = [os.path.join(data_path, x) for x in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, x))]\n",
        "cls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0d1e403",
      "metadata": {
        "id": "b0d1e403"
      },
      "outputs": [],
      "source": [
        "cls_files = {}\n",
        "\n",
        "for x in cls:\n",
        "    if x not in cls_files:\n",
        "        cls_files[x] = [f for f in os.listdir(x) if os.path.isfile(os.path.join(x, f))]\n",
        "\n",
        "cls_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf6df893",
      "metadata": {
        "id": "cf6df893"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import copy\n",
        "import shutil\n",
        "\n",
        "cls_val = {}\n",
        "# 0.8, 0.2 비율로 기존의 TRAIN 셋을 나눠봅시다.\n",
        "for x in cls:\n",
        "    n_train_data = int(len(cls_files[x]) * 0.8) # train 비율 0.8\n",
        "    n_val_data = len(cls_files[x]) - n_train_data # validation 비율 0.2\n",
        "    print(len(cls_files[x]), n_train_data, n_val_data)\n",
        "    train_data = random.sample(cls_files[x], n_train_data)\n",
        "    val_data = copy.deepcopy(cls_files[x])\n",
        "\n",
        "    for y in train_data: # TRAIN 폴더에서 VAL 폴더로 옮겨줄 데이터만 남기기\n",
        "        val_data.remove(y)\n",
        "\n",
        "    print(len(cls_files[x]), len(train_data), len(val_data))\n",
        "\n",
        "    # 현재 클래스 디렉토리 생성\n",
        "    x_cls = os.path.join('/aiffel/aiffel/model-fit/data/DATASET/VAL', x.split('/')[-1])\n",
        "    os.makedirs(x_cls, exist_ok=True)\n",
        "    for y in val_data:\n",
        "        shutil.move(os.path.join(x, y), os.path.join(x_cls, y))\n",
        "#         print(os.path.join(x, y), os.path.join(x_cls, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c4fe673",
      "metadata": {
        "id": "0c4fe673"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c85d668",
      "metadata": {
        "id": "0c85d668"
      },
      "outputs": [],
      "source": [
        "!pip3 install tensorflow-estimator==2.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63c5ac58",
      "metadata": {
        "id": "63c5ac58"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def process_path(file_path, class_names, img_shape=(224, 224)):\n",
        "    '''\n",
        "    file_path로부터 class label을 만들고, 이미지를 읽는 함수\n",
        "    '''\n",
        "    label = tf.strings.split(file_path, os.path.sep)\n",
        "    label = label[-2] == class_names\n",
        "\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, img_shape)\n",
        "    return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a4ba428",
      "metadata": {
        "id": "7a4ba428"
      },
      "outputs": [],
      "source": [
        "def prepare_for_training(ds, batch_size=32, cache=True, shuffle_buffer_size=1000):\n",
        "    '''\n",
        "    TensorFlow Data API를 이용해 data batch를 만드는 함수\n",
        "    '''\n",
        "    if cache:\n",
        "        if isinstance(cache, str):\n",
        "            ds = ds.cache(cache)\n",
        "        else:\n",
        "            ds = ds.cache()\n",
        "\n",
        "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "    ds = ds.repeat()\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f4514d6",
      "metadata": {
        "id": "8f4514d6"
      },
      "outputs": [],
      "source": [
        "def load_label(data_path):\n",
        "    '''\n",
        "    class 이름을 가져오는 함수\n",
        "    '''\n",
        "    class_names = [str(x) for x in data_path.iterdir()]\n",
        "    print('Find {} class : {}'.format(len(class_names), class_names))\n",
        "    return np.array(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20580154",
      "metadata": {
        "id": "20580154"
      },
      "outputs": [],
      "source": [
        "def show_batch(image_batch, label_batch, class_names):\n",
        "    '''\n",
        "    데이터를 시각화해주는 함수\n",
        "    '''\n",
        "    size = len(image_batch)\n",
        "    sub_size = size\n",
        "    plt.figure(figsize=(10, 10), dpi=80)\n",
        "    for n in range(size):\n",
        "        plt.rc('font', size=10)\n",
        "        plt.subplot(sub_size, sub_size, n+1)\n",
        "        plt.subplots_adjust(left=0.125, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.5)\n",
        "        print(plt.title(class_names[label_batch[n]==True][0].title()))\n",
        "        plt.title(label_batch[n].numpy().decode('utf-8'))\n",
        "        plt.imshow(image_batch[n])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0389f439",
      "metadata": {
        "id": "0389f439"
      },
      "outputs": [],
      "source": [
        "def load_data(data_path, batch_size=32):\n",
        "    '''\n",
        "    데이터를 만들기 위해 필요한 함수들을 호출하고 데이터를 리턴해주는 함수\n",
        "    '''\n",
        "    class_names = [cls for cls in os.listdir(data_path) if cls != '.DS_Store']\n",
        "    data_path = pathlib.Path(data_path)\n",
        "\n",
        "    list_ds = tf.data.Dataset.list_files(str(data_path/'*/*'))\n",
        "    labeled_ds = list_ds.map(lambda x: process_path(x, class_names, img_shape=(224, 224)))\n",
        "    ds = prepare_for_training(labeled_ds, batch_size=batch_size)\n",
        "\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef92a903",
      "metadata": {
        "id": "ef92a903"
      },
      "source": [
        "Ocurred Err!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b4c8e7a",
      "metadata": {
        "id": "4b4c8e7a"
      },
      "outputs": [],
      "source": [
        "# Investigate broken file\n",
        "\n",
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "data_path = '/aiffel/aiffel/model-fit/data/DATASET/TRAIN'\n",
        "extensions = ['.jpg', '.png', '.jpeg']\n",
        "\n",
        "for i, img_path in enumerate(glob.glob(os.path.join(data_path, '*/*'))):\n",
        "    try:\n",
        "        img = Image.open(img_path)\n",
        "        img.verify()\n",
        "        print('Valid image')\n",
        "    except Exception:\n",
        "        print('Invalid image')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04c9d379",
      "metadata": {
        "id": "04c9d379"
      },
      "outputs": [],
      "source": [
        "from struct import unpack\n",
        "import tqdm\n",
        "\n",
        "\n",
        "marker_mapping = {\n",
        "    0xffd8: \"Start of Image\",\n",
        "    0xffe0: \"Application Default Header\",\n",
        "    0xffdb: \"Quantization Table\",\n",
        "    0xffc0: \"Start of Frame\",\n",
        "    0xffc4: \"Define Huffman Table\",\n",
        "    0xffda: \"Start of Scan\",\n",
        "    0xffd9: \"End of Image\"\n",
        "}\n",
        "\n",
        "\n",
        "class JPEG:\n",
        "    def __init__(self, image_file):\n",
        "        with open(image_file, 'rb') as f:\n",
        "            self.img_data = f.read()\n",
        "\n",
        "    def decode(self):\n",
        "        data = self.img_data\n",
        "        while(True):\n",
        "            marker, = unpack(\">H\", data[0:2])\n",
        "            # print(marker_mapping.get(marker))\n",
        "            if marker == 0xffd8:\n",
        "                data = data[2:]\n",
        "            elif marker == 0xffd9:\n",
        "                return\n",
        "            elif marker == 0xffda:\n",
        "                data = data[-2:]\n",
        "            else:\n",
        "                lenchunk, = unpack(\">H\", data[2:4])\n",
        "                data = data[2+lenchunk:]\n",
        "            if len(data)==0:\n",
        "                break\n",
        "\n",
        "\n",
        "bads = []\n",
        "\n",
        "for img in glob.glob(os.path.join(data_path, '*/*')):\n",
        "    image = JPEG(img)\n",
        "    try:\n",
        "        image.decode()\n",
        "    except:\n",
        "        bads.append(img)\n",
        "\n",
        "print(bads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9d26ceb",
      "metadata": {
        "id": "c9d26ceb"
      },
      "outputs": [],
      "source": [
        "# Remove bad files\n",
        "\n",
        "for bad in bads:\n",
        "    os.remove(bad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6369271",
      "metadata": {
        "id": "f6369271"
      },
      "outputs": [],
      "source": [
        "# re-load data\n",
        "\n",
        "def process_path(file_path, class_names, img_shape=(224, 224)):\n",
        "    '''\n",
        "    file_path로 부터 class label을 만들고, 이미지를 읽는 함수\n",
        "    '''\n",
        "    label = tf.strings.split(file_path, os.path.sep)\n",
        "    label = label[-2] == class_names\n",
        "\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, img_shape)\n",
        "    return img, label\n",
        "\n",
        "\n",
        "def prepare_for_training(ds, batch_size=32, cache=True, shuffle_buffer_size=1000):\n",
        "    '''\n",
        "    TensorFlow Data API를 이용해 data batch를 만드는 함수\n",
        "    '''\n",
        "    if cache:\n",
        "        if isinstance(cache, str):\n",
        "            ds = ds.cache(cache)\n",
        "        else:\n",
        "            ds = ds.cache()\n",
        "\n",
        "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "    ds = ds.repeat()\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return ds\n",
        "\n",
        "\n",
        "def load_label(data_path):\n",
        "    '''\n",
        "    class 이름을 가져오는 함수\n",
        "    '''\n",
        "    class_names = [str(x) for x in data_path.iterdir()]\n",
        "    print('Find {} class : {}'.format(len(class_names), class_names))\n",
        "    return np.array(class_names)\n",
        "\n",
        "\n",
        "def show_batch(image_batch, label_batch, class_names):\n",
        "    size = len(image_batch)\n",
        "    sub_size = int(size ** 0.5) + 1\n",
        "\n",
        "    plt.figure(figsize=(10, 10), dpi=80)\n",
        "    for n in range(size):\n",
        "        plt.subplot(sub_size, sub_size, n+1)\n",
        "        plt.subplots_adjust(left=0.125, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.5)\n",
        "        plt.title(class_names[np.array(label_batch[n])==True][0].title().split('/')[-1])\n",
        "        plt.imshow(image_batch[n])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def load_data(data_path, batch_size=32):\n",
        "    '''\n",
        "    데이터를 만들기 위해 필요한 함수들을 호출하고 데이터를 리턴해주는 함수\n",
        "    '''\n",
        "    class_names = [cls for cls in os.listdir(data_path) if cls != '.DS_Store']\n",
        "    data_path = pathlib.Path(data_path)\n",
        "\n",
        "#     for item in data_path.glob(\"*\"):\n",
        "#         print(item.name)\n",
        "\n",
        "    list_ds = tf.data.Dataset.list_files(str(data_path/'*/*'))\n",
        "    labeled_ds = list_ds.map(lambda x: process_path(x, class_names, img_shape=(224, 224)))\n",
        "    ds = prepare_for_training(labeled_ds, batch_size=batch_size)\n",
        "\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4d532b8",
      "metadata": {
        "id": "e4d532b8"
      },
      "outputs": [],
      "source": [
        "data_path = '/aiffel/aiffel/model-fit/data/DATASET/TRAIN'\n",
        "train_dataset = load_data(data_path, batch_size=10)\n",
        "data_dir = pathlib.Path(data_path)\n",
        "class_names = load_label(data_dir)\n",
        "\n",
        "for img, label in train_dataset.take(5):\n",
        "    show_batch(img, label, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1ca193c",
      "metadata": {
        "id": "a1ca193c"
      },
      "outputs": [],
      "source": [
        "# tf.data.Dataset.list_files\n",
        "\n",
        "data_dir = '/aiffel/aiffel/model-fit/data/DATASET/TEST'\n",
        "data_dir = pathlib.Path(data_path)\n",
        "\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir / '*/*'))\n",
        "for f in list_ds.take(5):\n",
        "    print(f.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43546190",
      "metadata": {
        "id": "43546190"
      },
      "outputs": [],
      "source": [
        "# list_ds.map(lambda x: process_path(x, class_names))\n",
        "\n",
        "def process_path(file_path, class_names, img_shape=(224, 224)):\n",
        "    label = tf.strings.split(file_path, os.path.sep) # file path parse해서 라벨 얻기\n",
        "    label = label[-2] == class_names # 라벨 인코딩\n",
        "\n",
        "    img = tf.io.read_file(file_path) # 이미지 읽기\n",
        "    img = tf.image.decode_jpeg(img, channels=3) # 이미지 파일 디코딩\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32) # 이미지 타입 변환\n",
        "    img = tf.image.resize(img, img_shape) # 이미지 사이즈 변환\n",
        "    return img, label\n",
        "\n",
        "labeled_ds = list_ds.map(lambda x: process_path(x, class_names))\n",
        "labeled_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f2e4bbc",
      "metadata": {
        "id": "4f2e4bbc"
      },
      "outputs": [],
      "source": [
        "# cache(), shuffle(), repeat(), batch()\n",
        "# prefetch()\n",
        "\n",
        "def prepare_for_training(ds, batch_size=32, cache=True, shuffle_buffer_size=1000, n_repeat=3):\n",
        "    if cache:\n",
        "        if isinstance(cache, str):\n",
        "            ds = ds.cache(cache)\n",
        "        else:\n",
        "            ds = ds.cache()\n",
        "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "    ds = ds.repeat(n_repeat)\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b34a7c3",
      "metadata": {
        "id": "0b34a7c3"
      },
      "source": [
        "### Create a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58feed9c",
      "metadata": {
        "id": "58feed9c"
      },
      "outputs": [],
      "source": [
        "# EfficientNetB0\n",
        "\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "class YogaPose(tf.keras.Model):\n",
        "    '''\n",
        "    EfficientNetB0을 백본으로 사용하는 모델을 구성합니다.\n",
        "    Classification 문제로 접근할 것이기 때문에 맨 마지막 Dense 레이어에\n",
        "    우리가 원하는 클래스 갯수 만큼을 지정해주어야 합니다.\n",
        "    '''\n",
        "    def __init__(self, num_classes=5, freeze=False):\n",
        "        super(YogaPose, self).__init__()\n",
        "        self.base_model = EfficientNetB0(include_top=False, weights='imagenet')\n",
        "        if freeze:\n",
        "            self.base_model.trainable = False\n",
        "        self.top = tf.keras.Sequential([tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\"),\n",
        "                                       tf.keras.layers.BatchNormalization(),\n",
        "                                       tf.keras.layers.Dropout(0.5, name=\"top_dropout\")])\n",
        "        self.classifier = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")\n",
        "    def call(self, inputs, training=True):\n",
        "        x = self.base_model(inputs)\n",
        "        x = self.top(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = YogaPose(num_classes=5, freeze=True)\n",
        "    model.build(input_shape=(None, 224, 224, 3))\n",
        "    print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a278ac40",
      "metadata": {
        "id": "a278ac40"
      },
      "source": [
        "### Create a custom trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "683121bc",
      "metadata": {
        "id": "683121bc"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, epochs, batch, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.epochs = epochs\n",
        "        self.batch = batch\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "    def train(self, train_dataset, train_metric):\n",
        "        for epoch in range(self.epochs):\n",
        "            print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "            # 매 batch 마다 반복적으로 학습\n",
        "            for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "                with tf.GradientTape() as tape:\n",
        "                    logits = model(x_batch_train, training=True)\n",
        "                    loss_value = self.loss_fn(y_batch_train, logits)\n",
        "                grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "                self.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "                # train metric 업데이트\n",
        "                train_metric.update_state(y_batch_train, logits)\n",
        "                # 5 배치마다 로깅\n",
        "                if step % 5 == 0:\n",
        "                    print(\n",
        "                        \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                        % (step, float(loss_value))\n",
        "                    )\n",
        "                    print(\"Seen so far: %d samples\" % ((step + 1) * self.batch))\n",
        "                    print(train_metric.result().numpy())\n",
        "                # 마지막 epoch 학습이 끝나면 train 결과를 보여줌\n",
        "            train_acc = train_acc_metric.result()\n",
        "            print(\"Training acc over epoch: %.4f\" % (float(train_acc),))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0afa822",
      "metadata": {
        "id": "d0afa822"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "epoch = 1\n",
        "batch = 5\n",
        "model = YogaPose(num_classes=5)\n",
        "dataset = load_data(data_path=data_path, batch_size=batch)\n",
        "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "trainer = Trainer(model=model,\n",
        "                  epochs=epoch,\n",
        "                  batch=batch,\n",
        "                  loss_fn=loss_function,\n",
        "                  optimizer=optimizer)\n",
        "\n",
        "trainer.train(train_dataset=dataset,\n",
        "              train_metric=train_acc_metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac9bd93a",
      "metadata": {
        "id": "ac9bd93a"
      },
      "source": [
        "### Add Progbar and Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e27757dc",
      "metadata": {
        "id": "e27757dc"
      },
      "outputs": [],
      "source": [
        "# Calculate TRAIN_SIZE within the load_data function\n",
        "\n",
        "def load_data(data_path, img_shape, batch_size=64, is_train=True):\n",
        "    '''\n",
        "    데이터를 만들기 위해 필요한 함수들을 호출하고 데이터를 리턴해주는 함수\n",
        "    '''\n",
        "    class_names = [cls for cls in os.listdir(data_path) if cls != '.DS_Store']\n",
        "    data_path = pathlib.Path(data_path)\n",
        "\n",
        "#     for item in data_path.glob(\"*\"):\n",
        "#         print(item.name)\n",
        "\n",
        "    list_ds = tf.data.Dataset.list_files(str(data_path/'*/*'))\n",
        "    labeled_ds = list_ds.map(lambda x: process_path(x, class_names, img_shape=img_shape))\n",
        "    ds = prepare_for_training(labeled_ds, batch_size=batch_size)\n",
        "\n",
        "    DATASET_SIZE = tf.data.experimental.cardinality(list_ds).numpy()\n",
        "\n",
        "    return ds, DATASET_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3161bef7",
      "metadata": {
        "id": "3161bef7"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "dataset.py의 코드입니다!\n",
        "'''\n",
        "def process_path(file_path, class_names, img_shape=(224, 224)):\n",
        "    label = tf.strings.split(file_path, os.path.sep)\n",
        "    label = label[-2] == class_names\n",
        "\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, img_shape)\n",
        "    return img, label\n",
        "\n",
        "\n",
        "def prepare_for_training(ds, batch_size=32, cache=True, shuffle_buffer_size=1000):\n",
        "    if cache:\n",
        "        if isinstance(cache, str):\n",
        "            ds = ds.cache(cache)\n",
        "        else:\n",
        "            ds = ds.cache()\n",
        "\n",
        "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "    ds = ds.repeat()\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return ds\n",
        "\n",
        "\n",
        "def load_label(data_path):\n",
        "    class_names = [str(x) for x in data_path.iterdir()]\n",
        "    print('Find {} class : {}'.format(len(class_names), class_names))\n",
        "    return np.array(class_names)\n",
        "\n",
        "\n",
        "def show_batch(image_batch, label_batch, class_names):\n",
        "    size = len(image_batch)\n",
        "    sub_size = int(size ** 0.5) + 1\n",
        "\n",
        "    plt.figure(figsize=(10, 10), dpi=80)\n",
        "    for n in range(size):\n",
        "        plt.subplot(sub_size, sub_size, n+1)\n",
        "        plt.subplots_adjust(left=0.125, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.5)\n",
        "        plt.title(class_names[np.array(label_batch[n])==True][0].title())\n",
        "        plt.imshow(image_batch[n])\n",
        "    plt.show()\n",
        "\n",
        "def load_data(data_path, img_shape, batch_size=64, is_train=True):\n",
        "    '''\n",
        "    데이터를 만들기 위해 필요한 함수들을 호출하고 데이터를 리턴해주는 함수\n",
        "    '''\n",
        "    class_names = [cls for cls in os.listdir(data_path) if cls != '.DS_Store']\n",
        "    print(class_names)\n",
        "    data_path = pathlib.Path(data_path)\n",
        "\n",
        "#     for item in data_path.glob(\"*\"):\n",
        "#         print(item.name)\n",
        "\n",
        "    list_ds = tf.data.Dataset.list_files(str(data_path/'*/*'))\n",
        "    labeled_ds = list_ds.map(lambda x: process_path(x, class_names, img_shape=img_shape))\n",
        "    ds = prepare_for_training(labeled_ds, batch_size=batch_size)\n",
        "\n",
        "    DATASET_SIZE = tf.data.experimental.cardinality(list_ds).numpy()\n",
        "\n",
        "    return ds, DATASET_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e61faa8",
      "metadata": {
        "id": "6e61faa8"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "train_path = '/aiffel/aiffel/model-fit/data/DATASET/TRAIN'\n",
        "val_path = '/aiffel/aiffel/model-fit/data/DATASET/VAL'\n",
        "batch_size = 32\n",
        "\n",
        "train_ds, TRAIN_SIZE = load_data(data_path=train_path, img_shape=(224, 224), batch_size=batch_size)\n",
        "val_ds, VAL_SIZE = load_data(data_path=val_path, img_shape=(224, 224), batch_size=batch_size, is_train=False)\n",
        "\n",
        "compute_steps_per_epoch = lambda x: int(math.ceil(1. * x / batch_size))\n",
        "steps_per_epoch = compute_steps_per_epoch(TRAIN_SIZE)\n",
        "val_steps = compute_steps_per_epoch(VAL_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8b0783d",
      "metadata": {
        "id": "e8b0783d"
      },
      "outputs": [],
      "source": [
        "# train, val 데이터 셋 모두 (224, 224, 3) 사이즈의 input과 5개의 label에 대하여 true false로 이루어진 GT가 들어가있는지 확인합니다\n",
        "train_ds, val_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c4917e",
      "metadata": {
        "id": "25c4917e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import Progbar\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, epochs, batch, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.epochs = epochs\n",
        "        self.batch = batch\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def compute_acc(self, y_pred, y):\n",
        "        correct = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "        return accuracy\n",
        "\n",
        "    @tf.function\n",
        "    def train_on_batch(self, x_batch_train, y_batch_train):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(x_batch_train, training=True)    # 모델이 예측한 결과\n",
        "            train_loss = self.loss_fn(y_batch_train, logits)     # 모델이 예측한 결과와 GT를 이용한 loss 계산\n",
        "\n",
        "        grads = tape.gradient(train_loss, model.trainable_weights)  # gradient 계산\n",
        "        self.optimizer.apply_gradients(zip(grads, model.trainable_weights))  # Otimizer에게 처리된 그라데이션 적용을 요청\n",
        "\n",
        "        return train_loss, logits\n",
        "\n",
        "    def train(self, train_dataset, acc_metric, steps_per_epoch, val_dataset, val_step):\n",
        "        metrics_names = ['train_loss', 'train_acc', 'val_loss']\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            print(\"\\nEpoch {}/{}\".format(epoch+1, self.epochs))\n",
        "\n",
        "            train_dataset = train_dataset.shuffle(100)\n",
        "            val_dataset = val_dataset.shuffle(100)\n",
        "\n",
        "            train_dataset = train_dataset.take(steps_per_epoch)\n",
        "            val_dataset = val_dataset.take(val_step)\n",
        "\n",
        "            progBar = Progbar(steps_per_epoch * self.batch, stateful_metrics=metrics_names)\n",
        "\n",
        "            train_loss, val_loss = 100, 100\n",
        "\n",
        "            # 데이터 집합의 배치에 대해 반복합니다\n",
        "            for step_train, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "                train_loss, logits = self.train_on_batch(x_batch_train, y_batch_train)\n",
        "\n",
        "                # train metric(mean, auc, accuracy 등) 업데이트\n",
        "                acc_metric.update_state(y_batch_train, logits)\n",
        "\n",
        "                train_acc = self.compute_acc(logits, y_batch_train)\n",
        "                values = [('train_loss', train_loss), ('train_acc', train_acc)]\n",
        "                # print('{}'.format((step_train + 1) * self.batch))\n",
        "                progBar.update((step_train + 1) * self.batch, values=values)\n",
        "\n",
        "            for step, (x_batch_val, y_batch_val) in enumerate(val_dataset):\n",
        "                logits = model(x_batch_val, training=False)\n",
        "                val_loss = self.loss_fn(y_batch_val, logits)\n",
        "                val_acc = self.compute_acc(logits, y_batch_val)\n",
        "                values = [('train_loss', train_loss), ('train_acc', train_acc), ('val_loss', val_loss), ('val_acc', val_acc)]\n",
        "            progBar.update((step_train + 1) * self.batch, values=values, finalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6447a3ee",
      "metadata": {
        "id": "6447a3ee"
      },
      "outputs": [],
      "source": [
        "loss_function = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.3)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "model = YogaPose(num_classes=5)\n",
        "\n",
        "trainer = Trainer(model=model,\n",
        "                  epochs=3,\n",
        "                  batch=1,\n",
        "                  loss_fn=loss_function,\n",
        "                  optimizer=optimizer,)\n",
        "\n",
        "trainer.train(train_dataset=train_ds,\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            val_step=val_steps,\n",
        "            val_dataset=val_ds,\n",
        "            acc_metric=acc_metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daab6eb0",
      "metadata": {
        "id": "daab6eb0"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, epochs, batch, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.epochs = epochs\n",
        "        self.batch = batch\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def compute_acc(self, y_pred, y):\n",
        "        correct = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "        return accuracy\n",
        "\n",
        "    @tf.function\n",
        "    def train_on_batch(self, x_batch_train, y_batch_train):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(x_batch_train, training=True)    # 모델이 예측한 결과\n",
        "            train_loss = self.loss_fn(y_batch_train, logits)     # 모델이 예측한 결과와 GT를 이용한 loss 계산\n",
        "\n",
        "        grads = tape.gradient(train_loss, model.trainable_weights)  # gradient 계산\n",
        "        self.optimizer.apply_gradients(zip(grads, model.trainable_weights))  # Otimizer에게 처리된 그라데이션 적용을 요청\n",
        "\n",
        "        return train_loss, logits\n",
        "\n",
        "    def train(self, train_dataset, acc_metric, steps_per_epoch, val_dataset, val_step, checkpoint_manager):\n",
        "        metrics_names = ['train_loss', 'train_acc', 'val_loss']\n",
        "\n",
        "        best_loss = 100\n",
        "        for epoch in range(self.epochs):\n",
        "            print(\"\\nEpoch {}/{}\".format(epoch+1, self.epochs))\n",
        "\n",
        "            train_dataset = train_dataset.shuffle(100)\n",
        "            val_dataset = val_dataset.shuffle(100)\n",
        "\n",
        "            train_dataset = train_dataset.take(steps_per_epoch)\n",
        "            val_dataset = val_dataset.take(val_step)\n",
        "\n",
        "            progBar = Progbar(steps_per_epoch * self.batch, stateful_metrics=metrics_names)\n",
        "\n",
        "            train_loss, val_loss = 100, 100\n",
        "\n",
        "            # 데이터 집합의 배치에 대해 반복합니다\n",
        "            for step_train, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "                train_loss, logits = self.train_on_batch(x_batch_train, y_batch_train)\n",
        "\n",
        "                # train metric(mean, auc, accuracy 등) 업데이트\n",
        "                acc_metric.update_state(y_batch_train, logits)\n",
        "\n",
        "                train_acc = self.compute_acc(logits, y_batch_train)\n",
        "                values = [('train_loss', train_loss), ('train_acc', train_acc)]\n",
        "                # print('{}'.format((step_train + 1) * self.batch))\n",
        "                progBar.update((step_train + 1) * self.batch, values=values)\n",
        "\n",
        "            for step, (x_batch_val, y_batch_val) in enumerate(val_dataset):\n",
        "                logits = model(x_batch_val, training=False)\n",
        "                val_loss = self.loss_fn(y_batch_val, logits)\n",
        "                val_acc = self.compute_acc(logits, y_batch_val)\n",
        "                values = [('train_loss', train_loss), ('train_acc', train_acc), ('val_loss', val_loss), ('val_acc', val_acc)]\n",
        "            progBar.update((step_train + 1) * self.batch, values=values, finalize=True)\n",
        "\n",
        "            if val_loss < best_loss:\n",
        "                best_loss = val_loss\n",
        "                print(\"\\nSave better model\")\n",
        "                print(checkpoint_manager.save())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b10d979b",
      "metadata": {
        "id": "b10d979b"
      },
      "outputs": [],
      "source": [
        "loss_function = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.3)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "model = YogaPose(num_classes=5)\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
        "manager = tf.train.CheckpointManager(checkpoint, directory=\"aiffel/model-fit/checkpoint\", max_to_keep=5) #체크포인트 저장위치 자유롭게 변경\n",
        "\n",
        "trainer = Trainer(model=model,\n",
        "                  epochs=3,\n",
        "                  batch=1,\n",
        "                  loss_fn=loss_function,\n",
        "                  optimizer=optimizer,)\n",
        "\n",
        "trainer.train(train_dataset=train_ds,\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            val_step=val_steps,\n",
        "            val_dataset=val_ds,\n",
        "            acc_metric=acc_metric,\n",
        "            checkpoint_manager=manager)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e1796d6",
      "metadata": {
        "id": "3e1796d6"
      },
      "source": [
        "### Create a custom dataloader with coarse labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d792810e",
      "metadata": {
        "id": "d792810e"
      },
      "outputs": [],
      "source": [
        "# MoveNet\n",
        "\n",
        "# !pip install -q imageio\n",
        "# !pip install -q opencv-python\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05bb13a7",
      "metadata": {
        "id": "05bb13a7"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "from tensorflow_docs.vis import embed\n",
        "import cv2\n",
        "\n",
        "# matplotlib 라이브러리 import\n",
        "from matplotlib.collections import LineCollection\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# 이미지 display를 도와주는 imageio import\n",
        "import imageio\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "model_name = \"movenet_lightning\"\n",
        "\n",
        "if \"movenet_lightning\" in model_name:\n",
        "    module = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
        "    input_size = 192\n",
        "elif \"movenet_thunder\" in model_name:\n",
        "    module = hub.load(\"https://tfhub.dev/google/movenet/singlepose/thunder/4\")\n",
        "    input_size = 256\n",
        "else:\n",
        "    raise ValueError(\"Unsupported model name: %s\" % model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c3277b6",
      "metadata": {
        "id": "5c3277b6"
      },
      "outputs": [],
      "source": [
        "def movenet(module, input_image):\n",
        "    \"\"\"Runs detection on an input image.\n",
        "    Args:\n",
        "      input_image: A [1, height, width, 3] tensor represents the input image\n",
        "        pixels. Note that the height/width should already be resized and match the\n",
        "        expected input resolution of the model before passing into this function.\n",
        "    Returns:\n",
        "      A [1, 1, 17, 3] float numpy array representing the predicted keypoint\n",
        "      coordinates and scores.\n",
        "    \"\"\"\n",
        "    model = module.signatures['serving_default']\n",
        "\n",
        "    # SavedModel format expects tensor type of int32.\n",
        "    input_image = tf.cast(input_image, dtype=tf.int32)\n",
        "    # Run model inference.\n",
        "    outputs = model(input_image)\n",
        "    # Output is a [1, 1, 17, 3] tensor.\n",
        "    keypoints_with_scores = outputs['output_0'].numpy()\n",
        "    return keypoints_with_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5e8653a",
      "metadata": {
        "id": "e5e8653a"
      },
      "outputs": [],
      "source": [
        "# Import data for annotation\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# 데이터 셋 위치\n",
        "data_path = '/aiffel/aiffel/model-fit/data/DATASET/TRAIN'\n",
        "classes = [path for path in Path(data_path).iterdir() if path.is_dir()]\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cde9a2aa",
      "metadata": {
        "id": "cde9a2aa"
      },
      "outputs": [],
      "source": [
        "train_files = []\n",
        "for cls in classes:\n",
        "    train_files += [x.as_posix() for x in Path(cls).glob('**/*') if x.is_file()]\n",
        "train_files[:3], len(train_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46d16d25",
      "metadata": {
        "id": "46d16d25"
      },
      "outputs": [],
      "source": [
        "data_path = '/aiffel/aiffel/model-fit/data/DATASET/VAL'\n",
        "classes = [path for path in Path(data_path).iterdir() if path.is_dir()]\n",
        "val_files = []\n",
        "for cls in classes:\n",
        "    val_files += [x.as_posix() for x in Path(cls).glob('**/*') if x.is_file()]\n",
        "val_files[:3], len(val_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9902b78c",
      "metadata": {
        "id": "9902b78c"
      },
      "outputs": [],
      "source": [
        "data_path = '/aiffel/aiffel/model-fit/data/DATASET/TEST'\n",
        "classes = [path for path in Path(data_path).iterdir() if path.is_dir()]\n",
        "test_files = []\n",
        "for cls in classes:\n",
        "    test_files += [x.as_posix() for x in Path(cls).glob('**/*') if x.is_file()]\n",
        "test_files[:3], len(test_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bd5b44b",
      "metadata": {
        "id": "7bd5b44b"
      },
      "outputs": [],
      "source": [
        "# Inference and Save as JSON\n",
        "\n",
        "def get_keypoints(image,\n",
        "                  keypoints_with_scores,\n",
        "                  output_image_height=None,\n",
        "                  keypoint_threshold=0.0):\n",
        "    height, width, channel = image.shape\n",
        "    aspect_ratio = float(width) / height\n",
        "\n",
        "    keypoints_all = []\n",
        "    num_instances,_,_,_ = keypoints_with_scores.shape\n",
        "    for id in range(num_instances):\n",
        "        kpts_x = keypoints_with_scores[0,id,:,1]\n",
        "        kpts_y = keypoints_with_scores[0,id,:,0]\n",
        "        kpts_scores = keypoints_with_scores[0,id,:,2]\n",
        "        kpts_abs_xy = np.stack(\n",
        "            [width*np.array(kpts_x),height*np.array(kpts_y)],axis=-1)\n",
        "        kpts_above_thrs_abs = kpts_abs_xy[kpts_scores > keypoint_threshold,: ]\n",
        "        keypoints_all.append(kpts_above_thrs_abs)\n",
        "\n",
        "    return np.concatenate(keypoints_all,axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b21d7186",
      "metadata": {
        "id": "b21d7186"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def make_keypoints_json(files, module, input_size):\n",
        "    keypoints = {}\n",
        "    removed = []\n",
        "    for image_path in files:\n",
        "        # 이미지 에러에 대한 처리\n",
        "        # 이미지가 tf.io.read_file로 읽을 수 없는 타입인 경우에 대비\n",
        "        try:\n",
        "            image = tf.io.read_file(image_path)\n",
        "            image = tf.image.decode_jpeg(image)\n",
        "        except:\n",
        "            print('image error : ', image_path)\n",
        "            removed.append(image_path)\n",
        "            continue\n",
        "\n",
        "        input_image = tf.expand_dims(image, axis=0)\n",
        "        input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
        "\n",
        "        # 모델 인퍼런스 에러에 대한 처리\n",
        "        try:\n",
        "            keypoints_with_scores = movenet(module, input_image)\n",
        "            # print(keypoints_with_scores)\n",
        "        except Exception as e:\n",
        "#             print(input_image.shape)\n",
        "            print('modl error : ', image_path)\n",
        "            removed.append(image_path)\n",
        "            continue\n",
        "\n",
        "        keypoint_image = tf.expand_dims(image, axis=0)\n",
        "        keypoint_image = tf.cast(tf.image.resize_with_pad(\n",
        "            keypoint_image, 224, 224), dtype=tf.int32)\n",
        "        output_overlay = get_keypoints(np.squeeze(keypoint_image.numpy(), axis=0),\n",
        "                                      keypoints_with_scores)\n",
        "        # print(os.path.join('/'.join(image_path.split('/'))))\n",
        "        keypoints.setdefault(os.path.join('/'.join(image_path.split('/'))), output_overlay.tolist())\n",
        "\n",
        "    return keypoints, removed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55e7c112",
      "metadata": {
        "id": "55e7c112"
      },
      "outputs": [],
      "source": [
        "train_keypoints, train_removed_files = make_keypoints_json(train_files, module, input_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc913c44",
      "metadata": {
        "id": "fc913c44"
      },
      "outputs": [],
      "source": [
        "val_keypoints, val_removed_files = make_keypoints_json(val_files, module, input_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e28b7f6",
      "metadata": {
        "id": "0e28b7f6"
      },
      "outputs": [],
      "source": [
        "test_keypoints, test_removed_files = make_keypoints_json(test_files, module, input_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be9cfdd7",
      "metadata": {
        "id": "be9cfdd7"
      },
      "outputs": [],
      "source": [
        "# train, val keypoints 합쳐서 한 번에 저장하기\n",
        "\n",
        "train_keypoints.update(val_keypoints)\n",
        "train_keypoints.keys()\n",
        "with open(\"aiffel/model-fit/keypoints_train_val.json\", \"w\") as json_file:\n",
        "    json.dump(train_keypoints, json_file)\n",
        "\n",
        "# with open(\"/aiffel/aiffel/model-fit/keypoints_train_val.json\", \"r\") as json_file:\n",
        "#     keypoint_dict = json.load(json_file)\n",
        "# keypoint_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f944725c",
      "metadata": {
        "id": "f944725c"
      },
      "outputs": [],
      "source": [
        "# test keypoints 저장하기\n",
        "\n",
        "with open(\"aiffel/model-fit/keypoints_test.json\", \"w\") as json_file:\n",
        "    json.dump(test_keypoints, json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "475ee98d",
      "metadata": {
        "id": "475ee98d"
      },
      "outputs": [],
      "source": [
        "# keypoints_train_val.json, keypoints_test.json이 제대로 생겼는지 확인\n",
        "\n",
        "!ls aiffel/model-fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1af19480",
      "metadata": {
        "id": "1af19480"
      },
      "outputs": [],
      "source": [
        "def remove_files(removed):\n",
        "    for file_path in removed:\n",
        "        try:\n",
        "            os.remove(file_path)\n",
        "        except:\n",
        "            print(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad0ec8cf",
      "metadata": {
        "id": "ad0ec8cf"
      },
      "outputs": [],
      "source": [
        "remove_files(train_removed_files)\n",
        "remove_files(val_removed_files)\n",
        "remove_files(test_removed_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3320ad5c",
      "metadata": {
        "id": "3320ad5c"
      },
      "outputs": [],
      "source": [
        "# Create a data loader to load image data and keypoints data\n",
        "\n",
        "keypoint = {}\n",
        "\n",
        "def process_keypoint(file_path):\n",
        "    global keypoint_dict\n",
        "    file_path = file_path.numpy().decode('utf-8')\n",
        "    file_path = os.path.join('./', file_path)\n",
        "    keypoint = tf.convert_to_tensor(keypoint_dict[file_path], dtype=tf.float32)\n",
        "    return keypoint\n",
        "\n",
        "def process_path(file_path, class_names, img_shape=(224, 224)):\n",
        "    label = tf.strings.split(file_path, os.path.sep)\n",
        "    label = label[-2] == class_names\n",
        "    label = tf.cast(label, tf.float32)\n",
        "\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, img_shape)\n",
        "\n",
        "    [keypoint,] = tf.py_function(process_keypoint, [file_path], [tf.float32])\n",
        "\n",
        "    return {\"input_1\": img, \"input_2\": keypoint}, label\n",
        "\n",
        "def augment(inputs, label):\n",
        "    image, keypoint = inputs['input_1'], inputs['input_2']\n",
        "    image = tf.image.random_crop(image, size=[224, 224, 3])\n",
        "    image = tf.image.adjust_brightness(image, 0.4)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.4)\n",
        "    return {'input_1' : image, 'input_2' : keypoint}, label\n",
        "\n",
        "\n",
        "def prepare_for_training(ds, batch_size=32, cache=True, shuffle_buffer_size=1000, training=True):\n",
        "    if cache:\n",
        "        if isinstance(cache, str):\n",
        "            ds = ds.cache(cache)\n",
        "        else:\n",
        "            ds = ds.cache()\n",
        "\n",
        "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "    ds = ds.repeat()\n",
        "    if training:\n",
        "        ds = ds.map(lambda x, y: augment(x, y))\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return ds\n",
        "\n",
        "\n",
        "def load_label(data_path):\n",
        "    class_names = [str(x) for x in data_path.iterdir()]\n",
        "    print('Find {} class : {}'.format(len(class_names), class_names))\n",
        "    return np.array(class_names)\n",
        "\n",
        "\n",
        "def show_batch(image_batch, label_batch, class_names):\n",
        "    size = len(image_batch)\n",
        "    sub_size = int(size ** 0.5) + 1\n",
        "\n",
        "    plt.figure(figsize=(10, 10), dpi=80)\n",
        "    for n in range(size):\n",
        "        plt.subplot(sub_size, sub_size, n+1)\n",
        "        plt.subplots_adjust(left=0.125, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.5)\n",
        "        plt.title(class_names[np.array(label_batch[n])==True][0].title())\n",
        "        plt.imshow(image_batch[n])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def load_data(data_path, img_shape=(224, 224), batch_size=32, training=True):\n",
        "    class_names = [cls for cls in os.listdir(data_path) if cls != '.DS_Store']\n",
        "    data_path = pathlib.Path(data_path)\n",
        "\n",
        "    list_ds = tf.data.Dataset.list_files(str(data_path/'*/*'))\n",
        "    labeled_ds = list_ds.map(lambda x: process_path(x, class_names, img_shape=img_shape))\n",
        "    ds = prepare_for_training(labeled_ds, batch_size=batch_size)\n",
        "\n",
        "    DATASET_SIZE = tf.data.experimental.cardinality(list_ds).numpy()\n",
        "\n",
        "    global keypoint_dict\n",
        "    if training:\n",
        "        with open(\"/aiffel/aiffel/model-fit/keypoints_train_val.json\", \"r\") as json_file:\n",
        "            keypoint_dict = json.load(json_file)\n",
        "    else:\n",
        "        with open(\"/aiffel/aiffel/model-fit/keypoints_test.json\", \"r\") as json_file:\n",
        "            keypoint_dict = json.load(json_file)\n",
        "\n",
        "    return ds, DATASET_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cbd4e16",
      "metadata": {
        "id": "3cbd4e16"
      },
      "outputs": [],
      "source": [
        "# 내 데이터 위치\n",
        "\n",
        "train_data_path = '/aiffel/aiffel/model-fit/data/DATASET/TRAIN'\n",
        "\n",
        "train_ds, train_size = load_data(data_path=train_data_path, img_shape=(224, 224), batch_size=1)\n",
        "\n",
        "for inputs in train_ds.take(1):\n",
        "    print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9856748",
      "metadata": {
        "id": "f9856748"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "class YogaPose(tf.keras.Model):\n",
        "    def __init__(self, num_classes=30, freeze=False):\n",
        "        super(YogaPose, self).__init__()\n",
        "        self.base_model = EfficientNetB0(include_top=False, weights='imagenet')\n",
        "        self.keypoint = tf.keras.Sequential([tf.keras.layers.Flatten(input_shape=(17, 2)),\n",
        "                                              tf.keras.layers.Dense(34),])\n",
        "\n",
        "        if freeze:\n",
        "            self.base_model.trainable = False\n",
        "\n",
        "        self.top = tf.keras.Sequential([tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\"),\n",
        "                                        tf.keras.layers.BatchNormalization(),\n",
        "                                        tf.keras.layers.Dropout(0.6, name=\"top_dropout\")])\n",
        "\n",
        "        self.concat = tf.keras.layers.Concatenate(axis=-1)\n",
        "        self.classifier = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")\n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        image, keypoint = inputs['input_1'], inputs['input_2']\n",
        "        x1 = self.base_model(image)\n",
        "        x1 = self.top(x1)\n",
        "        x2 = self.keypoint(keypoint)\n",
        "        x = self.concat([x1, x2])\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9681c4a0",
      "metadata": {
        "id": "9681c4a0"
      },
      "outputs": [],
      "source": [
        "# fake input\n",
        "\n",
        "inputs = {'input_1':tf.ones([1, 224, 224, 3]), 'input_2':tf.ones([1, 17, 2])}\n",
        "model = YogaPose(num_classes=2, freeze=True)\n",
        "model(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "136d48d6",
      "metadata": {
        "id": "136d48d6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import Progbar\n",
        "import math\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, epochs, batch, loss_fn, optimizer):\n",
        "        self.model = model\n",
        "        self.epochs = epochs\n",
        "        self.batch = batch\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def compute_acc(self, y_pred, y):\n",
        "        correct = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "        return accuracy\n",
        "\n",
        "    @tf.function\n",
        "    def train_on_batch(self, x_batch_train, y_batch_train):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(x_batch_train, training=True)    # 모델이 예측한 결과\n",
        "            train_loss = self.loss_fn(y_batch_train, logits)     # 모델이 예측한 결과와 GT를 이용한 loss 계산\n",
        "\n",
        "        grads = tape.gradient(train_loss, model.trainable_weights)  # gradient 계산\n",
        "        self.optimizer.apply_gradients(zip(grads, model.trainable_weights))  # Otimizer에게 처리된 그라데이션 적용을 요청\n",
        "\n",
        "        return train_loss, logits\n",
        "\n",
        "    def train(self, train_dataset, acc_metric, steps_per_epoch, val_dataset, val_step):\n",
        "        metrics_names = ['train_loss', 'train_acc', 'val_loss']\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            print(\"\\nEpoch {}/{}\".format(epoch+1, self.epochs))\n",
        "\n",
        "            train_dataset = train_dataset.shuffle(100)\n",
        "            val_dataset = val_dataset.shuffle(100)\n",
        "\n",
        "            train_dataset = train_dataset.take(steps_per_epoch)\n",
        "            val_dataset = val_dataset.take(val_step)\n",
        "\n",
        "            progBar = Progbar(steps_per_epoch * self.batch, stateful_metrics=metrics_names)\n",
        "\n",
        "            train_loss, val_loss = 100, 100\n",
        "\n",
        "            # 데이터 집합의 배치에 대해 반복합니다\n",
        "            for step_train, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "                train_loss, logits = self.train_on_batch(x_batch_train, y_batch_train)\n",
        "\n",
        "                # train metric(mean, auc, accuracy 등) 업데이트\n",
        "                acc_metric.update_state(y_batch_train, logits)\n",
        "\n",
        "                train_acc = self.compute_acc(logits, y_batch_train)\n",
        "                values = [('train_loss', train_loss), ('train_acc', train_acc)]\n",
        "                # print('{}'.format((step_train + 1) * self.batch))\n",
        "                progBar.update((step_train + 1) * self.batch, values=values)\n",
        "\n",
        "            for step, (x_batch_val, y_batch_val) in enumerate(val_dataset):\n",
        "                logits = model(x_batch_val, training=False)\n",
        "                val_loss = self.loss_fn(y_batch_val, logits)\n",
        "                val_acc = self.compute_acc(logits, y_batch_val)\n",
        "                values = [('train_loss', train_loss), ('train_acc', train_acc), ('val_loss', val_loss), ('val_acc', val_acc)]\n",
        "            progBar.update((step_train + 1) * self.batch, values=values, finalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73c6273c",
      "metadata": {
        "id": "73c6273c"
      },
      "outputs": [],
      "source": [
        "train_data_path = '/aiffel/aiffel/model-fit/data/DATASET/TRAIN'\n",
        "val_data_path = '/aiffel/aiffel/model-fit/data/DATASET/VAL'\n",
        "batch_size = 16\n",
        "\n",
        "train_ds, TRAIN_SIZE = load_data(data_path=train_data_path, img_shape=(224, 224), batch_size=batch_size)\n",
        "val_ds, VAL_SIZE = load_data(data_path=val_data_path, img_shape=(224, 224), batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d2f8b9d",
      "metadata": {
        "id": "7d2f8b9d"
      },
      "outputs": [],
      "source": [
        "compute_steps_per_epoch = lambda x: int(math.ceil(1. * x / batch_size))\n",
        "steps_per_epoch = compute_steps_per_epoch(TRAIN_SIZE)\n",
        "val_steps = compute_steps_per_epoch(VAL_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4b97232",
      "metadata": {
        "id": "a4b97232"
      },
      "outputs": [],
      "source": [
        "loss_function = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.3)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "model = YogaPose(num_classes=5)\n",
        "\n",
        "# epoch을 조정해 보세요.\n",
        "trainer = Trainer(model=model,\n",
        "                  epochs=10,\n",
        "                  batch=1,\n",
        "                  loss_fn=loss_function,\n",
        "                  optimizer=optimizer,)\n",
        "\n",
        "trainer.train(train_dataset=train_ds,\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            val_step=val_steps,\n",
        "            val_dataset=val_ds,\n",
        "            acc_metric=acc_metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dc6c2f5",
      "metadata": {
        "id": "2dc6c2f5"
      },
      "source": [
        "### Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72429133",
      "metadata": {
        "id": "72429133"
      },
      "outputs": [],
      "source": [
        "# Test moodel\n",
        "\n",
        "num_classes = 1\n",
        "epoch = 1\n",
        "batch_size = 16\n",
        "img_size = 224\n",
        "test_data_path =  '/aiffel/aiffel/model-fit/data/DATASET/TEST'\n",
        "\n",
        "checkpoint_path = './checkpoints/'\n",
        "\n",
        "model = YogaPose(num_classes=num_classes)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "test, TEST_SIZE = load_data(data_path=test_data_path, img_shape=(img_size, img_size), batch_size=batch_size, training=False)\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))\n",
        "\n",
        "for step_train, (x_batch_train, y_batch_train) in enumerate(test.take(10)):\n",
        "    # print(model(x_batch_train))\n",
        "    prediction = model(x_batch_train)\n",
        "    # print(tf.argmax(y_batch_train, axis=1))\n",
        "    # print(tf.argmax(prediction, axis=1))\n",
        "    # print(tf.equal(tf.argmax(y_batch_train, axis=1), tf.argmax(prediction, axis=1)))\n",
        "    print(\"{}/{}\".format(np.array(tf.equal(tf.argmax(y_batch_train, axis=1), tf.argmax(prediction, axis=1))).sum(), tf.argmax(y_batch_train, axis=1).shape[0]))\n",
        "    # print(\"Prediction: {}\".format(tf.argmax(prediction, axis=1)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}