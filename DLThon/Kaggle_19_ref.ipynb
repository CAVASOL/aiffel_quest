{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CAVASOL/aiffel_quest/blob/main/DLThon/Kaggle_19_ref.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a3b7855",
      "metadata": {
        "id": "7a3b7855"
      },
      "source": [
        "## 1. 들어가며"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8f18fbb",
      "metadata": {
        "id": "f8f18fbb"
      },
      "source": [
        "### 준비물\n",
        "\n",
        "이번 노드에서는 회귀 모델을 구현하는 데에 사용하는 xgboost와 lightgbm 라이브러리와, 결측 데이터를 확인하는 missingno 라이브러리가 필요합니다.\n",
        "\n",
        "클라우드 커널 사용시에는 이미 필요한 라이브러리가 설치되어있기 때문에 따로 설치하지 않고 실습을 위한 디렉토리만 생성해 주면 됩니다.\n",
        "\n",
        "Cloud shell에서 아래 명령어를 입력해주세요.\n",
        "\n",
        "라이브러리가 잘 설치되어있는지 아래 명령어로 확인 할 수 있습니다.\n",
        "\n",
        "```\n",
        "$ conda list | grep xgboost\n",
        "$ conda list | grep lightgbm\n",
        "$ conda list | grep missingno\n",
        "$ pip list | grep scikit-learn\n",
        "```\n",
        "\n",
        "```\n",
        "$ mkdir -p ~/aiffel/kaggle_kakr_housing\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd868f35",
      "metadata": {
        "id": "cd868f35"
      },
      "source": [
        "## 2. 대회의 시작 (1) 참가 규칙, 평가 기준 살펴보기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a46f2d57",
      "metadata": {
        "id": "a46f2d57"
      },
      "source": [
        "앞서 말씀드렸듯이 대회는 데이터 사이언티스트들을 위한 경진대회 사이트 캐글(Kaggle) 에서 진행됩니다.\n",
        "지금까지 공부해오시는 동안 캐글에서 제공하는 데이터셋을 활용했던 적, 있으신가요?\n",
        "\n",
        "오늘은 캐글에서 직접 대회를 경험해보는 것인 만큼, 가입을 아직 안 하셨다면 우선 캐글에 가입을 하고 시작하겠습니다.\n",
        "\n",
        "아래 링크를 클릭해서 우리가 참가할 대회 페이지에 접속하겠습니다.\n",
        "\n",
        "> [캐글 코리아와 함께하는 2nd ML 대회 - House Price Prediction](https://www.kaggle.com/c/2019-2nd-ml-month-with-kakr)\n",
        "\n",
        "계정이 이미 있다면 Sign In으로 로그인을, 없다면 Register로 가입을 해주세요!\n",
        "캐글 사이트는 Google 계정을 활용한 가입을 지원하니 어렵지 않게 가입하실 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "532f3b71",
      "metadata": {
        "id": "532f3b71"
      },
      "source": [
        "### A. Description, 대회 소개\n",
        "\n",
        "가입 및 로그인을 무사히 마치고 나면 아마 다음과 같은 첫 페이지를 보게 되실 겁니다. 캐글에는 아주 다양한 경진대회들이 있고,  \n",
        "각 경진대회들은 모두 대회 소개, 데이터셋 소개, 규칙 설명 등 대회에 참가하는 사람들을 위한 세부 내용들로 구성되어 있습니다.  \n",
        "\n",
        "당연히 대회별로 평가 방법과 규칙이 상이하니, 대회를 본격적으로 시작하기 전에 소개와 세부 내용을 잘 읽고 시작하는 것이 좋겠죠!\n",
        "\n",
        "이번 대회의 참여 방법을 보니 특별한 링크를 눌러야만 참여가 가능하다고 하네요. 링크를 누르면 같은 페이지로 리디렉션 됩니다.  \n",
        "우리도 클릭해서 다시 한번 참가 페이지로 들어오겠습니다.  \n",
        "링크를 눌러 같은 페이지로 다시 들어왔다면, 대회에 참가할 준비는 모두 끝난 것입니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8381616a",
      "metadata": {
        "id": "8381616a"
      },
      "source": [
        "### B. Evaluation, 점수 평가 기준\n",
        "\n",
        "대회에서 각 참여자들의 점수를 어떤 기준으로 평가하는지도 매우 중요한 부분이죠.\n",
        "\n",
        "왼쪽 탭에서 Evaluation을 누르면 평가 방식은 RMSE라고 합니다.\n",
        "RMSE가 무엇인지 기억하시나요? 한번 기억을 더듬어 보시죠!\n",
        "\n",
        "이번 대회에서 다루는 문제는 \"집값\"을 예측하는 문제이기 때문에 우리가 예측해야 하는 값과 실제 정답값이 모두 실숫값입니다.  \n",
        "그 두 가지 값의 차이를 사용해 얼마나 떨어져 있는지 계산할 수 있는 RMSE를 평가 척도로 사용하는 것은 합리적으로 보이는군요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa6f5b49",
      "metadata": {
        "id": "fa6f5b49"
      },
      "source": [
        "### C. Prize, 상품\n",
        "\n",
        "이번 대회에는 상품도 있었나 보군요!\n",
        "\n",
        "상위 리더보드 100명, 즉 100등까지 상품을 주는데, 조건이 특이합니다.  \n",
        "대회가 마무리된 후 사용한 소스코드를 커널 항목에 공개해야 하는 의무가 있다고 하네요.  \n",
        "지식의 \"공유\"와 \"공개\"를 지향하는 캐글의 정신을 본따 정해진 규칙이라고 합니다.\n",
        "\n",
        "아쉽지만 대회는 이미 다 끝났기 때문에 우리는 상품을 받지 못합니다.\n",
        "\n",
        "하지만 이번 것을 연습 삼아 실제 지금 진행되고 있는 대회를 참가하면 우리도 상품 또는 상금을 받을 수도 있겠죠!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8c033e1",
      "metadata": {
        "id": "d8c033e1"
      },
      "source": [
        "### D. Timeline, 대회 일정\n",
        "\n",
        "실제 대회를 나간다면 대회 일정을 숙지하는 것도 중요합니다.\n",
        "상금을 노리고 있다면 대회의 공식 마감일 전에 여러 실험을 통해 성능을 끌어올려야겠죠!\n",
        "\n",
        "### E. Rules, 대회 규칙\n",
        "\n",
        "다음은 대회의 규칙입니다.\n",
        "\n",
        "많은 사람이 참가하고, 또 상품이 걸려있는 만큼 엄격한 규칙들이 있을 수 있습니다.  \n",
        "부정행위를 통해 얻은 점수는 무효가 될 뿐만 아니라 향후 캐글의 다른 대회에 참가하는 것에도 불이익이 있을 수 있다는 점, 잊지 마세요.\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1-0ApAnb5aeDIlYUAxyzWyPj82GQI2nfj)\n",
        "\n",
        "\n",
        "이번 대회에서는 외부 데이터의 사용을 금지한다고 합니다. 또한 하루 최대 제출 횟수는 5번이라고 합니다.  \n",
        "무작위로 많이 제출하는 것을 방지하기 위함으로 보이네요. 신중하게 제출해야겠어요!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93a048d",
      "metadata": {
        "id": "b93a048d"
      },
      "source": [
        "## 3. 대회의 시작 (2) 데이터 살펴보기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "676d4a22",
      "metadata": {
        "id": "676d4a22"
      },
      "source": [
        "### F. Data Description, 데이터 설명\n",
        "\n",
        "다음은 데이터에 대한 설명입니다.\n",
        "\n",
        "복잡한 데이터를 다루는 대회일수록, 데이터의 설명을 굉장히 꼼꼼하게 읽는 것도 중요합니다.\n",
        "데이터를 잘 이해할수록, 더 좋은 결과를 낼 수 있을 테니까요!\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1wM3FyUy_9qaqg5QfpJZvJhlmCWIy7mU7)\n",
        "\n",
        "\n",
        "\n",
        "다양한 컬럼들을 가지고 있는 데이터이군요. 우리가 예측해야 하는 컬럼은 price, 즉 집의 가격입니다.\n",
        "\n",
        "### G. Data Explorer, 데이터 파일\n",
        "\n",
        "데이터셋 자체에 대한 설명 외에도, 우리가 다운받아야 할 데이터 파일에 대한 형태를 살펴봐야 합니다.\n",
        "\n",
        "이 대회에서는 train.csv라는 모델 학습용 파일과, test.csv라는 테스트용 파일, 그리고 sample_submission.csv라는 제출용 파일이 제공됩니다.\n",
        "\n",
        "우리는 train.csv를 활용해서 데이터를 뜯어보고 모델을 학습시킨 후,  \n",
        "test.csv 파일의 데이터에 대해 price를 예측해서 sample_submission.csv의 형식에 맞는 형태로 캐글에 제출을 해볼 것입니다.\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1c44rpnaji8OF3gdX7FVRSM6OrO3h5yh1)\n",
        "\n",
        "\n",
        "원래라면 위 화면에서 Download 버튼을 누르시면 데이터를 다운 받으실 수 있지만 이번 대회에서는 데이터가 중간에 한 번 변경되었다고 합니다.  \n",
        "따라서 저희가 준비한 파일을 사용하시면 됩니다.  \n",
        "아래가 저희가 사용할 파일인데 참고용으로만 봐주세요. 클릭하지 않으셔도 진행하실 수 있습니다.  \n",
        "\n",
        "`kaggle-kakr-housing-data.zip`  \n",
        "\n",
        "데이터 다운로드 없이 Cloud shell에서 아래 명령어를 입력해주세요.\n",
        "\n",
        "```\n",
        "$ mkdir -p ~/aiffel/kaggle_kakr_housing\n",
        "$ cp -r ~/data/* ~/aiffel/kaggle_kakr_housing\n",
        "$ ls ~/aiffel/kaggle_kakr_housing/data  # 디렉토리 내 파일 확인\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecc04659",
      "metadata": {
        "id": "ecc04659"
      },
      "source": [
        "## 4. 일단 제출하고 시작해! Baseline 모델 (1) Baseline 셋팅하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35a34900",
      "metadata": {
        "id": "35a34900"
      },
      "source": [
        "이번 대회에서는 주최자 차원에서 Baseline을 제공하였습니다.  \n",
        "Baseline이라 함은 기본적으로 문제 해결을 시작할 때 쉽게 사용해볼 수 있는 샘플을 이야기하죠.  \n",
        "\n",
        "보통 대회에서 Baseline은 제공이 되는 경우도, 아닌 경우도 있는데 이번 대회는 특히 교육적인 성격도 있어서 제공이 되었던 것 같습니다.  \n",
        "우리도 있는 것을 안 써먹을 이유는 없으니, Baseline으로 빠르게 제출해보도록 하겠습니다!\n",
        "\n",
        "Baseline 커널은 다음 링크에 있는데요. 한번 이동해봅시다.  \n",
        "\n",
        ">[2019 ML month 2nd baseline 커널](https://www.kaggle.com/code/kcs93023/2019-ml-month-2nd-baseline/notebook)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e69d58c0",
      "metadata": {
        "id": "e69d58c0"
      },
      "source": [
        "### 다른 사람의 커널을 ipynb 파일로 다운받아 사용하기\n",
        "\n",
        "캐글의 커널(Kernel) 은 우리가 쓰는 주피터 노트북 형태의 파일이 캐글 서버에서 실행될 때 그 프로그램을 일컫는 개념입니다.\n",
        "\n",
        "우리도 캐글 자체의 서버에서 baseline 노트북 파일을 돌리고 모델 학습을 시킬 수도 있는데요,  \n",
        "그러기 위해 아래와 같이 보이는 화면에서 Copy and Edit 버튼을 클릭해보겠습니다.  \n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1sNUDb4ptq-NkWS8-uCmsdAibZx84jOj5)\n",
        "\n",
        "\n",
        "Copy and Edit 버튼을 클릭했다면 다음과 같은 웹상에서 코드를 돌려볼 수 있는 커널 창이 뜹니다.\n",
        "\n",
        "이렇게 커널 창 위에서 그대로 진행해도 되지만, 우리는 노트북 파일을 다운로드하여 사용해보겠습니다.\n",
        "아래처럼 File > Download 를 통해 커널을 ipynb 파일로 다운받아 주세요!\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1b2zmSK6ZbxnunCaYPGqtg-TqYK5xPiS3)\n",
        "\n",
        "\n",
        "다운로드를 클릭하면 다음과 같은 이름으로 된 ipynb 파일이 다운로드된 것을 확인할 수 있죠.\n",
        "\n",
        "2019-ml-month-2nd-baseline.ipynb\n",
        "\n",
        "이제 이 파일을 프로젝트 폴더로 이동시킨 뒤, 주피터 노트북을 실행시켜서 파일을 열겠습니다.\n",
        "\n",
        ">[코딩도장 - 주피터 노트북 사용하기](https://dojang.io/mod/page/view.php?id=2457), 아래서부터는 Cloud Jupyter 을 열어 2019-ml-month-2nd-baseline.ipynb 파일의 주피터 노트북을 직접 띄우고 설명을 참고하면서 노트북의 셀을 직접 실행하셔도 되고, 이곳 AIFFEL에서 바로 실행하셔도 좋습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3353946c",
      "metadata": {
        "id": "3353946c"
      },
      "source": [
        "### Baseline 커널 파일 실행 준비\n",
        "\n",
        "Baseline 노트북 파일을 다운받았으니 우리가 직접 돌려보고 점수까지 내보아야겠죠.  \n",
        "다만 Baseline의 모든 코드를 에러없이 잘 돌리기 위해서는 몇 가지 준비가 필요합니다.  \n",
        "\n",
        "✓ 데이터 파일을 현재 디렉토리로 옮기기  \n",
        "먼저, 당연히 데이터를 노트북 파일과 같은 폴더 내에 두어야겠죠.  \n",
        "혹시 다른 위치에 압축을 해제하셨다면, 모델 학습 및 예측에 필요한 파일이 들어있는 데이터 폴더를 아래와 같은 형태로 노트북과 같은 위치로 옮겨주세요.  \n",
        "\n",
        "클라우드 커널 사용시 본 화면 우측 하단에 있는 버튼들 중, 위에서 두 번째의 Cloud Jupyter 환경을 열어주세요.  \n",
        "aiffel, kaggle_kakr_housing 디렉토리 순으로 이동하여 Cloud Jupyter 화면 우측 상단의 Upload 버튼을 눌러,  \n",
        "캐글에서 다운 받으셨던 2019-ml-month-2nd-baseline.ipynb 파일을 업로드 해주세요.  \n",
        "\n",
        "💡 ~/aiffel/kaggle_kakr_housing 폴더를 활용하세요!\n",
        "\n",
        "```\n",
        ".    \n",
        "├── 2019-ml-month-2nd-baseline.ipynb\n",
        "└── data\n",
        "    ├── sample_submission.csv       \n",
        "    ├── test.csv       \n",
        "    └── train.csv\n",
        "```  \n",
        "\n",
        "✓ 필요한 라이브러리 설치하기  \n",
        "다음은 Baseline이 사용하는 몇 가지 라이브러리를 설치하는 법을 알아보겠습니다.  \n",
        "LMS 상에는 이미 설치돼있으니 참고만 해주세요! 앞서 \"들어가며\"에서도 말씀드렸지만,  \n",
        "이번 노드에서는 회귀 모델을 구현하는 데에 사용하는 xgboost와 lightgbm 라이브러리와,  \n",
        "결측 데이터를 확인하는 missingno 라이브러리가 필요합니다.\n",
        "\n",
        "```\n",
        "$ conda install -c conda-forge xgboost=1.3.3\n",
        "$ conda install -c conda-forge lightgbm=3.1.1\n",
        "$ conda install -c conda-forge missingno=0.4.2\n",
        "```  \n",
        "\n",
        "✓ Jupyter Notebook 파일 실행 후 matplotlib 시각화를 위해 다음 셀 실행하기  \n",
        "마지막으로, 위에서 다운받았던 2019-ml-month-2nd-baseline.ipynb 주피터 노트북 파일을 실행합니다.  \n",
        "혹은 앞서 말씀드린대로 LMS 상에서만 코드를 돌려보셔도 무방합니다.  \n",
        "\n",
        "Baseline 커널에는 다양한 시각화 코드가 있기 때문에 노트북의 맨 위에 아래의 코드를 실행시켜서 시각화 그래프가 나타날 수 있도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfc21ba2",
      "metadata": {
        "id": "bfc21ba2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28bc73d6",
      "metadata": {
        "id": "28bc73d6"
      },
      "source": [
        "## 5. 일단 제출하고 시작해! Baseline 모델 (2) 라이브러리, 데이터 가져오기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e8924e9",
      "metadata": {
        "id": "2e8924e9"
      },
      "source": [
        "이제부터는 실제 Baseline 커널에 있는 내용입니다.  \n",
        "대다수의 코드는 Baseline 커널에 있는 그대로이고, 중간중간 필요한 부분에 한해 부가설명을 추가하였습니다.  \n",
        "\n",
        "✓ 필요한 라이브러리 import 하기  \n",
        "전체 코드를 실행시키는 데에 필요한 모든 라이브러리를 한 번에 가져오는군요.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c5a9ebc",
      "metadata": {
        "id": "4c5a9ebc"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "from os.path import join\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import missingno as msno\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print('얍💢')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea104d7b",
      "metadata": {
        "id": "ea104d7b"
      },
      "source": [
        "✓ 데이터 경로 지정하기  \n",
        "그다음은 데이터의 경로를 지정합니다. 여기서 잠깐, 주의해야 할 점은 우리의 파일 경로는 Baseline 커널과 다르다는 점입니다.  \n",
        "\n",
        ">[파이썬 공식 문서 - os.path.join](https://docs.python.org/3/library/os.path.html#os.path.join)\n",
        "\n",
        "Baseline 커널은 위에서 말했던 캐글의 서버에서 돌아가도록 코드가 설계되었기 때문에 데이터가 아래와 같이 ../input 이라는 디렉토리에 위치합니다.  \n",
        "\n",
        "**1) Baseline 커널의 기존 코드**\n",
        "\n",
        "```\n",
        "train_data_path = join('../input', 'train.csv')\n",
        "sub_data_path = join('../input', 'test.csv')\n",
        "```\n",
        "\n",
        "하지만 우리는 프로젝트 디렉토리(~/aiffel/kaggle_kakr_housing 등) 내 data 폴더에 있는 파일을 사용하기로 했으므로 다음과 같이 바꾸겠습니다.  \n",
        "\n",
        "**2) LMS에서 사용할 때 알맞은 파일 경로**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48ece08e",
      "metadata": {
        "id": "48ece08e"
      },
      "outputs": [],
      "source": [
        "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
        "\n",
        "train_data_path = join(data_dir, 'train.csv')\n",
        "sub_data_path = join(data_dir, 'test.csv')      # 테스트, 즉 submission 시 사용할 데이터 경로\n",
        "\n",
        "print(train_data_path)\n",
        "print(sub_data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5daac7e",
      "metadata": {
        "id": "f5daac7e"
      },
      "source": [
        "## 6. 일단 제출하고 시작해! Baseline 모델 (3) 데이터 이해하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04c48c99",
      "metadata": {
        "id": "04c48c99"
      },
      "source": [
        "✓ 데이터 살펴보기  \n",
        "Baseline 노트북은 먼저 아래와 같이 데이터를 살펴보고 있네요. 각 변수들이 나타내는 의미를 읽어 보겠습니다.  \n",
        "\n",
        "```\n",
        "1. ID : 집을 구분하는 번호\n",
        "2. date : 집을 구매한 날짜\n",
        "3. price : 타겟 변수인 집의 가격\n",
        "4. bedrooms : 침실의 수\n",
        "5. bathrooms : 침실당 화장실 개수\n",
        "6. sqft_living : 주거 공간의 평방 피트\n",
        "7. sqft_lot : 부지의 평방 피트\n",
        "8. floors : 집의 층수\n",
        "9. waterfront : 집의 전방에 강이 흐르는지 유무 (a.k.a. 리버뷰)\n",
        "10. view : 집이 얼마나 좋아 보이는지의 정도\n",
        "11. condition : 집의 전반적인 상태\n",
        "12. grade : King County grading 시스템 기준으로 매긴 집의 등급\n",
        "13. sqft_above : 지하실을 제외한 평방 피트\n",
        "14. sqft_basement : 지하실의 평방 피트\n",
        "15. yr_built : 집을 지은 년도\n",
        "16. yr_renovated : 집을 재건축한 년도\n",
        "17. zipcode : 우편번호\n",
        "18. lat : 위도\n",
        "19. long : 경도\n",
        "20. sqft_living15 : 근처 15 가구의 주거 공간, 평방 피트\n",
        "21. sqft_lot15 : 근처 15가구의 부지, 평방 피트\n",
        "```\n",
        "\n",
        "(위 데이터 설명중 sqft_living15, sqft_lot15항목 설명이 캐글 원본과 다릅니다. 여기 자료가 데이터 원본으로 추정되니 참고하세요.)  \n",
        "\n",
        "집에 대한 다양한 정보가 들어있는 것으로 보입니다. 이들의 특징을 활용해서 집의 가격을 맞추어야 하겠죠.  \n",
        "\n",
        "✓ 데이터 불러오기  \n",
        "데이터를 data, sub이라는 변수로 불러옵니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "362660cb",
      "metadata": {
        "id": "362660cb"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(train_data_path)\n",
        "sub = pd.read_csv(sub_data_path)\n",
        "print('train data dim : {}'.format(data.shape))\n",
        "print('sub data dim : {}'.format(sub.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17f9a396",
      "metadata": {
        "id": "17f9a396"
      },
      "source": [
        "학습 데이터는 약 1만 5천 개, 테스트 데이터는 약 6천 개로 이루어져 있군요.\n",
        "테스트 데이터는 물론 우리가 맞추어야 할 집의 가격, price가 없기 때문에 컬럼이 하나 적습니다.\n",
        "\n",
        "✓ 학습 데이터에서 라벨 제거하기\n",
        "price 컬럼은 따로 y라는 변수에 저장한 후 해당 컬럼은 지워줍니다.\n",
        "\n",
        ">[파이썬 del 명령어의 기능, 자료형별 사용 예제 정리](https://jimmy-ai.tistory.com/236)  \n",
        ">참고로 데이터 분석 과정에서 칼럼을 없애고 싶다면 [pandas.DataFrame.drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)도 사용할 수 있습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d448f6a2",
      "metadata": {
        "id": "d448f6a2"
      },
      "outputs": [],
      "source": [
        "y = data['price']\n",
        "del data['price']\n",
        "\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a7c88fe",
      "metadata": {
        "id": "8a7c88fe"
      },
      "source": [
        "✓ 학습 데이터와 테스트 데이터 합치기  \n",
        "모델을 학습시키기 전에, 전체 데이터에 대해 탐색해보기 위해 두 데이터를 pd.concat으로 합쳐봅니다.  \n",
        "\n",
        "물론, 모델 학습을 진행할 때에는 다시 분리해서 사용해야 하기 때문에  \n",
        "데이터를 합치기 전 train_len에 training data의 개수를 저장해서 추후에 학습데이터만 불러올 수 있는 인덱스로 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96e2f0a1",
      "metadata": {
        "id": "96e2f0a1"
      },
      "outputs": [],
      "source": [
        "train_len = len(data)\n",
        "data = pd.concat((data, sub), axis=0)\n",
        "\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86613593",
      "metadata": {
        "id": "86613593"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "221c7abe",
      "metadata": {
        "id": "221c7abe"
      },
      "source": [
        "✓ 간단한 전처리  \n",
        "빈 데이터와 전체 데이터의 분포를 확인하는 전처리 작업입니다.  \n",
        "결측치, 즉 빈 데이터가 있는지는 위에서 설치했던 missingno 라이브러리를 사용해서 확인하는군요.  \n",
        "\n",
        "원본 노트북에서는 다음과 같이 설명합니다.  \n",
        "\n",
        ">각 변수들에 대해 결측 유무를 확인하고, 분포를 확인해보면서 간단하게 전처리를 하겠습니다.  \n",
        "먼저 데이터에 결측치가 있는지를 확인하겠습니다.  \n",
        "missingno 라이브러리의 matrix 함수를 사용하면, 데이터의 결측 상태를 시각화를 통해 살펴볼 수 있습니다.  \n",
        "\n",
        "전체 이미지가 안 보일 시 새 탭에서 이미지 열기 를 눌러보세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e18740bf",
      "metadata": {
        "id": "e18740bf"
      },
      "outputs": [],
      "source": [
        "msno.matrix(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f144a79d",
      "metadata": {
        "id": "f144a79d"
      },
      "source": [
        "위에 출력된 것은 data라는 DataFrame을 매트릭스 모양 그대로 시각화한 것입니다.  \n",
        "만약 특정 row, col에 NaN이라는 결측치가 있었다면 해당 부분이 하얗게 나옵니다.  \n",
        "결측치가 없다면 매트릭스 전체가 까맣게 나올 겁니다. 실제로 그렇게 나왔나요??  \n",
        "\n",
        "아래와 같이 직접 결측치의 개수를 출력해서 확인할 수도 있습니다.  \n",
        "\n",
        ">[데이터프레임 고급 인덱싱](https://datascienceschool.net/01%20python/04.03%20%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%94%84%EB%A0%88%EC%9E%84%20%EA%B3%A0%EA%B8%89%20%EC%9D%B8%EB%8D%B1%EC%8B%B1.html?highlight=%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%94%84%EB%A0%88%EC%9E%84%20%EA%B3%A0%EA%B8%89%20%EC%9D%B8%EB%8D%B1%EC%8B%B1)\n",
        "\n",
        "우선 id를 가지고 데이터프레임 인덱싱을 적용해 사용법을 익혀봅시다.  \n",
        "\n",
        "천천히 진행하면 3단계를 거칩니다.  \n",
        "\n",
        "1. id컬럼이 결측치인지 확인합니다.  \n",
        "2. 결측치인 데이터만 뽑아냅니다.  \n",
        "3. 결측치인 데이터의 개수를 셉니다.  \n",
        "\n",
        "코드를 하나하나 작성해 볼까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1444c8ab",
      "metadata": {
        "id": "1444c8ab"
      },
      "outputs": [],
      "source": [
        "# 1. id 컬럼이 결측치인지 확인합니다.\n",
        "null_check = pd.isnull(data['id'])\n",
        "print(null_check)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "140cc773",
      "metadata": {
        "id": "140cc773"
      },
      "source": [
        "무엇이 출력되나요?! True와 False로 이루어진 데이터프레임이 출력된다는 점에 주목하세요!  \n",
        "\n",
        "이 다음에 이루어지는 것이 인덱싱입니다. 데이터프레임을 이용해서 데이터프레임으로부터 원하는 값을 가져오는 아주 훌륭한 기능입니다!  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26ab06a0",
      "metadata": {
        "id": "26ab06a0"
      },
      "outputs": [],
      "source": [
        "# 2. 결측치인 데이터만 뽑아냅니다.\n",
        "null_data = data.loc[null_check, 'id']\n",
        "null_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "217f481a",
      "metadata": {
        "id": "217f481a"
      },
      "source": [
        "어떤가요? 결측치가 없기 때문에 빈 데이터프레임이 나왔네요.\n",
        "\n",
        "인덱싱을 이용하면 데이터프레임을 그대로 사용할 수 있다는 것이 매우 큰 장점이에요.  \n",
        "인덱싱 기능이 없었더라면 항상 데이터프레임을 배열로 바꾸고 for문을 사용해야 했을겁니다. 게다가 인덱싱 기능이 속도면에서도 월등히 빠릅니다.  \n",
        "\n",
        "이제 마지막으로 데이터 개수를 출력해주면 결측치 개수를 확인할 수 있네요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04a5d0ca",
      "metadata": {
        "id": "04a5d0ca"
      },
      "outputs": [],
      "source": [
        "# 3. 결측치인 데이터의 개수를 셉니다.\n",
        "print(f'id: {len(null_data.values)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9dd014d",
      "metadata": {
        "id": "d9dd014d"
      },
      "source": [
        "이걸 한 번에 작성하면 이렇게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c93e21c9",
      "metadata": {
        "id": "c93e21c9"
      },
      "outputs": [],
      "source": [
        "# 한 번에 뿅!\n",
        "# 추가 : 위에 실행했던 코드는 f-string으로 작동하지만 해당 코드는 대괄호가 2개가 있어 f-string으로 표현하면 에러가 발생합니다. 이럴 경우 format으로 실행합니다.\n",
        "# 추가에 대한 내용 : https://blockdmask.tistory.com/429\n",
        "print('{} : {}'.format('id', len(data.loc[pd.isnull(data['id']), 'id'].values)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eef97afd",
      "metadata": {
        "id": "eef97afd"
      },
      "source": [
        "id 컬럼 외에도 모든 컬럼에 적용해야 하니 for문을 사용하면 완성입니다!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffd3387c",
      "metadata": {
        "id": "ffd3387c"
      },
      "outputs": [],
      "source": [
        "for c in data.columns:\n",
        "    print('{} : {}'.format(c, len(data.loc[pd.isnull(data[c]), c].values)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af8bb623",
      "metadata": {
        "id": "af8bb623"
      },
      "source": [
        "✓ id, date 변수 정리  \n",
        "필요 없는 id 컬럼을 제거합니다. 나중에 예측 결과를 제출할 때를 대비하여 sub_id 변수에 id 칼럼을 저장해두고 지우도록 하겠습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d02b6a74",
      "metadata": {
        "id": "d02b6a74"
      },
      "outputs": [],
      "source": [
        "sub_id = data['id'][train_len:]\n",
        "del data['id']\n",
        "\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17c10ab0",
      "metadata": {
        "id": "17c10ab0"
      },
      "source": [
        "date 컬럼은 apply 함수로 필요한 부분만 잘라줍니다.\n",
        "\n",
        ">[Pandas Lambda, apply를 활용하여 복잡한 로직 적용하기](https://data-newbie.tistory.com/207)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3652001a",
      "metadata": {
        "id": "3652001a"
      },
      "outputs": [],
      "source": [
        "data['date'] = data['date'].apply(lambda x : str(x[:6]))\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47e1cb9a",
      "metadata": {
        "id": "47e1cb9a"
      },
      "source": [
        "특히, 여기에서 str(x[:6]) 으로 처리한 것은 20141013T000000 형식의 데이터를 연/월 데이터만 사용하기 위해 201410까지 자르기 위한 것입니다.  \n",
        "\n",
        "✓ 각 변수들의 분포 확인  \n",
        "전체 데이터들의 분포를 확인합니다.  \n",
        "특히 너무 치우친 분포를 가지는 컬럼의 경우 모델이 결과를 예측하는 데에 좋지 않은 영향을 미치므로 다듬는 작업을 합니다.  \n",
        "\n",
        "아래 시각화 코드를 통해 id 컬럼을 제외한 19개 컬럼에 대해 한 번에 모든 그래프를 그려줍니다.  \n",
        "10행 2열의 subplot에 그래프를 그리기 위해 2중 for문을 사용하고 있군요.  \n",
        "\n",
        "그래프의 종류는 sns.kdeplot을 사용합니다.  \n",
        "kdeplot은 이산(discrete) 데이터의 경우에도 부드러운 곡선으로 전체 분포를 확인할 수 있도록 하는 시각화 함수입니다.  \n",
        "\n",
        ">[seaborn.kdeplot](https://seaborn.pydata.org/generated/seaborn.kdeplot.html)\n",
        "\n",
        "우리도 아래 코드로 전체 그래프를 그려보죠. 코드 실행 완료 후에도 실제 그래프가 나타나기까지 몇 초 정도 소요될 수 있습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7bee9c2",
      "metadata": {
        "id": "c7bee9c2"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(9, 2, figsize=(12, 50))   # 가로스크롤 때문에 그래프 확인이 불편하다면 figsize의 x값을 조절해 보세요.\n",
        "\n",
        "# id 변수(count==0인 경우)는 제외하고 분포를 확인합니다.\n",
        "count = 1\n",
        "columns = data.columns\n",
        "for row in range(9):\n",
        "    for col in range(2):\n",
        "        sns.kdeplot(data=data[columns[count]], ax=ax[row][col])\n",
        "        ax[row][col].set_title(columns[count], fontsize=15)\n",
        "        count += 1\n",
        "        if count == 19 :\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4510495",
      "metadata": {
        "id": "b4510495"
      },
      "source": [
        "그래프의 분포를 보면 어떤 처리를 해주면 좋을지 떠올릴 수 있습니다.  \n",
        "\n",
        "위 그래프 중에서는 bedrooms, sqft_living, sqft_lot, sqft_above, sqft_basement, sqft_living15, sqft_lot15 변수가 한쪽으로 치우친 경향을 보이는군요.\n",
        "\n",
        "이렇게 한 쪽으로 치우친 분포의 경우에는 로그 변환(log-scaling)을 통해 데이터 분포를 정규분포에 가깝게 만들 수 있습니다.  \n",
        "자세한 이유는 아래에서 다시 다루고, 우선 결과부터 살펴봅시다.  \n",
        "\n",
        "아래와 같이 치우친 컬럼들을 skew_columns 리스트 안에 담고, 모두 np.log1p()를 활용해서 로그 변환을 해주도록 하겠습니다.  \n",
        "numpy.log1p() 함수는 입력 배열의 각 요소에 대해 자연로그 log(1 + x)을 반환해 주는 함수입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3a8f99a",
      "metadata": {
        "id": "d3a8f99a"
      },
      "outputs": [],
      "source": [
        "skew_columns = ['bedrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_lot15', 'sqft_living15']\n",
        "\n",
        "for c in skew_columns:\n",
        "    data[c] = np.log1p(data[c].values)\n",
        "\n",
        "print('얍💢')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "749264db",
      "metadata": {
        "id": "749264db"
      },
      "source": [
        "변환이 된 후의 분포를 다시 한 번 확인해볼까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2fd8d6f",
      "metadata": {
        "id": "f2fd8d6f"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(4, 2, figsize=(12, 24))\n",
        "\n",
        "count = 0\n",
        "for row in range(4):\n",
        "    for col in range(2):\n",
        "        if count == 7:\n",
        "            break\n",
        "        sns.kdeplot(data=data[skew_columns[count]], ax=ax[row][col])\n",
        "        ax[row][col].set_title(skew_columns[count], fontsize=15)\n",
        "        count += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cb32707",
      "metadata": {
        "id": "7cb32707"
      },
      "source": [
        "이전보다 훨씬 치우침이 줄어든 분포를 확인할 수 있습니다.  \n",
        "\n",
        "그렇다면 왜 로그 변환은 분포의 치우침을 줄어들게 만드는 걸까요?  \n",
        "이는 로그 함수의 형태를 보면 알 수 있습니다. 아래의 일반적인 로그 함수를 살펴봅시다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f0e3e23",
      "metadata": {
        "id": "8f0e3e23"
      },
      "outputs": [],
      "source": [
        "xx = np.linspace(0, 10, 500)\n",
        "yy = np.log(xx)\n",
        "\n",
        "plt.hlines(0, 0, 10)\n",
        "plt.vlines(0, -5, 5)\n",
        "plt.plot(xx, yy, c='r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d97b3119",
      "metadata": {
        "id": "d97b3119"
      },
      "source": [
        "위와 같은 로그 함수의 특징은 다음과 같습니다.  \n",
        "\n",
        "* 0<x<1 범위에서는 기울기가 매우 가파릅니다. 즉, x의 구간은 (0,1)로 매우 짧은 반면, y의 구간은 (−∞,0)으로 매우 큽니다.  \n",
        "* 따라서 0에 가깝게 모여있는 값들이 x로 입력되면, 그 함수값인 y 값들은 매우 큰 범위로 벌어지게 됩니다. 즉, 로그 함수는 0에 가까운 값들이 조밀하게 모여있는 입력값을, 넓은 범위로 펼칠 수 있는 특징을 가집니다.  \n",
        "* 반면, x값이 점점 커짐에 따라 로그 함수의 기울기는 급격히 작아집니다. 이는 곧 큰 x값들에 대해서는 y값이 크게 차이나지 않게 된다는 뜻이고, 따라서 넓은 범위를 가지는 x를 비교적 작은 y값의 구간 내에 모이게 하는 특징을 가집니다.  \n",
        "\n",
        "위와 같은 특성 때문에 한 쪽으로 몰려있는 분포에 로그 변환을 취하게 되면 넓게 퍼질 수 있는 것이죠.  \n",
        "\n",
        "왜 한쪽으로 치우친 분포를 로그 변환을 취하게 되면 정규분포 모양으로 고르게 분포하게 될 수 있는지 이해가 되시나요?  \n",
        "\n",
        "그렇다면 우리가 맞추어야 할 타겟인 집의 가격, 즉 data[price]의 분포를 로그 변환했을 때 결과를 유추해봅시다.  \n",
        "원래 price의 분포는 다음과 같습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a0bb8d",
      "metadata": {
        "id": "10a0bb8d"
      },
      "outputs": [],
      "source": [
        "sns.kdeplot(y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9557536d",
      "metadata": {
        "id": "9557536d"
      },
      "source": [
        "위 분포를 log 변환하게 되면 그 분포는 어떤 모양을 가지게 될까요? 직접 확인해봅시다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "540fa6c4",
      "metadata": {
        "id": "540fa6c4"
      },
      "outputs": [],
      "source": [
        "y_log_transformation = np.log1p(y)\n",
        "\n",
        "sns.kdeplot(y_log_transformation)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53070aa7",
      "metadata": {
        "id": "53070aa7"
      },
      "source": [
        "확실히 아름다운 정규분포의 모양으로 가까워진 것으로 보입니다!  \n",
        "\n",
        "그러면 여기까지 로그 변환이 필요한 데이터에 대해 처리를 마무리하였으니, 아래와 같이 전체 데이터를 다시 나누어 줍니다.  \n",
        "\n",
        "위에서 저장해두었던 train_len을 인덱스로 활용해서 :train_len까지는 학습 데이터,  \n",
        "즉 x에 저장하고, train_len: 부터는 실제로 추론을 해야 하는 테스트 데이터, 즉 sub 변수에 저장합니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb599228",
      "metadata": {
        "id": "fb599228"
      },
      "outputs": [],
      "source": [
        "sub = data.iloc[train_len:, :]\n",
        "x = data.iloc[:train_len, :]\n",
        "\n",
        "print(x.shape)\n",
        "print(sub.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7358d1b",
      "metadata": {
        "id": "b7358d1b"
      },
      "source": [
        "## 7. 일단 제출하고 시작해! Baseline 모델 (4) 모델 설계"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f0d4883",
      "metadata": {
        "id": "8f0d4883"
      },
      "source": [
        "✓ 모델링  \n",
        "이제 본격적으로 학습시킬 모델을 준비합니다.  \n",
        "Baseline 커널에서는 여러 가지 모델을 함께 사용해서 결과를 섞는, 블렌딩(blending) 이라는 기법을 활용합니다.  \n",
        "\n",
        "블렌딩이란 하나의 개별 모델을 사용하는 것이 아니라 다양한 여러 모델을 종합하여 결과를 얻는 기법입니다.  \n",
        "블렌딩은 앙상블 기법이라고 하기도 하는데요, 자세한 내용을 다음 포스팅에서 살짝 읽어보겠습니다.  \n",
        "\n",
        ">[Part 1. Introduction to Ensemble Learning](https://subinium.github.io/introduction-to-ensemble-1/#:~:text=%EC%95%99%EC%83%81%EB%B8%94(Ensemble)%20%ED%95%99%EC%8A%B5%EC%9D%80%20%EC%97%AC%EB%9F%AC,%EB%A5%BC%20%EA%B0%80%EC%A7%80%EA%B3%A0%20%EC%9D%B4%ED%95%B4%ED%95%98%EB%A9%B4%20%EC%A2%8B%EC%8A%B5%EB%8B%88%EB%8B%A4.)\n",
        "\n",
        "앙상블은 강력한 개별 모델 하나보다 약한 여러 개의 모델의 결과를 합치는 것이 낫다는 기본 전제로부터 시작됩니다.  \n",
        "하지만 위 전제가 실제로 성립한다면, 그 이유는 무엇일까요?  \n",
        "\n",
        "이에 관한 내용은 아래 포스팅에서 읽어보겠습니다. 중간에 0과 1로 나타낸 예시가 굉장히 직관적이니 유심히 읽어보고, 다음 퀴즈를 풀어보세요!  \n",
        "\n",
        ">[Kaggle Ensemble Guide](https://jamm-notnull.tistory.com/16)  \n",
        "\n",
        "간단한 산술을 통해, 어느 정도의 성능을 보이는 개별 모델의 결과를 종합하면 보다 나은 결과를 만들어낼 수 있다는 것을 확인할 수 있군요.  \n",
        "우리는 이번에 회귀 문제를 풀고 있으므로, 위 분류기의 앙상블처럼 투표로 정하는 대신 예측 결과를 평균 내어 활용할 예정입니다.  \n",
        "\n",
        "✓ Average Blending  \n",
        "여러 가지 모델의 결과를 산술평균하여 블렌딩 모델을 만들겠습니다.  \n",
        "\n",
        "모델은 부스팅 계열인 gboost, xgboost, lightgbm 세 가지를 사용합니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71e94b57",
      "metadata": {
        "id": "71e94b57"
      },
      "outputs": [],
      "source": [
        "gboost = GradientBoostingRegressor(random_state=2019)\n",
        "xgboost = xgb.XGBRegressor(random_state=2019)\n",
        "lightgbm = lgb.LGBMRegressor(random_state=2019)\n",
        "\n",
        "models = [{'model':gboost, 'name':'GradientBoosting'}, {'model':xgboost, 'name':'XGBoost'},\n",
        "          {'model':lightgbm, 'name':'LightGBM'}]\n",
        "\n",
        "print('얍💢')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b23dd379",
      "metadata": {
        "id": "b23dd379"
      },
      "source": [
        "✓ Cross Validation  \n",
        "교차 검증을 통해 모델의 성능을 간단히 평가하겠습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d4b72a7",
      "metadata": {
        "id": "7d4b72a7"
      },
      "outputs": [],
      "source": [
        "def get_cv_score(models):\n",
        "    kfold = KFold(n_splits=5).get_n_splits(x.values)\n",
        "    for m in models:\n",
        "        CV_score = np.mean(cross_val_score(m['model'], X=x.values, y=y, cv=kfold))\n",
        "        print(f\"Model: {m['name']}, CV score:{CV_score:.4f}\")\n",
        "print('얍💢')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "373ae90a",
      "metadata": {
        "id": "373ae90a"
      },
      "outputs": [],
      "source": [
        "get_cv_score(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae70a599",
      "metadata": {
        "id": "ae70a599"
      },
      "source": [
        "✓ Make Submission File  \n",
        "cross_val_score() 함수는 회귀모델을 전달할 경우 R2점수를 반환합니다.  \n",
        "R2값은 1에 가까울수록 모델이 잘 학습되었다는 것을 나타냅니다. 결정계수 R2값에 대한 간단한 설명은 아래 링크의 글을 참고하세요.  \n",
        "\n",
        ">[결정계수 R squared](https://ltlkodae.tistory.com/19)\n",
        "\n",
        "위의 결과를 보니 3개 트리 모델이 모두 훈련 데이터에 대해 괜찮은 성능을 보여주고 있군요.  \n",
        "\n",
        "Baseline 모델에서는 다음과 같이 여러 모델을 입력하면 각 모델에 대한 예측 결과를 평균 내어 주는 AveragingBlending() 함수를 만들어 사용합니다. AveragingBlending() 함수는 models 딕셔너리 안에 있는 모델을 모두 x와 y로 학습시킨 뒤 predictions에 그 예측 결괏값을 모아서 평균한 값을 반환합니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfca0328",
      "metadata": {
        "id": "dfca0328"
      },
      "outputs": [],
      "source": [
        "def AveragingBlending(models, x, y, sub_x):\n",
        "    for m in models :\n",
        "        m['model'].fit(x.values, y)\n",
        "\n",
        "    predictions = np.column_stack([\n",
        "        m['model'].predict(sub_x.values) for m in models\n",
        "    ])\n",
        "    return np.mean(predictions, axis=1)\n",
        "\n",
        "print('얍💢')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "431d1c9f",
      "metadata": {
        "id": "431d1c9f"
      },
      "source": [
        "좋습니다! 함수를 활용해서 예측값을 생성해 볼까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80d56766",
      "metadata": {
        "id": "80d56766"
      },
      "outputs": [],
      "source": [
        "y_pred = AveragingBlending(models, x, y, sub)\n",
        "print(len(y_pred))\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a436b9c",
      "metadata": {
        "id": "3a436b9c"
      },
      "source": [
        "적당한 실수값들로 예측을 해낸 것 같습니다. 그렇다면 우리는 이 결과를 캐글에 제출하기 위해 어떻게 해야 할까요?  \n",
        "\n",
        "제출해야 하는 csv 파일의 샘플이 바로 data 폴더에 있는 sample_submission.csv 입니다.  \n",
        "다음 코드로 sample_submission.csv 파일을 확인해보겠습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d777c89",
      "metadata": {
        "id": "1d777c89"
      },
      "outputs": [],
      "source": [
        "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
        "\n",
        "submission_path = join(data_dir, 'sample_submission.csv')\n",
        "submission = pd.read_csv(submission_path)\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76b43b24",
      "metadata": {
        "id": "76b43b24"
      },
      "source": [
        "id와 price의 두 가지 열로 구성되어 있습니다. 그렇다면 우리도 이에 맞게 id와 price로 구성된 데이터 프레임을 만들어주도록 하겠습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdb9c84d",
      "metadata": {
        "id": "bdb9c84d"
      },
      "outputs": [],
      "source": [
        "result = pd.DataFrame({\n",
        "    'id' : sub_id,\n",
        "    'price' : y_pred\n",
        "})\n",
        "\n",
        "result.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da99ecbb",
      "metadata": {
        "id": "da99ecbb"
      },
      "source": [
        "좋습니다! 이제 제출할 일만 남았습니다. 다음 코드로 submission.csv 파일을 저장해 주세요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b852f61",
      "metadata": {
        "id": "5b852f61"
      },
      "outputs": [],
      "source": [
        "my_submission_path = join(data_dir, 'submission.csv')\n",
        "result.to_csv(my_submission_path, index=False)\n",
        "\n",
        "print(my_submission_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "addee5a1",
      "metadata": {
        "id": "addee5a1"
      },
      "source": [
        "## 8. 일단 제출하고 시작해! Baseline 모델 (5) 캐글에 첫 결과 제출하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf31d9b1",
      "metadata": {
        "id": "cf31d9b1"
      },
      "source": [
        "두구두구..! 첫 번째 결과를 캐글에 직접 제출하겠습니다.  \n",
        "\n",
        "앞서 말했다시피 이번 대회는 이미 끝난 대회이기 때문에 Late Submission만 가능한 상태입니다.  \n",
        "아래와 같이 탭에 있는 Late Submission 버튼을 클릭하면 다음과 같은 화면을 만날 수 있습니다.  \n",
        "\n",
        ">[대회 링크](https://www.kaggle.com/c/2019-2nd-ml-month-with-kakr)\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=16zq5Ha-B7POpIvYSf4T8mHdNxpESOkzL)\n",
        "\n",
        "\n",
        "위의 화면에서 Step 1에 점선으로 보이는 제출 박스를 클릭하거나, submission.csv 파일을 해당 박스 안에 드래그앤드롭 하면 파일이 업로드됩니다.  \n",
        "\n",
        "성공적으로 업로드하였다면, Step 2에 원하는 메세지를 작성한 후 Make Submission을 클릭해 주세요!  \n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1hpAlYjUo5ZFF5z4mcfyT1EL7vzDImQ1V)\n",
        "\n",
        "\n",
        "위와 같은 화면이 보인다면 성공입니다. 오른쪽에 129560 정도의 점수도 보이는군요!! 하하 열심히 개선해 봐야겠습니다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "befbfc50",
      "metadata": {
        "id": "befbfc50"
      },
      "source": [
        "## 9. 랭킹을 올리고 싶다면? (1) 다시 한 번, 내 입맛대로 데이터 준비하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0408bc04",
      "metadata": {
        "id": "0408bc04"
      },
      "source": [
        "### 최적의 모델을 찾아서, 하이퍼 파라미터 튜닝\n",
        "\n",
        "자, 이제 지난 결과를 개선해 볼 시간입니다.  \n",
        "\n",
        "더 좋은 결과를 얻으려면 어떻게 해야 할까요? 우리는 아직 모델을 하나도 건드려보지 않았습니다.  \n",
        "이번 스텝에서는 직접 다양한 하이퍼 파라미터를 튜닝해보면서 모델의 성능을 끌어올려 볼 것입니다.  \n",
        "\n",
        "### 다시 한번, 내 입맛대로 데이터 준비하기\n",
        "\n",
        "Baseline 커널을 열심히 따라 해보았으니, 이제는 우리가 주도적으로 다시 데이터를 다뤄봐야겠죠.  \n",
        "처음의 마음가짐으로 돌아와서! 다시 데이터를 가져오는 것부터 시작하겠습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14b5e81b",
      "metadata": {
        "id": "14b5e81b"
      },
      "outputs": [],
      "source": [
        "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
        "\n",
        "train_data_path = join(data_dir, 'train.csv')\n",
        "test_data_path = join(data_dir, 'test.csv')\n",
        "\n",
        "train = pd.read_csv(train_data_path)\n",
        "test = pd.read_csv(test_data_path)\n",
        "\n",
        "print('얍💢')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d98a5d3",
      "metadata": {
        "id": "5d98a5d3"
      },
      "source": [
        "좋습니다. 데이터를 가져오는 것 정도는 이제 눈 감고도 하겠어요!  \n",
        "\n",
        "데이터를 다시 한번 살펴보고 시작합시다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a8ec87d",
      "metadata": {
        "id": "0a8ec87d"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "600e0edd",
      "metadata": {
        "id": "600e0edd"
      },
      "source": [
        "네, 역시 date가 눈에 거슬리는군요. 저 친구를 먼저 전처리를 해주어야겠습니다.  \n",
        "\n",
        "Baseline 커널이 했던 것과 달리, 우리는 int, 즉 정수형 데이터로 처리해보겠습니다.  \n",
        "이렇게 하면 모델이 date도 예측을 위한 특성으로 활용할 수 있겠죠!  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a54581",
      "metadata": {
        "id": "33a54581"
      },
      "outputs": [],
      "source": [
        "train['date'] = train['date'].apply(lambda i: i[:6]).astype(int)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3579685e",
      "metadata": {
        "id": "3579685e"
      },
      "source": [
        "좋습니다! date 컬럼은 깔끔하게 정리가 됐군요.  \n",
        "\n",
        "두 번째로 처리해야 할 것은 바로 타겟 데이터에 해당하는 price 컬럼이죠.  \n",
        "y 변수에 price를 넣어두고, train에서는 삭제하겠습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "039f51f3",
      "metadata": {
        "id": "039f51f3"
      },
      "outputs": [],
      "source": [
        "y = train['price']\n",
        "del train['price']\n",
        "\n",
        "print(train.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ccb20ed",
      "metadata": {
        "id": "1ccb20ed"
      },
      "source": [
        "마지막으로 id 컬럼을 삭제하는 것까지 하면 기본적인 전처리는 모두 마무리됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "171aee4b",
      "metadata": {
        "id": "171aee4b"
      },
      "outputs": [],
      "source": [
        "del train['id']\n",
        "\n",
        "print(train.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1789fa8",
      "metadata": {
        "id": "b1789fa8"
      },
      "source": [
        "test 데이터에 대해서도 같은 작업을 진행합니다.  \n",
        "단, test에 우리가 맞추어야 할 타겟 데이터인 price는 없으니 훈련 데이터셋과는 다르게 price에 대한 처리는 해주지 않아도 된다는 것을 잊지 마세요!  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b5b8b34",
      "metadata": {
        "id": "1b5b8b34"
      },
      "outputs": [],
      "source": [
        "test['date'] = test['date'].apply(lambda i: i[:6]).astype(int)\n",
        "\n",
        "del test['id']\n",
        "\n",
        "print(test.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c1ed0a8",
      "metadata": {
        "id": "0c1ed0a8"
      },
      "source": [
        "자, 그러면 타겟 데이터인 y를 한번 확인해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "554b4693",
      "metadata": {
        "id": "554b4693"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a79cc88c",
      "metadata": {
        "id": "a79cc88c"
      },
      "source": [
        "네, 아주 큰 값들로 이루어져 있군요. 직접 코드를 작성해 가격 데이터의 분포도 한번 확인해 보시죠."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2579c202",
      "metadata": {
        "id": "2579c202"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "seaborn의 `kdeplot`을 활용해 `y`의 분포를 확인\n",
        "\"\"\"\n",
        "\n",
        "sns.kdeplot(y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cff54302",
      "metadata": {
        "id": "cff54302"
      },
      "source": [
        "앞서 살펴봤듯이 price는 왼쪽으로 크게 치우쳐 있는 형태를 보입니다.  \n",
        "\n",
        "따라서 y는 np.log1p() 함수를 통해 로그 변환을 해주고, 나중에 모델이 값을 예측한 후에 다시 np.expm1()을 활용해서 되돌리겠습니다.  \n",
        "np.expm1()은 np.log1p()과는 반대로 각 원소 x마다 exp(x)-1의 값을 반환해 줍니다.  \n",
        "\n",
        ">[numpy.log1p](https://numpy.org/doc/stable/reference/generated/numpy.log1p.html)  \n",
        ">[numpy.expm1](https://numpy.org/doc/stable/reference/generated/numpy.expm1.html)  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce7cca35",
      "metadata": {
        "id": "ce7cca35"
      },
      "outputs": [],
      "source": [
        "y = np.log1p(y)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcaac96c",
      "metadata": {
        "id": "bcaac96c"
      },
      "outputs": [],
      "source": [
        "sns.kdeplot(y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe717772",
      "metadata": {
        "id": "fe717772"
      },
      "source": [
        "비교적 완만한 정규분포의 형태로 잘 변환되었습니다.  \n",
        "\n",
        "그러면 info() 함수로 전체 데이터의 자료형을 한눈에 확인해 볼까요?  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46d395d3",
      "metadata": {
        "id": "46d395d3"
      },
      "outputs": [],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8d7ee92",
      "metadata": {
        "id": "d8d7ee92"
      },
      "source": [
        "모두 실수 또는 정수 자료형으로, 문제 없이 모델 학습에 활용할 수 있을 것 같습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6752dbfa",
      "metadata": {
        "id": "6752dbfa"
      },
      "source": [
        "## 10. 랭킹을 올리고 싶다면? (2) 다양한 실험을 위해 함수로 만들어 쓰자"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "700f0978",
      "metadata": {
        "id": "700f0978"
      },
      "source": [
        "이제부터 본격적으로 모델 튜닝을 해보겠습니다.  \n",
        "\n",
        "머신러닝 모델을 학습시키고 튜닝을 하다 보면 몇 시간이 훌쩍 지났는지 모를 만큼 실험해볼 것들이 많습니다.  \n",
        "보다 다양하고 많은 실험을 하기 위해서는, 그만큼 실험을 위한 도구들이 잘 준비되어 있는 것이 유리하겠죠.  \n",
        "\n",
        "따라서 여러 가지 반복되는 작업들은 함수로 먼저 만들어 놓고 많은 실험을 하는 것이 좋습니다. 이제부터 구현해 보겠습니다.  \n",
        "\n",
        "먼저 필요한 라이브러리를 가져오겠습니다.  \n",
        "데이터셋을 훈련 데이터셋과 검증 데이터셋으로 나누기 위한 train_test_split 함수와, RMSE 점수를 계산하기 위한 mean_squared_error를 가져옵니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5a2aac8",
      "metadata": {
        "id": "c5a2aac8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "print('얍💢')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd4aa53e",
      "metadata": {
        "id": "cd4aa53e"
      },
      "source": [
        "대회에서 점수를 매기는 것과 같은 평가 척도인 RMSE를 계산하기 위해 다음과 같은 함수를 만들어놓겠습니다.  \n",
        "한 가지 주의해야 할 것은, y_test나 y_pred는 위에서 np.log1p()로 변환이 된 값이기 때문에  \n",
        "원래 데이터의 단위에 맞게 되돌리기 위해 np.expm1()을 추가해야 한다는 점입니다.  \n",
        "\n",
        "exp로 다시 변환해서 mean_squared_error를 계산한 값에 np.sqrt를 취하면 RMSE 값을 얻을 수 있겠죠!  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1ca44e5",
      "metadata": {
        "id": "a1ca44e5"
      },
      "outputs": [],
      "source": [
        "def rmse(y_test, y_pred):\n",
        "    return np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred)))\n",
        "\n",
        "print('얍💢')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3667ff6",
      "metadata": {
        "id": "a3667ff6"
      },
      "source": [
        "다음으로 XGBRegressor, LGBMRegressor, GradientBoostingRegressor, RandomForestRegressor 네 가지 모델을 가져오겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b872bab",
      "metadata": {
        "id": "2b872bab"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "\n",
        "print('얍💢')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf02f14b",
      "metadata": {
        "id": "cf02f14b"
      },
      "source": [
        "아래와 같이 모델 인스턴스를 생성한 후 models라는 리스트에 넣어줍니다.  \n",
        "\n",
        "이때, 모델 파라미터 초기화나 데이터셋 구성에 사용되는 랜덤 시드값인 random_state 값을 특정 값으로 고정시키거나, 아니면 지정하지 않고 None으로 세팅할 수 있습니다. random_state를 고정값으로 주면 모델과 데이터셋이 동일한 경우 머신러닝 학습결과도 항상 동일하게 재현됩니다. 하지만 이 값을 지정하지 않고 None으로 남겨 두면 모델 내부에서 랜덤 시드값을 임의로 선택하기 때문에, 결과적으로 파라미터 초기화나 데이터셋 구성 양상이 달라져서 모델과 데이터셋이 동일하더라도 머신러닝 학습결과는 학습할 때마다 달라집니다.  \n",
        "\n",
        "앞으로 우리는 베이스라인에서부터 시작해서 다양한 실험을 통해 성능이 개선되는지를 검증해 보려고 합니다. 이때, 어떤 시도가 모델 성능 향상에 긍정적이었는지 여부를 판단하기 위해서는 랜덤적 요소의 변화 때문에 생기는 불확실성을 제거해야 합니다. 따라서 아래와 같이 random_state 값을 특정 값으로 고정시킬 것입니다. 혹시 고정하지 않았을 때 어떤 상황이 벌어지는지 궁금하시다면 random_state 값을 None으로 남겨두고 실험을 반복해 보셔도 됩니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62ad63ed",
      "metadata": {
        "id": "62ad63ed"
      },
      "outputs": [],
      "source": [
        "# random_state는 모델초기화나 데이터셋 구성에 사용되는 랜덤 시드값입니다.\n",
        "#random_state=None    # 이게 초기값입니다. 아무것도 지정하지 않고 None을 넘겨주면 모델 내부에서 임의로 선택합니다.\n",
        "random_state=2020        # 하지만 우리는 이렇게 고정값을 세팅해 두겠습니다.\n",
        "\n",
        "gboost = GradientBoostingRegressor(random_state=random_state)\n",
        "xgboost = XGBRegressor(random_state=random_state)\n",
        "lightgbm = LGBMRegressor(random_state=random_state)\n",
        "rdforest = RandomForestRegressor(random_state=random_state)\n",
        "\n",
        "models = [gboost, xgboost, lightgbm, rdforest]\n",
        "\n",
        "print('얍💢')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "577b8ef4",
      "metadata": {
        "id": "577b8ef4"
      },
      "source": [
        "각 모델의 이름은 다음과 같이 클래스의 __name__ 속성에 접근해서 얻을 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfdf9371",
      "metadata": {
        "id": "dfdf9371"
      },
      "outputs": [],
      "source": [
        "gboost.__class__.__name__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bc3ebf9",
      "metadata": {
        "id": "3bc3ebf9"
      },
      "source": [
        "이렇게 이름을 접근할 수 있다면 다음과 같이 for문 안에서 각 모델 별로 학습 및 예측을 해볼 수 있죠."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "745c17c5",
      "metadata": {
        "id": "745c17c5"
      },
      "outputs": [],
      "source": [
        "df = {}\n",
        "\n",
        "for model in models:\n",
        "    # 모델 이름 획득\n",
        "    model_name = model.__class__.__name__\n",
        "\n",
        "    # train, test 데이터셋 분리 - 여기에도 random_state를 고정합니다.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(train, y, random_state=random_state, test_size=0.2)\n",
        "\n",
        "    # 모델 학습\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # 예측\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # 예측 결과의 rmse값 저장\n",
        "    df[model_name] = rmse(y_test, y_pred)\n",
        "\n",
        "    # data frame에 저장\n",
        "    score_df = pd.DataFrame(df, index=['RMSE']).T.sort_values('RMSE', ascending=False)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdb3cae4",
      "metadata": {
        "id": "bdb3cae4"
      },
      "source": [
        "네, 이렇게 간단하게 네 가지의 모델에 대해 모두 RMSE값을 빠르게 얻을 수 있습니다.\n",
        "\n",
        "위의 과정을 get_scores(models, train, y) 함수로 만들어 보겠습니다. 아래에 있는 코드 블록에 작성 후 실행해 보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "511f5566",
      "metadata": {
        "id": "511f5566"
      },
      "outputs": [],
      "source": [
        "def get_scores(models, train, y):\n",
        "    df = {}\n",
        "\n",
        "    for model in models:\n",
        "        model_name = model.__class__.__name__\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(train, y, random_state=random_state, test_size=0.2)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        df[model_name] = rmse(y_test, y_pred)\n",
        "        score_df = pd.DataFrame(df, index=['RMSE']).T.sort_values('RMSE', ascending=False)\n",
        "\n",
        "    return score_df\n",
        "\n",
        "get_scores(models, train, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "436fb3ad",
      "metadata": {
        "id": "436fb3ad"
      },
      "source": [
        "## 11. 랭킹을 올리고 싶다면? (3) 하이퍼 파라미터 튜닝의 최강자, 그리드 탐색"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d0a2857",
      "metadata": {
        "id": "0d0a2857"
      },
      "source": [
        "이제 모델과 데이터셋이 있다면 RMSE 결괏값을 나타내주는 함수가 준비되었으니, 다양한 하이퍼 파라미터로 실험하는 일만 남았죠.  \n",
        "\n",
        "실험은 sklearn.model_selection 라이브러리 안에 있는 GridSearchCV 클래스를 활용합니다.  \n",
        "다음 함수를 import 해주세요!  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d4d5388",
      "metadata": {
        "id": "2d4d5388"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "print('얍💢')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7ab9314",
      "metadata": {
        "id": "a7ab9314"
      },
      "source": [
        "GridSearchCV란 무엇일까요?  \n",
        "\n",
        "우선 그리드 탐색과 랜덤 탐색을 알아볼 필요가 있습니다. 두 가지 모두 하이퍼 파라미터를 조합해 보는 방법입니다.  \n",
        "\n",
        "그리드 탐색은 사람이 먼저 탐색할 하이퍼 파라미터의 값들을 정해두고, 그 값들로 만들어질 수 있는 모든 조합을 탐색합니다.  \n",
        "특정 값에 대한 하이퍼 파라미터 조합을 모두 탐색하고자 할 때 유리하겠네요!\n",
        "\n",
        "랜덤 탐색은 사람이 탐색할 하이퍼 파라미터의 공간만 정해두고, 그 안에서 랜덤으로 조합을 선택해서 탐색하는 방법입니다.  \n",
        "\n",
        "그리드 탐색에서는 사람이 정해둔 값들로 이루어지는 조합만 탐색하기 때문에 최적의 조합을 놓칠 수 있는 반면, 랜덤 탐색에서는 말 그대로 랜덤으로 탐색하기 때문에 최적의 조합을 찾을 수 있는 가능성이 언제나 열려 있습니다. 하지만 그 가능성 또한 랜덤성에 의존하기 때문에 언제나 최적을 찾는다는 보장은 없어요.\n",
        "\n",
        "다음 이미지가 그리드 탐색(grid search)과 랜덤 탐색(random search) 두 가지를 잘 나타내고 있습니다.  \n",
        "그리드 탐색은 정해진 하이퍼 파라미터의 조합을 격자와 같이 탐색하는 반면, 랜덤 탐색은 랜덤으로 점을 찍어서 탐색합니다.  \n",
        "\n",
        "확실히 그리드 탐색의 탐색 공간은 매우 제한적인 반면 랜덤 탐색은 탐색하는 공간이 훨씬 넓습니다.  \n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1M2Wfl8sA5wqx5Tkq0GbAfigUj4YXcz5W)\n",
        "\n",
        "\n",
        "우리는 앞서 언급했듯 다양한 파라미터를 입력하면 가능한 모든 조합을 탐색하는 사이킷런의 GridSearchCV를 활용해 볼 것입니다.  \n",
        "먼저 GridSearchCV에 입력되는 인자들은 다음과 같습니다.  \n",
        "\n",
        "* param_grid : 탐색할 파라미터의 종류 (딕셔너리로 입력)\n",
        "* scoring : 모델의 성능을 평가할 지표\n",
        "* cv : cross validation을 수행하기 위해 train 데이터셋을 나누는 조각의 개수\n",
        "* verbose : 그리드 탐색을 진행하면서 진행 과정을 출력해서 보여줄 메세지의 양 (숫자가 클수록 더 많은 메세지를 출력합니다.)\n",
        "* n_jobs : 그리드 탐색을 진행하면서 사용할 CPU의 개수\n",
        "\n",
        "그러면 param_grid에 탐색할 xgboost 관련 하이퍼 파라미터를 넣어서 준비하겠습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43e2c61d",
      "metadata": {
        "id": "43e2c61d"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [1, 10],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a87a41a3",
      "metadata": {
        "id": "a87a41a3"
      },
      "source": [
        "그다음으로 모델을 준비합니다. 모델은 LightGBM(lgbm)를 사용해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d22414b6",
      "metadata": {
        "id": "d22414b6"
      },
      "outputs": [],
      "source": [
        "model = LGBMRegressor(random_state=random_state)\n",
        "\n",
        "print('얍💢')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cdd3c34",
      "metadata": {
        "id": "5cdd3c34"
      },
      "source": [
        "그러면 model, param_grid와 함께 다른 여러 가지 인자를 넣어서 GridSearchCV를 수행할 수 있습니다!  \n",
        "\n",
        "다음과 같이 GridSearchCV를 이용해서 grid_model 모델을 초기화하고,  \n",
        "train과 y 데이터로 모델을 간단히 학습시키면 param_grid 내의 모든 하이퍼 파라미터의 조합에 대해 실험이 완료됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51d470fd",
      "metadata": {
        "id": "51d470fd"
      },
      "outputs": [],
      "source": [
        "grid_model = GridSearchCV(model, param_grid=param_grid, \\\n",
        "                        scoring='neg_mean_squared_error', \\\n",
        "                        cv=5, verbose=1, n_jobs=5)\n",
        "\n",
        "grid_model.fit(train, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9dcce26",
      "metadata": {
        "id": "d9dcce26"
      },
      "source": [
        "grid_model.fit 함수를 통해서 4가지 조합에 대한 실험을 모두 마쳤습니다.\n",
        "\n",
        "실험에 대한 결과는 다음과 같이 grid_model.cv_results_ 안에 저장됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2979cc01",
      "metadata": {
        "id": "2979cc01"
      },
      "outputs": [],
      "source": [
        "grid_model.cv_results_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cdd4cee",
      "metadata": {
        "id": "1cdd4cee"
      },
      "source": [
        "정보가 너무 많아서 눈에 잘 들어오지 않는군요. 우리는 원하는 값만 정제해서 확인하도록 하겠습니다.  \n",
        "\n",
        "우리가 관심 있는 정보는 어떤 파라미터 조합일 때 점수가 어떻게 나오게 되는지에 관한 것이겠죠.  \n",
        "파라미터 조합은 위 딕셔너리 중 params에, 각각에 대한 테스트 점수는 mean_test_score에 저장되어 있습니다.  \n",
        "\n",
        "이 두 정보만 빼내어 보겠습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c007c48",
      "metadata": {
        "id": "2c007c48"
      },
      "outputs": [],
      "source": [
        "params = grid_model.cv_results_['params']\n",
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ebde4fa",
      "metadata": {
        "id": "3ebde4fa"
      },
      "outputs": [],
      "source": [
        "score = grid_model.cv_results_['mean_test_score']\n",
        "score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5d3132e",
      "metadata": {
        "id": "a5d3132e"
      },
      "source": [
        "params에는 각 파라미터의 조합이, score에는 각 조합에 대한 점수가 들어가 있군요.  \n",
        "\n",
        "이제 이 둘만 가지고 데이터 프레임을 만들고 최적의 성능을 내는 하이퍼 파라미터의 조합을 찾아봅시다.  \n",
        "\n",
        "다음과 같은 형태의 데이터 프레임을 출력하는 코드를 작성해 보세요.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60948691",
      "metadata": {
        "id": "60948691"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame(params)\n",
        "results['score'] = score\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7805589e",
      "metadata": {
        "id": "7805589e"
      },
      "source": [
        "자, 그런데 여기에서 한 가지 의문이 드는 것이 있습니다. 왜 점수는 음수일까요?!\n",
        "\n",
        "그 이유는 바로 GridSearchCV을 초기화 한 코드에 힌트가 있습니다.  \n",
        "우리가 위에서 GridSearchCV로 grid_model 모델을 초기화할 때, scoring 인자에 무엇을 넣었는지 기억하시나요?\n",
        "GridSearchCV를 사용할 때에는 이 외에도 다양한 점수 체계(scoring)를 사용할 수 있습니다.  \n",
        "그에 대한 정보는 다음 페이지에서 확인하겠습니다.  \n",
        "\n",
        ">[사이킷런 - The scoring parameter: defining model evaluation rules](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n",
        "\n",
        "우리는 Regression 문제를 풀고 있기 때문에 그에 알맞은 성능 평가 지표를 사용하였습니다.  \n",
        "neg_mean_squared_error를 사용했기 때문에 점수가 음수로 표현되는 것이죠!\n",
        "\n",
        "아래와 같은 간단한 변환 함수로 RMSE 점수를 볼 수 있도록 하겠습니다.  \n",
        "음수로 된 MSE였으니, -1을 곱해주고 np.sqrt로 루트 연산을 해주면 되겠죠."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a9ebc36",
      "metadata": {
        "id": "6a9ebc36"
      },
      "outputs": [],
      "source": [
        "results['RMSE'] = np.sqrt(-1 * results['score'])\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3df3fc3b",
      "metadata": {
        "id": "3df3fc3b"
      },
      "source": [
        "앗, 하지만 아직도 위에서 보았던 10만 단위의 RMSE와는 값의 크기가 아주 다른 것 같습니다.  \n",
        "\n",
        "그 이유는 price에 있습니다. 위에서 우리는 price의 분포가 한쪽으로 치우쳐져 있는 것을 보고 log 변환을 했었죠.  \n",
        "그 후 RMSE 값을 계산하기 위한 함수에서는 np.expm1 함수를 활용해 다시 원래대로 복원한 후 RMSE 값을 계산했습니다.  \n",
        "\n",
        "하지만 그리드 탐색을 하면서는 np.expm1()으로 변환하는 과정이 없었기 때문에 log 변환되어 있는 price 데이터에서 손실함수값을 계산한 것이죠.  \n",
        "따라서 사실, 위의 데이터 프레임에 나타난 값은 정확히 말하면 RMSE가 아니라 RMSLE, 즉 Root Mean Squared Log Error 입니다.  \n",
        "log를 취한 값에서 RMSE를 구했다는 뜻이죠!\n",
        "\n",
        "이에 맞게 컬럼의 이름을 RMSLE로 변환해 주도록 하겠습니다. 판다스에서 컬럼의 이름 변환은 rename으로 할 수 있습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54e2d340",
      "metadata": {
        "id": "54e2d340"
      },
      "outputs": [],
      "source": [
        "results = results.rename(columns={'RMSE': 'RMSLE'})\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49704526",
      "metadata": {
        "id": "49704526"
      },
      "source": [
        "이제 마지막 할 일은 RMSLE가 낮은 순서대로 정렬하는 것뿐이군요! sort_values로 간단히 할 수 있습니다.  \n",
        "공식 문서를 참고해 직접 작성해 보세요.  \n",
        "\n",
        ">[pandas.DataFrame.sort_values](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78594473",
      "metadata": {
        "id": "78594473"
      },
      "outputs": [],
      "source": [
        "results = results.sort_values('RMSLE')\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1291e421",
      "metadata": {
        "id": "1291e421"
      },
      "source": [
        "복잡한 과정이었습니다. 지금까지 그리드 탐색을 수행하고 그 결과를 깔끔하게 확인했습니다!  \n",
        "이 과정을 하나의 함수로 만들어서 앞으로는 간결한 코드로 진행하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a1e46cd",
      "metadata": {
        "id": "9a1e46cd"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "다음과 같은 과정을 진행할 수 있는 `my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5)` 함수를 구현해 보세요.\n",
        "\n",
        "1. GridSearchCV 모델로 `model`을 초기화합니다.\n",
        "2. 모델을 fitting 합니다.\n",
        "3. params, score에 각 조합에 대한 결과를 저장합니다.\n",
        "4. 데이터 프레임을 생성하고, RMSLE 값을 추가한 후 점수가 높은 순서로 정렬한 `results`를 반환합니다.\n",
        "\"\"\"\n",
        "def my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5):\n",
        "    # GridSearchCV 모델로 초기화\n",
        "    grid_model = GridSearchCV(model, param_grid=param_grid, scoring='neg_mean_squared_error', \\\n",
        "                              cv=5, verbose=verbose, n_jobs=n_jobs)\n",
        "\n",
        "    # 모델 fitting\n",
        "    grid_model.fit(train, y)\n",
        "\n",
        "    # 결과값 저장\n",
        "    params = grid_model.cv_results_['params']\n",
        "    score = grid_model.cv_results_['mean_test_score']\n",
        "\n",
        "    # 데이터 프레임 생성\n",
        "    results = pd.DataFrame(params)\n",
        "    results['score'] = score\n",
        "\n",
        "    # RMSLE 값 계산 후 정렬\n",
        "    results['RMSLE'] = np.sqrt(-1 * results['score'])\n",
        "    results = results.sort_values('RMSLE')\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c54da6f",
      "metadata": {
        "id": "0c54da6f"
      },
      "source": [
        "## 12. 랭킹을 올리고 싶다면? (4) 제출하는 것도, 빠르고 깔끔하게!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2a11fbd",
      "metadata": {
        "id": "e2a11fbd"
      },
      "source": [
        "이제 실험에 대한 준비는 모두 끝났습니다! 실험을 통해 좋은 결과를 내는 모델을 찾았다면 제출을 해봐야겠죠.  \n",
        "제출 과정 또한 하나의 함수로 깔끔하게 진행하겠습니다.  \n",
        "\n",
        "먼저 위에서 만들어놓은 my_GridSearch() 함수로 간단한 그리드 탐색을 해보겠습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "026beba7",
      "metadata": {
        "id": "026beba7"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [1, 10],\n",
        "}\n",
        "\n",
        "model = LGBMRegressor(random_state=random_state)\n",
        "my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57ca7315",
      "metadata": {
        "id": "57ca7315"
      },
      "source": [
        "가장 좋은 조합은 max_depth=10, n_estimators=100 이군요.  \n",
        "해당 모델로 학습을 해서 예측값인 submission.csv 파일을 만들어서 제출해보겠습니다.  \n",
        "\n",
        "먼저 해당 파라미터로 구성된 모델을 준비하고, 학습 후 예측 결과를 생성합니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dcc9dd3",
      "metadata": {
        "id": "6dcc9dd3"
      },
      "outputs": [],
      "source": [
        "model = LGBMRegressor(max_depth=10, n_estimators=100, random_state=random_state)\n",
        "model.fit(train, y)\n",
        "prediction = model.predict(test)\n",
        "prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed348ed3",
      "metadata": {
        "id": "ed348ed3"
      },
      "source": [
        "앗, 예측 결과에 np.expm1()을 씌워서 다시 원래 스케일로 되돌리는 것도 잊으면 안 되겠죠!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7efa9990",
      "metadata": {
        "id": "7efa9990"
      },
      "outputs": [],
      "source": [
        "prediction = np.expm1(prediction)\n",
        "prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f226ce4a",
      "metadata": {
        "id": "f226ce4a"
      },
      "source": [
        "이제 위에서 했던 대로 sample_submission.csv 파일을 가져와보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9925a0f5",
      "metadata": {
        "id": "9925a0f5"
      },
      "outputs": [],
      "source": [
        "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
        "\n",
        "submission_path = join(data_dir, 'sample_submission.csv')\n",
        "submission = pd.read_csv(submission_path)\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "101ffaec",
      "metadata": {
        "id": "101ffaec"
      },
      "source": [
        "위의 데이터프레임에 우리의 모델이 예측한 값을 덮어씌우면 제출할 데이터가 완성되겠죠!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ada1515",
      "metadata": {
        "id": "9ada1515"
      },
      "outputs": [],
      "source": [
        "submission['price'] = prediction\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e80e779",
      "metadata": {
        "id": "7e80e779"
      },
      "source": [
        "위의 데이터를 csv 파일로 저장하겠습니다.  \n",
        "\n",
        "단, 앞으로는 많은 실험이 있을 예정이니 파일 이름에 모델의 종류와 위에서 확인했던 RMSLE 값을 넣어주면 제출 파일들이 깔끔하게 관리될 것입니다!  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abedd8ea",
      "metadata": {
        "id": "abedd8ea"
      },
      "outputs": [],
      "source": [
        "submission_csv_path = '{}/submission_{}_RMSLE_{}.csv'.format(data_dir, 'lgbm', '0.164399')\n",
        "submission.to_csv(submission_csv_path, index=False)\n",
        "print(submission_csv_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05e8b7a4",
      "metadata": {
        "id": "05e8b7a4"
      },
      "source": [
        "위의 과정들도 하나의 함수로 정리해두면 사용하기 편리하겠죠."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8089e652",
      "metadata": {
        "id": "8089e652"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "아래의 과정을 수행하는 `save_submission(model, train, y, test, model_name, rmsle)` 함수를 구현해 주세요.\n",
        "1. 모델을 `train`, `y`로 학습시킵니다.\n",
        "2. `test`에 대해 예측합니다.\n",
        "3. 예측값을 `np.expm1`으로 변환하고, `submission_model_name_RMSLE_100000.csv` 형태의 `csv` 파일을 저장합니다.\n",
        "\"\"\"\n",
        "\n",
        "def save_submission(model, train, y, test, model_name, rmsle=None):\n",
        "    model.fit(train, y)\n",
        "    prediction = model.predict(test)\n",
        "    prediction = np.expm1(prediction)\n",
        "    data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
        "    submission_path = join(data_dir, 'sample_submission.csv')\n",
        "    submission = pd.read_csv(submission_path)\n",
        "    submission['price'] = prediction\n",
        "    submission_csv_path = '{}/submission_{}_RMSLE_{}.csv'.format(data_dir, model_name, rmsle)\n",
        "    submission.to_csv(submission_csv_path, index=False)\n",
        "    print('{} saved!'.format(submission_csv_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c574cc36",
      "metadata": {
        "id": "c574cc36"
      },
      "source": [
        "이 함수를 사용한다면 다음 한 줄로 모델을 학습시킨 후 예측 결과를 저장할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "202e1a4f",
      "metadata": {
        "id": "202e1a4f"
      },
      "outputs": [],
      "source": [
        "save_submission(model, train, y, test, 'lgbm', rmsle='0.164399')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c309bfda",
      "metadata": {
        "id": "c309bfda"
      },
      "source": [
        "여기까지 모든 도구는 준비되었습니다. 이제, 여러분이 직접 리더보드를 정복할 시간입니다!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}