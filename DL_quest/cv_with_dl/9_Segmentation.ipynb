{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CAVASOL/aiffel_quest/blob/main/DL_quest/cv_with_dl/9_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0b004c7",
      "metadata": {
        "id": "f0b004c7"
      },
      "source": [
        "## Segmentation\n",
        "\n",
        "**학습 목표**\n",
        "\n",
        "* Segmentation의 목표를 이해하고, semantic segmentation과 instance segmentation의 차이점을 설명할 수 있습니다.\n",
        "* U-Net 모델을 직접 코드로 구현해 보고 다시 한번 Semantic Segmentation 이해하고 Encoder-Decoder 구조를 알아봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc5acec",
      "metadata": {
        "id": "dfc5acec"
      },
      "source": [
        "**Q. Segmentation는 어떤 task 인지 설명해 보세요.**\n",
        "```\n",
        "이미지를 픽셀 단위로 나누어서 특정 픽셀이 무엇을 지칭하는지를 파악\n",
        "```\n",
        "\n",
        "**Q. Semantic Segmentation과 Instance Segmentation 어떤 차이가 있는지 각 개념을 설명해 보세요.**\n",
        "```\n",
        "semantic segmentation은 하나의 이미지 안에 들어있는 객체의 종류(object category)를 픽셀 단위로 찾습니다. 반면 instance segmentation은 하나의 이미지 안에 들어있는 객체의 개체(object instance)를 픽셀 단위로 찾습니다.\n",
        "\n",
        "어떤 Segmentation 종류이든 이미지 데이터를 segmentation 모델 학습에 사용하기 위해서는 픽셀 하나하나 labeling을 해줘야 하기 때문에 데이터셋 구축이 어렵고, 따라서 data augmentation이 매우 중요합니다.\n",
        "```\n",
        "\n",
        "**Q. Semantic segmentation의 목표는 무엇인지 설명해 보세요.**\n",
        "```\n",
        "Semantic segmentation의 목표는 이미지가 주어졌을 때, 픽셀 단위로 Classification을 수행하여 이미지와 동일한 높이와 너비를 가진 Segmentation map을 생성하는 것입니다.\n",
        "```\n",
        "\n",
        "**Q. U-Net 모델은 Encoder-Decoder 모델에 skip connection을 추가한 모델이라고 할 수 있습니다. U-Net 모델 구조 중 Encoder에 해당하는 Contracting path 부분의 특징을 설명해 보세요.**\n",
        "```\n",
        "convolution 연산으로 이루어진 부분이며 CNN 구조와 유사하다는 특징이 있습니다. 또한 3x3 kernel을 사용하는 VGG 모델과 매우 유사하며 입력 이미지가 가지고 있는 context 정보를 추출합니다. U-Net 모델 구조 중 Encoder에 해당하며 convolution 연산을 하기 때문에 이미지의 위치에 대한 정보가 차츰 사라집니다.\n",
        "```\n",
        "\n",
        "**Q. U-Net 모델 구조 중 Decoder에 해당하는 Expanding (Expansive) path 부분의 특징을 설명해 보세요.**\n",
        "```\n",
        "up-convolution 연산으로 이루어진 부분이며 low resolution의 latent representation을 high resolution으로 변형합니다. 또한 Encoder 부분인 contracting path에서 만들어진 feature map을 cropping 한 결과물이 concatenation 됩니다. U-Net 모델 구조 중 Decoder에 해당하며 up-convolution 연산을 하기 때문에 원본 이미지가 가지고 있었던 위치 정보가 복원됩니다.\n",
        "```\n",
        "\n",
        "**Q. U-Net 모델은 Encoding 부분에서 이미지를 압축하며 정보의 손실이 발생합니다. 이를 보완하기 위해 어떤 방법을 사용하는지, 그 방법의 특징은 무엇인 설명해 보세요.**\n",
        "```\n",
        "Encoding 과정에서의 정보 손실을 보충하기 위해 skip connection을 사용합니다. 이것은 Decoding 단계에서, 저차원의 정보와 고차원의 정보도 함께 이용하기 위한 방법입니다.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d125710",
      "metadata": {
        "id": "0d125710"
      },
      "source": [
        "### U-Net Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7e3882f",
      "metadata": {
        "id": "e7e3882f",
        "outputId": "564872cc-4d7b-44b1-94e7-1f10d757cb2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: graphviz in /opt/conda/lib/python3.9/site-packages (0.20.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pydot in /opt/conda/lib/python3.9/site-packages (1.4.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /opt/conda/lib/python3.9/site-packages (from pydot) (3.0.7)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install graphviz\n",
        "!pip install pydot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "187e10d6",
      "metadata": {
        "id": "187e10d6"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17652a87",
      "metadata": {
        "id": "17652a87"
      },
      "outputs": [],
      "source": [
        "inputs = layers.Input(shape=(572, 572, 1))\n",
        "\n",
        "# Contracting path 시작\n",
        "# [1]\n",
        "conv0 = layers.Conv2D(64, activation='relu', kernel_size = 3)(inputs)\n",
        "conv1 = layers.Conv2D(64, activation='relu', kernel_size=3)(conv0)  # Skip connection으로 Expanding path로 이어질 예정\n",
        "conv2 = layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))(conv1)\n",
        "\n",
        "# Q.위 이미지를 보고 [2]번 블럭을 구현해 봅시다. (filter 수를 주의하세요!)\n",
        "conv3 = layers.Conv2D(128, activation='relu', kernel_size=3)(conv2)\n",
        "conv4 = layers.Conv2D(128, activation='relu', kernel_size=3)(conv3)\n",
        "conv5 = layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))(conv4)\n",
        "\n",
        "# Q.위 이미지를 보고 [3]번 블럭을 구현해 봅시다. (filter 수를 주의하세요!)\n",
        "conv6 = layers.Conv2D(256, activation='relu', kernel_size=3)(conv5)\n",
        "conv7 = layers.Conv2D(256, activation='relu', kernel_size=3)(conv6)\n",
        "conv8 = layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))(conv7)\n",
        "\n",
        "# Q.위 이미지를 보고 [4]번 블럭을 구현해 봅시다. (filter 수를 주의하세요!)\n",
        "conv9 = layers.Conv2D(512, activation='relu', kernel_size=3)(conv8)\n",
        "conv10 = layers.Conv2D(512, activation='relu', kernel_size=3)(conv9)\n",
        "conv11 = layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))(conv10)\n",
        "\n",
        "# [5]\n",
        "conv12 = layers.Conv2D(1024, activation='relu', kernel_size=3)(conv11)\n",
        "conv13 = layers.Conv2D(1024, activation='relu', kernel_size=3)(conv12)\n",
        "# Contracting path 끝\n",
        "\n",
        "# Expanding path 시작\n",
        "# [6]\n",
        "trans01 = layers.Conv2DTranspose(512, kernel_size=2, strides=(2, 2), activation='relu')(conv13)\n",
        "crop01 = layers.Cropping2D(cropping=(4, 4))(conv10)\n",
        "concat01 = layers.concatenate([trans01, crop01], axis=-1)\n",
        "\n",
        "# [7]\n",
        "conv14 = layers.Conv2D(512, activation='relu', kernel_size=3)(concat01)\n",
        "conv15 = layers.Conv2D(512, activation='relu', kernel_size=3)(conv14)\n",
        "trans02 = layers.Conv2DTranspose(256, kernel_size=2, strides=(2, 2), activation='relu')(conv15)\n",
        "\n",
        "# [8]\n",
        "crop02 = layers.Cropping2D(cropping=(16, 16))(conv7)\n",
        "concat02 = layers.concatenate([trans02, crop02], axis=-1)\n",
        "\n",
        "# Q.위 이미지를 보고 [9]번 블럭을 구현해 봅시다. (filter 수를 주의하세요!)\n",
        "conv16 = layers.Conv2D(256, activation='relu', kernel_size=3)(concat02)\n",
        "conv17 = layers.Conv2D(256, activation='relu', kernel_size=3)(conv16)\n",
        "trans03 = layers.Conv2DTranspose(128, kernel_size=2, strides=(2, 2), activation='relu')(conv17)\n",
        "\n",
        "# Q.위 이미지를 보고 [10]번 블럭을 구현해 봅시다. (cropping=(40, 40))\n",
        "crop03 = layers.Cropping2D(cropping=(40, 40))(conv4)\n",
        "concat03 = layers.concatenate([trans03, crop03], axis=-1)\n",
        "\n",
        "# Q.위 이미지를 보고 [11]번 블럭을 구현해 봅시다. (filter 수를 주의하세요!)\n",
        "conv18 = layers.Conv2D(128, activation='relu', kernel_size=3)(concat03)\n",
        "conv19 = layers.Conv2D(128, activation='relu', kernel_size=3)(conv18)\n",
        "trans04 = layers.Conv2DTranspose(64, kernel_size=2, strides=(2, 2), activation='relu')(conv19)\n",
        "\n",
        "# Q.위 이미지를 보고 [12]번 블럭을 구현해 봅시다. (cropping=(88, 88))\n",
        "crop04 = layers.Cropping2D(cropping=(88, 88))(conv1)\n",
        "concat04 = layers.concatenate([trans04, crop04], axis=-1)\n",
        "\n",
        "# [13]\n",
        "conv20 = layers.Conv2D(64, activation='relu', kernel_size=3)(concat04)\n",
        "conv21 = layers.Conv2D(64, activation='relu', kernel_size=3)(conv20)\n",
        "# Expanding path 끝\n",
        "\n",
        "outputs = layers.Conv2D(2, kernel_size=1)(conv21)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"u-netmodel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "053f6dff",
      "metadata": {
        "id": "053f6dff",
        "outputId": "bf4018fa-2871-4264-ea2d-00ac3c954809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"u-netmodel\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 572, 572, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 570, 570, 64) 640         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 568, 568, 64) 36928       conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 284, 284, 64) 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 282, 282, 128 73856       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 280, 280, 128 147584      conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 140, 140, 128 0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 138, 138, 256 295168      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 136, 136, 256 590080      conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 68, 68, 256)  0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 66, 66, 512)  1180160     max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 64, 64, 512)  2359808     conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 30, 30, 1024) 4719616     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 28, 28, 1024) 9438208     conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 56, 56, 512)  2097664     conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "cropping2d (Cropping2D)         (None, 56, 56, 512)  0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 56, 56, 1024) 0           conv2d_transpose[0][0]           \n",
            "                                                                 cropping2d[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 54, 54, 512)  4719104     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 52, 52, 512)  2359808     conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 104, 104, 256 524544      conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "cropping2d_1 (Cropping2D)       (None, 104, 104, 256 0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 104, 104, 512 0           conv2d_transpose_1[0][0]         \n",
            "                                                                 cropping2d_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 102, 102, 256 1179904     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 100, 100, 256 590080      conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 200, 200, 128 131200      conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "cropping2d_2 (Cropping2D)       (None, 200, 200, 128 0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 200, 200, 256 0           conv2d_transpose_2[0][0]         \n",
            "                                                                 cropping2d_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 198, 198, 128 295040      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 196, 196, 128 147584      conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 392, 392, 64) 32832       conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "cropping2d_3 (Cropping2D)       (None, 392, 392, 64) 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 392, 392, 128 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 cropping2d_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 390, 390, 64) 73792       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 388, 388, 64) 36928       conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 388, 388, 2)  130         conv2d_17[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 31,030,658\n",
            "Trainable params: 31,030,658\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e67d23b8",
      "metadata": {
        "id": "e67d23b8"
      },
      "outputs": [],
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes= True, show_layer_names=True, dpi=8192).create(prog='dot', format='svg'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69395f07",
      "metadata": {
        "id": "69395f07"
      },
      "source": [
        "### Transposed Convolution Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fdbbbf4",
      "metadata": {
        "id": "0fdbbbf4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "590483b7",
      "metadata": {
        "id": "590483b7"
      },
      "outputs": [],
      "source": [
        "# input data\n",
        "\n",
        "X = np.asarray([[1, 2], [3, 4]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb4a8e54",
      "metadata": {
        "id": "fb4a8e54",
        "outputId": "022c103d-33b1-411a-c52b-bd160c919c6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n",
            "(2, 2)\n"
          ]
        }
      ],
      "source": [
        "print(X)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88fc31db",
      "metadata": {
        "id": "88fc31db"
      },
      "outputs": [],
      "source": [
        "X = X.reshape((1, 2, 2, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12377ba4",
      "metadata": {
        "id": "12377ba4",
        "outputId": "01519f26-1469-4986-80ea-12fadbd51e45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[[1]\n",
            "   [2]]\n",
            "\n",
            "  [[3]\n",
            "   [4]]]]\n",
            "(1, 2, 2, 1)\n"
          ]
        }
      ],
      "source": [
        "print(X)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "249011b3",
      "metadata": {
        "id": "249011b3"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2DTranspose(1, (1, 1), strides=(2, 2), input_shape=(2, 2, 1))) # Conv2DTranspos layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "281ef085",
      "metadata": {
        "id": "281ef085"
      },
      "outputs": [],
      "source": [
        "weights = [np.asarray([[[[1]]]]), np.asarray([1])] # weight = 1, bias = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49c803a3",
      "metadata": {
        "id": "49c803a3",
        "outputId": "d37fb0a9-539c-48f4-e7e9-e28d6ae93439"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[[[1]]]]), array([1])]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d851ba96",
      "metadata": {
        "id": "d851ba96"
      },
      "outputs": [],
      "source": [
        "model.set_weights(weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeb4a967",
      "metadata": {
        "id": "aeb4a967",
        "outputId": "d5944a3c-919d-465b-ea84-f3eca97e0fa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2. 1. 3. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [4. 1. 5. 1.]\n",
            " [1. 1. 1. 1.]]\n"
          ]
        }
      ],
      "source": [
        "yhat = model.predict(X)\n",
        "yhat = yhat.reshape((4, 4))\n",
        "print(yhat)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}