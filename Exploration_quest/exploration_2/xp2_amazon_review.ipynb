{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CAVASOL/aiffel_quest/blob/main/Exploration_quest/exploration_2/xp2_amazon_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20be7aba",
      "metadata": {
        "id": "20be7aba"
      },
      "source": [
        "## Exploration 2. \bNatural Language Process\n",
        "\n",
        "**Goal**\n",
        "\n",
        "* `Extractive/Abstractive summarization` 이해할 수 있습니다.\n",
        "* 단어장 크기를 줄이는 다양한 text normalization 적용할 수 있습니다.\n",
        "* `seq2seq`의 성능을 Up시키는 `Attention Mechanism` 적용할 수 있습니다.\n",
        "\n",
        "**Index**\n",
        "\n",
        "    1. Introduction\n",
        "    2. Text Summarization\n",
        "    3. Training text summarization\n",
        "    4. Prep Data\n",
        "    5. Data Preprocessing (1) Organizing data\n",
        "    6. Data Preprocessing (2) Divide training data and test data\n",
        "    7. Data Preprocessing (3) Integer encoding\n",
        "    8. Design Model\n",
        "    9. Training\n",
        "    10. Implementing the inference model\n",
        "    11. Test\n",
        "    12. Extractive Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13ecca10",
      "metadata": {
        "id": "13ecca10"
      },
      "source": [
        "### 2. Text Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3eda8593",
      "metadata": {
        "id": "3eda8593"
      },
      "source": [
        "**Q. RNN은 학습 데이터의 길이가 길어질수록 먼 과거의 정보를 현재에 전달하기 어렵다는 문제가 있습니다. 이 문제를 해결하기 위해 LSTM과 GRU가 등장했고, 나아가 Attention 메커니즘이 등장했지요. 이 문제의 이름은 무엇인가요?**\n",
        "```\n",
        "Long-Term Dependency 문제로 알려져 있습니다. RNN은 시퀀스 데이터를 처리하는 데 강력하지만, 학습 데이터의 길이가 길어질수록 먼 과거의 정보를 기억하고 전달하기 어려워지는 경향이 있습니다. 이로 인해 모델이 장기 의존성을 적절하게 학습하지 못하고 성능이 제한됩니다.\n",
        "```\n",
        "\n",
        "**Q. 텍스트마이닝 분야의 IDF 같은 지표를 활용해 문서 내 중요한 부분을 추출하고 그것을 요약문에 담는 방식을 썼을 때의 문제점은 무엇인가요?**\n",
        "```\n",
        "텍스트 요약에서 역문서빈도(IDF)나 다른 중요성 지표를 사용하는 방식은 일반적으로 중요한 단어나 구를 추출하여 요약문을 생성하는 데 활용됩니다. 그러나 이러한 방식에는 문맥의 부재 / 일관성 부족 / 의미의 손실 / 문서의 다양성 무시와 같은 문제점이 있을 수 있습니다.\n",
        "```\n",
        "\n",
        "**Q. 구글은 짧은 문장. 요약문을 생성하는 모델을 딥러닝을 통해 end-to-end으로 설계했어요. 구글 메일서비스의 Smart Reply 기능과 비슷한 딥러닝 기법으로 인코더와 디코더의 구조로 구성된 이 아키텍처의 이름은 무엇인가요?**\n",
        "```\n",
        "구글이 짧은 문장 요약 및 자동 회신 Smart Reply 과 관련하여 사용한 딥 러닝 아키텍처는 Seq2Seq, Sequence-to-Sequence 입니다. Seq2Seq는 주로 기계 번역에서 시작되었으며, 인코더 Encoder와 디코더 Decoder로 구성된 구조를 가지고 있습니다. Seq2Seq 아키텍처는 입력과 출력 시퀀스의 길이가 다를 수 있으며, 특히 가변 길이 시퀀스에 적합합니다. 이러한 구조는 자연어 처리 및 기타 시퀀스 변환 작업에서 널리 사용되고 있습니다. Smart Reply와 같은 응용 프로그램에서는 짧은 문장에 대한 요약이나 자동 회신을 생성하는 데 활용될 수 있습니다.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "132d19f6",
      "metadata": {
        "id": "132d19f6"
      },
      "source": [
        "### 3. Training text summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95a5a460",
      "metadata": {
        "id": "95a5a460"
      },
      "source": [
        "**Q. SOS 토큰과 EOS 토큰을 사용하는 이유가 무엇인가요?**\n",
        "```\n",
        "SOS 토큰은 디코더에 입력되는 첫 번째 토큰으로 사용되며, 디코더가 문장 생성을 시작하도록 합니다. EOS 토큰은 디코더가 문장 생성을 끝내야 할 때 사용되며, 디코더가 문장 생성을 멈추게 합니다. 즉, SOS 토큰과 EOS 토큰은 seq2seq 모델이 문장 생성을 시작하고 끝내는 시점을 알려주는 역할을 합니다.\n",
        "```\n",
        "\n",
        "**Q. Attention 모델과 seq2seq 모델의 차이점이 무엇인가요?**\n",
        "```\n",
        "Attention 모델에서는 모든 스텝의 hidden state 정보가 컨텍스트 벡터에 반영됩니다. 그리고 디코더가 출력을 생성할 때, 컨텍스트 벡터에 반영된 각각의 hidden state에 대한 가중치 값은 디코더의 현재 스텝이 어딘지에 따라 다르게 반영됩니다.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f0fab1d",
      "metadata": {
        "id": "5f0fab1d"
      },
      "source": [
        "### 4. Prep Data\n",
        "\n",
        "텍스트 요약 모델 학습에 사용할 데이터셋은 Kaggle에서 제공된 [Amazon Product Reviews Dataset](https://www.kaggle.com/datasets/yasserh/amazon-product-reviews-dataset) 입니다. 이번 실습에서는 `NLTK`의 불용어 `stopwords` 를 사용할 거에요. NLTK는 Natural Language Toolkit의 축약어로 영어 기호, 통계, 자연어 처리를 위한 라이브러리 입니다. 자 그럼, NLTK 패키지에서 불용어 사전을 다운로드 하고, 데이터 전처리를 위한 나머지 패키지도 함께 설치할까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6222cb41",
      "metadata": {
        "id": "6222cb41",
        "outputId": "4fb66f39-35a3-4d07-cdb8-709ca4557c46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Heya\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from bs4 import BeautifulSoup\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import urllib.request\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
        "\n",
        "print(\"Heya\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6107a852",
      "metadata": {
        "id": "6107a852"
      },
      "source": [
        "다운로드 받은 데이터 `Reviews.csv` 는 총 `568,454` 개의 샘플을 가지고 있습니다. 간단히 `10만 개`의 샘플만 사용해 볼게요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f004281",
      "metadata": {
        "id": "5f004281",
        "outputId": "afb61f69-1ac0-43ac-dc7a-ac179848fcca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 샘플수 : 100000\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/news_summarization/data/Reviews.csv\", nrows=100000)\n",
        "print('전체 샘플수 :', (len(data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f1dbb0b",
      "metadata": {
        "id": "9f1dbb0b"
      },
      "source": [
        "출력된 샘플 수를 보면 총 10만 개의 샘플이 잘 불러와진 것을 확인할 수 있습니다. 이 중에 5개만 출력해 볼까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "875c6dfe",
      "metadata": {
        "id": "875c6dfe",
        "outputId": "c8c89faf-ce72-418c-8ceb-114232292c77"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id   ProductId          UserId                      ProfileName  \\\n",
              "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
              "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
              "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
              "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
              "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
              "\n",
              "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
              "0                     1                       1      5  1303862400   \n",
              "1                     0                       0      1  1346976000   \n",
              "2                     1                       1      4  1219017600   \n",
              "3                     3                       3      2  1307923200   \n",
              "4                     0                       0      5  1350777600   \n",
              "\n",
              "                 Summary                                               Text  \n",
              "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
              "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
              "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
              "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
              "4            Great taffy  Great taffy at a great price.  There was a wid...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59c9de3a",
      "metadata": {
        "id": "59c9de3a"
      },
      "source": [
        "열이 너무 많아서 보기에 조금 까다롭죠? 사실 전체 데이터 중 `Summary` 열과 `Text` 열만 훈련에 사용할 거에요. 다시 출력해 볼게요.\n",
        "\n",
        "**Q. 데이터프레임 data의 Text와 Summary 컬럼의 데이터만 남기는 코드를 작성하세요.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c42ed44",
      "metadata": {
        "id": "3c42ed44",
        "outputId": "a719d52d-7380-47a4-dac3-91fca1e3cf21"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>87792</th>\n",
              "      <td>Stash Chamomile Herbal Tea is tea bags with dr...</td>\n",
              "      <td>A ginormous box of 1,000 tea bags</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48798</th>\n",
              "      <td>Love this freezer tray.  I set it on the count...</td>\n",
              "      <td>Perfect freezer tray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51338</th>\n",
              "      <td>Stevia is kind of funny. Brands and batches va...</td>\n",
              "      <td>Bad batch of Stevia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38762</th>\n",
              "      <td>Product, was a great Christmas gift, and well ...</td>\n",
              "      <td>popcorn 3 pack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1173</th>\n",
              "      <td>Well one of my friends asked for a really big ...</td>\n",
              "      <td>Gummy Bears</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13633</th>\n",
              "      <td>Tastes like pine needles!!! I've had other ear...</td>\n",
              "      <td>YUCK!!! Buy another variety!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36593</th>\n",
              "      <td>I have used the noodle in several recipes and ...</td>\n",
              "      <td>Miracle Noodle=WOW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3147</th>\n",
              "      <td>My family and I all agree that Hodgson Mill Po...</td>\n",
              "      <td>Potato Bread Winner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31524</th>\n",
              "      <td>Like many others, I've been so addicted to Dun...</td>\n",
              "      <td>Very delicious!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30418</th>\n",
              "      <td>I was so excited to order and receive this cof...</td>\n",
              "      <td>No pumpkin flavor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65935</th>\n",
              "      <td>Our dogs love these treats, they are small and...</td>\n",
              "      <td>our dogs love these treats!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98504</th>\n",
              "      <td>If you are looking for an energy bar with genu...</td>\n",
              "      <td>Energy Bar with Nutritional Value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47171</th>\n",
              "      <td>I expected the coffee would arrive in a vacuum...</td>\n",
              "      <td>not vacume packed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59877</th>\n",
              "      <td>I recently started the Optifast diet, and it's...</td>\n",
              "      <td>Big Help in Weight Loss!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14332</th>\n",
              "      <td>These crackers are horrible. They taste burnt ...</td>\n",
              "      <td>Taste Burnt!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Text  \\\n",
              "87792  Stash Chamomile Herbal Tea is tea bags with dr...   \n",
              "48798  Love this freezer tray.  I set it on the count...   \n",
              "51338  Stevia is kind of funny. Brands and batches va...   \n",
              "38762  Product, was a great Christmas gift, and well ...   \n",
              "1173   Well one of my friends asked for a really big ...   \n",
              "13633  Tastes like pine needles!!! I've had other ear...   \n",
              "36593  I have used the noodle in several recipes and ...   \n",
              "3147   My family and I all agree that Hodgson Mill Po...   \n",
              "31524  Like many others, I've been so addicted to Dun...   \n",
              "30418  I was so excited to order and receive this cof...   \n",
              "65935  Our dogs love these treats, they are small and...   \n",
              "98504  If you are looking for an energy bar with genu...   \n",
              "47171  I expected the coffee would arrive in a vacuum...   \n",
              "59877  I recently started the Optifast diet, and it's...   \n",
              "14332  These crackers are horrible. They taste burnt ...   \n",
              "\n",
              "                                 Summary  \n",
              "87792  A ginormous box of 1,000 tea bags  \n",
              "48798               Perfect freezer tray  \n",
              "51338                Bad batch of Stevia  \n",
              "38762                     popcorn 3 pack  \n",
              "1173                         Gummy Bears  \n",
              "13633     YUCK!!! Buy another variety!!!  \n",
              "36593                 Miracle Noodle=WOW  \n",
              "3147                 Potato Bread Winner  \n",
              "31524                   Very delicious!!  \n",
              "30418                  No pumpkin flavor  \n",
              "65935        our dogs love these treats!  \n",
              "98504  Energy Bar with Nutritional Value  \n",
              "47171                  not vacume packed  \n",
              "59877           Big Help in Weight Loss!  \n",
              "14332                       Taste Burnt!  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = data[['Text', 'Summary']]\n",
        "data.head()\n",
        "\n",
        "#랜덤한 15개 샘플 출력\n",
        "data.sample(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3e4ee89",
      "metadata": {
        "id": "b3e4ee89"
      },
      "source": [
        "Text 열의 내용을 요약한 것이 Summary 열이에요.  \n",
        "여기서는 인공 신경망을 통해 Text 시퀀스를 입력받으면, Summary 시퀀스를 예측하도록 인공 신경망을 훈련시킬 거예요.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "441a7dd5",
      "metadata": {
        "id": "441a7dd5"
      },
      "source": [
        "### 5. Data Preprocessing (1) Organizing data\n",
        "\n",
        "**중복 샘플과 NULL 값이 존재하는 샘플 제거**\n",
        "\n",
        "우선 데이터의 중복 샘플 유무를 확인해 볼게요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c960f48f",
      "metadata": {
        "id": "c960f48f",
        "outputId": "b8bfeb3c-b651-4c06-91dc-0ccf72061468"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text 열에서 중복을 배제한 유일한 샘플의 수 : 88426\n",
            "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 72348\n"
          ]
        }
      ],
      "source": [
        "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Text'].nunique())\n",
        "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['Summary'].nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "017a90d2",
      "metadata": {
        "id": "017a90d2"
      },
      "source": [
        "중복을 제외하면 `Text에는 88,426개`, `Summary에는 72,348개` 의 유니크한 데이터가 존재해요. 사실 이 데이터의 Summary는 'Smelly'나 'Good Product'와 같이 아주 간단한 요약들도 많아서 Text가 달라도 Summary는 동일할 수 있어요. 하지만 Text 자체가 중복이 된 경우는 중복 샘플이므로 제거해야겠죠? 데이터 프레임의 `drop_duplicates()`를 사용하면, 손쉽게 중복 샘플을 제거할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afd75e8b",
      "metadata": {
        "id": "afd75e8b",
        "outputId": "70526942-dc79-41ce-e1de-e1bc7125e675"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 샘플수 : 88426\n"
          ]
        }
      ],
      "source": [
        "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다.\n",
        "\n",
        "data.drop_duplicates(subset = ['Text'], inplace=True)\n",
        "print('전체 샘플수 :', (len(data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67e93f46",
      "metadata": {
        "id": "67e93f46"
      },
      "source": [
        "중복이 제거되어 샘플 수가 `88,426`개가 되었어요. 그런데 만약 데이터 Null 값을 가지는 샘플이 있었다면? `drop_duplicates()`이 중복된 Null들을 지우겠지만 여전히 어딘가에 Null 값이 남아 있을 수 있어요. 데이터에 Null 값이 남아 있는지 `.isnull().sum()` 을 사용하여 확인해 볼게요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d077f7d",
      "metadata": {
        "id": "4d077f7d",
        "outputId": "cf57b02a-922e-433e-befb-172d2d11bd45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text       0\n",
            "Summary    1\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(data.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fa7300c",
      "metadata": {
        "id": "1fa7300c"
      },
      "source": [
        "Summary에 1개의 Null 값이 있네요? 데이터 프레임에서 Null을 제거하기 위해 `dropna()` 함수를 사용하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff46600a",
      "metadata": {
        "id": "ff46600a",
        "outputId": "c0987de7-2142-4654-afcb-5080068ab12b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 샘플수 : 88425\n"
          ]
        }
      ],
      "source": [
        "data.dropna(axis=0, inplace=True)\n",
        "print('전체 샘플수 :', (len(data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bac52f8c",
      "metadata": {
        "id": "bac52f8c"
      },
      "source": [
        "이제 전체 샘플 수는 `88,425개`입니다. 중복 샘플과 Null 값이 있는 샘플들을 제거하니 10만 개의 샘플 중 1만 개 이상의 샘플이 제거되었어요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "996f4eb7",
      "metadata": {
        "id": "996f4eb7"
      },
      "source": [
        "**텍스트 정규화와 불용어 제거**\n",
        "\n",
        "같은 의미인데도 다른 표현으로 쓰여 마치 다른 단어들처럼 간주되는 경우는 어떻게 처리할까요? 예를 들어서 `it'll` 은 `it will` 과 같고, `mustn't` 과 `must not` 은 사실 같은 표현이죠. 이런 경우 기계가 굳이 이들을 마치 다른 단어로 간주하게 해서 연산량을 늘리는 것보다는 기계 학습 전에 미리 같은 표현으로 정리하는 것이 기계의 연산량을 줄일 수 있답니다. 이러한 방법론을 텍스트 정규화 `text normalization` 라고 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18d7431e",
      "metadata": {
        "id": "18d7431e",
        "outputId": "dc1d8ae2-6acd-4c93-dc50-c04dc52d4d45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "정규화 사전의 수:  120\n"
          ]
        }
      ],
      "source": [
        "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "\n",
        "print(\"정규화 사전의 수: \", len(contractions))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51c7c950",
      "metadata": {
        "id": "51c7c950"
      },
      "source": [
        "일반적으로 텍스트에는 자주 등장하지만 자연어 처리를 할 때 실질적으로 별 도움이 되지 않는 단어들이 존재합니다. 이를 불용어 `stopwords` 라고 해요. 때로는 불용어를 제거하는 것이 자연어 처리의 성능을 높이는 방법일 수 있어요. NLTK에서 제공하는 불용어 리스트를 참조해 샘플에서 불용어를 제거할 거예요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51c61a95",
      "metadata": {
        "id": "51c61a95",
        "outputId": "34710a2e-bad9-4618-d5b9-1eaf97254c8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "불용어 개수 : 179\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ],
      "source": [
        "print('불용어 개수 :', len(stopwords.words('english') ))\n",
        "print(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e932db9d",
      "metadata": {
        "id": "e932db9d"
      },
      "source": [
        "NLTK에서 미리 정의하여 제공하고 있는 불용어는 총 `179개` 라는 것을 알 수 있습니다. 이를 사용하여 불용어를 제거하겠습니다. 이 작업 외에도 모든 영어 문자는 `소문자`로 만들고, 섞여 있는 `html 태그를 제거`하고, 정규 표현식을 통해 각종 `특수문자를 제거`해서 필요한 내용만 학습할 수 있도록 처리하겠습니다. NLTK를 이용해 불용어를 제거하는 파트가 있는데 이는 Text 전처리 시에서만 호출하고, 이미 상대적으로 문장 길이가 짧은 Summary를 전처리 할 때는 호출하지 않을 거에요. 추상적인 문장 요약의 결과문이 자연스러운 문장이 되려면 이 불용어들이 Summary에는 남아 있는 게 더 좋습니다. 이를 위해서  `remove_stopwords`와 `if` 문을 추가했어요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd9645f5",
      "metadata": {
        "id": "bd9645f5",
        "outputId": "76efa6dd-b675-4059-86da-161a6e1b2d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gotcha\n"
          ]
        }
      ],
      "source": [
        "# 데이터 전처리 함수\n",
        "\n",
        "def preprocess_sentence(sentence, remove_stopwords=True):\n",
        "    sentence = sentence.lower()\n",
        "    sentence = BeautifulSoup(sentence, \"lxml\").text\n",
        "    sentence = re.sub(r'\\([^)]*\\)', '', sentence)\n",
        "    sentence = re.sub('\"','', sentence)\n",
        "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")])\n",
        "    sentence = re.sub(r\"'s\\b\",\"\", sentence)\n",
        "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n",
        "    sentence = re.sub('[m]{2,}', 'mm', sentence)\n",
        "\n",
        "    # 불용어 제거 (Text)\n",
        "    if remove_stopwords:\n",
        "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
        "    # 불용어 미제거 (Summary)\n",
        "    else:\n",
        "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
        "    return tokens\n",
        "\n",
        "print(\"Gotcha\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39a062c1",
      "metadata": {
        "id": "39a062c1"
      },
      "source": [
        "전처리 전후의 결과를 확인하기 위해서 임의의 text와 summary를 만들어 함수를 호출해 볼까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2326f3fd",
      "metadata": {
        "id": "2326f3fd",
        "outputId": "e6af7001-81fb-419f-ddee-3e135adefd75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text:  everything bought great infact ordered twice third ordered wasfor mother father\n",
            "summary: great way to start the day\n"
          ]
        }
      ],
      "source": [
        "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
        "temp_summary = 'Great way to start (or finish) the day!!!'\n",
        "\n",
        "print(\"text: \", preprocess_sentence(temp_text))\n",
        "print(\"summary:\", preprocess_sentence(temp_summary, False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "033bdf56",
      "metadata": {
        "id": "033bdf56"
      },
      "source": [
        "이제 함수가 잘 작동하는 것을 확인했으니, 훈련 데이터 전체에 대해서 전처리를 진행하겠습니다. 이 때, Text의 경우에는 불용어를 제거하고, Summary의 경우에는 불용어를 제거하지 않을 것이므로 따로 호출해서 진행하니다. 먼저 Text를 전처리하고, 결과를 확인하기 위해 상위 5개의 줄을 출력해볼게요.\n",
        "\n",
        "**Q. 훈련 데이터 전체의 Text 컬럼 데이터를 전처리하는 코드를 작성하세요. (반복문 사용)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "416d5a4f",
      "metadata": {
        "id": "416d5a4f",
        "outputId": "a360b2fd-f2bf-4c01-8c4e-5a68d6d0f058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text 전처리 후 결과:  ['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better', 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo', 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch', 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal', 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']\n"
          ]
        }
      ],
      "source": [
        "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다.\n",
        "\n",
        "clean_text = []\n",
        "\n",
        "for text in data['Text']:\n",
        "    clean_text.append(preprocess_sentence(text))\n",
        "\n",
        "# 전처리 후 출력\n",
        "print(\"Text 전처리 후 결과: \", clean_text[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65b6cdd8",
      "metadata": {
        "id": "65b6cdd8"
      },
      "source": [
        "이제 Summary에 대해서 전처리를 진행하겠습니다. 함수를 호출해 줄 때는 불용어 제거를 수행하지 않으므로 두 번째 인자로 `False`를 적용합니다.\n",
        "\n",
        "**Q. 훈련 데이터 전체의 Summary 컬럼 데이터를 전처리하는 코드를 작성하세요. (반복문 사용)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ef72fcc",
      "metadata": {
        "id": "6ef72fcc",
        "outputId": "2a8dd733-fe66-471f-da61-9e9ded7f2a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary 전처리 후 결과:  ['good quality dog food', 'not as advertised', 'delight says it all', 'cough medicine', 'great taffy']\n"
          ]
        }
      ],
      "source": [
        "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다.\n",
        "clean_summary = []\n",
        "\n",
        "for summary in data['Summary']:\n",
        "    clean_summary.append(preprocess_sentence(summary, False))\n",
        "\n",
        "# 전처리 후 출력\n",
        "print(\"Summary 전처리 후 결과: \", clean_summary[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02fcc2c0",
      "metadata": {
        "id": "02fcc2c0"
      },
      "source": [
        "이렇게 텍스트 정제의 과정을 거친 후에는 다시 한번 빈 샘플이 생겼는지 확인하는 것이 좋아요. 정제 전에는 데이터가 존재했지만, 정제 과정에서 문장의 모든 단어가 사라지는 경우가 있을 수 있어요. 이렇게 되면 샘플 자체가 빈값을 가지게 되겠죠? 보다 쉽게 확인하기 위해 데이터들을 데이터 프레임에 다시 저장할게요. 빈값을 가진 샘플들이 있다면, 모두 Null 값을 가진 샘플로 대체하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f01a1741",
      "metadata": {
        "id": "f01a1741",
        "outputId": "597a780f-0c44-4041-8bb1-f105ef5dfcc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yar\n"
          ]
        }
      ],
      "source": [
        "data['Text'] = clean_text\n",
        "data['Summary'] = clean_summary\n",
        "\n",
        "# 빈 값을 Null 값으로 변환\n",
        "data.replace('', np.nan, inplace=True)\n",
        "print(\"Yar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a34e0b06",
      "metadata": {
        "id": "a34e0b06"
      },
      "source": [
        "`.isnull().sum()` 을 사용해서 Null 값이 생겼는지 확인해 볼게요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b66a896",
      "metadata": {
        "id": "0b66a896",
        "outputId": "0439e03b-81d0-4c86-b232-b672ad339550"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text        0\n",
              "Summary    70\n",
              "dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ceace03",
      "metadata": {
        "id": "8ceace03"
      },
      "source": [
        "Summary 열에서 70개의 Null 값이 생겼네요? 정제 과정에서 모든 단어가 제거되어 빈 샘플이 70개나 생겼어요. 이 샘플들은 모두 제거할게요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31c28a1a",
      "metadata": {
        "id": "31c28a1a",
        "outputId": "df7119be-3d9e-4a1a-8726-787cff896a4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 샘플수 : 88355\n"
          ]
        }
      ],
      "source": [
        "data.dropna(axis=0, inplace=True)\n",
        "print('전체 샘플수 :', (len(data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86d287f9",
      "metadata": {
        "id": "86d287f9"
      },
      "source": [
        "### 6. Data Preprocessing (2) Divide training data and test data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76eaa6a6",
      "metadata": {
        "id": "76eaa6a6"
      },
      "source": [
        "**샘플의 최대 길이 정하기**\n",
        "\n",
        "원본 데이터에서 필요 없는 단어를 모두 정리했어요. 이제 훈련에 사용할 샘플의 최대 길이를 정할게요.  \n",
        "Text와 Summary의 최소 / 최대 / 평균의 길이를 구하고, 또한 길이 분포를 시각화해서 확인하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b885d6f7",
      "metadata": {
        "id": "b885d6f7",
        "outputId": "f3dadc59-5498-4787-ab22-f9eea6d66f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "텍스트의 최소 길이 : 2\n",
            "텍스트의 최대 길이 : 1235\n",
            "텍스트의 평균 길이 : 38.792428272310566\n",
            "요약의 최소 길이 : 1\n",
            "요약의 최대 길이 : 28\n",
            "요약의 평균 길이 : 4.010729443721352\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 길이 분포 출력\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_len = [len(s.split()) for s in data['Text']]\n",
        "summary_len = [len(s.split()) for s in data['Summary']]\n",
        "\n",
        "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
        "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
        "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
        "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
        "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
        "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.boxplot(text_len)\n",
        "plt.title('Text')\n",
        "plt.subplot(1,2,2)\n",
        "plt.boxplot(summary_len)\n",
        "plt.title('Summary')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.title('Text')\n",
        "plt.hist(text_len, bins = 40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()\n",
        "\n",
        "plt.title('Summary')\n",
        "plt.hist(summary_len, bins = 40)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07e7aa9d",
      "metadata": {
        "id": "07e7aa9d"
      },
      "source": [
        "위에서부터 차례대로 그래프는 각각 `실제 텍스트와 요약의 길이 분포`, `실제 텍스트 샘플 길이 별 개수`, `요약본 샘플 길이 별 개수`를 나타내고 있어요.\n",
        "\n",
        "Text의 경우 최소 길이가 2, 최대 길이가 1,235로 그 차이가 굉장히 크죠? 하지만 평균 길이는 38로 시각화 된 그래프로 봤을 때 대체적으로는 100 내외의 길이를 가집니다. Summary의 경우, 최소 길이가 1, 최대 길이가 28, 그리고 평균 길이가 4로 Text에 비해 상대적으로 길이가 매우 짧아요. 그래프로 봤을 때에도 대체적으로 10 이하의 길이를 가지고 있습니다. 위의 결과를 토대로 Text의 최대 길이와 Summary의 적절한 최대 길이를 임의로 정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dbf85f6",
      "metadata": {
        "id": "1dbf85f6",
        "outputId": "428d9515-36a9-4756-de71-6bba367d7c76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yar\n"
          ]
        }
      ],
      "source": [
        "text_max_len = 50\n",
        "summary_max_len = 8\n",
        "\n",
        "print(\"Yar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a4e8f77",
      "metadata": {
        "id": "7a4e8f77"
      },
      "source": [
        "각각 50과 8로 정했는데 이 길이를 선택했을 때, 얼마나 많은 샘플들을 자르지 않고 포함할 수 있는지 통계로 확인하면 객관적으로 길이를 결정하는 데 도움이 될 거예요.  \n",
        "훈련 데이터와 샘플의 길이를 입력하면 데이터의 몇 %가 해당하는지 계산하는 함수를 만들어서 좀 더 정확하게 판단해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faf1e516",
      "metadata": {
        "id": "faf1e516",
        "outputId": "0c148c12-07bb-49ae-f403-6b044ab382f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yar\n"
          ]
        }
      ],
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if(len(s.split()) <= max_len):\n",
        "        cnt = cnt + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
        "\n",
        "print(\"Yar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdaa7ed1",
      "metadata": {
        "id": "bdaa7ed1"
      },
      "source": [
        "이렇게 만든 함수를 Text와 Summary에 적용해 우리가 결정한 임의의 길이가 몇 %의 샘플까지 포함하는지 볼 수 있겠죠?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac3727b9",
      "metadata": {
        "id": "ac3727b9",
        "outputId": "01a66f72-1378-43b6-de11-cf7b5d34a652"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.7745119121724859\n",
            "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.9424593967517402\n"
          ]
        }
      ],
      "source": [
        "below_threshold_len(text_max_len, data['Text'])\n",
        "below_threshold_len(summary_max_len,  data['Summary'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dbe310e",
      "metadata": {
        "id": "9dbe310e"
      },
      "source": [
        "각각 50과 8로 패딩을 하게 되면 해당 길이보다 긴 샘플들은 내용이 잘리게 되는데, Text 열의 경우에는 약 23%의 샘플들이 내용이 망가지게 된다고 하네요.\n",
        "우리는 정해진 길이에 맞춰 자르는 것이 아니라, 정해진 길이보다 길면 제외하는 방법으로 데이터를 정제할게요.\n",
        "\n",
        "**Q. Text와 Summary를 담고 있는 데이터 프레임을 위에서 임의로 정의한 text_max_len과 summary_max_len의 길이보다 큰 샘플을 제외하는 코드를 작성하세요. (apply 함수와 lamda식 사용)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb0b2ba7",
      "metadata": {
        "id": "fb0b2ba7",
        "outputId": "ad9ade26-ec13-4b0a-8e94-31e04cd23627"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 샘플수 (최대 길이 이하): 65818\n"
          ]
        }
      ],
      "source": [
        "text_max_len = 50\n",
        "summary_max_len = 8\n",
        "\n",
        "data = data[data.apply(lambda x: len(x['Text'].split()) <= text_max_len and len(x['Summary'].split()) <= summary_max_len, axis=1)]\n",
        "\n",
        "print('전체 샘플수 (최대 길이 이하):', len(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a429ebbe",
      "metadata": {
        "id": "a429ebbe"
      },
      "source": [
        "**시작 토큰과 종료 토큰 추가하기**\n",
        "\n",
        "`seq2seq 훈련을 위해서는 디코더의 입력과 레이블에 시작 토큰과 종료 토큰을 추가할 필요가 있어요`. 이번 실습에서는 시작 토큰은 `sostoken`, 종료 토큰은 `eostoken` 이라 임의로 명명하고 앞뒤로 추가하겠습니다. 디코더의 입력에 해당하면서 시작 토큰이 맨 앞에 있는 문장의 이름을 `decoder_input`, 디코더의 출력 또는 레이블에 해당되면서 종료 토큰이 맨 뒤에 붙는 문장의 이름을 `decoder_target` 이라고 정하겠습니다. 두 개의 문장 모두 Summary 열로부터 만들 거예요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff4d0431",
      "metadata": {
        "id": "ff4d0431",
        "outputId": "fd871478-9feb-4db0-90aa-dc858484fa33"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Summary</th>\n",
              "      <th>decoder_input</th>\n",
              "      <th>decoder_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bought several vitality canned dog food produc...</td>\n",
              "      <td>good quality dog food</td>\n",
              "      <td>sostoken good quality dog food</td>\n",
              "      <td>good quality dog food eostoken</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
              "      <td>not as advertised</td>\n",
              "      <td>sostoken not as advertised</td>\n",
              "      <td>not as advertised eostoken</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>confection around centuries light pillowy citr...</td>\n",
              "      <td>delight says it all</td>\n",
              "      <td>sostoken delight says it all</td>\n",
              "      <td>delight says it all eostoken</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>looking secret ingredient robitussin believe f...</td>\n",
              "      <td>cough medicine</td>\n",
              "      <td>sostoken cough medicine</td>\n",
              "      <td>cough medicine eostoken</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great taffy great price wide assortment yummy ...</td>\n",
              "      <td>great taffy</td>\n",
              "      <td>sostoken great taffy</td>\n",
              "      <td>great taffy eostoken</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text                Summary  \\\n",
              "0  bought several vitality canned dog food produc...  good quality dog food   \n",
              "1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n",
              "2  confection around centuries light pillowy citr...    delight says it all   \n",
              "3  looking secret ingredient robitussin believe f...         cough medicine   \n",
              "4  great taffy great price wide assortment yummy ...            great taffy   \n",
              "\n",
              "                    decoder_input                  decoder_target  \n",
              "0  sostoken good quality dog food  good quality dog food eostoken  \n",
              "1      sostoken not as advertised      not as advertised eostoken  \n",
              "2    sostoken delight says it all    delight says it all eostoken  \n",
              "3         sostoken cough medicine         cough medicine eostoken  \n",
              "4            sostoken great taffy            great taffy eostoken  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가\n",
        "\n",
        "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
        "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b6d05e9",
      "metadata": {
        "id": "8b6d05e9"
      },
      "source": [
        "앞뒤로 토큰이 추가되었습니다. 인코더의 입력, 디코더의 입력과 레이블을 각각 다시 Numpy 타입으로 저장해 줄게요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e07046f",
      "metadata": {
        "id": "0e07046f"
      },
      "outputs": [],
      "source": [
        "encoder_input = np.array(data['Text'])\n",
        "decoder_input = np.array(data['decoder_input'])\n",
        "decoder_target = np.array(data['decoder_target'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7914272",
      "metadata": {
        "id": "e7914272"
      },
      "source": [
        "이제 훈련 데이터와 테스트 데이터를 분리하겠습니다. 우선, encoder_input과 크기와 형태가 같은 순서가 섞인 정수 시퀀스를 만들어 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fa0189a",
      "metadata": {
        "id": "7fa0189a",
        "outputId": "ef14a087-6bab-4c41-b147-9cfe60c80de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[46167 41298 37751 ... 19482 55667 58116]\n"
          ]
        }
      ],
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print(indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "008445e9",
      "metadata": {
        "id": "008445e9"
      },
      "source": [
        "이 정수 시퀀스를 이용해 다시 데이터의 샘플 순서를 정의하면 잘 섞인 샘플이 되겠죠?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "617c151a",
      "metadata": {
        "id": "617c151a"
      },
      "outputs": [],
      "source": [
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf8c5988",
      "metadata": {
        "id": "bf8c5988"
      },
      "source": [
        "이제 섞인 데이터를 `8:2의 비율`로 훈련 데이터와 테스트 데이터로 분리하겠습니다. 전체 데이터의 크기에서 0.2를 곱하여 테스트 데이터의 크기를 정의하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "633af8fb",
      "metadata": {
        "id": "633af8fb",
        "outputId": "5471878c-584e-4617-c1e6-239af6b0ce7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "테스트 데이터의 수 : 13163\n"
          ]
        }
      ],
      "source": [
        "n_of_val = int(len(encoder_input)*0.2)\n",
        "print('테스트 데이터의 수 :', n_of_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd86d876",
      "metadata": {
        "id": "dd86d876"
      },
      "source": [
        "이렇게 정의한 테스트 데이터의 개수를 이용해 전체 데이터를 양분하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f82b810",
      "metadata": {
        "id": "5f82b810",
        "outputId": "7aa28730-46c4-4538-819f-ff0619f4161c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "훈련 데이터의 개수 : 52655\n",
            "훈련 레이블의 개수 : 52655\n",
            "테스트 데이터의 개수 : 13163\n",
            "테스트 레이블의 개수 : 13163\n"
          ]
        }
      ],
      "source": [
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]\n",
        "\n",
        "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
        "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
        "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
        "print('테스트 레이블의 개수 :', len(decoder_input_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cae14ba0",
      "metadata": {
        "id": "cae14ba0"
      },
      "source": [
        "훈련 데이터와 테스트 데이터가 각각 `52,655개`와 `13,163개`로 잘 분리된 것을 확인했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dade353",
      "metadata": {
        "id": "6dade353"
      },
      "source": [
        "### 7. Data Preprocessing (3) Integer encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22c05040",
      "metadata": {
        "id": "22c05040"
      },
      "source": [
        "**Vocabulary 만들기 및 정수 인코딩**\n",
        "\n",
        "이제 기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터의 단어들을 모두 정수로 변환해야 합니다. 이를 위해서는 각 단어에 고유한 정수를 맵핑하는 작업이 필요해요. 이 과정을 단어 집합 `Vocabulary`을 만든다 라고 표현합니다. 훈련 데이터에 대해서 단어 집합을 만들어 보겠습니다. 우선, 원문에 해당되는 `encoder_input_train`에 대해 단어 집합을 만들겠습니다. Keras의 `Tokenizer()`를 사용하면 입력된 훈련 데이터로부터 단어 집합을 만들 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b6efca8",
      "metadata": {
        "id": "0b6efca8",
        "outputId": "6b1d8a5a-3670-4a86-fc5c-5985ba75a0b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gotcha\n"
          ]
        }
      ],
      "source": [
        "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
        "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성\n",
        "\n",
        "print(\"Gotcha\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02dd780d",
      "metadata": {
        "id": "02dd780d"
      },
      "source": [
        "이제 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었습니다. 현재 생성된 단어 집합은 `src_tokenizer.word_index`에 저장되어 있습니다. 그런데 우리는 이렇게 만든 단어 집합에 있는 모든 단어를 사용하는 것이 아닙니다. 빈도수가 낮은 단어들은 훈련 데이터에서 제외할 거에요. 등장 빈도수가 7회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인해 보겠습니다. `src_tokenizer.word_counts.items()`에는 단어와 각 단어의 등장 빈도수가 저장되어 있는데, 이를 통해서 통계적인 정보를 얻을 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de8bc924",
      "metadata": {
        "id": "de8bc924",
        "outputId": "c037991c-eb9b-4252-b92c-5ef2600860ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기 : 31957\n",
            "등장 빈도가 6번 이하인 희귀 단어의 수: 23700\n",
            "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8257\n",
            "단어 집합에서 희귀 단어의 비율: 74.1621553963138\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.3874079615702644\n"
          ]
        }
      ],
      "source": [
        "threshold = 7\n",
        "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in src_tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "879b81a9",
      "metadata": {
        "id": "879b81a9"
      },
      "source": [
        "`encoder_input_train`에는 `3만여 개`의 단어가 있네요. 그 아래의 통계 정보들을 해석해 볼까요?\n",
        "\n",
        "등장 빈도가 threshold 값인 7회 미만, 즉 6회 이하인 단어들은 단어 집합에서 무려 70% 이상을 차지하네요. 하지만 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 3.39% 입니다. 그래서 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 제외하고, 훈련 데이터에서 제거하고자 합니다. 위에서 이를 제외한 단어 집합의 크기를 8천여 개로 계산했는데 이와 비슷한 값으로 어림잡아 단어 집합의 크기를 8,000으로 제한하겠습니다. `토크나이저를 정의할 때 num_words의 값을 정해주면, 단어 집합의 크기를 제한할 수 있습니다.`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cf7819e",
      "metadata": {
        "id": "1cf7819e",
        "outputId": "79ee4aba-02d1-4334-86f5-91e1bceb648d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gotcha\n"
          ]
        }
      ],
      "source": [
        "src_vocab = 8000\n",
        "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
        "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
        "print(\"Gotcha\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "433b4034",
      "metadata": {
        "id": "433b4034"
      },
      "source": [
        "`texts_to_sequences()`는 생성된 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 모두 정수로 변환하는 정수 인코딩을 수행합니다.  \n",
        "현재 단어 집합의 크기를 8,000으로 제한했으니, 이제 8,000이 넘는 숫자들은 정수 인코딩 후에는 데이터에 존재하지 않아요.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e7d15b5",
      "metadata": {
        "id": "2e7d15b5",
        "outputId": "6e34f4d3-a977-473d-8eaf-4c784fc7b77a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[244, 16, 376, 72, 1026, 1453, 57, 27, 601, 721, 3259, 1753], [35, 52, 355, 889, 162, 11, 1229, 829, 91, 562, 66, 7, 93, 1200, 385], [168, 5095, 5, 374, 352, 1827, 9, 2764, 1561, 1561, 712, 22, 5, 768, 138, 1084, 15, 165, 83, 296, 7159, 239, 5, 57, 15, 99, 58, 57, 855, 2658, 814]]\n"
          ]
        }
      ],
      "source": [
        "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
        "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train)\n",
        "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
        "\n",
        "# 잘 진행되었는지 샘플 출력\n",
        "print(encoder_input_train[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af1dc8f6",
      "metadata": {
        "id": "af1dc8f6"
      },
      "source": [
        "이제 더 이상 텍스트 데이터가 아닌 정수로 나타나고 있어요. Summary 데이터에 대해서도 동일한 작업을 수행하겠습니다. 케라스의 토크나이저를 사용하여 `decoder_input_train`을 입력으로 전체 단어 집합과 각 단어에 대한 빈도수를 계산해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b80f2ea",
      "metadata": {
        "id": "8b80f2ea",
        "outputId": "b6d20229-65a2-4214-b9c5-5067919532ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gotcha\n"
          ]
        }
      ],
      "source": [
        "tar_tokenizer = Tokenizer()\n",
        "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
        "print(\"Gotcha\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92d8cef8",
      "metadata": {
        "id": "92d8cef8"
      },
      "source": [
        "이제 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었습니다. 이는 `tar_tokenizer.word_index`에 저장되어 있어요. `tar_tokenizer.word_counts.items()`에는 단어와 각 단어의 등장 빈도수가 저장되어 있는데, 이를 통해서 통계적인 정보를 얻어서 등장 빈도수가 6회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "790f24fe",
      "metadata": {
        "id": "790f24fe",
        "outputId": "c07ce911-69a3-4366-b1ac-f810892de6ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기 : 10527\n",
            "등장 빈도가 5번 이하인 희귀 단어의 수: 8148\n",
            "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2379\n",
            "단어 집합에서 희귀 단어의 비율: 77.4009689370191\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.919577887367659\n"
          ]
        }
      ],
      "source": [
        "threshold = 6\n",
        "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tar_tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e62097b0",
      "metadata": {
        "id": "e62097b0"
      },
      "source": [
        "등장 빈도가 5회 이하인 단어들은 단어 집합에서 약 77%를 차지하고 있습니다. 하지만 실제 훈련 데이터에서 등장 빈도로 차지하는 비중은 5.87% 밖에 되지 않아요. 앞서 진행했던 작업과 동일하게 이 단어들은 모두 제거하겠습니다. 어림잡아 2,000을 단어 집합의 크기로 제한해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "311d38ca",
      "metadata": {
        "id": "311d38ca",
        "outputId": "356c7226-7944-4a5e-ffb1-b4336f58e4a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input\n",
            "input  [[1], [1, 29, 18, 77, 6, 1212, 22, 490], [1, 27, 1826, 7, 1827, 1363], [1, 465, 23, 498, 22, 30], [1, 946, 14]]\n",
            "target\n",
            "decoder  [[2], [29, 18, 77, 6, 1212, 22, 490, 2], [27, 1826, 7, 1827, 1363, 2], [465, 23, 498, 22, 30, 2], [946, 14, 2]]\n"
          ]
        }
      ],
      "source": [
        "tar_vocab = 2000\n",
        "tar_tokenizer = Tokenizer(num_words=tar_vocab)\n",
        "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
        "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
        "\n",
        "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
        "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train)\n",
        "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
        "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
        "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
        "\n",
        "# 잘 변환되었는지 확인\n",
        "print('input')\n",
        "print('input ',decoder_input_train[:5])\n",
        "print('target')\n",
        "print('decoder ',decoder_target_train[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed3da35c",
      "metadata": {
        "id": "ed3da35c"
      },
      "source": [
        "정수 인코딩 작업이 끝났습니다. 현재 `decoder_input_train`과 `decoder_target_train`에는 더 이상 2,000이 넘는 숫자들은 존재하지 않아요. 그런데 다음 작업인 `패딩`으로 넘어가기 전에 한 가지 점검해야 할 것이 있습니다. 전체 데이터에서 빈도수가 낮은 단어가 삭제되었다는 것은 빈도수가 낮은 단어만으로 구성되었던 샘플들은 이제 빈 샘플이 되었을 가능성이 있어요. 이 현상은 길이가 상대적으로 길었던 원문 Text의 경우에는 문제되지 않지만 애초에 평균 길이가 4 정도 였던 Summary의 경우 이 현상이 굉장히 두드러졌을 가능성이 높겠죠?  \n",
        "\n",
        "요약문에서 길이가 0이 된 샘플들의 인덱스를 받겠습니다. 여기서 주의할 점은 요약문인 `decoder_input`에는 `sostoken` 또는 `decoder_target`에는 `eostoken`이 추가된 상태이고, 이 두 토큰은 모든 샘플에서 등장하므로 빈도수가 샘플 수와 동일하게 매우 높으므로 단어 집합 제한에도 삭제되지 않아요. 그래서 이제 `길이가 0이 된 요약문의 실제 길이는 1로 나올 거예요`. 길이가 0이 된 `decoder_input`에는 `sostoken`, `decoder_target`에는 `eostoken`만 남아 있을 테니까요. 훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 1인 경우의 인덱스를 각각 `drop_train`과 `drop_test`에 라는 변수에 저장하겠습니다. 이 샘플들은 모두 삭제할 거예요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45bc1a87",
      "metadata": {
        "id": "45bc1a87",
        "outputId": "2d1be885-2020-4c87-d695-75849e3235ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "삭제할 훈련 데이터의 개수 : 1273\n",
            "삭제할 테스트 데이터의 개수 : 344\n",
            "훈련 데이터의 개수 : 51382\n",
            "훈련 레이블의 개수 : 51382\n",
            "테스트 데이터의 개수 : 12819\n",
            "테스트 레이블의 개수 : 12819\n"
          ]
        }
      ],
      "source": [
        "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
        "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
        "\n",
        "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
        "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
        "\n",
        "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
        "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
        "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
        "\n",
        "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
        "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
        "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
        "\n",
        "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
        "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
        "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
        "print('테스트 레이블의 개수 :', len(decoder_input_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "659b10eb",
      "metadata": {
        "id": "659b10eb"
      },
      "source": [
        "훈련 데이터와 테스트 데이터 모두 일정량의 샘플들이 제거된 것을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93d302ae",
      "metadata": {
        "id": "93d302ae"
      },
      "source": [
        "**패딩하기**\n",
        "\n",
        "텍스트 시퀀스를 정수 시퀀스로 변환했다면, 이제 서로 다른 길이의 샘플들을 병렬로 처리하기 위해 같은 길이로 맞춰주는 패딩 작업이 필요합니다. 앞서 정해두었던 최대 길이로 패딩을 진행하겠습니다. 최대 길이보다 짧은 데이터들은 뒤의 공간에 숫자 0을 넣어 최대 길이로 길이를 맞춰 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef3d2c4c",
      "metadata": {
        "id": "ef3d2c4c",
        "outputId": "ad3b5d67-d37d-4ab5-cceb-40be2a50e027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Are you ready?\n"
          ]
        }
      ],
      "source": [
        "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
        "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
        "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
        "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
        "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
        "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')\n",
        "\n",
        "print(\"Are you ready?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b61214ba",
      "metadata": {
        "id": "b61214ba"
      },
      "source": [
        "이제 학습에 필요한 데이터 전처리가 모두 끝났어요."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f2a3c5f",
      "metadata": {
        "id": "8f2a3c5f"
      },
      "source": [
        "### 8. Design Model\n",
        "\n",
        "이제 모델을 설계하겠습니다. 우선 함수형 API를 이용해서 인코더를 설계하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff93d4ba",
      "metadata": {
        "id": "ff93d4ba"
      },
      "source": [
        "**Q.인코더 LSTM 1을 참고해서 나머지 인코더의 LSTM 2, LSTM 3의 코드를 완성하세요.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8037fe03",
      "metadata": {
        "id": "8037fe03",
        "outputId": "8a2d109c-6be4-4510-fb00-4f38479f25ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "# 인코더 설계 시작\n",
        "embedding_dim = 128\n",
        "hidden_size = 256\n",
        "\n",
        "# 인코더\n",
        "encoder_inputs = Input(shape=(text_max_len,))\n",
        "\n",
        "# 인코더의 임베딩 층\n",
        "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
        "\n",
        "# 인코더의 LSTM 1\n",
        "# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
        "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "# 인코더의 LSTM 2\n",
        "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1, initial_state=[state_h1, state_c1])\n",
        "\n",
        "# 인코더의 LSTM 3\n",
        "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2, initial_state=[state_h2, state_c2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70deb116",
      "metadata": {
        "id": "70deb116"
      },
      "source": [
        "`임베딩 벡터의 차원은 128`로 정의하고, `hidden state의 크기를 256`으로 정의했어요. hidden state는 LSTM에서 얼만큼의 수용력(capacity)를 가질지 정하는 파라미터입니다. 이 파라미터는 LSTM 용량의 크기나, LSTM 에서의 뉴런 개수라고 이해하면 되겠습니다. 다른 신경망과 마찬가지로 무조건 용량을 많이 늘린다고 성능이 반드시 올라가는 것은 아닙니다. 인코더의 LSTM은 총 3개의 층으로 구성해서 모델의 복잡도를 높였어요. hidden state의 크기를 늘리는 것이 LSTM 층 1개의 용량을 늘린다면, 3개의 층을 사용하는 것은 모델의 용량을 늘린다고 볼 수 있습니다. 3개의 층을 지나서 인코더로부터 나온 출력 벡터는 디코더로 보내야겠죠?\n",
        "\n",
        "LSTM은 dropout 뿐 아니라 `recurrent dropout`을 사용할 수 있어요. 일반적인 dropout은 레이어의 weight를 랜덤으로 생략하여 모델의 과적합을 해결해주는 방법입니다. 반면 recurrent dropout은 dropout을 레이어가 아닌 time step 마다 적용하는 방식이에요. 즉, time step의 입력을 랜덤으로 생략하는 거죠. recurrent dropout은 일반적인 dropout와 같이 regularization을 해주는 효과가 있고, 과적합을 방지할 수 있습니다. 참고로 recurrent dropout을 사용하면 아래와 같은 경고문이 뜹니다.\n",
        "\n",
        "```\n",
        "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
        "```\n",
        "\n",
        "`recurrent dropout`을 사용할 시 cuDNN을 사용할 수 없어서 recurrent dropout을 사용하지 않을 때보다 학습 시간이 오래 걸립니다. recurrent dropout에 대한 자세한 내용은 [Recurrent Dropout without Memory Loss](https://arxiv.org/pdf/1603.05118v2.pdf) 논문을 참고하세요. 이제 디코더를 설계해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2d43d60",
      "metadata": {
        "id": "b2d43d60"
      },
      "outputs": [],
      "source": [
        "# 디코더 설계\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "# 디코더의 임베딩 층\n",
        "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 디코더의 LSTM\n",
        "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
        "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8efaf439",
      "metadata": {
        "id": "8efaf439"
      },
      "source": [
        "디코더의 임베딩 층과 LSTM을 설계하는 것은 인코더와 거의 동일하니다. 하지만 LSTM의 입력을 정의할 때, initial_state의 인자값으로 인코더의 hidden state와 cell state의 값을 넣어줘야 합니다. 디코더의 출력층을 설계해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b25de5e",
      "metadata": {
        "id": "7b25de5e",
        "outputId": "fb617630-e48d-4af2-fd90-2b70fe7ec967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 2000)   514000      lstm_3[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 3,633,104\n",
            "Trainable params: 3,633,104\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 디코더의 출력층\n",
        "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
        "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "# 모델 정의\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "770dfb59",
      "metadata": {
        "id": "770dfb59"
      },
      "source": [
        "`디코더의 출력층에서는 Summary의 단어장인 tar_vocab의 수 많은 선택지 중 하나의 단어를 선택하는 다중 클래스 분류 문제를 풀어야 합니다.` 그렇기 때문에 Dense의 인자로 tar_vocab을 주고, 활성화 함수로 소프트맥스 함수를 사용합니다. 지금까지 설계한 것은 인코더의 hidden state와 cell state를 디코더의 초기 state로 사용하는 가장 기본적인 `seq2seq` 모델입니다. 그런데 디코더의 출력층 설계를 살짝 바꿔서 성능을 높일 수 있는 방법이 있습니다. 바로 `어텐션 메커니즘`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8902840e",
      "metadata": {
        "id": "8902840e"
      },
      "source": [
        "**어텐션 메커니즘**\n",
        "\n",
        "어텐션 메커니즘을 수행하는 어텐션 함수를 설계하는 것은 또 다른 새로운 신경망을 설계해야 한다는 의미입니다. 어텐션 함수를 설계하는 것은 다음 기회로 미루기로 하고, 여기서는 TensorFlow에 이미 구현된 어텐션 함수를 가져와서 디코더의 출력층에 어떤 방식으로 결합하는지 봅시다. 참고로 여기서 사용하는 어텐션 함수는 `Bahdanau 스타일의 어텐션`입니다. 이 어텐션에 대한 자세한 설명은 [텐서플로우 홈페이지](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AdditiveAttention)를 참고하세요. 어텐션 층을 만들고, 위에서 설계한 디코더의 출력층을 수정해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f18b9095",
      "metadata": {
        "id": "f18b9095",
        "outputId": "52a4c42d-70b5-4c30-beaa-8fd31baa7224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_3[0][0]                     \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 2000)   1026000     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 4,145,360\n",
            "Trainable params: 4,145,360\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import AdditiveAttention\n",
        "\n",
        "# 어텐션 층(어텐션 함수)\n",
        "attn_layer = AdditiveAttention(name='attention_layer')\n",
        "\n",
        "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
        "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
        "\n",
        "\n",
        "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "# 디코더의 출력층\n",
        "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
        "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
        "\n",
        "# 모델 정의\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f6931cc",
      "metadata": {
        "id": "5f6931cc"
      },
      "source": [
        "위의 코드는 인코더의 hidden state들과 디코더의 hidden state들을 어텐션 함수의 입력으로 사용하고, 어텐션 함수가 리턴한 값을 예측 시에 디코더의 hidden state와 함께 활용하는 형태로 작동합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13974d2c",
      "metadata": {
        "id": "13974d2c"
      },
      "source": [
        "### 9. Training\n",
        "\n",
        "앞서 설계한 모델로 훈련을 진행해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f378bb50",
      "metadata": {
        "id": "f378bb50",
        "outputId": "12bc16e1-618e-4db6-db2b-72dac08659dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "201/201 [==============================] - 123s 438ms/step - loss: 2.7018 - val_loss: 2.4327\n",
            "Epoch 2/50\n",
            "201/201 [==============================] - 87s 434ms/step - loss: 2.3761 - val_loss: 2.3263\n",
            "Epoch 3/50\n",
            "201/201 [==============================] - 88s 437ms/step - loss: 2.2510 - val_loss: 2.1842\n",
            "Epoch 4/50\n",
            "201/201 [==============================] - 87s 431ms/step - loss: 2.1340 - val_loss: 2.1021\n",
            "Epoch 5/50\n",
            "201/201 [==============================] - 87s 432ms/step - loss: 2.0542 - val_loss: 2.0469\n",
            "Epoch 6/50\n",
            "201/201 [==============================] - 87s 434ms/step - loss: 1.9924 - val_loss: 2.0046\n",
            "Epoch 7/50\n",
            "201/201 [==============================] - 87s 434ms/step - loss: 1.9399 - val_loss: 1.9743\n",
            "Epoch 8/50\n",
            "201/201 [==============================] - 87s 431ms/step - loss: 1.8925 - val_loss: 1.9481\n",
            "Epoch 9/50\n",
            "201/201 [==============================] - 87s 434ms/step - loss: 1.8510 - val_loss: 1.9310\n",
            "Epoch 10/50\n",
            "201/201 [==============================] - 88s 436ms/step - loss: 1.8124 - val_loss: 1.9127\n",
            "Epoch 11/50\n",
            "201/201 [==============================] - 87s 435ms/step - loss: 1.7782 - val_loss: 1.9068\n",
            "Epoch 12/50\n",
            "201/201 [==============================] - 88s 436ms/step - loss: 1.7461 - val_loss: 1.8921\n",
            "Epoch 13/50\n",
            "201/201 [==============================] - 87s 432ms/step - loss: 1.7140 - val_loss: 1.8891\n",
            "Epoch 14/50\n",
            "201/201 [==============================] - 88s 439ms/step - loss: 1.6868 - val_loss: 1.8862\n",
            "Epoch 15/50\n",
            "201/201 [==============================] - 88s 439ms/step - loss: 1.6594 - val_loss: 1.8820\n",
            "Epoch 16/50\n",
            "201/201 [==============================] - 88s 438ms/step - loss: 1.6335 - val_loss: 1.8835\n",
            "Epoch 17/50\n",
            "201/201 [==============================] - 89s 445ms/step - loss: 1.6092 - val_loss: 1.8810\n",
            "Epoch 18/50\n",
            "201/201 [==============================] - 91s 450ms/step - loss: 1.5856 - val_loss: 1.8798\n",
            "Epoch 19/50\n",
            "201/201 [==============================] - 90s 448ms/step - loss: 1.5632 - val_loss: 1.8827\n",
            "Epoch 20/50\n",
            "201/201 [==============================] - 89s 441ms/step - loss: 1.5414 - val_loss: 1.8841\n",
            "Epoch 00020: early stopping\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
        "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
        "          batch_size=256, callbacks=[es], epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee4cc079",
      "metadata": {
        "id": "ee4cc079"
      },
      "source": [
        "```\n",
        "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
        "```\n",
        "\n",
        "`val_loss`를 관찰하다가, 검증 데이터의 손실이 줄어들지 않고 증가하는 현상이 2회(patience=2) 관측되면 학습을 멈추도록 설정했습니다. [EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)이 작동한다면 `epochs`가 아무리 크게 설정되어 있어도 모델 훈련을 최적점에서 멈출 수 있습니다.\n",
        "\n",
        "**Q. Early Stopping을 사용할 경우 조심해야 하는 경우가 있는데, 어떤 경우일까요?**\n",
        "```\n",
        "patience가 0이 아닌 경우에는 훈련이 종료되었을 때 성능이 최고인 상황이 아닐 수 있습니다. 예를들어 patience가 3인 경우, 15 epoch에서 loss가 감소하다가 16 epoch부터 loss가 증가한다면 18 epoch 때 모델을 저장하고 학습을 종료합니다. 그래서 학습 중에 모델을 저장하는 callback 함수를 같이 사용한다.\n",
        "```\n",
        "\n",
        "이제 훈련 데이터의 손실과 검증 데이터의 손실이 줄어드는 과정을 시각화 해볼까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6acca6c4",
      "metadata": {
        "id": "6acca6c4",
        "outputId": "b43d667c-23d6-4bfd-d9e1-2ae2c8625e1a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c759fcdb",
      "metadata": {
        "id": "c759fcdb"
      },
      "source": [
        "### 10. Implementing the inference model\n",
        "\n",
        "테스트 단계에서는 정수 인덱스 행렬로 존재하던 텍스트 데이터를 실제 데이터로 복원해야 하므로 필요한 3개의 사전을 아래와 같이 미리 준비해 둡니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e4ab987",
      "metadata": {
        "id": "6e4ab987",
        "outputId": "30e2b061-a556-4e5d-8740-aef7d1c0a09c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gotcha\n"
          ]
        }
      ],
      "source": [
        "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
        "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
        "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
        "\n",
        "print(\"Gotcha\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e730522",
      "metadata": {
        "id": "3e730522"
      },
      "source": [
        "**`seq2seq`는 훈련할 때와 실제 동작할 때(인퍼런스 단계)의 방식이 다르므로, 그에 맞게 모델 설계를 별개로 진행해야 합니다.**\n",
        "\n",
        "훈련 단계에서는 디코더의 입력부에 정답이 되는 문장 전체를 한 번에 넣고 디코더의 출력과 한 번에 비교할 수 있으므로, 인코더와 디코더를 엮은 모델 하나만 준비하겠습니다. 그러나 정답 문장이 없는 인퍼런스 단계에서는 생성해야 할 문장의 길이만큼 디코더가 반복 구조로 동작해야 하므로 부득이 인퍼런스를 위한 모델 설계가 별도로 필요합니다. 이 때에는 인코더 모델과 디코더 모델을 분리해서 설계합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3abe9f45",
      "metadata": {
        "id": "3abe9f45",
        "outputId": "2c615be4-9a06-4278-c4f6-52e867f5523a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gotcha\n"
          ]
        }
      ],
      "source": [
        "# 인코더 설계\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(hidden_size,))\n",
        "decoder_state_input_c = Input(shape=(hidden_size,))\n",
        "\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "print(\"Gotcha\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8185e46e",
      "metadata": {
        "id": "8185e46e"
      },
      "source": [
        "어텐션 메커니즘을 사용하는 출력층을 설계해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f26a14",
      "metadata": {
        "id": "f2f26a14",
        "outputId": "e4d5900c-a91a-40e1-c491-128a208c0b85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gotcha\n"
          ]
        }
      ],
      "source": [
        "# 어텐션 함수\n",
        "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
        "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# 디코더의 출력층\n",
        "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat)\n",
        "\n",
        "# 최종 디코더 모델\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])\n",
        "\n",
        "print(\"Gotcha\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db7b4f2d",
      "metadata": {
        "id": "db7b4f2d"
      },
      "source": [
        "인퍼런스 단계에서 단어 시퀀스를 완성하는 함수를 만들어 볼까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e241417",
      "metadata": {
        "id": "2e241417",
        "outputId": "e3007ebc-c6a6-40c7-ffcf-d76d9cd6f736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gotcha\n"
          ]
        }
      ],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "     # <SOS>에 해당하는 토큰 생성\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
        "\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = tar_index_to_word[sampled_token_index]\n",
        "\n",
        "        if (sampled_token!='eostoken'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # 상태를 업데이트 합니다.\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "print(\"Gotcha\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2213caa3",
      "metadata": {
        "id": "2213caa3"
      },
      "source": [
        "**Q. 정답 문장이 없는 추론 Inference 단계에서는 왜 모델 설계를 별도로 해주어야 하나요?**\n",
        "```\n",
        "생성해야 할 문장의 길이만큼 디코더가 반복 구조로 동작해야하기 때문입니다.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cda8245b",
      "metadata": {
        "id": "cda8245b"
      },
      "source": [
        "### 11. Test\n",
        "\n",
        "테스트 단계에서는 정수 시퀀스를 텍스트 시퀀스로 변환하여 결과를 확인하는 것이 편하겠죠? 주어진 정수 시퀀스를 텍스트 시퀀스로 변환하는 함수를 만들어 봅시다. 함수를 만들 때, Text의 정수 시퀀스에서는 패딩을 위해 사용되는 숫자 0을 제외하고 Summary의 정수 시퀀스에서는 숫자 0, 시작 토큰의 인덱스, 종료 토큰의 인덱스를 출력에서 제외하도록 만들겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "100f6e0d",
      "metadata": {
        "id": "100f6e0d"
      },
      "source": [
        "**Q. seq2text 함수처럼 요약문의 정수 시퀀스를 텍스트로 변환하는 seq2summary 함수 코드를 작성하세요.\n",
        "(요약문에는 sostoken과 eostoken을 고려)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3675a065",
      "metadata": {
        "id": "3675a065",
        "outputId": "5d25ed39-b190-4529-fc6b-a08b496348e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gotcha\n"
          ]
        }
      ],
      "source": [
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2text(input_seq):\n",
        "    temp=''\n",
        "    for i in input_seq:\n",
        "        if (i!=0):\n",
        "            temp = temp + src_index_to_word[i]+' '\n",
        "    return temp\n",
        "\n",
        "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq2summary(input_seq):\n",
        "    temp = ''\n",
        "    for i in input_seq:\n",
        "        if i != 0 and i != tar_word_to_index['sostoken'] and i != tar_word_to_index['eostoken']:\n",
        "            temp += tar_index_to_word[i] + ' '\n",
        "    return temp\n",
        "\n",
        "print(\"Gotcha\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6418d79",
      "metadata": {
        "id": "b6418d79"
      },
      "source": [
        "테스트 데이터 약 50개의 샘플에 대해서 실제 요약과 예측된 요약을 비교해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f3a31eb",
      "metadata": {
        "id": "1f3a31eb",
        "outputId": "b8423519-9b5b-4afa-e3fe-5463dcab65f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "원문 : two cats love surprised since picky eaters comes good price well \n",
            "실제 요약 : great price \n",
            "예측 요약 :  cat treats\n",
            "\n",
            "\n",
            "원문 : best organic coffee ever enjoyed aroma taste like good french roast full rich flavor product price customer service excellent \n",
            "실제 요약 : delicious \n",
            "예측 요약 :  great coffee\n",
            "\n",
            "\n",
            "원문 : keep car case starting feel tired one taste best job \n",
            "실제 요약 : good for pick me up \n",
            "예측 요약 :  great taste\n",
            "\n",
            "\n",
            "원문 : tea strange taste enjoyable buying flavor look elsewhere present tea cheap tasting \n",
            "실제 요약 : weird taste flavors \n",
            "예측 요약 :  not what expected\n",
            "\n",
            "\n",
            "원문 : ordered coffee amazon friday special one advertized bold like strong cup coffee bitter one hits taste really nice bad taste keurig years coffee two favorites far tully italian roast gets top spot less expensive keep list run \n",
            "실제 요약 : my new favorite \n",
            "예측 요약 :  not bitter\n",
            "\n",
            "\n",
            "원문 : husband love bars great healthy alternative breakfast bars contain high fructose corn syrup junk put products tried chocolate chocolate peanut butter also pleased berry bars enjoy \n",
            "실제 요약 : love bars \n",
            "예측 요약 :  delicious\n",
            "\n",
            "\n",
            "원문 : great organic chocolate great organic chocolate even good even fair organic chocolate extremely poor chocolate chalky smooth flavor absolutely horrendous expected hint ginger chai bar overpowered hint flavors completely washed chocolate flavor surprised bar spit threw bar yuck \n",
            "실제 요약 : double yuck \n",
            "예측 요약 :  worst chocolate have ever tasted\n",
            "\n",
            "\n",
            "원문 : youngest child eat weight nutri grain bars great price us \n",
            "실제 요약 : great price \n",
            "예측 요약 :  good but not great\n",
            "\n",
            "\n",
            "원문 : people make taste buds taste like berry flavored anything actual berries ever eaten tastes horrible flavors fine one pretty bad one give none likes taste either \n",
            "실제 요약 : ounces bottles of pure \n",
            "예측 요약 :  not bad\n",
            "\n",
            "\n",
            "원문 : tully house blend coffee bold coffee bitter delivers good coffee flavor use cups perfect cup coffee every time looking replacement kona blend coffee since become difficult find prices sky find house blend good replacement \n",
            "실제 요약 : excellent coffee \n",
            "예측 요약 :  good coffee\n",
            "\n",
            "\n",
            "원문 : visiting friend london last month strongly try broth wow delicious bought wish would bought sipping cups cannot get enough flavorful easy dissolve pure natural taste fantastic highly recommend \n",
            "실제 요약 : the best veggie have ever tasted \n",
            "예측 요약 :  great taste\n",
            "\n",
            "\n",
            "원문 : good wonderful first opened good day day basis expensive good coffee great price \n",
            "실제 요약 : for the money cannot be beat \n",
            "예측 요약 :  great coffee\n",
            "\n",
            "\n",
            "원문 : box soaked oil caps lose one jar oil bad bad pkg purchased amazon \n",
            "실제 요약 : bad packing \n",
            "예측 요약 :  not as advertised\n",
            "\n",
            "\n",
            "원문 : stuff awesome use everything breakfast dinner great creations great ever eat good favor \n",
            "실제 요약 : excellent \n",
            "예측 요약 :  great\n",
            "\n",
            "\n",
            "원문 : love gummi bears haribo best nice chewy excellent fruit flavors convenient sized packages cheaper grocery store ordering \n",
            "실제 요약 : absolutely delicious \n",
            "예측 요약 :  great tasting gummy bears\n",
            "\n",
            "\n",
            "원문 : love stuff tastes like ice cream cold seriously tried \n",
            "실제 요약 : the greatest stuff ever \n",
            "예측 요약 :  best of the best\n",
            "\n",
            "\n",
            "원문 : low carb sugar delicious satisfy sweet tooth one feelings hunger several hours good substitute used snacking \n",
            "실제 요약 : good diet candies \n",
            "예측 요약 :  great snack\n",
            "\n",
            "\n",
            "원문 : really enjoy flavor tulsi tea really taste lavender like taste lavender tea think stick pure tulsi future \n",
            "실제 요약 : okay but no flavor \n",
            "예측 요약 :  not as good as the real thing\n",
            "\n",
            "\n",
            "원문 : biscuits delicious expected surprised poorly amazon packed packages mcvities box thrown plastic air bubbles top ends roll biscuits bit cookies totally crumbled intact expect careful packing disappointed \n",
            "실제 요약 : great biscuit poor packing \n",
            "예측 요약 :  great product bad packaging\n",
            "\n",
            "\n",
            "원문 : dogs well wellness simple solutions great dogs allergies purchasing amazon easy reliable \n",
            "실제 요약 : wellness simple dog food \n",
            "예측 요약 :  great product\n",
            "\n",
            "\n",
            "원문 : always lookout healthy tasty foods low calories crackers good omg type good interesting yet addictive taste cannot really explain would definately recommend everyone give keeps asking guess stop sharing \n",
            "실제 요약 : addictive \n",
            "예측 요약 :  great low fat snack\n",
            "\n",
            "\n",
            "원문 : drank one didnt get sleep maybe involved drink cup coffee around pm dont get sleep late well anyway local dollar store sells check around still bit expensive ill drink em berry tastes decent lemon lime \n",
            "실제 요약 : energy \n",
            "예측 요약 :  good stuff\n",
            "\n",
            "\n",
            "원문 : dog treats great new puppy size dog loves small soft \n",
            "실제 요약 : great dog treats for training \n",
            "예측 요약 :  great treats\n",
            "\n",
            "\n",
            "원문 : first time ordered coffee fresh sealed tight second order coffee fresh good price though bulk \n",
            "실제 요약 : good but better first time \n",
            "예측 요약 :  good coffee\n",
            "\n",
            "\n",
            "원문 : college looking healthy snack take class sure product first tried love admit taste buds adjust natural flavors especially use bars lot artificial ingredients local kroger tried almost flavors apple pie cashew cookie lemon favorites \n",
            "실제 요약 : love larabars \n",
            "예측 요약 :  great snack\n",
            "\n",
            "\n",
            "원문 : really appreciate ingredients gum fact natural flavor kids complained picky comes things like gum problems sticking teeth fillings pleasant spite sides probably purchase gum like giving kids artificial sweeteners kinds gum \n",
            "실제 요약 : some \n",
            "예측 요약 :  not so good\n",
            "\n",
            "\n",
            "원문 : snacks yummy bought busy husband take work something healthy munch busy days likes could happier could remember take work \n",
            "실제 요약 : yummy \n",
            "예측 요약 :  great snack\n",
            "\n",
            "\n",
            "원문 : dogs loved easy break smaller pieces complaints price amazon seemed reasonable compared costs pet stores \n",
            "실제 요약 : two paws up \n",
            "예측 요약 :  great treat\n",
            "\n",
            "\n",
            "원문 : buying year subscribe deliveries ever run next shipment \n",
            "실제 요약 : some of the finest coffee \n",
            "예측 요약 :  great\n",
            "\n",
            "\n",
            "원문 : tea lacks distinctive scottish breakfast tea malt flavor bad better much less expensive teas \n",
            "실제 요약 : disappointing \n",
            "예측 요약 :  not what expected\n",
            "\n",
            "\n",
            "원문 : great snack low calorie tasty healthy noticed though couple boxes sesame seeds falling unopened packages still buy crackers sister flatbread \n",
            "실제 요약 : very tasty healthy snack \n",
            "예측 요약 :  great snack\n",
            "\n",
            "\n",
            "원문 : boxes contain sausages means received half description says charged received contacted amazon say credit right amount \n",
            "실제 요약 : wrong quantity \n",
            "예측 요약 :  not as advertised\n",
            "\n",
            "\n",
            "원문 : couple years enjoyed tea last snack day natural peanut butter whole wheat crackers sliced apples mm good celestial seasonings green tea decaf mandarin orchard count tea bags \n",
            "실제 요약 : late night snack \n",
            "예측 요약 :  great tea\n",
            "\n",
            "\n",
            "원문 : since gastric bypass surgery give carbonated drinks become favorite flavor sugar free drinks subtle sweet flavor nice aroma blueberry impossible find local stores glad get amazon \n",
            "실제 요약 : my favorite flavor \n",
            "예측 요약 :  great taste\n",
            "\n",
            "\n",
            "원문 : thought good flavor took two tubs work people liked two three people commented liked better brands salty \n",
            "실제 요약 : good flavor and not too salty \n",
            "예측 요약 :  not good\n",
            "\n",
            "\n",
            "원문 : cannot say much actually help dogs digestive system opened bag two dogs gave one relish bag claims enzymes help clean teeth would definite plus read reviews say neither dog upset stomach however dogs one hundred pounds plus fairly strong stomachs \n",
            "실제 요약 : dogs liked them \n",
            "예측 요약 :  not for small dogs\n",
            "\n",
            "\n",
            "원문 : switch orange tangerine nice beverage lightly carbonated made real fruit juice unlike sodas switch products made real ingredients tastes great cans come convenient ounce great lunch mid afternoon treat want light beverage made good stuff want grab switch favor throw hfcs sodas make switch \n",
            "실제 요약 : fine citrus beverage from the switch \n",
            "예측 요약 :  great soda alternative to soda\n",
            "\n",
            "\n",
            "원문 : really like cocoa butter makes excellent chocolates would definately order good quality shipped quickly happy overall \n",
            "실제 요약 : awesome stuff \n",
            "예측 요약 :  great cocoa\n",
            "\n",
            "\n",
            "원문 : tree nice part besides pot come drip tray promised instructions lacking information merely printed piece paper \n",
            "실제 요약 : nice tree but where is the rest \n",
            "예측 요약 :  not as good as expected\n",
            "\n",
            "\n",
            "원문 : liked noodles intolerance gluten eat \n",
            "실제 요약 : noodles \n",
            "예측 요약 :  not gluten free\n",
            "\n",
            "\n",
            "원문 : buying treats year lab looks forward treat finishing meal mention happy hips watch smile \n",
            "실제 요약 : healthy dog snack \n",
            "예측 요약 :  great treats\n",
            "\n",
            "\n",
            "원문 : crunchy enough salt nothing ruin taste rye definitely buy \n",
            "실제 요약 : great with cheese or \n",
            "예측 요약 :  not bad\n",
            "\n",
            "\n",
            "원문 : one favorite candies time sugar coated black licorice candy comes white purple eating good plenty movie theater since forever got tons trick treating years eat much might get sugar high headache highly recommend candy \n",
            "실제 요약 : good rules \n",
            "예측 요약 :  delicious\n",
            "\n",
            "\n",
            "원문 : always order tea amazon cannot get locally sad hear offering \n",
            "실제 요약 : great tea \n",
            "예측 요약 :  great tea\n",
            "\n",
            "\n",
            "원문 : guy around tasted tons olives authentic notice halves whole seed flavor exactly correct great price \n",
            "실제 요약 : very nice flavor \n",
            "예측 요약 :  great product\n",
            "\n",
            "\n",
            "원문 : delicious glad able get line since friend loves finding hard find local stores grandson ate one \n",
            "실제 요약 : so good crisp bars \n",
            "예측 요약 :  delicious\n",
            "\n",
            "\n",
            "원문 : love dark chocolate really enjoyed previous order lindt chocolate bars type prefer available ordered fine bit sweet \n",
            "실제 요약 : good but little too sweet \n",
            "예측 요약 :  chocolate heaven\n",
            "\n",
            "\n",
            "원문 : really eaters far loved fun bites products usually would turn nose dog treats chew chew good breath teeth last quite \n",
            "실제 요약 : my babies love these \n",
            "예측 요약 :  my dog loves these\n",
            "\n",
            "\n",
            "원문 : standby timothy german chocolate cake die tried delicious smells great tastes like warm chocolate glazed donut must try coffee \n",
            "실제 요약 : my new favorite \n",
            "예측 요약 :  delicious\n",
            "\n",
            "\n",
            "원문 : put gingerbread houses together kids buy far worst experience ever one waste money pile garbage use name draw nothing fits together directions horrible house tiny stick name brand gingerbread house wife left buy real house finished throwing piece garbage trash one good thing kids eating tasty \n",
            "실제 요약 : horrible mess \n",
            "예측 요약 :  worst ever\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(50, 100):\n",
        "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
        "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
        "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b9fea72",
      "metadata": {
        "id": "5b9fea72"
      },
      "source": [
        "많은 결과문이 출력 되는데, 기존의 요약과는 다른 요약을 출력하면서도 원문의 내용을 담고 있는 의미 있는 요약들이 보입니다. 심지어 일부 요약의 경우에는 원문에 없던 단어를 사용해서 요약을 하기도 합니다. 워드 임베딩과 RNN의 콜라보로 이뤄낸 신기한 성과네요!\n",
        "\n",
        "물론 그다지 좋지 않은 요약의 예도 꽤나 보입니다. 성능을 개선하기 위해서는 seq2seq와 어텐션의 자체의 조합을 좀 더 좋게 수정하는 방법이 있고, 빔 서치(beam search), 사전 훈련된 워드 임베딩(pre-trained word embedding), 또는 인코더-디코더 자체의 구조를 새롭게 변경하는 트랜스포머(Transformer)와 같은 다양한 개선 방안들이 있습니다. 이런 방안들에 대해서도 향후 살펴보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "714dc116",
      "metadata": {
        "id": "714dc116"
      },
      "source": [
        "### 12. Extractive Summarization\n",
        "\n",
        "앞서 seq2seq를 통해서 추상적 요약을 진행했습니다.  \n",
        "그런데 텍스트 요약에는 추상적 요약 외에도 이미 본문에 존재하는 단어구, 문장을 뽑아서 요약으로 삼는 추출적 요약 방법도 있습니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c750598",
      "metadata": {
        "id": "4c750598"
      },
      "source": [
        "**Q. 우리가 앞에서 seq2seq 모델을 사용하여 추상적 요약을 했습니다. 그렇다면 추출적 요약은 무엇일까요?**\n",
        "```\n",
        "추출적 요약은 원문에서 중요한 핵심 문장 또는 단어를 뽑아 구성된 요약문을 만드는 방식입니다. 그래서 생성된 문장이나 단어는 원문에 포함되어 있기 때문에, 단점으로 언어 표현 능력이 제한되어 생성된 문장이 매끄럽지 않을 수 있습니다. 대표적인 알고리즘으로는 TextRank가 있습니다.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c886ab8",
      "metadata": {
        "id": "1c886ab8"
      },
      "source": [
        "**패키지 설치**\n",
        "\n",
        "```\n",
        "$ pip list | grep summa\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08ef785a",
      "metadata": {
        "id": "08ef785a"
      },
      "source": [
        "**데이터 다운로드하기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c896203",
      "metadata": {
        "id": "7c896203"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from summa.summarizer import summarize"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b7883a9",
      "metadata": {
        "id": "4b7883a9"
      },
      "source": [
        "매트릭스 시놉시스를 다운로드 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62f00b9e",
      "metadata": {
        "id": "62f00b9e"
      },
      "outputs": [],
      "source": [
        "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75c049aa",
      "metadata": {
        "id": "75c049aa"
      },
      "source": [
        "text에는 매트릭스 시놉시스가 문자열로 저장되어 있습니다. 출력 결과가 아주 길기 때문에 일부만 출력하고, 저장이 잘 되었는지 확인해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72009bcc",
      "metadata": {
        "id": "72009bcc",
        "outputId": "72d01a3a-86f3-4536-9439-ab3527a064a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The screen is filled with green, cascading code which gives way to the title, The Matrix.\r\n",
            "\r\n",
            "A phone rings and text appears on the screen: \"Call trans opt: received. 2-19-98 13:24:18 REC: Log>\" As a conversation takes place between Trinity (Carrie-Anne Moss) and Cypher (Joe Pantoliano), two free humans, a table of random green numbers are being scanned and individual numbers selected, creating a series of digits not unlike an ordinary phone number, as if a code is being deciphered or a call is being traced.\r\n",
            "\r\n",
            "Trinity discusses some unknown person. Cypher taunts Trinity, suggesting she enjoys watching him. Trinity counters that \"Morpheus (Laurence Fishburne) says he may be 'the One',\" just as the sound of a number being selected alerts Trinity that someone may be tracing their call. She ends the call.\r\n",
            "\r\n",
            "Armed policemen move down a darkened, decrepit hallway in the Heart O' the City Hotel, their flashlight beam bouncing just ahead of them. They come to room 303, kick down the door and find a woman dressed in black, facing away from them. It's Trinity. She brings her hands up from the laptop she's working on at their command.\r\n",
            "\r\n",
            "Outside the hotel a car drives up and three agents appear in neatly pressed black suits. They are Agent Smith (Hugo Weaving), Agent Brown (Paul Goddard), and Agent Jones (Robert Taylor). Agent Smith and the presiding police lieutenant argue. Agent Smith admonishes the policeman that they were given specific orders to contact the agents first, for their\n"
          ]
        }
      ],
      "source": [
        "print(text[:1500])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8715bcf7",
      "metadata": {
        "id": "8715bcf7"
      },
      "source": [
        "**summarize 사용하기**\n",
        "\n",
        "`Summa`의 `summarize()`에 인자로 사용되는 값들에 대해서 알아볼까요?\n",
        "\n",
        "* text (str) - 요약할 텍스트.\n",
        "* ratio (float, optional) – 요약문과 원본에서 선택되는 문장의 비율. 0~1 사이의 값.\n",
        "* words (int or None, optional) – 출력에 포함할 단어의 수.\n",
        "* 만약, ratio와 함께 두 파라미터가 모두 제공되는 경우 ratio는 무시합니다.\n",
        "* split (bool, optional) – True면 문장 list, False는 조인(join)된 문자열을 반환.\n",
        "\n",
        "`Summa`의 `summarize`는 문장 토큰화를 별도로 하지 않더라도 내부적으로 문장 토큰화를 수행합니다. 그렇기 때문에 문장 구분이 되어있지 않은 원문을 바로 입력으로 넣을 수 있어요. 비율을 적게 주어서 요약문으로 선택되는 문장의 개수를 줄여 보겠습니다. 원문의 0.005%를 출력하도록 설정해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dd9e9c7",
      "metadata": {
        "id": "7dd9e9c7",
        "outputId": "adb4776a-2e48-4557-baa2-3789cccca6f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary:\n",
            "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
            "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
          ]
        }
      ],
      "source": [
        "print('Summary:')\n",
        "print(summarize(text, ratio=0.005))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caf3996c",
      "metadata": {
        "id": "caf3996c"
      },
      "source": [
        "만약 리스트로 출력 결과를 받고 싶다면 split 인자의 값을 True로 설정하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f03e72c3",
      "metadata": {
        "id": "f03e72c3",
        "outputId": "99c74754-8fb9-45b0-d5ba-365f677662da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary:\n",
            "['Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.', 'Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.']\n"
          ]
        }
      ],
      "source": [
        "print('Summary:')\n",
        "print(summarize(text, ratio=0.005, split=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84ff092d",
      "metadata": {
        "id": "84ff092d"
      },
      "source": [
        "단어의 수로 요약문의 크기를 조절할 수 있습니다. 단어를 50개만 선택해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb3acf2c",
      "metadata": {
        "id": "fb3acf2c",
        "outputId": "c3b327df-bfb6-4d4b-e6cb-27c8b88b4334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary:\n",
            "Trinity takes Neo to Morpheus.\n",
            "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
            "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
          ]
        }
      ],
      "source": [
        "print('Summary:')\n",
        "print(summarize(text, words=50))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a61da38c",
      "metadata": {
        "id": "a61da38c"
      },
      "source": [
        "amazon_review data를 활용하여 `Extractive/Abstractive summarization` 이해하기 위해 위와 같이 단어장 크기를 줄이는 다양한 `text normalization` 적용하여 자연어 처리 작업을 실습하였고, `seq2seq` 모델의 성능을 향상시키는 `Attention Mechanism` 적용해 봤습니다."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}