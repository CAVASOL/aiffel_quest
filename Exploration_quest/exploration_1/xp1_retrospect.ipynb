{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CAVASOL/aiffel_quest/blob/main/Exploration_quest/exploration_1/xp1_retrospect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2fd6150",
      "metadata": {
        "id": "d2fd6150"
      },
      "source": [
        "## 2-1. 프로젝트: 새로운 데이터셋으로 나만의 이미지 분류기 만들어보기"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1FF7VVaqPcGw6_QijNz1XeiHM_DAAsyDQ)"
      ],
      "metadata": {
        "id": "BMe2BghtYhDv"
      },
      "id": "BMe2BghtYhDv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Details\n",
        "\n",
        "`tensorflow_datasets`의 `tf_flowers` 데이터를 사용하여 `VGG16`, `ResNet18`, `ResNet34`, `ResNet50` 모듈 별로 모델을 디자인하고, 결과를 시각화하여 확인한 후 모델 성능을 올리기 위해 다각도로 실험을 진행했습니다. 데이터 전처리 과정에서 `Autotune` 기법을 적용했고, 모델의 성능을 최적화하기 위해 Dropout()이나 Batch Normalization()과 같은 `Regularization` 기법을 적용하여 모델을 디자인하였습니다. 데이터를 학습한 후, 임의의 새로운 사진 `daisy.jpg`를 활용하여 테스트 하였습니다. 각 모델에 대한 실험 결과는 아래와 같습니다."
      ],
      "metadata": {
        "id": "C47yY-z-Fo6B"
      },
      "id": "C47yY-z-Fo6B"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result"
      ],
      "metadata": {
        "id": "L5INTaA3aCYO"
      },
      "id": "L5INTaA3aCYO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1YUE-QSZaXKMhzc4MHs1GiXeBw2l-naMI)"
      ],
      "metadata": {
        "id": "Hiez6udMY3oH"
      },
      "id": "Hiez6udMY3oH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1oZrQASqo4xhLp5TZbeDq8QL0d4MbRYLm)"
      ],
      "metadata": {
        "id": "VboNB4Had2p8"
      },
      "id": "VboNB4Had2p8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1Ejp7QsA4UF2b-VtEHqe8FRroT4sOnz3E)"
      ],
      "metadata": {
        "id": "0YvDOZAieOOD"
      },
      "id": "0YvDOZAieOOD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=182oSWbW481xL2wnx4z0dtVsbtPSOe0fa)"
      ],
      "metadata": {
        "id": "vgKxoto5fORK"
      },
      "id": "vgKxoto5fORK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1fLpD-XNEK-DfMNyQzGvTkW3izGt_H6Kt)"
      ],
      "metadata": {
        "id": "5jI2_EtnYdBM"
      },
      "id": "5jI2_EtnYdBM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1g-t1ekFeZO4hgHD4yQnu9_NCdH56H6Z0)"
      ],
      "metadata": {
        "id": "WJdukJ9ugDHK"
      },
      "id": "WJdukJ9ugDHK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrospect\n",
        "\n",
        "`tensorflow_datasets`의 `tf_flowers` 데이터를 각각의 모델에 활용하여 성능을 평가했을 때, 결과는 각각 다르게 나타났습니다. 데이터 전 처리 과정에서 데이터 증강 `Augmentation` 기법과 Dropout() 적용 시의 변화를 관찰했으나, 제가 디자인한 모델의 경우에서 탁월한 성능의 변화나 차이는 없었습니다.  옵티마이저에 따른 지표의 변화들이 다르게 나타났습니다. VGG16의 경우 Adam을 사용했을 때 결과가 우수했고, ResNet의 경우 RMSprop을 사용했을 때 학습 진행이 안정적이었습니다. ResNet34와 ResNet50 모델의 경우 학습 진행 시 Validation data의 정확도가 불안정했습니다. ResNet34의 경우, 에폭을 5로 조정하였을 때 정확도는 80% 미만이었으나 테스트 이미지를 분류하였습니다. 두 모델의 경우, 최종 결과의 정확도는 70% 이상(75에서 85사이)으로 나타났지만, 테스트에서 임의의 사진인 daisy.jpg를 분류하지 못 했습니다.  \n",
        "\n",
        "\n",
        "이번 실험에서는 데이터의 유형과 크기를 고려한 모델 디자인과 성능 최적화에 노력하였고, 결과를 나타내는 지표들의 변화들을 관찰하는 것에 집중했습니다. 모델 디자인과 데이터 학습 시 발생한 오류를 해결하기 위해 다양한 해결 방안들을 시도하였고, 그 과정이 즐거웠습니다. 다양한 방법으로 데이터를 확인하고 이해한 후, 데이터 전처리에 대해 좀 더 주의를 기울여야 겠습니다. EDA 과정에서 `K-means clustering`을 적용하여 데이터 분석에 대해 모의의 기준이나 방향을 가질 수 있다라는 것을 알게 되었고, 흥미로웠습니다. 각 모듈 별 실험에 관한 자세한 세부적인 내용은 해당 모듈 이름의 파일에서 확인하실 수 있으며, 실험 과정과 결과에 대한 비교 및 궁금했던 부분에 대해 `xp1_retrospect.ipynb` 파일에 정리하였습니다.\n"
      ],
      "metadata": {
        "id": "kNvIRm5oFtSD"
      },
      "id": "kNvIRm5oFtSD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data augmentation**\n",
        "\n",
        "```\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.2),\n",
        "])\n",
        "```\n",
        "\n",
        "```\n",
        "# Add the image to a batch.\n",
        "image = tf.cast(tf.expand_dims(image, 0), tf.float32)\n",
        "```\n",
        "\n",
        "```\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  augmented_image = data_augmentation(image)\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(augmented_image[0])\n",
        "  plt.axis(\"off\")\n",
        "```\n",
        "\n",
        "**Two options to use the Keras preprocessing layers**\n",
        "\n",
        "```\n",
        "Option 1: Make the preprocessing layers part of your model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  # Add the preprocessing layers you created earlier.\n",
        "  resize_and_rescale,\n",
        "  data_augmentation,\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  # Rest of your model.\n",
        "])\n",
        "```\n",
        "\n",
        "```\n",
        "Option 2: Apply the preprocessing layers to your dataset\n",
        "\n",
        "aug_ds = train_ds.map(\n",
        "  lambda x, y: (resize_and_rescale(x, training=True), y))\n",
        "```"
      ],
      "metadata": {
        "id": "rY-V5IE8viVp"
      },
      "id": "rY-V5IE8viVp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Can you break down how EDA and K-Means Clustering team up and work together?**\n",
        "\n",
        "Exploratory Data Analysis (EDA) and K-Means Clustering can work together to gain insights into the structure and patterns within a dataset.\n",
        "\n",
        "* `Pattern Identification`: EDA involves visually exploring and summarizing the main characteristics of a dataset. K-Means Clustering helps in identifying hidden patterns by grouping similar data points into clusters. By applying K-Means Clustering during EDA, you can uncover structure and relationships that might not be immediately apparent.\n",
        "\n",
        "* `Segmentation and Grouping`: K-Means Clustering divides the dataset into groups or clusters based on the similarity of data points. EDA, on the other hand, helps in understanding the nature of these clusters by exploring the distribution and characteristics of variables within each cluster. This segmentation can provide a more detailed view of different groups present in the data.\n",
        "\n",
        "* `Outlier Detection`: EDA often involves identifying outliers or unusual observations in the data. K-Means Clustering can be used to assign each data point to a cluster, and points that are far from the cluster centers may be considered outliers. This combined approach helps in both understanding the main structure of the data and identifying potential anomalies.\n",
        "\n",
        "* `Comparison of Clusters`: EDA facilitates the comparison of different clusters generated by K-Means. You can use various visualization techniques and statistical measures to compare the distribution of variables across clusters. This comparison helps in understanding the distinctive features of each cluster and the overall differences between them.\n",
        "\n",
        "* `Feature Extraction and Reduction`: K-Means Clustering can be used as a tool for feature extraction during EDA. The centroids of clusters represent the \"average\" behavior within each cluster. This information can be used to reduce the dimensionality of the data, focusing on the most important features that characterize each cluster.\n",
        "\n",
        "* `Insights for Decision Making`: The combination of EDA and K-Means Clustering provides a more holistic understanding of the dataset. This can lead to actionable insights for decision-making, such as targeted marketing strategies, product improvements, or customer segmentation."
      ],
      "metadata": {
        "id": "3_ZeGHYgZ21R"
      },
      "id": "3_ZeGHYgZ21R"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Processing exploratory data analysis (EDA) with image data using K-Means Clustering involves several steps.**\n",
        "\n",
        "a. `Data Preparation`: Collect and preprocess the image data. This may involve resizing images to a consistent resolution, converting them to grayscale or RGB, and flattening them into feature vectors.\n",
        "\n",
        "b. `Flattening Images`: For each image, flatten the pixel values into a one-dimensional array. This converts the 2D or 3D image data into a format suitable for clustering algorithms like K-Means, which operate on flat feature vectors.\n",
        "\n",
        "c. `Feature Scaling`: Normalize or standardize the feature vectors. This ensures that each feature contributes proportionally to the distance calculations during clustering.\n",
        "\n",
        "d. `Applying K-Means Clustering`: Use the K-Means clustering algorithm on the flattened and scaled feature vectors. Specify the number of clusters (K) based on your understanding of the data or through methods like the elbow method.\n",
        "\n",
        "e. `Cluster Assignment`: Assign each image to the cluster to which its feature vector is closest. This grouping helps identify similar patterns or structures in the image data.\n",
        "\n",
        "f. `Visualizing Clusters`: Visualize the clusters to gain insights. This could involve displaying representative images from each cluster or creating visualizations that highlight the differences between clusters. For instance, you might visualize the cluster centroids as \"average\" images.\n",
        "\n",
        "g. `Interpreting Results`: Analyze the characteristics of each cluster. Identify what types of images are grouped together and what distinguishes one cluster from another. This step is crucial for extracting meaningful insights from the clustering results.\n",
        "\n",
        "h. `Adjusting Parameters`: Fine-tune the parameters of the K-Means algorithm if needed. Experiment with different values of K or try alternative clustering algorithms to see how they affect the results.\n",
        "\n",
        "i. `Iterative Exploration`: EDA is often an iterative process. Based on the insights gained from the initial clustering, you might refine your preprocessing steps, adjust clustering parameters, or incorporate additional features for a more comprehensive analysis.\n",
        "\n",
        "j. `Drawing Conclusions`: Use the results of the clustering analysis to draw conclusions about the underlying patterns in your image data. This could inform further analysis, such as targeted image processing techniques, feature engineering, or the development of image classification models.\n",
        "\n",
        "Remember that `the success of the clustering analysis depends on the quality of your feature representation and the appropriateness of the chosen clustering algorithm`. `Experimentation and visual inspection of results are key components of the process`."
      ],
      "metadata": {
        "id": "Hg3QsIC9ax_F"
      },
      "id": "Hg3QsIC9ax_F"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reference\n",
        "\n",
        "* [Load and preprocess images](https://www.tensorflow.org/tutorials/load_data/images)\n",
        "* [Image classification](https://www.tensorflow.org/tutorials/images/classification)\n",
        "* [Data augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation)\n",
        "* [TensorFlow model optimization](https://www.tensorflow.org/model_optimization/guide)\n",
        "* [Weight clustering in Keras example](https://www.tensorflow.org/model_optimization/guide/clustering/clustering_example)\n",
        "* [In-depth EDA and K-Means Clustering](https://www.kaggle.com/code/thebrownviking20/in-depth-eda-and-k-means-clustering)\n",
        "* [Clustering and Analysis using EDA and K Means](https://www.kaggle.com/code/ham9615/clustering-and-analysis-using-eda-and-k-means)\n",
        "* [Python for Data Science: Implementing Exploratory Data Analysis (EDA) and K-Means Clustering](https://medium.com/@aziszamcalvin/python-for-data-science-implementing-exploratory-data-analysis-eda-and-k-means-clustering-bcf1d24adc12)"
      ],
      "metadata": {
        "id": "59IRa95bFvyR"
      },
      "id": "59IRa95bFvyR"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}